{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.width\", 1500)\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\", index_col=\"PassengerId\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\", index_col=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_full = train_data[\"Survived\"]\n",
    "X_train_full = train_data.drop(\"Survived\", axis=1).copy()\n",
    "\n",
    "X_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_full, Y_train_full, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define pre-processing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "import re\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "name_transformer = Pipeline(steps=[\n",
    "    (\"convert_to_title\", FunctionTransformer(lambda df: df.applymap(\n",
    "            lambda name: re.search(\", ([\\w ]+).\", name).group(1)\n",
    "    ))),\n",
    "    (\"rare_to_others\", FunctionTransformer(lambda df: df.applymap(\n",
    "        lambda title: title if title in [\"Mr\", \"Mrs\", \"Miss\", \"Master\"] else \"Others\"\n",
    "    ))),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "fare_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"log\", FunctionTransformer(np.log1p))\n",
    "])\n",
    "\n",
    "family_transformer = FunctionTransformer(lambda df: df.sum(axis=1).to_frame())\n",
    "\n",
    "remember_missing_transformer = FunctionTransformer(lambda df: df.apply(lambda col: np.where(col.isnull(), 1, 0)))\n",
    "\n",
    "# A custom transformer for age group-mean, so that mean is from train set always (the one fitted to).\n",
    "class GroupbyMeanTransformer(TransformerMixin):\n",
    "    def __init__(self, group_by_labels, target_label):\n",
    "        self.group_by_labels = group_by_labels\n",
    "        self.target_label = target_label\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.group_mean = self._get_grouped(X).mean()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self._get_grouped(X).transform(lambda x: x.fillna(self.group_mean[x.name])).to_frame()\n",
    "    \n",
    "    def _get_grouped(self, X):\n",
    "        return X.groupby(self.group_by_labels)[self.target_label]\n",
    "\n",
    "\n",
    "age_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", GroupbyMeanTransformer(group_by_labels=\"Pclass Sex\".split(), target_label=\"Age\")),\n",
    "    (\"bin\", FunctionTransformer(lambda df: pd.cut(df.Age, bins=[0, 16, 30, 50, 80], labels=False).to_frame() + 1))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"keep\", FunctionTransformer(), [\"Pclass\"]),\n",
    "        (\"onehot\", categorical_transformer, \"Sex Embarked\".split()),\n",
    "        (\"name\", name_transformer, [\"Name\"]),\n",
    "        (\"fare\", fare_transformer, [\"Fare\"]),\n",
    "        (\"family\", family_transformer, [\"Parch\", \"SibSp\"]),\n",
    "        (\"missing\", remember_missing_transformer, [\"Age\"]),\n",
    "        (\"age\", age_transformer, [\"Age\", \"Pclass\", \"Sex\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessed_column_names = [\"Pclass\"] + sorted(\"Female Male\".split()) + sorted(\"C Q S\".split()) + sorted(\"Master Miss Mr Mrs Others\".split()) + [\"Fare\", \"Family\"] + sorted(\"Age_Missing\".split()) + [\"Age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processed data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The preprocessor is fitted to train data, and used to valid/test data, and is not fitted to valid/test.\n",
    "# This avoids cross-contamination of information from valid/test into train data.\n",
    "X_train_preproc = preprocessor.fit_transform(X_train)\n",
    "X_valid_preproc = preprocessor.transform(X_valid)\n",
    "X_test_preproc = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             Pclass  Female  Male    C    Q    S  Master  Miss   Mr  Mrs  Others      Fare  Family  Age_Missing  Age\nPassengerId                                                                                                         \n332             1.0     0.0   1.0  0.0  0.0  1.0     0.0   0.0  1.0  0.0     0.0  3.384390     0.0          0.0  3.0\n734             2.0     0.0   1.0  0.0  0.0  1.0     0.0   0.0  1.0  0.0     0.0  2.639057     0.0          0.0  2.0\n383             3.0     0.0   1.0  0.0  0.0  1.0     0.0   0.0  1.0  0.0     0.0  2.188856     0.0          0.0  3.0\n705             3.0     0.0   1.0  0.0  0.0  1.0     0.0   0.0  1.0  0.0     0.0  2.180892     1.0          0.0  2.0\n814             3.0     1.0   0.0  0.0  0.0  1.0     0.0   1.0  0.0  0.0     0.0  3.474293     6.0          0.0  1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Female</th>\n      <th>Male</th>\n      <th>C</th>\n      <th>Q</th>\n      <th>S</th>\n      <th>Master</th>\n      <th>Miss</th>\n      <th>Mr</th>\n      <th>Mrs</th>\n      <th>Others</th>\n      <th>Fare</th>\n      <th>Family</th>\n      <th>Age_Missing</th>\n      <th>Age</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>332</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.384390</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>734</th>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.639057</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>383</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.188856</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>705</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.180892</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>814</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.474293</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "pd.DataFrame(X_train_preproc, index=X_train.index, columns=preprocessed_column_names).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model and the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def fit_model(model, X, y, **fit_kwargs):\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    pipeline.fit(X, y, **fit_kwargs)\n",
    "    return pipeline\n",
    "\n",
    "def score_model(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    score = accuracy_score(y, y_pred)\n",
    "    print(\"Accuracy:\", score)\n",
    "    return score\n",
    "\n",
    "def score_cross_val(model, X, y):\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "    print(\"Scores:\", scores)\n",
    "    score = scores.mean()\n",
    "    print(\"Avg score:\", score)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.8435754189944135\n"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def get_random_forest_model(X_train, Y_train, X_valid, Y_valid, n_estimators=100):\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    model = fit_model(model, X_train, Y_train)\n",
    "    score = score_model(model, X_valid, Y_valid)\n",
    "    return model, score\n",
    "\n",
    "rf_model, _ = get_random_forest_model(X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Scores: [0.79888268 0.79213483 0.83707865 0.7752809  0.81460674]\nAvg score: 0.8035967610319503\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8035967610319503"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "score_cross_val(rf_model, X_train_full, Y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.8491620111731844\n"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def get_xgb_model(X_train, Y_train, X_valid, Y_valid, n_estimators=1000, learning_rate=0.05):\n",
    "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, n_jobs=4)\n",
    "    model = fit_model(model, X_train, Y_train, model__early_stopping_rounds=5, model__eval_set=[(X_valid_preproc, Y_valid)], model__verbose=False)\n",
    "    score = score_model(model, X_valid, Y_valid)\n",
    "    return model, score\n",
    "\n",
    "xgb_model, _ = get_xgb_model(X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Scores: [0.80446927 0.79775281 0.85393258 0.81460674 0.84831461]\nAvg score: 0.8238152030632101\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8238152030632101"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "score_cross_val(xgb_model, X_train_full, Y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_predictions(model, submission_name):\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    print(f\"{submission_name}:\\n{predictions[:100]}...\")\n",
    "    \n",
    "    output = pd.DataFrame({\"Survived\": predictions}, index=test_data.index)\n",
    "    output.to_csv(f\"/kaggle/working/{submission_name}_submission.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "rf:\n[0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0\n 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0]...\nxgb:\n[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0\n 0 0 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0\n 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0]...\n"
    }
   ],
   "source": [
    "store_predictions(rf_model, \"rf\")\n",
    "store_predictions(xgb_model, \"xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit26036f9dd6fd4360b35d7bd99f8e1f11",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}