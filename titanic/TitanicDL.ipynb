{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\r\n",
      "  Downloading pip-20.1.1-py2.py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 4.9 MB/s \r\n",
      "\u001b[?25hInstalling collected packages: pip\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 20.1\r\n",
      "    Uninstalling pip-20.1:\r\n",
      "      Successfully uninstalled pip-20.1\r\n",
      "Successfully installed pip-20.1.1\r\n",
      "Collecting keras-tuner\r\n",
      "  Downloading keras-tuner-1.0.1.tar.gz (54 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 54 kB 1.3 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (1.18.1)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.8.7)\r\n",
      "Collecting terminaltables\r\n",
      "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (4.45.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (2.23.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (1.4.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.22.2.post1)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (1.24.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (2020.4.5.1)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (2.9)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (3.0.4)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->keras-tuner) (0.14.1)\r\n",
      "Building wheels for collected packages: keras-tuner, terminaltables\r\n",
      "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-py3-none-any.whl size=73198 sha256=baa728208c437d750c8eaf966a174362c64639e4605bbadd09e5a491419986b5\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/cf/2f/1a1749d3a3650fac3305a8d7f9237b6de7c41068e2f8520ca2\r\n",
      "  Building wheel for terminaltables (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=897892b5c4f58c6c7915fe2beb29d07f56574ee6b29b2e6b03db51e84aadeda1\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\r\n",
      "Successfully built keras-tuner terminaltables\r\n",
      "Installing collected packages: terminaltables, keras-tuner\r\n",
      "Successfully installed keras-tuner-1.0.1 terminaltables-3.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define seed to reprodicibility of random generation\n",
    "SEED = 42\n",
    "\n",
    "DEV_SPLIT=0.2\n",
    "\n",
    "# MODE = \"DEV\"\n",
    "MODE = \"EVAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print(physical_devices)\n",
    "for device in (physical_devices or []):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Data observations\n",
    "*Have NaNs:* Age, Fare (some zeros, nans too), Cabin, Embarked\n",
    "*NOTE:* maybe need to approximate missing values using some other technique, like an additional model?\n",
    "\n",
    "* (+) Pclass:\n",
    "  * 1 - 3 number, 1 being the highest\n",
    "  * Range: 1-3\n",
    "  * Current approach: convert to one-hot.\n",
    "  * Previous approaches:\n",
    "      * normalize by 3.\n",
    "* (+) Name:\n",
    "  * has person's title, which could be used (Mr, Ms, Mrs, etc.)\n",
    "  * From title, can infer marital status?\n",
    "  * Current approach: extract titles, replace infrequent ones with \"Others\", convert them to one-hot, and calculate 'Married' based on title (1 - married (Mr, Mrs), -1 - unmarried (Miss, Master), 0 - unknown (other titles))\n",
    "  * Potential improvements: use more titles for getting 'married'; use 'maiden name' in calculation of 'married'; use 'nickname' somehow?\n",
    "* (+) Sex:\n",
    "  * Either male or female\n",
    "  * male: 65%, female: 35%\n",
    "  * Current approach: convert to one-hot.\n",
    "  * Potential improvements: use 1 and -1 for sexes?\n",
    "* (+) Age:\n",
    "  * has fractions if approximated. Has missing values.\n",
    "  * Range: 0.42-80\n",
    "  * Current approach: fill NaN with average in group-by Pclass-Sex, but create a column that identifies missing values. Also, normalize by 80.\n",
    "  * Potential improvements: have a better approximation of age. Convert to age categories?\n",
    "* (+) SibSp:\n",
    "  * how many siblings or spouses on board.\n",
    "  * Range: 0-8\n",
    "  * Current approach: Add to 'Family'.\n",
    "  * Previous approaches:\n",
    "    * normalize by 8.\n",
    "* (+) Parch:\n",
    "  * How many parents/children. (can be 0 for babies, if with nannies)\n",
    "  * Range: 0-6\n",
    "  * Current approach: Add to 'Family'\n",
    "  * Previous approachesL\n",
    "    * normalize by 6.\n",
    "* Ticket:\n",
    "  * A number with some optional letters (which can have some meaning?).\n",
    "  * Has repetitions (maybe for people travelling together).\n",
    "* (+) Fare:\n",
    "  * can have zeros (what do they mean?). Can have omitted (just one in test).\n",
    "  * Range: 0-512.3292\n",
    "  * Current approach: fill nan with mean, normalize by 512.\n",
    "  * Potential improvements: most fare is <= 30 USD, so maybe use fare categories.\n",
    "* (+) Cabin:\n",
    "  * has a lot of omitted values (78%). Can have multiple values (probably for families?).\n",
    "  * One value is a letter with a number. (both probably have meaning and impact?)\n",
    "  * Current approach: convert to one-hot (based on letter), include a 'nan' column for those that are missing values. Create a column for cabin number, and a column to identify missing numbers.\n",
    "  * Potential improvements: maybe cabin number itself doesn't mean much? Also, maybe need to deal with missing values in a different way? Also, maybe deal with multiple values better?\n",
    "* (+) Embarked:\n",
    "  * Either of 3 letters (with different frequency). Has just a few omitted.\n",
    "  * S - 72/65%, C - 19/24%, Q - 9/11%\n",
    "  * Current approach: convert to one-hot matrix (fill 2 missing with mode)\n",
    "  * Potential improvements: somehow take into the account different distribution of embarkation city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(csv_data):\n",
    "    # To display all the columns from left to right without breaking into next line.\n",
    "    pd.set_option('display.width', 1500)\n",
    "\n",
    "    import re\n",
    "    \n",
    "    features = \"Pclass Sex SibSp Parch Fare Embarked Name Cabin Age\".split()\n",
    "    \n",
    "    titles = ['Mr', 'Mrs', 'Miss', 'Master', 'Ms', 'Don', 'Rev', 'Dr', 'Mme', 'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess', 'Jonkheer', 'Dona']\n",
    "    \n",
    "    # === Get X - the features. ===\n",
    "\n",
    "    X = csv_data[features].copy()\n",
    "\n",
    "    # == Post-process data ==\n",
    "\n",
    "#     if \"SibSp\" in X:\n",
    "#         X.SibSp = X.SibSp.divide(8)\n",
    "\n",
    "#     if \"Parch\" in X:\n",
    "#         X.Parch = X.Parch.divide(6)\n",
    "        \n",
    "    if \"Parch\" in X and \"SibSp\" in X:\n",
    "        X[\"Family\"] = X.Parch + X.SibSp\n",
    "#         X.Family = X.Family.divide(14)\n",
    "        X = X.drop(columns=\"Parch SibSp\".split())\n",
    "\n",
    "    if \"Fare\" in X:\n",
    "        # Since only a few would miss 'fare' value, it's okay to fill with average.\n",
    "        X.Fare = X.Fare.fillna(X.Fare.mean())\n",
    "        \n",
    "        X.Fare = np.where(X.Fare < 50, 1, 2)\n",
    "        \n",
    "#         X.Fare = X.Fare.divide(512)\n",
    "\n",
    "    if \"Embarked\" in X:\n",
    "        X.Embarked = X.Embarked.fillna(X.Embarked.mode()[0])\n",
    "        X.Embarked = X.Embarked.astype(pd.api.types.CategoricalDtype(categories=\"C Q S\".split()))\n",
    "        X = pd.get_dummies(X, columns=[\"Embarked\"])\n",
    "\n",
    "    if \"Name\" in X:\n",
    "        X[\"Title\"] = X.Name.apply(lambda name: re.search(\", ([\\w ]+).\", name).group(1))\n",
    "\n",
    "        # Try to see if the person is married (1), or not (-1), or unknown (0).\n",
    "        X[\"Married\"] = X.Title.apply(lambda title: 1 if title in \"Mrs Mr\".split() else -1 if title in \"Miss Master\".split() else 0)\n",
    "\n",
    "        # Get dummies for title\n",
    "        \n",
    "        # Include all possible values, even those not present in current dataset.\n",
    "#         X.Title = X.Title.astype(pd.api.types.CategoricalDtype(categories=titles))\n",
    "        \n",
    "        # Titles that are rare are converted to 'Others'\n",
    "        important_titles = ['Mr', 'Mrs', 'Miss', 'Master']\n",
    "        X.Title = X.Title.apply(lambda title: title if title in important_titles else \"Others\")\n",
    "        \n",
    "        X = pd.get_dummies(X, columns=[\"Title\"])\n",
    "        \n",
    "        # We don't need the name itself.\n",
    "        X = X.drop(columns=[\"Name\"])\n",
    "        \n",
    "    if \"Cabin\" in X:\n",
    "        X[\"Cabin_Missing\"] = np.where(X.Cabin.isnull(), 1, 0)\n",
    "        X.Cabin = X.Cabin.fillna(\"-\")\n",
    "        \n",
    "#         X[\"Cabin_Number\"] = X.Cabin.apply(lambda cabin: int(re.search(\"\\w(\\d+)\", cabin).group(1)) if len(cabin) > 1 else 0)\n",
    "#         # Do some sort of normalization.\n",
    "#         X.Cabin_Number = X.Cabin_Number.divide(200)\n",
    "#         X[\"Cabin_Number_Missing\"] = np.where(X.Cabin_Number == 0, 1, 0)\n",
    "        \n",
    "        X.Cabin = X.Cabin.apply(lambda cabin: cabin[:1])\n",
    "        \n",
    "        # Convert to one-hot\n",
    "#         X.Cabin = X.Cabin.astype(pd.api.types.CategoricalDtype(categories=list(\"ABCDEFGT\")))\n",
    "#         X = pd.get_dummies(X, columns=[\"Cabin\"], dummy_na=True)\n",
    "\n",
    "        # Convert to numbers with T beeing the lowest deck and S - the highest (sun deck).\n",
    "        X[\"Deck_Level\"] = X.Cabin.apply(lambda cabin: \"SABCDEFGT\".find(cabin[0]))\n",
    "        X = X.drop(columns=[\"Cabin\"])\n",
    "\n",
    "    if \"Age\" in X:\n",
    "        X[\"Age_Missing\"] = np.where(X.Age.isnull(), 1, 0)\n",
    "\n",
    "        # No need to skip 'nan' for Age when calculating mean, as Pandas does that automatically.\n",
    "        # 'transform' will go through each group, and fill its nan values with its mean value.\n",
    "        # Then, all that will be aggregated back into the column, thus replacing nan values with group's mean.\n",
    "        X[\"Age\"] = X.groupby(\"Pclass Sex\".split())[\"Age\"].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "#         X.Age = X.Age.divide(80)\n",
    "\n",
    "        # Convert age to categories 1 - child, 2 - young, 3 - older, 4 - senile\n",
    "        X.Age = pd.cut(X.Age, bins=[0, 16, 30, 50, 80], labels=False) + 1\n",
    "        \n",
    "    # Needs to be after 'Age', since age is using original Sex column.\n",
    "    if \"Sex\" in X:\n",
    "        X.Sex = X.Sex.astype(pd.api.types.CategoricalDtype(categories=\"male female\".split()))\n",
    "        X = pd.get_dummies(X, columns=[\"Sex\"])\n",
    "\n",
    "    if \"Pclass\" in X:\n",
    "        X = pd.get_dummies(X, columns=[\"Pclass\"])\n",
    "        # Do not normalize small numbers\n",
    "#         X.Pclass = X.Pclass.divide(3)\n",
    "    \n",
    "    # === Get Y - the result values. ===\n",
    "    Y = csv_data.get(\"Survived\")\n",
    "    \n",
    "    print(X.head(5))\n",
    "    print(None if Y is None else Y.head(5))\n",
    "    \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "   Fare  Age  Family  Embarked_C  Embarked_Q  Embarked_S  Married  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Others  Cabin_Missing  Deck_Level  Age_Missing  Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3\n",
      "0     1    2       1           0           0           1        1             0           0         1          0             0              1          -1            0         1           0         0         0         1\n",
      "1     2    3       1           1           0           0        1             0           0         0          1             0              0           3            0         0           1         1         0         0\n",
      "2     1    2       0           0           0           1       -1             0           1         0          0             0              1          -1            0         0           1         0         0         1\n",
      "3     2    3       1           0           0           1        1             0           0         0          1             0              0           3            0         0           1         1         0         0\n",
      "4     1    3       0           0           0           1        1             0           0         1          0             0              1          -1            0         1           0         0         0         1\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\")\n",
    "train_data_X, train_data_Y = prepare_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data:\n",
      "   Fare  Age  Family  Embarked_C  Embarked_Q  Embarked_S  Married  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Others  Cabin_Missing  Deck_Level  Age_Missing  Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3\n",
      "0     1    3       0           0           1           0        1             0           0         1          0             0              1          -1            0         1           0         0         0         1\n",
      "1     1    3       1           0           0           1        1             0           0         0          1             0              1          -1            0         0           1         0         0         1\n",
      "2     1    4       0           0           1           0        1             0           0         1          0             0              1          -1            0         1           0         0         1         0\n",
      "3     1    2       0           0           0           1        1             0           0         1          0             0              1          -1            0         1           0         0         0         1\n",
      "4     1    2       2           0           0           1        1             0           0         0          1             0              1          -1            0         0           1         0         0         1\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Test data:\")\n",
    "test_data_X, _ = prepare_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 20) (712, 1)\n",
      "(179, 20) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# if MODE == \"DEV\":\n",
    "train_X, dev_X, train_Y, dev_Y = train_test_split(train_data_X, train_data_Y, test_size=DEV_SPLIT, random_state=SEED)\n",
    "\n",
    "train_Y = train_Y.reshape((-1, 1))\n",
    "dev_Y = dev_Y.reshape((-1, 1))\n",
    "\n",
    "print(train_X.shape, train_Y.shape)\n",
    "print(dev_X.shape, dev_Y.shape)\n",
    "# else:\n",
    "#     train_X, train_Y = train_data_X, train_data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_size):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(128, input_shape=(input_size,), activation=\"relu\", kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation=\"relu\", kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),\n",
    "        Dense(20, activation=\"relu\", kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.25),\n",
    "        Dense(6, activation=\"tanh\", kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(6e-3), metrics=[\"accuracy\"], loss=\"binary_crossentropy\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(train_X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 2s 2ms/sample - loss: 1.3979 - accuracy: 0.6896 - val_loss: 0.9665 - val_accuracy: 0.8101\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.8874 - accuracy: 0.8020 - val_loss: 0.7117 - val_accuracy: 0.8156\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7044 - accuracy: 0.7935 - val_loss: 0.6350 - val_accuracy: 0.8045\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6326 - accuracy: 0.8132 - val_loss: 0.5700 - val_accuracy: 0.8212\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5838 - accuracy: 0.8160 - val_loss: 0.5524 - val_accuracy: 0.7933\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5638 - accuracy: 0.8202 - val_loss: 0.5292 - val_accuracy: 0.8380\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5619 - accuracy: 0.8132 - val_loss: 0.5257 - val_accuracy: 0.8212\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5511 - accuracy: 0.8118 - val_loss: 0.5166 - val_accuracy: 0.8156\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.5358 - accuracy: 0.8272 - val_loss: 0.5302 - val_accuracy: 0.8212\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5253 - accuracy: 0.8216 - val_loss: 0.5073 - val_accuracy: 0.8212\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5245 - accuracy: 0.8315 - val_loss: 0.5318 - val_accuracy: 0.8212\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5064 - accuracy: 0.8385 - val_loss: 0.5710 - val_accuracy: 0.7877\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5245 - accuracy: 0.8104 - val_loss: 0.5136 - val_accuracy: 0.8045\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5105 - accuracy: 0.8216 - val_loss: 0.5090 - val_accuracy: 0.8268\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5222 - accuracy: 0.8287 - val_loss: 0.5600 - val_accuracy: 0.7877\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5257 - accuracy: 0.8076 - val_loss: 0.5039 - val_accuracy: 0.8101\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5288 - accuracy: 0.8090 - val_loss: 0.5077 - val_accuracy: 0.7877\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5137 - accuracy: 0.8357 - val_loss: 0.4893 - val_accuracy: 0.8268\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5110 - accuracy: 0.8118 - val_loss: 0.5172 - val_accuracy: 0.8101\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4970 - accuracy: 0.8244 - val_loss: 0.5393 - val_accuracy: 0.7989\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5275 - accuracy: 0.8301 - val_loss: 0.4923 - val_accuracy: 0.8268\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4932 - accuracy: 0.8329 - val_loss: 0.5027 - val_accuracy: 0.8101\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4937 - accuracy: 0.8188 - val_loss: 0.4948 - val_accuracy: 0.8212\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4847 - accuracy: 0.8244 - val_loss: 0.5120 - val_accuracy: 0.8156\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5035 - accuracy: 0.8216 - val_loss: 0.4928 - val_accuracy: 0.8268\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5182 - accuracy: 0.8329 - val_loss: 0.5187 - val_accuracy: 0.7877\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5333 - accuracy: 0.8090 - val_loss: 0.5001 - val_accuracy: 0.8268\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4903 - accuracy: 0.8329 - val_loss: 0.5225 - val_accuracy: 0.7989\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5032 - accuracy: 0.8272 - val_loss: 0.5232 - val_accuracy: 0.8212\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5139 - accuracy: 0.8118 - val_loss: 0.4979 - val_accuracy: 0.8268\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5143 - accuracy: 0.8230 - val_loss: 0.4833 - val_accuracy: 0.8380\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5177 - accuracy: 0.8104 - val_loss: 0.5170 - val_accuracy: 0.7933\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5256 - accuracy: 0.8076 - val_loss: 0.4993 - val_accuracy: 0.8380\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4992 - accuracy: 0.8272 - val_loss: 0.5112 - val_accuracy: 0.8156\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5105 - accuracy: 0.8034 - val_loss: 0.5080 - val_accuracy: 0.8268\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5114 - accuracy: 0.8188 - val_loss: 0.5223 - val_accuracy: 0.8212\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5002 - accuracy: 0.8174 - val_loss: 0.5075 - val_accuracy: 0.8212\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5107 - accuracy: 0.8118 - val_loss: 0.4953 - val_accuracy: 0.8101\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5138 - accuracy: 0.8188 - val_loss: 0.4881 - val_accuracy: 0.8212\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5091 - accuracy: 0.8146 - val_loss: 0.4993 - val_accuracy: 0.8101\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4916 - accuracy: 0.8244 - val_loss: 0.4986 - val_accuracy: 0.7877\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5074 - accuracy: 0.8343 - val_loss: 0.4955 - val_accuracy: 0.8324\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5134 - accuracy: 0.8216 - val_loss: 0.4947 - val_accuracy: 0.8212\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4824 - accuracy: 0.8216 - val_loss: 0.4876 - val_accuracy: 0.8268\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4998 - accuracy: 0.8258 - val_loss: 0.5420 - val_accuracy: 0.7989\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5074 - accuracy: 0.8202 - val_loss: 0.5009 - val_accuracy: 0.8045\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5011 - accuracy: 0.8230 - val_loss: 0.4976 - val_accuracy: 0.7765\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4815 - accuracy: 0.8216 - val_loss: 0.5248 - val_accuracy: 0.8212\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4959 - accuracy: 0.8160 - val_loss: 0.5374 - val_accuracy: 0.7709\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5015 - accuracy: 0.8118 - val_loss: 0.5418 - val_accuracy: 0.7933\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5049 - accuracy: 0.8160 - val_loss: 0.5023 - val_accuracy: 0.8212\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4995 - accuracy: 0.8188 - val_loss: 0.5479 - val_accuracy: 0.8045\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5140 - accuracy: 0.8076 - val_loss: 0.4896 - val_accuracy: 0.8045\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4992 - accuracy: 0.8132 - val_loss: 0.5283 - val_accuracy: 0.7933\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5036 - accuracy: 0.8174 - val_loss: 0.4854 - val_accuracy: 0.8324\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4925 - accuracy: 0.8146 - val_loss: 0.4980 - val_accuracy: 0.8156\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5035 - accuracy: 0.8076 - val_loss: 0.5025 - val_accuracy: 0.8268\n",
      "Epoch 58/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4936 - accuracy: 0.8202 - val_loss: 0.4949 - val_accuracy: 0.8268\n",
      "Epoch 59/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4738 - accuracy: 0.8258 - val_loss: 0.5079 - val_accuracy: 0.7654\n",
      "Epoch 60/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4958 - accuracy: 0.8076 - val_loss: 0.4965 - val_accuracy: 0.8212\n",
      "Epoch 61/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4933 - accuracy: 0.8230 - val_loss: 0.4950 - val_accuracy: 0.8101\n",
      "Epoch 62/500\n",
      "712/712 [==============================] - 0s 199us/sample - loss: 0.5010 - accuracy: 0.8090 - val_loss: 0.4942 - val_accuracy: 0.8212\n",
      "Epoch 63/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5053 - accuracy: 0.8301 - val_loss: 0.5048 - val_accuracy: 0.8101\n",
      "Epoch 64/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4902 - accuracy: 0.8244 - val_loss: 0.4923 - val_accuracy: 0.7933\n",
      "Epoch 65/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.5033 - accuracy: 0.8188 - val_loss: 0.5166 - val_accuracy: 0.8212\n",
      "Epoch 66/500\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.5032 - accuracy: 0.8315 - val_loss: 0.5139 - val_accuracy: 0.8268\n",
      "Epoch 67/500\n",
      "712/712 [==============================] - 0s 217us/sample - loss: 0.4870 - accuracy: 0.8230 - val_loss: 0.4973 - val_accuracy: 0.8156\n",
      "Epoch 68/500\n",
      "712/712 [==============================] - 0s 211us/sample - loss: 0.5224 - accuracy: 0.8104 - val_loss: 0.4985 - val_accuracy: 0.8101\n",
      "Epoch 69/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4855 - accuracy: 0.8272 - val_loss: 0.4914 - val_accuracy: 0.8324\n",
      "Epoch 70/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4828 - accuracy: 0.8202 - val_loss: 0.5128 - val_accuracy: 0.8156\n",
      "Epoch 71/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4873 - accuracy: 0.8188 - val_loss: 0.5086 - val_accuracy: 0.8212\n",
      "Epoch 72/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4883 - accuracy: 0.8258 - val_loss: 0.4971 - val_accuracy: 0.8156\n",
      "Epoch 73/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4918 - accuracy: 0.8272 - val_loss: 0.5143 - val_accuracy: 0.8212\n",
      "Epoch 74/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5212 - accuracy: 0.8132 - val_loss: 0.4862 - val_accuracy: 0.8212\n",
      "Epoch 75/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5028 - accuracy: 0.8230 - val_loss: 0.4889 - val_accuracy: 0.7821\n",
      "Epoch 76/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5063 - accuracy: 0.8132 - val_loss: 0.5205 - val_accuracy: 0.7765\n",
      "Epoch 77/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5227 - accuracy: 0.8216 - val_loss: 0.4918 - val_accuracy: 0.8268\n",
      "Epoch 78/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5022 - accuracy: 0.8343 - val_loss: 0.4928 - val_accuracy: 0.8324\n",
      "Epoch 79/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4993 - accuracy: 0.8343 - val_loss: 0.5179 - val_accuracy: 0.8156\n",
      "Epoch 80/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5190 - accuracy: 0.8146 - val_loss: 0.4794 - val_accuracy: 0.8380\n",
      "Epoch 81/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4900 - accuracy: 0.8258 - val_loss: 0.4993 - val_accuracy: 0.7821\n",
      "Epoch 82/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4706 - accuracy: 0.8287 - val_loss: 0.5039 - val_accuracy: 0.8212\n",
      "Epoch 83/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5033 - accuracy: 0.8216 - val_loss: 0.4762 - val_accuracy: 0.8212\n",
      "Epoch 84/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4988 - accuracy: 0.8230 - val_loss: 0.5013 - val_accuracy: 0.8156\n",
      "Epoch 85/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5086 - accuracy: 0.8230 - val_loss: 0.4945 - val_accuracy: 0.8268\n",
      "Epoch 86/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5126 - accuracy: 0.8160 - val_loss: 0.4958 - val_accuracy: 0.8101\n",
      "Epoch 87/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4775 - accuracy: 0.8343 - val_loss: 0.4987 - val_accuracy: 0.8212\n",
      "Epoch 88/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4965 - accuracy: 0.8202 - val_loss: 0.4898 - val_accuracy: 0.8324\n",
      "Epoch 89/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5037 - accuracy: 0.8132 - val_loss: 0.5311 - val_accuracy: 0.7542\n",
      "Epoch 90/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4839 - accuracy: 0.8371 - val_loss: 0.5794 - val_accuracy: 0.7877\n",
      "Epoch 91/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5158 - accuracy: 0.8244 - val_loss: 0.4761 - val_accuracy: 0.8324\n",
      "Epoch 92/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4786 - accuracy: 0.8188 - val_loss: 0.4957 - val_accuracy: 0.8324\n",
      "Epoch 93/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4796 - accuracy: 0.8216 - val_loss: 0.5289 - val_accuracy: 0.7989\n",
      "Epoch 94/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4980 - accuracy: 0.8230 - val_loss: 0.4955 - val_accuracy: 0.8268\n",
      "Epoch 95/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4935 - accuracy: 0.8202 - val_loss: 0.4913 - val_accuracy: 0.8268\n",
      "Epoch 96/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5040 - accuracy: 0.8160 - val_loss: 0.4897 - val_accuracy: 0.8324\n",
      "Epoch 97/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5295 - accuracy: 0.8118 - val_loss: 0.4999 - val_accuracy: 0.8212\n",
      "Epoch 98/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4855 - accuracy: 0.8216 - val_loss: 0.5082 - val_accuracy: 0.8156\n",
      "Epoch 99/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4813 - accuracy: 0.8174 - val_loss: 0.5039 - val_accuracy: 0.8268\n",
      "Epoch 100/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4863 - accuracy: 0.8244 - val_loss: 0.5000 - val_accuracy: 0.8324\n",
      "Epoch 101/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4726 - accuracy: 0.8399 - val_loss: 0.5098 - val_accuracy: 0.7933\n",
      "Epoch 102/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4988 - accuracy: 0.8048 - val_loss: 0.5054 - val_accuracy: 0.8101\n",
      "Epoch 103/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5054 - accuracy: 0.8216 - val_loss: 0.4896 - val_accuracy: 0.8268\n",
      "Epoch 104/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4803 - accuracy: 0.8272 - val_loss: 0.4955 - val_accuracy: 0.8101\n",
      "Epoch 105/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4810 - accuracy: 0.8272 - val_loss: 0.4897 - val_accuracy: 0.8268\n",
      "Epoch 106/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4744 - accuracy: 0.8146 - val_loss: 0.5188 - val_accuracy: 0.8045\n",
      "Epoch 107/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4795 - accuracy: 0.8329 - val_loss: 0.4907 - val_accuracy: 0.8212\n",
      "Epoch 108/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4996 - accuracy: 0.8132 - val_loss: 0.4840 - val_accuracy: 0.8324\n",
      "Epoch 109/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4829 - accuracy: 0.8272 - val_loss: 0.5091 - val_accuracy: 0.8156\n",
      "Epoch 110/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5020 - accuracy: 0.8090 - val_loss: 0.4994 - val_accuracy: 0.8212\n",
      "Epoch 111/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4792 - accuracy: 0.8343 - val_loss: 0.4898 - val_accuracy: 0.8324\n",
      "Epoch 112/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4912 - accuracy: 0.8076 - val_loss: 0.5009 - val_accuracy: 0.8045\n",
      "Epoch 113/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4788 - accuracy: 0.8188 - val_loss: 0.4854 - val_accuracy: 0.8212\n",
      "Epoch 114/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4866 - accuracy: 0.8174 - val_loss: 0.4951 - val_accuracy: 0.8212\n",
      "Epoch 115/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4899 - accuracy: 0.8385 - val_loss: 0.5006 - val_accuracy: 0.8212\n",
      "Epoch 116/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4929 - accuracy: 0.8076 - val_loss: 0.5103 - val_accuracy: 0.8268\n",
      "Epoch 117/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5126 - accuracy: 0.8146 - val_loss: 0.4847 - val_accuracy: 0.8156\n",
      "Epoch 118/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4933 - accuracy: 0.8216 - val_loss: 0.4863 - val_accuracy: 0.8268\n",
      "Epoch 119/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4783 - accuracy: 0.8258 - val_loss: 0.4903 - val_accuracy: 0.8156\n",
      "Epoch 120/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5086 - accuracy: 0.8160 - val_loss: 0.4906 - val_accuracy: 0.8045\n",
      "Epoch 121/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4943 - accuracy: 0.8090 - val_loss: 0.4742 - val_accuracy: 0.8268\n",
      "Epoch 122/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4803 - accuracy: 0.8188 - val_loss: 0.4994 - val_accuracy: 0.8045\n",
      "Epoch 123/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4937 - accuracy: 0.8118 - val_loss: 0.5646 - val_accuracy: 0.7933\n",
      "Epoch 124/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4936 - accuracy: 0.8188 - val_loss: 0.5012 - val_accuracy: 0.8268\n",
      "Epoch 125/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4718 - accuracy: 0.8301 - val_loss: 0.4879 - val_accuracy: 0.8324\n",
      "Epoch 126/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4717 - accuracy: 0.8301 - val_loss: 0.5021 - val_accuracy: 0.7709\n",
      "Epoch 127/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4996 - accuracy: 0.8160 - val_loss: 0.4883 - val_accuracy: 0.8045\n",
      "Epoch 128/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4853 - accuracy: 0.8132 - val_loss: 0.4975 - val_accuracy: 0.8101\n",
      "Epoch 129/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4891 - accuracy: 0.8118 - val_loss: 0.5070 - val_accuracy: 0.8268\n",
      "Epoch 130/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4903 - accuracy: 0.8287 - val_loss: 0.5153 - val_accuracy: 0.8101\n",
      "Epoch 131/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4939 - accuracy: 0.8188 - val_loss: 0.4905 - val_accuracy: 0.8156\n",
      "Epoch 132/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4790 - accuracy: 0.8329 - val_loss: 0.5257 - val_accuracy: 0.8045\n",
      "Epoch 133/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4914 - accuracy: 0.8272 - val_loss: 0.4980 - val_accuracy: 0.8101\n",
      "Epoch 134/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4835 - accuracy: 0.8216 - val_loss: 0.5113 - val_accuracy: 0.8212\n",
      "Epoch 135/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4969 - accuracy: 0.8104 - val_loss: 0.4862 - val_accuracy: 0.7933\n",
      "Epoch 136/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5006 - accuracy: 0.8244 - val_loss: 0.5079 - val_accuracy: 0.8380\n",
      "Epoch 137/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5438 - accuracy: 0.7935 - val_loss: 0.5072 - val_accuracy: 0.8324\n",
      "Epoch 138/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4965 - accuracy: 0.8301 - val_loss: 0.5278 - val_accuracy: 0.8212\n",
      "Epoch 139/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4925 - accuracy: 0.8188 - val_loss: 0.5333 - val_accuracy: 0.8212\n",
      "Epoch 140/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4899 - accuracy: 0.8146 - val_loss: 0.4959 - val_accuracy: 0.8045\n",
      "Epoch 141/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4995 - accuracy: 0.8216 - val_loss: 0.4987 - val_accuracy: 0.7933\n",
      "Epoch 142/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4972 - accuracy: 0.8244 - val_loss: 0.4916 - val_accuracy: 0.8212\n",
      "Epoch 143/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4909 - accuracy: 0.8216 - val_loss: 0.4932 - val_accuracy: 0.7877\n",
      "Epoch 144/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4951 - accuracy: 0.8132 - val_loss: 0.5079 - val_accuracy: 0.8045\n",
      "Epoch 145/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5061 - accuracy: 0.8160 - val_loss: 0.4882 - val_accuracy: 0.8156\n",
      "Epoch 146/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4888 - accuracy: 0.8244 - val_loss: 0.4848 - val_accuracy: 0.8324\n",
      "Epoch 147/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4784 - accuracy: 0.8160 - val_loss: 0.5423 - val_accuracy: 0.8045\n",
      "Epoch 148/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5177 - accuracy: 0.7893 - val_loss: 0.5002 - val_accuracy: 0.8156\n",
      "Epoch 149/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4695 - accuracy: 0.8413 - val_loss: 0.5053 - val_accuracy: 0.7821\n",
      "Epoch 150/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4753 - accuracy: 0.8174 - val_loss: 0.5037 - val_accuracy: 0.7989\n",
      "Epoch 151/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4752 - accuracy: 0.8230 - val_loss: 0.4817 - val_accuracy: 0.8324\n",
      "Epoch 152/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4745 - accuracy: 0.8258 - val_loss: 0.4805 - val_accuracy: 0.8324\n",
      "Epoch 153/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4696 - accuracy: 0.8272 - val_loss: 0.4821 - val_accuracy: 0.8268\n",
      "Epoch 154/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4958 - accuracy: 0.8118 - val_loss: 0.4982 - val_accuracy: 0.8268\n",
      "Epoch 155/500\n",
      "712/712 [==============================] - 0s 382us/sample - loss: 0.4844 - accuracy: 0.8258 - val_loss: 0.5024 - val_accuracy: 0.8268\n",
      "Epoch 156/500\n",
      "712/712 [==============================] - 0s 250us/sample - loss: 0.4922 - accuracy: 0.8118 - val_loss: 0.4922 - val_accuracy: 0.8212\n",
      "Epoch 157/500\n",
      "712/712 [==============================] - 0s 260us/sample - loss: 0.4879 - accuracy: 0.8202 - val_loss: 0.5010 - val_accuracy: 0.8156\n",
      "Epoch 158/500\n",
      "712/712 [==============================] - 0s 235us/sample - loss: 0.4905 - accuracy: 0.8118 - val_loss: 0.4782 - val_accuracy: 0.8547\n",
      "Epoch 159/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4795 - accuracy: 0.8230 - val_loss: 0.5334 - val_accuracy: 0.8156\n",
      "Epoch 160/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5014 - accuracy: 0.8090 - val_loss: 0.4997 - val_accuracy: 0.8212\n",
      "Epoch 161/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.4860 - accuracy: 0.8118 - val_loss: 0.4855 - val_accuracy: 0.8101\n",
      "Epoch 162/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4728 - accuracy: 0.8272 - val_loss: 0.5042 - val_accuracy: 0.8101\n",
      "Epoch 163/500\n",
      "712/712 [==============================] - 0s 221us/sample - loss: 0.4863 - accuracy: 0.8258 - val_loss: 0.5090 - val_accuracy: 0.8156\n",
      "Epoch 164/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4665 - accuracy: 0.8202 - val_loss: 0.5099 - val_accuracy: 0.8212\n",
      "Epoch 165/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4786 - accuracy: 0.8301 - val_loss: 0.5350 - val_accuracy: 0.7877\n",
      "Epoch 166/500\n",
      "712/712 [==============================] - 0s 192us/sample - loss: 0.4821 - accuracy: 0.8188 - val_loss: 0.5303 - val_accuracy: 0.8101\n",
      "Epoch 167/500\n",
      "712/712 [==============================] - 0s 204us/sample - loss: 0.5073 - accuracy: 0.8146 - val_loss: 0.5496 - val_accuracy: 0.8045\n",
      "Epoch 168/500\n",
      "712/712 [==============================] - 0s 215us/sample - loss: 0.5010 - accuracy: 0.7978 - val_loss: 0.5344 - val_accuracy: 0.7989\n",
      "Epoch 169/500\n",
      "712/712 [==============================] - 0s 214us/sample - loss: 0.4848 - accuracy: 0.8202 - val_loss: 0.5013 - val_accuracy: 0.8156\n",
      "Epoch 170/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4820 - accuracy: 0.8216 - val_loss: 0.4968 - val_accuracy: 0.8101\n",
      "Epoch 171/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4803 - accuracy: 0.8160 - val_loss: 0.4881 - val_accuracy: 0.8212\n",
      "Epoch 172/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4849 - accuracy: 0.8174 - val_loss: 0.4871 - val_accuracy: 0.8380\n",
      "Epoch 173/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5018 - accuracy: 0.8132 - val_loss: 0.4805 - val_accuracy: 0.8268\n",
      "Epoch 174/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5037 - accuracy: 0.8160 - val_loss: 0.4847 - val_accuracy: 0.8101\n",
      "Epoch 175/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4722 - accuracy: 0.8216 - val_loss: 0.4853 - val_accuracy: 0.7933\n",
      "Epoch 176/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4776 - accuracy: 0.8272 - val_loss: 0.4867 - val_accuracy: 0.8268\n",
      "Epoch 177/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4767 - accuracy: 0.8329 - val_loss: 0.5012 - val_accuracy: 0.8101\n",
      "Epoch 178/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.4886 - accuracy: 0.8076 - val_loss: 0.4941 - val_accuracy: 0.8212\n",
      "Epoch 179/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4786 - accuracy: 0.8202 - val_loss: 0.4964 - val_accuracy: 0.8101\n",
      "Epoch 180/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4824 - accuracy: 0.8301 - val_loss: 0.5119 - val_accuracy: 0.8045\n",
      "Epoch 181/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4706 - accuracy: 0.8118 - val_loss: 0.5505 - val_accuracy: 0.8101\n",
      "Epoch 182/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4772 - accuracy: 0.8258 - val_loss: 0.4759 - val_accuracy: 0.8268\n",
      "Epoch 183/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4956 - accuracy: 0.8118 - val_loss: 0.5112 - val_accuracy: 0.8212\n",
      "Epoch 184/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4633 - accuracy: 0.8385 - val_loss: 0.4890 - val_accuracy: 0.7765\n",
      "Epoch 185/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4804 - accuracy: 0.8244 - val_loss: 0.4759 - val_accuracy: 0.8324\n",
      "Epoch 186/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4680 - accuracy: 0.8160 - val_loss: 0.4792 - val_accuracy: 0.8212\n",
      "Epoch 187/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4859 - accuracy: 0.8160 - val_loss: 0.5310 - val_accuracy: 0.8101\n",
      "Epoch 188/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4939 - accuracy: 0.8104 - val_loss: 0.4911 - val_accuracy: 0.8212\n",
      "Epoch 189/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4759 - accuracy: 0.8244 - val_loss: 0.4935 - val_accuracy: 0.8156\n",
      "Epoch 190/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4931 - accuracy: 0.8132 - val_loss: 0.4718 - val_accuracy: 0.8380\n",
      "Epoch 191/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5075 - accuracy: 0.8244 - val_loss: 0.4795 - val_accuracy: 0.8380\n",
      "Epoch 192/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4763 - accuracy: 0.8343 - val_loss: 0.4812 - val_accuracy: 0.8156\n",
      "Epoch 193/500\n",
      "712/712 [==============================] - 0s 258us/sample - loss: 0.4857 - accuracy: 0.8272 - val_loss: 0.4874 - val_accuracy: 0.8212\n",
      "Epoch 194/500\n",
      "712/712 [==============================] - 0s 277us/sample - loss: 0.4721 - accuracy: 0.8160 - val_loss: 0.5519 - val_accuracy: 0.7877\n",
      "Epoch 195/500\n",
      "712/712 [==============================] - 0s 363us/sample - loss: 0.5227 - accuracy: 0.8006 - val_loss: 0.5102 - val_accuracy: 0.8268\n",
      "Epoch 196/500\n",
      "712/712 [==============================] - 0s 255us/sample - loss: 0.4850 - accuracy: 0.8104 - val_loss: 0.4949 - val_accuracy: 0.8156\n",
      "Epoch 197/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4736 - accuracy: 0.8188 - val_loss: 0.5039 - val_accuracy: 0.8156\n",
      "Epoch 198/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4644 - accuracy: 0.8357 - val_loss: 0.4925 - val_accuracy: 0.8324\n",
      "Epoch 199/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5034 - accuracy: 0.8090 - val_loss: 0.4985 - val_accuracy: 0.8324\n",
      "Epoch 200/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4678 - accuracy: 0.8272 - val_loss: 0.4953 - val_accuracy: 0.8324\n",
      "Epoch 201/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4853 - accuracy: 0.8216 - val_loss: 0.4885 - val_accuracy: 0.8101\n",
      "Epoch 202/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4767 - accuracy: 0.8258 - val_loss: 0.4817 - val_accuracy: 0.8268\n",
      "Epoch 203/500\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.4799 - accuracy: 0.8329 - val_loss: 0.4694 - val_accuracy: 0.8380\n",
      "Epoch 204/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.4604 - accuracy: 0.8441 - val_loss: 0.5073 - val_accuracy: 0.8156\n",
      "Epoch 205/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4746 - accuracy: 0.8188 - val_loss: 0.5374 - val_accuracy: 0.7933\n",
      "Epoch 206/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.4755 - accuracy: 0.8371 - val_loss: 0.5039 - val_accuracy: 0.7877\n",
      "Epoch 207/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4825 - accuracy: 0.8048 - val_loss: 0.5015 - val_accuracy: 0.7877\n",
      "Epoch 208/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4872 - accuracy: 0.8188 - val_loss: 0.5117 - val_accuracy: 0.7654\n",
      "Epoch 209/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.4874 - accuracy: 0.8188 - val_loss: 0.4863 - val_accuracy: 0.8268\n",
      "Epoch 210/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4726 - accuracy: 0.8216 - val_loss: 0.4938 - val_accuracy: 0.8101\n",
      "Epoch 211/500\n",
      "712/712 [==============================] - 0s 214us/sample - loss: 0.4849 - accuracy: 0.8146 - val_loss: 0.4883 - val_accuracy: 0.8324\n",
      "Epoch 212/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4970 - accuracy: 0.8174 - val_loss: 0.4987 - val_accuracy: 0.8268\n",
      "Epoch 213/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4985 - accuracy: 0.8160 - val_loss: 0.4874 - val_accuracy: 0.8380\n",
      "Epoch 214/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4970 - accuracy: 0.8258 - val_loss: 0.5090 - val_accuracy: 0.7821\n",
      "Epoch 215/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5052 - accuracy: 0.8160 - val_loss: 0.4926 - val_accuracy: 0.8268\n",
      "Epoch 216/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4855 - accuracy: 0.8272 - val_loss: 0.4813 - val_accuracy: 0.8212\n",
      "Epoch 217/500\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.4875 - accuracy: 0.8315 - val_loss: 0.4907 - val_accuracy: 0.8101\n",
      "Epoch 218/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4848 - accuracy: 0.8287 - val_loss: 0.4821 - val_accuracy: 0.8212\n",
      "Epoch 219/500\n",
      "712/712 [==============================] - 0s 201us/sample - loss: 0.4799 - accuracy: 0.8146 - val_loss: 0.4970 - val_accuracy: 0.8268\n",
      "Epoch 220/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.4845 - accuracy: 0.8188 - val_loss: 0.5114 - val_accuracy: 0.7709\n",
      "Epoch 221/500\n",
      "712/712 [==============================] - 0s 193us/sample - loss: 0.4678 - accuracy: 0.8343 - val_loss: 0.5077 - val_accuracy: 0.8268\n",
      "Epoch 222/500\n",
      "712/712 [==============================] - 0s 231us/sample - loss: 0.4948 - accuracy: 0.8216 - val_loss: 0.5188 - val_accuracy: 0.8101\n",
      "Epoch 223/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4920 - accuracy: 0.8188 - val_loss: 0.4917 - val_accuracy: 0.8156\n",
      "Epoch 224/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4667 - accuracy: 0.8315 - val_loss: 0.4994 - val_accuracy: 0.8101\n",
      "Epoch 225/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4867 - accuracy: 0.7992 - val_loss: 0.4906 - val_accuracy: 0.8268\n",
      "Epoch 226/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4643 - accuracy: 0.8343 - val_loss: 0.4975 - val_accuracy: 0.8268\n",
      "Epoch 227/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.4991 - accuracy: 0.8048 - val_loss: 0.5257 - val_accuracy: 0.8212\n",
      "Epoch 228/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4825 - accuracy: 0.8146 - val_loss: 0.4785 - val_accuracy: 0.8156\n",
      "Epoch 229/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.4815 - accuracy: 0.8160 - val_loss: 0.4808 - val_accuracy: 0.7989\n",
      "Epoch 230/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4894 - accuracy: 0.8216 - val_loss: 0.5069 - val_accuracy: 0.8212\n",
      "Epoch 231/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4930 - accuracy: 0.8202 - val_loss: 0.4848 - val_accuracy: 0.8380\n",
      "Epoch 232/500\n",
      "712/712 [==============================] - 0s 200us/sample - loss: 0.4613 - accuracy: 0.8216 - val_loss: 0.4653 - val_accuracy: 0.8324\n",
      "Epoch 233/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4872 - accuracy: 0.8202 - val_loss: 0.4949 - val_accuracy: 0.8212\n",
      "Epoch 234/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4842 - accuracy: 0.8244 - val_loss: 0.5038 - val_accuracy: 0.8045\n",
      "Epoch 235/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4592 - accuracy: 0.8301 - val_loss: 0.5025 - val_accuracy: 0.8212\n",
      "Epoch 236/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4906 - accuracy: 0.8188 - val_loss: 0.4770 - val_accuracy: 0.7821\n",
      "Epoch 237/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4725 - accuracy: 0.8258 - val_loss: 0.4738 - val_accuracy: 0.8324\n",
      "Epoch 238/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.4808 - accuracy: 0.8160 - val_loss: 0.4945 - val_accuracy: 0.8156\n",
      "Epoch 239/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4695 - accuracy: 0.8315 - val_loss: 0.4896 - val_accuracy: 0.8212\n",
      "Epoch 240/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4712 - accuracy: 0.8244 - val_loss: 0.4831 - val_accuracy: 0.8156\n",
      "Epoch 241/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4958 - accuracy: 0.8104 - val_loss: 0.4756 - val_accuracy: 0.8268\n",
      "Epoch 242/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4725 - accuracy: 0.8329 - val_loss: 0.5001 - val_accuracy: 0.8101\n",
      "Epoch 243/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4729 - accuracy: 0.8244 - val_loss: 0.4822 - val_accuracy: 0.7989\n",
      "Epoch 244/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4969 - accuracy: 0.8188 - val_loss: 0.4943 - val_accuracy: 0.8212\n",
      "Epoch 245/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4779 - accuracy: 0.8048 - val_loss: 0.4841 - val_accuracy: 0.8380\n",
      "Epoch 246/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4756 - accuracy: 0.8258 - val_loss: 0.4755 - val_accuracy: 0.8212\n",
      "Epoch 247/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4826 - accuracy: 0.8174 - val_loss: 0.4784 - val_accuracy: 0.8268\n",
      "Epoch 248/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4906 - accuracy: 0.8104 - val_loss: 0.5250 - val_accuracy: 0.7765\n",
      "Epoch 249/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4836 - accuracy: 0.8118 - val_loss: 0.5015 - val_accuracy: 0.8268\n",
      "Epoch 250/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4829 - accuracy: 0.8174 - val_loss: 0.4791 - val_accuracy: 0.8324\n",
      "Epoch 251/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4708 - accuracy: 0.8146 - val_loss: 0.4820 - val_accuracy: 0.8324\n",
      "Epoch 252/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5022 - accuracy: 0.8006 - val_loss: 0.5014 - val_accuracy: 0.7877\n",
      "Epoch 253/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5000 - accuracy: 0.8118 - val_loss: 0.4872 - val_accuracy: 0.8212\n",
      "Epoch 254/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4896 - accuracy: 0.8272 - val_loss: 0.4820 - val_accuracy: 0.8212\n",
      "Epoch 255/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4777 - accuracy: 0.8230 - val_loss: 0.4977 - val_accuracy: 0.8156\n",
      "Epoch 256/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4880 - accuracy: 0.8132 - val_loss: 0.4617 - val_accuracy: 0.8380\n",
      "Epoch 257/500\n",
      "712/712 [==============================] - 0s 227us/sample - loss: 0.4699 - accuracy: 0.8287 - val_loss: 0.4891 - val_accuracy: 0.8324\n",
      "Epoch 258/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4992 - accuracy: 0.8188 - val_loss: 0.4869 - val_accuracy: 0.8212\n",
      "Epoch 259/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4862 - accuracy: 0.8258 - val_loss: 0.4908 - val_accuracy: 0.8212\n",
      "Epoch 260/500\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.4890 - accuracy: 0.8090 - val_loss: 0.4913 - val_accuracy: 0.7821\n",
      "Epoch 261/500\n",
      "712/712 [==============================] - 0s 217us/sample - loss: 0.4903 - accuracy: 0.8287 - val_loss: 0.5010 - val_accuracy: 0.8156\n",
      "Epoch 262/500\n",
      "712/712 [==============================] - 0s 293us/sample - loss: 0.4697 - accuracy: 0.8216 - val_loss: 0.4943 - val_accuracy: 0.8156\n",
      "Epoch 263/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.4632 - accuracy: 0.8258 - val_loss: 0.4874 - val_accuracy: 0.8212\n",
      "Epoch 264/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4753 - accuracy: 0.8160 - val_loss: 0.4849 - val_accuracy: 0.8268\n",
      "Epoch 265/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4901 - accuracy: 0.8230 - val_loss: 0.4807 - val_accuracy: 0.8212\n",
      "Epoch 266/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4529 - accuracy: 0.8216 - val_loss: 0.4865 - val_accuracy: 0.8268\n",
      "Epoch 267/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4790 - accuracy: 0.8132 - val_loss: 0.4841 - val_accuracy: 0.8101\n",
      "Epoch 268/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4751 - accuracy: 0.8146 - val_loss: 0.4856 - val_accuracy: 0.8268\n",
      "Epoch 269/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4681 - accuracy: 0.8357 - val_loss: 0.4886 - val_accuracy: 0.8212\n",
      "Epoch 270/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4923 - accuracy: 0.8118 - val_loss: 0.4818 - val_accuracy: 0.8268\n",
      "Epoch 271/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4675 - accuracy: 0.8385 - val_loss: 0.5152 - val_accuracy: 0.7933\n",
      "Epoch 272/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4931 - accuracy: 0.8202 - val_loss: 0.4899 - val_accuracy: 0.8156\n",
      "Epoch 273/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4967 - accuracy: 0.8174 - val_loss: 0.4968 - val_accuracy: 0.8156\n",
      "Epoch 274/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4898 - accuracy: 0.8076 - val_loss: 0.5097 - val_accuracy: 0.8156\n",
      "Epoch 275/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4939 - accuracy: 0.8230 - val_loss: 0.4908 - val_accuracy: 0.8268\n",
      "Epoch 276/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4827 - accuracy: 0.8287 - val_loss: 0.4912 - val_accuracy: 0.8156\n",
      "Epoch 277/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4689 - accuracy: 0.8329 - val_loss: 0.5148 - val_accuracy: 0.8156\n",
      "Epoch 278/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.4746 - accuracy: 0.8174 - val_loss: 0.4791 - val_accuracy: 0.8268\n",
      "Epoch 279/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4721 - accuracy: 0.8301 - val_loss: 0.4985 - val_accuracy: 0.8156\n",
      "Epoch 280/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4678 - accuracy: 0.8315 - val_loss: 0.4913 - val_accuracy: 0.8101\n",
      "Epoch 281/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4866 - accuracy: 0.8258 - val_loss: 0.4713 - val_accuracy: 0.8324\n",
      "Epoch 282/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4912 - accuracy: 0.8216 - val_loss: 0.4825 - val_accuracy: 0.8324\n",
      "Epoch 283/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4727 - accuracy: 0.8329 - val_loss: 0.4897 - val_accuracy: 0.8156\n",
      "Epoch 284/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4718 - accuracy: 0.8216 - val_loss: 0.4705 - val_accuracy: 0.8268\n",
      "Epoch 285/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4893 - accuracy: 0.8160 - val_loss: 0.4911 - val_accuracy: 0.7877\n",
      "Epoch 286/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4862 - accuracy: 0.8020 - val_loss: 0.5058 - val_accuracy: 0.7765\n",
      "Epoch 287/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4683 - accuracy: 0.8160 - val_loss: 0.4938 - val_accuracy: 0.8212\n",
      "Epoch 288/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4814 - accuracy: 0.8216 - val_loss: 0.5115 - val_accuracy: 0.7765\n",
      "Epoch 289/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4867 - accuracy: 0.8118 - val_loss: 0.5045 - val_accuracy: 0.8268\n",
      "Epoch 290/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4959 - accuracy: 0.8076 - val_loss: 0.4923 - val_accuracy: 0.8324\n",
      "Epoch 291/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4655 - accuracy: 0.8244 - val_loss: 0.5503 - val_accuracy: 0.7989\n",
      "Epoch 292/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4821 - accuracy: 0.8244 - val_loss: 0.5080 - val_accuracy: 0.8268\n",
      "Epoch 293/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4766 - accuracy: 0.8132 - val_loss: 0.5045 - val_accuracy: 0.8268\n",
      "Epoch 294/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4761 - accuracy: 0.8230 - val_loss: 0.5163 - val_accuracy: 0.8101\n",
      "Epoch 295/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4787 - accuracy: 0.8301 - val_loss: 0.4787 - val_accuracy: 0.8268\n",
      "Epoch 296/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4899 - accuracy: 0.8118 - val_loss: 0.4835 - val_accuracy: 0.8045\n",
      "Epoch 297/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4550 - accuracy: 0.8357 - val_loss: 0.5199 - val_accuracy: 0.8212\n",
      "Epoch 298/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4756 - accuracy: 0.8287 - val_loss: 0.5005 - val_accuracy: 0.7765\n",
      "Epoch 299/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5029 - accuracy: 0.8090 - val_loss: 0.4932 - val_accuracy: 0.7877\n",
      "Epoch 300/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4922 - accuracy: 0.8301 - val_loss: 0.4746 - val_accuracy: 0.8380\n",
      "Epoch 301/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4770 - accuracy: 0.8230 - val_loss: 0.5252 - val_accuracy: 0.8101\n",
      "Epoch 302/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5257 - accuracy: 0.7907 - val_loss: 0.5448 - val_accuracy: 0.8101\n",
      "Epoch 303/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5046 - accuracy: 0.8258 - val_loss: 0.4852 - val_accuracy: 0.8268\n",
      "Epoch 304/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4843 - accuracy: 0.8230 - val_loss: 0.4991 - val_accuracy: 0.8324\n",
      "Epoch 305/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4823 - accuracy: 0.8230 - val_loss: 0.4883 - val_accuracy: 0.8324\n",
      "Epoch 306/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4813 - accuracy: 0.8146 - val_loss: 0.5157 - val_accuracy: 0.8101\n",
      "Epoch 307/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4655 - accuracy: 0.8258 - val_loss: 0.5183 - val_accuracy: 0.8212\n",
      "Epoch 308/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4834 - accuracy: 0.8272 - val_loss: 0.4872 - val_accuracy: 0.8268\n",
      "Epoch 309/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4685 - accuracy: 0.8329 - val_loss: 0.4919 - val_accuracy: 0.7821\n",
      "Epoch 310/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5092 - accuracy: 0.8202 - val_loss: 0.4659 - val_accuracy: 0.8547\n",
      "Epoch 311/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4838 - accuracy: 0.8076 - val_loss: 0.4743 - val_accuracy: 0.8324\n",
      "Epoch 312/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4802 - accuracy: 0.8216 - val_loss: 0.4888 - val_accuracy: 0.8212\n",
      "Epoch 313/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4643 - accuracy: 0.8301 - val_loss: 0.4828 - val_accuracy: 0.8324\n",
      "Epoch 314/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4825 - accuracy: 0.8343 - val_loss: 0.4832 - val_accuracy: 0.8212\n",
      "Epoch 315/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4696 - accuracy: 0.8230 - val_loss: 0.4863 - val_accuracy: 0.8156\n",
      "Epoch 316/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4686 - accuracy: 0.8146 - val_loss: 0.4798 - val_accuracy: 0.7933\n",
      "Epoch 317/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4808 - accuracy: 0.8146 - val_loss: 0.4881 - val_accuracy: 0.7821\n",
      "Epoch 318/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4780 - accuracy: 0.8230 - val_loss: 0.4961 - val_accuracy: 0.8268\n",
      "Epoch 319/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4833 - accuracy: 0.8258 - val_loss: 0.4841 - val_accuracy: 0.8324\n",
      "Epoch 320/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4768 - accuracy: 0.8188 - val_loss: 0.4955 - val_accuracy: 0.8212\n",
      "Epoch 321/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4795 - accuracy: 0.8202 - val_loss: 0.4867 - val_accuracy: 0.8324\n",
      "Epoch 322/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4614 - accuracy: 0.8258 - val_loss: 0.5155 - val_accuracy: 0.8156\n",
      "Epoch 323/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5024 - accuracy: 0.8160 - val_loss: 0.5171 - val_accuracy: 0.8101\n",
      "Epoch 324/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4616 - accuracy: 0.8287 - val_loss: 0.4728 - val_accuracy: 0.8324\n",
      "Epoch 325/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4737 - accuracy: 0.8287 - val_loss: 0.4843 - val_accuracy: 0.8212\n",
      "Epoch 326/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4734 - accuracy: 0.8244 - val_loss: 0.4845 - val_accuracy: 0.8268\n",
      "Epoch 327/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4694 - accuracy: 0.8258 - val_loss: 0.5139 - val_accuracy: 0.8156\n",
      "Epoch 328/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4810 - accuracy: 0.8272 - val_loss: 0.4982 - val_accuracy: 0.8156\n",
      "Epoch 329/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4830 - accuracy: 0.8132 - val_loss: 0.4939 - val_accuracy: 0.8212\n",
      "Epoch 330/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4861 - accuracy: 0.8160 - val_loss: 0.4942 - val_accuracy: 0.8212\n",
      "Epoch 331/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4757 - accuracy: 0.8272 - val_loss: 0.4902 - val_accuracy: 0.8212\n",
      "Epoch 332/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4567 - accuracy: 0.8230 - val_loss: 0.4920 - val_accuracy: 0.8324\n",
      "Epoch 333/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4573 - accuracy: 0.8301 - val_loss: 0.4812 - val_accuracy: 0.8212\n",
      "Epoch 334/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4754 - accuracy: 0.8062 - val_loss: 0.5028 - val_accuracy: 0.8045\n",
      "Epoch 335/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5112 - accuracy: 0.8104 - val_loss: 0.4917 - val_accuracy: 0.8436\n",
      "Epoch 336/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4847 - accuracy: 0.8287 - val_loss: 0.4965 - val_accuracy: 0.8268\n",
      "Epoch 337/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4770 - accuracy: 0.8371 - val_loss: 0.4911 - val_accuracy: 0.8268\n",
      "Epoch 338/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4861 - accuracy: 0.8076 - val_loss: 0.5111 - val_accuracy: 0.8156\n",
      "Epoch 339/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5025 - accuracy: 0.8034 - val_loss: 0.5098 - val_accuracy: 0.7877\n",
      "Epoch 340/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4989 - accuracy: 0.8258 - val_loss: 0.4929 - val_accuracy: 0.8101\n",
      "Epoch 341/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5089 - accuracy: 0.8020 - val_loss: 0.4947 - val_accuracy: 0.7877\n",
      "Epoch 342/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4703 - accuracy: 0.8272 - val_loss: 0.5144 - val_accuracy: 0.7765\n",
      "Epoch 343/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4951 - accuracy: 0.8090 - val_loss: 0.4967 - val_accuracy: 0.8212\n",
      "Epoch 344/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4849 - accuracy: 0.8118 - val_loss: 0.5070 - val_accuracy: 0.7989\n",
      "Epoch 345/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4694 - accuracy: 0.8174 - val_loss: 0.4940 - val_accuracy: 0.8156\n",
      "Epoch 346/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4846 - accuracy: 0.8258 - val_loss: 0.5318 - val_accuracy: 0.8101\n",
      "Epoch 347/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4937 - accuracy: 0.8146 - val_loss: 0.4822 - val_accuracy: 0.8212\n",
      "Epoch 348/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4709 - accuracy: 0.8244 - val_loss: 0.4987 - val_accuracy: 0.8156\n",
      "Epoch 349/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4807 - accuracy: 0.8132 - val_loss: 0.5105 - val_accuracy: 0.8156\n",
      "Epoch 350/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5043 - accuracy: 0.8146 - val_loss: 0.5087 - val_accuracy: 0.8101\n",
      "Epoch 351/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4967 - accuracy: 0.8188 - val_loss: 0.5031 - val_accuracy: 0.8324\n",
      "Epoch 352/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4696 - accuracy: 0.8104 - val_loss: 0.4912 - val_accuracy: 0.8045\n",
      "Epoch 353/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4789 - accuracy: 0.8301 - val_loss: 0.4972 - val_accuracy: 0.8045\n",
      "Epoch 354/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4718 - accuracy: 0.8216 - val_loss: 0.4981 - val_accuracy: 0.8156\n",
      "Epoch 355/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4732 - accuracy: 0.8244 - val_loss: 0.5058 - val_accuracy: 0.8212\n",
      "Epoch 356/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4847 - accuracy: 0.8216 - val_loss: 0.4704 - val_accuracy: 0.8380\n",
      "Epoch 357/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4653 - accuracy: 0.8272 - val_loss: 0.5045 - val_accuracy: 0.8045\n",
      "Epoch 358/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5054 - accuracy: 0.8048 - val_loss: 0.5122 - val_accuracy: 0.8380\n",
      "Epoch 359/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4912 - accuracy: 0.8188 - val_loss: 0.4948 - val_accuracy: 0.8324\n",
      "Epoch 360/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4766 - accuracy: 0.8287 - val_loss: 0.5238 - val_accuracy: 0.8156\n",
      "Epoch 361/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4822 - accuracy: 0.8258 - val_loss: 0.5157 - val_accuracy: 0.8156\n",
      "Epoch 362/500\n",
      "712/712 [==============================] - 0s 201us/sample - loss: 0.4879 - accuracy: 0.8160 - val_loss: 0.4851 - val_accuracy: 0.8212\n",
      "Epoch 363/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4871 - accuracy: 0.8076 - val_loss: 0.4830 - val_accuracy: 0.7933\n",
      "Epoch 364/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4772 - accuracy: 0.8216 - val_loss: 0.4850 - val_accuracy: 0.8268\n",
      "Epoch 365/500\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.4823 - accuracy: 0.8076 - val_loss: 0.4756 - val_accuracy: 0.8268\n",
      "Epoch 366/500\n",
      "712/712 [==============================] - 0s 193us/sample - loss: 0.4770 - accuracy: 0.8272 - val_loss: 0.5118 - val_accuracy: 0.8101\n",
      "Epoch 367/500\n",
      "712/712 [==============================] - 0s 200us/sample - loss: 0.4822 - accuracy: 0.8244 - val_loss: 0.5113 - val_accuracy: 0.8156\n",
      "Epoch 368/500\n",
      "712/712 [==============================] - 0s 209us/sample - loss: 0.4707 - accuracy: 0.8062 - val_loss: 0.5071 - val_accuracy: 0.8268\n",
      "Epoch 369/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4759 - accuracy: 0.8343 - val_loss: 0.4700 - val_accuracy: 0.8045\n",
      "Epoch 370/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4781 - accuracy: 0.8315 - val_loss: 0.4950 - val_accuracy: 0.7765\n",
      "Epoch 371/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5035 - accuracy: 0.7978 - val_loss: 0.4852 - val_accuracy: 0.7821\n",
      "Epoch 372/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4649 - accuracy: 0.8272 - val_loss: 0.5006 - val_accuracy: 0.8212\n",
      "Epoch 373/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4658 - accuracy: 0.8315 - val_loss: 0.5106 - val_accuracy: 0.8156\n",
      "Epoch 374/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4964 - accuracy: 0.8020 - val_loss: 0.4752 - val_accuracy: 0.8268\n",
      "Epoch 375/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4710 - accuracy: 0.8216 - val_loss: 0.4985 - val_accuracy: 0.8101\n",
      "Epoch 376/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4821 - accuracy: 0.8272 - val_loss: 0.5022 - val_accuracy: 0.8212\n",
      "Epoch 377/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4759 - accuracy: 0.8230 - val_loss: 0.4932 - val_accuracy: 0.8268\n",
      "Epoch 378/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4786 - accuracy: 0.8272 - val_loss: 0.4779 - val_accuracy: 0.8268\n",
      "Epoch 379/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4793 - accuracy: 0.8329 - val_loss: 0.5060 - val_accuracy: 0.8324\n",
      "Epoch 380/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4803 - accuracy: 0.8174 - val_loss: 0.5356 - val_accuracy: 0.7877\n",
      "Epoch 381/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4642 - accuracy: 0.8258 - val_loss: 0.5115 - val_accuracy: 0.8212\n",
      "Epoch 382/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4748 - accuracy: 0.8329 - val_loss: 0.4814 - val_accuracy: 0.8156\n",
      "Epoch 383/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4688 - accuracy: 0.8202 - val_loss: 0.4795 - val_accuracy: 0.8268\n",
      "Epoch 384/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4920 - accuracy: 0.8118 - val_loss: 0.4729 - val_accuracy: 0.8268\n",
      "Epoch 385/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4833 - accuracy: 0.8118 - val_loss: 0.4836 - val_accuracy: 0.8212\n",
      "Epoch 386/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4908 - accuracy: 0.8188 - val_loss: 0.4963 - val_accuracy: 0.8045\n",
      "Epoch 387/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4934 - accuracy: 0.8160 - val_loss: 0.5064 - val_accuracy: 0.8212\n",
      "Epoch 388/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4837 - accuracy: 0.8301 - val_loss: 0.4929 - val_accuracy: 0.8156\n",
      "Epoch 389/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4762 - accuracy: 0.8104 - val_loss: 0.4971 - val_accuracy: 0.7933\n",
      "Epoch 390/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4640 - accuracy: 0.8343 - val_loss: 0.5156 - val_accuracy: 0.8212\n",
      "Epoch 391/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4938 - accuracy: 0.8272 - val_loss: 0.5094 - val_accuracy: 0.7765\n",
      "Epoch 392/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4857 - accuracy: 0.8188 - val_loss: 0.4923 - val_accuracy: 0.8101\n",
      "Epoch 393/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4900 - accuracy: 0.8174 - val_loss: 0.4952 - val_accuracy: 0.8156\n",
      "Epoch 394/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4835 - accuracy: 0.8216 - val_loss: 0.5019 - val_accuracy: 0.8212\n",
      "Epoch 395/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4865 - accuracy: 0.8202 - val_loss: 0.4762 - val_accuracy: 0.8380\n",
      "Epoch 396/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4690 - accuracy: 0.8146 - val_loss: 0.4941 - val_accuracy: 0.8324\n",
      "Epoch 397/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4884 - accuracy: 0.8104 - val_loss: 0.4879 - val_accuracy: 0.8101\n",
      "Epoch 398/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4743 - accuracy: 0.8132 - val_loss: 0.5147 - val_accuracy: 0.8212\n",
      "Epoch 399/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4878 - accuracy: 0.8048 - val_loss: 0.4968 - val_accuracy: 0.8268\n",
      "Epoch 400/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4655 - accuracy: 0.8244 - val_loss: 0.4900 - val_accuracy: 0.8045\n",
      "Epoch 401/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4753 - accuracy: 0.8230 - val_loss: 0.4797 - val_accuracy: 0.8156\n",
      "Epoch 402/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4798 - accuracy: 0.8146 - val_loss: 0.4961 - val_accuracy: 0.8212\n",
      "Epoch 403/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4977 - accuracy: 0.8174 - val_loss: 0.4742 - val_accuracy: 0.8380\n",
      "Epoch 404/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4770 - accuracy: 0.8287 - val_loss: 0.5027 - val_accuracy: 0.8212\n",
      "Epoch 405/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4685 - accuracy: 0.8202 - val_loss: 0.4933 - val_accuracy: 0.8212\n",
      "Epoch 406/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4920 - accuracy: 0.8188 - val_loss: 0.4836 - val_accuracy: 0.8380\n",
      "Epoch 407/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4916 - accuracy: 0.8090 - val_loss: 0.4833 - val_accuracy: 0.8324\n",
      "Epoch 408/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4641 - accuracy: 0.8230 - val_loss: 0.5244 - val_accuracy: 0.7989\n",
      "Epoch 409/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5227 - accuracy: 0.7907 - val_loss: 0.4918 - val_accuracy: 0.8212\n",
      "Epoch 410/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4768 - accuracy: 0.8216 - val_loss: 0.5001 - val_accuracy: 0.8268\n",
      "Epoch 411/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4888 - accuracy: 0.8272 - val_loss: 0.5134 - val_accuracy: 0.8324\n",
      "Epoch 412/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5000 - accuracy: 0.8076 - val_loss: 0.5046 - val_accuracy: 0.8101\n",
      "Epoch 413/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4655 - accuracy: 0.8216 - val_loss: 0.4886 - val_accuracy: 0.8045\n",
      "Epoch 414/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5106 - accuracy: 0.7921 - val_loss: 0.5095 - val_accuracy: 0.8045\n",
      "Epoch 415/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4830 - accuracy: 0.8272 - val_loss: 0.4971 - val_accuracy: 0.8045\n",
      "Epoch 416/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4818 - accuracy: 0.8188 - val_loss: 0.4889 - val_accuracy: 0.8045\n",
      "Epoch 417/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4778 - accuracy: 0.8174 - val_loss: 0.5195 - val_accuracy: 0.7709\n",
      "Epoch 418/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4933 - accuracy: 0.8202 - val_loss: 0.4949 - val_accuracy: 0.8156\n",
      "Epoch 419/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4738 - accuracy: 0.8272 - val_loss: 0.5056 - val_accuracy: 0.8268\n",
      "Epoch 420/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4809 - accuracy: 0.8258 - val_loss: 0.5003 - val_accuracy: 0.8045\n",
      "Epoch 421/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4760 - accuracy: 0.8188 - val_loss: 0.5012 - val_accuracy: 0.8045\n",
      "Epoch 422/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4849 - accuracy: 0.8315 - val_loss: 0.4754 - val_accuracy: 0.8101\n",
      "Epoch 423/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4856 - accuracy: 0.8146 - val_loss: 0.4638 - val_accuracy: 0.8324\n",
      "Epoch 424/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4868 - accuracy: 0.8343 - val_loss: 0.4730 - val_accuracy: 0.8324\n",
      "Epoch 425/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4830 - accuracy: 0.8104 - val_loss: 0.4987 - val_accuracy: 0.8156\n",
      "Epoch 426/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4744 - accuracy: 0.8315 - val_loss: 0.4942 - val_accuracy: 0.8156\n",
      "Epoch 427/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4742 - accuracy: 0.8160 - val_loss: 0.4925 - val_accuracy: 0.8268\n",
      "Epoch 428/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4713 - accuracy: 0.8118 - val_loss: 0.4856 - val_accuracy: 0.8156\n",
      "Epoch 429/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4910 - accuracy: 0.8174 - val_loss: 0.4897 - val_accuracy: 0.7989\n",
      "Epoch 430/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5084 - accuracy: 0.8020 - val_loss: 0.4879 - val_accuracy: 0.8156\n",
      "Epoch 431/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4872 - accuracy: 0.8301 - val_loss: 0.4735 - val_accuracy: 0.8380\n",
      "Epoch 432/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4681 - accuracy: 0.8287 - val_loss: 0.4808 - val_accuracy: 0.8324\n",
      "Epoch 433/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4477 - accuracy: 0.8399 - val_loss: 0.5129 - val_accuracy: 0.8268\n",
      "Epoch 434/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4668 - accuracy: 0.8329 - val_loss: 0.4886 - val_accuracy: 0.8268\n",
      "Epoch 435/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4706 - accuracy: 0.8244 - val_loss: 0.5174 - val_accuracy: 0.7765\n",
      "Epoch 436/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4842 - accuracy: 0.8174 - val_loss: 0.5056 - val_accuracy: 0.8101\n",
      "Epoch 437/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4739 - accuracy: 0.8244 - val_loss: 0.4825 - val_accuracy: 0.8324\n",
      "Epoch 438/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4668 - accuracy: 0.8216 - val_loss: 0.5242 - val_accuracy: 0.7989\n",
      "Epoch 439/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4706 - accuracy: 0.8301 - val_loss: 0.4869 - val_accuracy: 0.7933\n",
      "Epoch 440/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4873 - accuracy: 0.8174 - val_loss: 0.4735 - val_accuracy: 0.8324\n",
      "Epoch 441/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4508 - accuracy: 0.8174 - val_loss: 0.4930 - val_accuracy: 0.8045\n",
      "Epoch 442/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4876 - accuracy: 0.8160 - val_loss: 0.4817 - val_accuracy: 0.8324\n",
      "Epoch 443/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4664 - accuracy: 0.8104 - val_loss: 0.5044 - val_accuracy: 0.8101\n",
      "Epoch 444/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4868 - accuracy: 0.8188 - val_loss: 0.5027 - val_accuracy: 0.8101\n",
      "Epoch 445/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4700 - accuracy: 0.8287 - val_loss: 0.4826 - val_accuracy: 0.8268\n",
      "Epoch 446/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4690 - accuracy: 0.8441 - val_loss: 0.4928 - val_accuracy: 0.7821\n",
      "Epoch 447/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4736 - accuracy: 0.8202 - val_loss: 0.5111 - val_accuracy: 0.8268\n",
      "Epoch 448/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5027 - accuracy: 0.8216 - val_loss: 0.5363 - val_accuracy: 0.7933\n",
      "Epoch 449/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4945 - accuracy: 0.8146 - val_loss: 0.4776 - val_accuracy: 0.8324\n",
      "Epoch 450/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4797 - accuracy: 0.8160 - val_loss: 0.4960 - val_accuracy: 0.7654\n",
      "Epoch 451/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4733 - accuracy: 0.8160 - val_loss: 0.4859 - val_accuracy: 0.8268\n",
      "Epoch 452/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4884 - accuracy: 0.8104 - val_loss: 0.4962 - val_accuracy: 0.8212\n",
      "Epoch 453/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4761 - accuracy: 0.8160 - val_loss: 0.4760 - val_accuracy: 0.8212\n",
      "Epoch 454/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5018 - accuracy: 0.8048 - val_loss: 0.4782 - val_accuracy: 0.8380\n",
      "Epoch 455/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4694 - accuracy: 0.8329 - val_loss: 0.4841 - val_accuracy: 0.8268\n",
      "Epoch 456/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4651 - accuracy: 0.8357 - val_loss: 0.4750 - val_accuracy: 0.8101\n",
      "Epoch 457/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4672 - accuracy: 0.8230 - val_loss: 0.5118 - val_accuracy: 0.8101\n",
      "Epoch 458/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4725 - accuracy: 0.8202 - val_loss: 0.4949 - val_accuracy: 0.8101\n",
      "Epoch 459/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4576 - accuracy: 0.8287 - val_loss: 0.4950 - val_accuracy: 0.7877\n",
      "Epoch 460/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4711 - accuracy: 0.8244 - val_loss: 0.4860 - val_accuracy: 0.8268\n",
      "Epoch 461/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4861 - accuracy: 0.8244 - val_loss: 0.4862 - val_accuracy: 0.8212\n",
      "Epoch 462/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4761 - accuracy: 0.8216 - val_loss: 0.4768 - val_accuracy: 0.8380\n",
      "Epoch 463/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4881 - accuracy: 0.8174 - val_loss: 0.4949 - val_accuracy: 0.7989\n",
      "Epoch 464/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4989 - accuracy: 0.8062 - val_loss: 0.4851 - val_accuracy: 0.8380\n",
      "Epoch 465/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4718 - accuracy: 0.8329 - val_loss: 0.4803 - val_accuracy: 0.7989\n",
      "Epoch 466/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4916 - accuracy: 0.8272 - val_loss: 0.4720 - val_accuracy: 0.8212\n",
      "Epoch 467/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4862 - accuracy: 0.8244 - val_loss: 0.4861 - val_accuracy: 0.8156\n",
      "Epoch 468/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4638 - accuracy: 0.8357 - val_loss: 0.5008 - val_accuracy: 0.8380\n",
      "Epoch 469/500\n",
      "712/712 [==============================] - 0s 216us/sample - loss: 0.5227 - accuracy: 0.8188 - val_loss: 0.5352 - val_accuracy: 0.7989\n",
      "Epoch 470/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4724 - accuracy: 0.8202 - val_loss: 0.4901 - val_accuracy: 0.8268\n",
      "Epoch 471/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4733 - accuracy: 0.8174 - val_loss: 0.4829 - val_accuracy: 0.8268\n",
      "Epoch 472/500\n",
      "712/712 [==============================] - 0s 213us/sample - loss: 0.4943 - accuracy: 0.8090 - val_loss: 0.5166 - val_accuracy: 0.8101\n",
      "Epoch 473/500\n",
      "712/712 [==============================] - 0s 260us/sample - loss: 0.4944 - accuracy: 0.8230 - val_loss: 0.5071 - val_accuracy: 0.8156\n",
      "Epoch 474/500\n",
      "712/712 [==============================] - 0s 238us/sample - loss: 0.4813 - accuracy: 0.8230 - val_loss: 0.5177 - val_accuracy: 0.7933\n",
      "Epoch 475/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4938 - accuracy: 0.8034 - val_loss: 0.4815 - val_accuracy: 0.8101\n",
      "Epoch 476/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4788 - accuracy: 0.8258 - val_loss: 0.4993 - val_accuracy: 0.8268\n",
      "Epoch 477/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5050 - accuracy: 0.8132 - val_loss: 0.4871 - val_accuracy: 0.7989\n",
      "Epoch 478/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4812 - accuracy: 0.8188 - val_loss: 0.4800 - val_accuracy: 0.8212\n",
      "Epoch 479/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4790 - accuracy: 0.8230 - val_loss: 0.5016 - val_accuracy: 0.8156\n",
      "Epoch 480/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4669 - accuracy: 0.8272 - val_loss: 0.4957 - val_accuracy: 0.8212\n",
      "Epoch 481/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4796 - accuracy: 0.8132 - val_loss: 0.4890 - val_accuracy: 0.8156\n",
      "Epoch 482/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4652 - accuracy: 0.8301 - val_loss: 0.4709 - val_accuracy: 0.8380\n",
      "Epoch 483/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4717 - accuracy: 0.8244 - val_loss: 0.4802 - val_accuracy: 0.8268\n",
      "Epoch 484/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5082 - accuracy: 0.8034 - val_loss: 0.5858 - val_accuracy: 0.7989\n",
      "Epoch 485/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4874 - accuracy: 0.8160 - val_loss: 0.4989 - val_accuracy: 0.8380\n",
      "Epoch 486/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4709 - accuracy: 0.8160 - val_loss: 0.4735 - val_accuracy: 0.8101\n",
      "Epoch 487/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4905 - accuracy: 0.8174 - val_loss: 0.4895 - val_accuracy: 0.7709\n",
      "Epoch 488/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5087 - accuracy: 0.7963 - val_loss: 0.4802 - val_accuracy: 0.8212\n",
      "Epoch 489/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4907 - accuracy: 0.7992 - val_loss: 0.5579 - val_accuracy: 0.7989\n",
      "Epoch 490/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4864 - accuracy: 0.8216 - val_loss: 0.5199 - val_accuracy: 0.8268\n",
      "Epoch 491/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4894 - accuracy: 0.8216 - val_loss: 0.5325 - val_accuracy: 0.8045\n",
      "Epoch 492/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4808 - accuracy: 0.8174 - val_loss: 0.4970 - val_accuracy: 0.8045\n",
      "Epoch 493/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4901 - accuracy: 0.7992 - val_loss: 0.4861 - val_accuracy: 0.7989\n",
      "Epoch 494/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4737 - accuracy: 0.8216 - val_loss: 0.4908 - val_accuracy: 0.7765\n",
      "Epoch 495/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4748 - accuracy: 0.8315 - val_loss: 0.4842 - val_accuracy: 0.8045\n",
      "Epoch 496/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4837 - accuracy: 0.8118 - val_loss: 0.4585 - val_accuracy: 0.8436\n",
      "Epoch 497/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4592 - accuracy: 0.8315 - val_loss: 0.4874 - val_accuracy: 0.8212\n",
      "Epoch 498/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4805 - accuracy: 0.8146 - val_loss: 0.4808 - val_accuracy: 0.8045\n",
      "Epoch 499/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4867 - accuracy: 0.8216 - val_loss: 0.4863 - val_accuracy: 0.8268\n",
      "Epoch 500/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4751 - accuracy: 0.8202 - val_loss: 0.4824 - val_accuracy: 0.8212\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_Y, epochs=500, batch_size=32, validation_data=(dev_X, dev_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 - 0s - loss: 0.4293 - accuracy: 0.8399\n",
      "\n",
      "Train accuracy: 0.8398876\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(train_X, train_Y, verbose=2)\n",
    "\n",
    "print('\\nTrain accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 - 0s - loss: 0.4824 - accuracy: 0.8212\n",
      "\n",
      "Dev accuracy: 0.82122904\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(dev_X, dev_Y, verbose=2)\n",
    "\n",
    "print('\\nDev accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner import HyperModel\n",
    "\n",
    "# https://www.sicara.ai/blog/hyperparameter-tuning-keras-tuner\n",
    "# https://www.curiousily.com/posts/hackers-guide-to-hyperparameter-tuning/\n",
    "\n",
    "class TitanicHyperModel(HyperModel):\n",
    "    def __init__(self, input_size):\n",
    "        self.input_shape = (input_size, )\n",
    "\n",
    "    def build(self, hp):\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import Dense, Dropout\n",
    "#         from tensorflow.keras.regularizers import L1L2\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        for layer_n in range(hp.Int(\"num_layers\", min_value=1, max_value=6, step=1, default=6) + 1):\n",
    "            units = hp.Int(\n",
    "                f\"dense_units_{layer_n}\",\n",
    "                min_value=8,\n",
    "                max_value=64,\n",
    "                step=8,\n",
    "                default=64\n",
    "            )\n",
    "            activation = hp.Choice(\n",
    "                f\"dense_activation_{layer_n}\",\n",
    "                values=['relu', 'tanh', 'sigmoid'],\n",
    "                default='relu'\n",
    "            )\n",
    "#             regularizer_l1 = hp.Float(\n",
    "#                 f'l1_{layer_n}',\n",
    "#                 min_value=1e-5,\n",
    "#                 max_value=0.1,\n",
    "#                 sampling='LOG',\n",
    "#                 default=0\n",
    "#             )\n",
    "#             regularizer_l2 = hp.Float(\n",
    "#                 f'l2_{layer_n}',\n",
    "#                 min_value=1e-5,\n",
    "#                 max_value=0.1,\n",
    "#                 sampling='LOG',\n",
    "#                 default=0.01\n",
    "#             )\n",
    "            \n",
    "            input_shape_params = {\"input_shape\": self.input_shape} if layer_n == 0 else {}\n",
    "            model.add(Dense(units=units, **input_shape_params, activation=activation)) #, kernel_regularizer=L1L2(l1=regularizer_l1, l2=regularizer_l2)))\n",
    "            \n",
    "            droupout_rate = hp.Float(\n",
    "                f'dropout_{layer_n}',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            )\n",
    "            \n",
    "            model.add(Dropout(rate=droupout_rate))\n",
    "        \n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                hp.Float(\n",
    "                    'learning_rate',\n",
    "                    min_value=1e-4,\n",
    "                    max_value=1e-2,\n",
    "                    sampling='LOG',\n",
    "                    default=1e-3\n",
    "                )\n",
    "            ),\n",
    "            metrics=[\"accuracy\"],\n",
    "            loss=\"binary_crossentropy\",\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "hypermodel = TitanicHyperModel(input_size=train_X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dev mode\n",
    "\n",
    "if MODE == \"DEV\":\n",
    "    MAX_TRIALS = 20\n",
    "    EXECUTION_PER_TRIAL = 2\n",
    "    N_EPOCH_SEARCH = 20\n",
    "else:\n",
    "    MAX_TRIALS = 200\n",
    "    EXECUTION_PER_TRIAL = 3\n",
    "    N_EPOCH_SEARCH = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Default search space size: 23</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">num_layers (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_units_0 (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_activation_0 (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: ['relu', 'tanh', 'sigmoid']</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dropout_0 (Float)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_units_1 (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_activation_1 (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: ['relu', 'tanh', 'sigmoid']</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dropout_1 (Float)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_units_2 (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_activation_2 (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: ['relu', 'tanh', 'sigmoid']</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dropout_2 (Float)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_units_3 (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_activation_3 (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: ['relu', 'tanh', 'sigmoid']</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dropout_3 (Float)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_units_4 (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_activation_4 (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: ['relu', 'tanh', 'sigmoid']</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dropout_4 (Float)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_units_5 (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_activation_5 (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: ['relu', 'tanh', 'sigmoid']</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dropout_5 (Float)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_units_6 (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_activation_6 (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: ['relu', 'tanh', 'sigmoid']</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dropout_6 (Float)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Float)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: log</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "try:\n",
    "    ATTEMPT = ATTEMPT + 1\n",
    "except NameError:\n",
    "    ATTEMPT = 0\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective=\"val_accuracy\",\n",
    "    seed=SEED,\n",
    "    max_trials=MAX_TRIALS,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory=f'random_search_{ATTEMPT}',\n",
    "    project_name='titanic'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/400\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.9425 - accuracy: 0.6236 - val_loss: 0.8706 - val_accuracy: 0.5866\n",
      "Epoch 2/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.7507 - accuracy: 0.6236 - val_loss: 0.7165 - val_accuracy: 0.5866\n",
      "Epoch 3/400\n",
      "712/712 [==============================] - 0s 281us/sample - loss: 0.6738 - accuracy: 0.6236 - val_loss: 0.6782 - val_accuracy: 0.5866\n",
      "Epoch 4/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6585 - accuracy: 0.6236 - val_loss: 0.6566 - val_accuracy: 0.5866\n",
      "Epoch 5/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.6401 - accuracy: 0.6278 - val_loss: 0.6274 - val_accuracy: 0.5866\n",
      "Epoch 6/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.6102 - accuracy: 0.6278 - val_loss: 0.5960 - val_accuracy: 0.5866\n",
      "Epoch 7/400\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.5948 - accuracy: 0.6419 - val_loss: 0.5643 - val_accuracy: 0.7989\n",
      "Epoch 8/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5645 - accuracy: 0.6868 - val_loss: 0.5408 - val_accuracy: 0.7989\n",
      "Epoch 9/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5444 - accuracy: 0.7177 - val_loss: 0.5219 - val_accuracy: 0.7821\n",
      "Epoch 10/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5359 - accuracy: 0.7444 - val_loss: 0.5096 - val_accuracy: 0.7709\n",
      "Epoch 11/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5213 - accuracy: 0.7626 - val_loss: 0.4998 - val_accuracy: 0.7821\n",
      "Epoch 12/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5203 - accuracy: 0.7654 - val_loss: 0.4937 - val_accuracy: 0.7821\n",
      "Epoch 13/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5029 - accuracy: 0.7654 - val_loss: 0.4897 - val_accuracy: 0.7765\n",
      "Epoch 14/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4974 - accuracy: 0.7837 - val_loss: 0.4872 - val_accuracy: 0.7765\n",
      "Epoch 15/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4969 - accuracy: 0.7837 - val_loss: 0.4839 - val_accuracy: 0.7877\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4953 - accuracy: 0.7893 - val_loss: 0.4818 - val_accuracy: 0.7877\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4830 - accuracy: 0.7935 - val_loss: 0.4768 - val_accuracy: 0.7821\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4836 - accuracy: 0.8006 - val_loss: 0.4717 - val_accuracy: 0.7933\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.4691 - accuracy: 0.8160 - val_loss: 0.4677 - val_accuracy: 0.8101\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4607 - accuracy: 0.8202 - val_loss: 0.4625 - val_accuracy: 0.8045\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4561 - accuracy: 0.8272 - val_loss: 0.4589 - val_accuracy: 0.8045\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4573 - accuracy: 0.8174 - val_loss: 0.4551 - val_accuracy: 0.8045\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4540 - accuracy: 0.8258 - val_loss: 0.4543 - val_accuracy: 0.8101\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.4554 - accuracy: 0.8216 - val_loss: 0.4535 - val_accuracy: 0.8268\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4566 - accuracy: 0.8118 - val_loss: 0.4537 - val_accuracy: 0.8101\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4409 - accuracy: 0.8216 - val_loss: 0.4479 - val_accuracy: 0.8156\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4483 - accuracy: 0.8315 - val_loss: 0.4455 - val_accuracy: 0.8268\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4538 - accuracy: 0.8230 - val_loss: 0.4479 - val_accuracy: 0.8156\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4392 - accuracy: 0.8258 - val_loss: 0.4445 - val_accuracy: 0.8212\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4449 - accuracy: 0.8343 - val_loss: 0.4426 - val_accuracy: 0.8212\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4446 - accuracy: 0.8174 - val_loss: 0.4424 - val_accuracy: 0.8156\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4526 - accuracy: 0.8244 - val_loss: 0.4437 - val_accuracy: 0.8212\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4426 - accuracy: 0.8272 - val_loss: 0.4431 - val_accuracy: 0.8212\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4407 - accuracy: 0.8272 - val_loss: 0.4403 - val_accuracy: 0.8212\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4427 - accuracy: 0.8315 - val_loss: 0.4369 - val_accuracy: 0.8212\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4232 - accuracy: 0.8399 - val_loss: 0.4345 - val_accuracy: 0.8268\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4367 - accuracy: 0.8244 - val_loss: 0.4357 - val_accuracy: 0.8212\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4382 - accuracy: 0.8343 - val_loss: 0.4300 - val_accuracy: 0.8212\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 227us/sample - loss: 0.4237 - accuracy: 0.8441 - val_loss: 0.4297 - val_accuracy: 0.8212\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.4262 - accuracy: 0.8301 - val_loss: 0.4280 - val_accuracy: 0.8324\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.4410 - accuracy: 0.8272 - val_loss: 0.4281 - val_accuracy: 0.8324\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 224us/sample - loss: 0.4225 - accuracy: 0.8315 - val_loss: 0.4254 - val_accuracy: 0.8324\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 225us/sample - loss: 0.4262 - accuracy: 0.8258 - val_loss: 0.4285 - val_accuracy: 0.8212\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 279us/sample - loss: 0.4287 - accuracy: 0.8287 - val_loss: 0.4251 - val_accuracy: 0.8380\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4222 - accuracy: 0.8329 - val_loss: 0.4271 - val_accuracy: 0.8156\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4260 - accuracy: 0.8315 - val_loss: 0.4236 - val_accuracy: 0.8324\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4238 - accuracy: 0.8230 - val_loss: 0.4238 - val_accuracy: 0.8324\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4239 - accuracy: 0.8301 - val_loss: 0.4244 - val_accuracy: 0.8380\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4170 - accuracy: 0.8357 - val_loss: 0.4257 - val_accuracy: 0.8268\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4308 - accuracy: 0.8301 - val_loss: 0.4261 - val_accuracy: 0.8268\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4118 - accuracy: 0.8357 - val_loss: 0.4231 - val_accuracy: 0.8324\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4177 - accuracy: 0.8315 - val_loss: 0.4223 - val_accuracy: 0.8324\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4125 - accuracy: 0.8329 - val_loss: 0.4237 - val_accuracy: 0.8268\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4207 - accuracy: 0.8315 - val_loss: 0.4234 - val_accuracy: 0.8324\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4156 - accuracy: 0.8357 - val_loss: 0.4211 - val_accuracy: 0.8324\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4142 - accuracy: 0.8427 - val_loss: 0.4244 - val_accuracy: 0.8324\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4180 - accuracy: 0.8272 - val_loss: 0.4203 - val_accuracy: 0.8268\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4161 - accuracy: 0.8371 - val_loss: 0.4230 - val_accuracy: 0.8324\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4285 - accuracy: 0.8343 - val_loss: 0.4215 - val_accuracy: 0.8324\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4179 - accuracy: 0.8343 - val_loss: 0.4173 - val_accuracy: 0.8380\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4068 - accuracy: 0.8385 - val_loss: 0.4188 - val_accuracy: 0.8380\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4189 - accuracy: 0.8399 - val_loss: 0.4198 - val_accuracy: 0.8380\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4032 - accuracy: 0.8385 - val_loss: 0.4192 - val_accuracy: 0.8380\n",
      "Epoch 64/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4026 - accuracy: 0.8497 - val_loss: 0.4209 - val_accuracy: 0.8324\n",
      "Epoch 65/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4166 - accuracy: 0.8315 - val_loss: 0.4273 - val_accuracy: 0.8324\n",
      "Epoch 66/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4064 - accuracy: 0.8357 - val_loss: 0.4215 - val_accuracy: 0.8324\n",
      "Epoch 67/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4124 - accuracy: 0.8469 - val_loss: 0.4219 - val_accuracy: 0.8324\n",
      "Epoch 68/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3993 - accuracy: 0.8427 - val_loss: 0.4219 - val_accuracy: 0.8324\n",
      "Epoch 69/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4151 - accuracy: 0.8287 - val_loss: 0.4219 - val_accuracy: 0.8268\n",
      "Epoch 70/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4157 - accuracy: 0.8301 - val_loss: 0.4221 - val_accuracy: 0.8268\n",
      "Epoch 71/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4148 - accuracy: 0.8343 - val_loss: 0.4234 - val_accuracy: 0.8268\n",
      "Epoch 72/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4084 - accuracy: 0.8413 - val_loss: 0.4210 - val_accuracy: 0.8324\n",
      "Epoch 73/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4038 - accuracy: 0.8427 - val_loss: 0.4203 - val_accuracy: 0.8324\n",
      "Epoch 74/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4135 - accuracy: 0.8357 - val_loss: 0.4182 - val_accuracy: 0.8324\n",
      "Epoch 75/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4038 - accuracy: 0.8441 - val_loss: 0.4208 - val_accuracy: 0.8324\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4073 - accuracy: 0.8329 - val_loss: 0.4195 - val_accuracy: 0.8324\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4157 - accuracy: 0.8216 - val_loss: 0.4210 - val_accuracy: 0.8324\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4025 - accuracy: 0.8441 - val_loss: 0.4218 - val_accuracy: 0.8212\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3980 - accuracy: 0.8385 - val_loss: 0.4181 - val_accuracy: 0.8324\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4162 - accuracy: 0.8371 - val_loss: 0.4185 - val_accuracy: 0.8324\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4145 - accuracy: 0.8343 - val_loss: 0.4196 - val_accuracy: 0.8324\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3967 - accuracy: 0.8455 - val_loss: 0.4224 - val_accuracy: 0.8212\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3993 - accuracy: 0.8427 - val_loss: 0.4240 - val_accuracy: 0.8268\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4137 - accuracy: 0.8371 - val_loss: 0.4203 - val_accuracy: 0.8324\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4052 - accuracy: 0.8385 - val_loss: 0.4188 - val_accuracy: 0.8324\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4120 - accuracy: 0.8399 - val_loss: 0.4215 - val_accuracy: 0.8380\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4020 - accuracy: 0.8343 - val_loss: 0.4210 - val_accuracy: 0.8324\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4149 - accuracy: 0.8315 - val_loss: 0.4203 - val_accuracy: 0.8324\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4028 - accuracy: 0.8244 - val_loss: 0.4203 - val_accuracy: 0.8324\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4090 - accuracy: 0.8258 - val_loss: 0.4210 - val_accuracy: 0.8268\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4061 - accuracy: 0.8413 - val_loss: 0.4220 - val_accuracy: 0.8324\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4029 - accuracy: 0.8441 - val_loss: 0.4240 - val_accuracy: 0.8212\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4048 - accuracy: 0.8329 - val_loss: 0.4231 - val_accuracy: 0.8380\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4162 - accuracy: 0.8329 - val_loss: 0.4224 - val_accuracy: 0.8380\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3987 - accuracy: 0.8427 - val_loss: 0.4211 - val_accuracy: 0.8324\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3841 - accuracy: 0.8525 - val_loss: 0.4210 - val_accuracy: 0.8324\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3950 - accuracy: 0.8455 - val_loss: 0.4215 - val_accuracy: 0.8268\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4060 - accuracy: 0.8385 - val_loss: 0.4204 - val_accuracy: 0.8324\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.3887 - accuracy: 0.8469 - val_loss: 0.4225 - val_accuracy: 0.8324\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4092 - accuracy: 0.8343 - val_loss: 0.4227 - val_accuracy: 0.8324\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4049 - accuracy: 0.8357 - val_loss: 0.4216 - val_accuracy: 0.8324\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3948 - accuracy: 0.8413 - val_loss: 0.4219 - val_accuracy: 0.8324\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3888 - accuracy: 0.8567 - val_loss: 0.4213 - val_accuracy: 0.8380\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4006 - accuracy: 0.8441 - val_loss: 0.4208 - val_accuracy: 0.8380\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3916 - accuracy: 0.8413 - val_loss: 0.4211 - val_accuracy: 0.8324\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4061 - accuracy: 0.8357 - val_loss: 0.4214 - val_accuracy: 0.8324\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4004 - accuracy: 0.8399 - val_loss: 0.4215 - val_accuracy: 0.8324\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3818 - accuracy: 0.8511 - val_loss: 0.4225 - val_accuracy: 0.8324\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4062 - accuracy: 0.8230 - val_loss: 0.4221 - val_accuracy: 0.8324\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4018 - accuracy: 0.8329 - val_loss: 0.4229 - val_accuracy: 0.8324\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4054 - accuracy: 0.8385 - val_loss: 0.4246 - val_accuracy: 0.8156\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4050 - accuracy: 0.8301 - val_loss: 0.4236 - val_accuracy: 0.8212\n",
      "Epoch 113/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3972 - accuracy: 0.8427 - val_loss: 0.4206 - val_accuracy: 0.8324\n",
      "Epoch 114/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3947 - accuracy: 0.8385 - val_loss: 0.4222 - val_accuracy: 0.8380\n",
      "Epoch 115/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3973 - accuracy: 0.8371 - val_loss: 0.4250 - val_accuracy: 0.8156\n",
      "Epoch 116/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4057 - accuracy: 0.8371 - val_loss: 0.4253 - val_accuracy: 0.8324\n",
      "Epoch 117/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3994 - accuracy: 0.8301 - val_loss: 0.4209 - val_accuracy: 0.8324\n",
      "Epoch 118/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3879 - accuracy: 0.8455 - val_loss: 0.4200 - val_accuracy: 0.8380\n",
      "Epoch 119/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3997 - accuracy: 0.8315 - val_loss: 0.4193 - val_accuracy: 0.8324\n",
      "Epoch 120/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3837 - accuracy: 0.8427 - val_loss: 0.4186 - val_accuracy: 0.8324\n",
      "Epoch 121/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3945 - accuracy: 0.8371 - val_loss: 0.4175 - val_accuracy: 0.8212\n",
      "Epoch 122/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3925 - accuracy: 0.8357 - val_loss: 0.4182 - val_accuracy: 0.8324\n",
      "Epoch 123/400\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.3921 - accuracy: 0.8469 - val_loss: 0.4200 - val_accuracy: 0.8324\n",
      "Epoch 124/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3822 - accuracy: 0.8483 - val_loss: 0.4194 - val_accuracy: 0.8380\n",
      "Epoch 125/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3959 - accuracy: 0.8371 - val_loss: 0.4167 - val_accuracy: 0.8324\n",
      "Epoch 126/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3938 - accuracy: 0.8371 - val_loss: 0.4209 - val_accuracy: 0.8268\n",
      "Epoch 127/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3887 - accuracy: 0.8427 - val_loss: 0.4207 - val_accuracy: 0.8268\n",
      "Epoch 128/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3966 - accuracy: 0.8413 - val_loss: 0.4193 - val_accuracy: 0.8268\n",
      "Epoch 129/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3929 - accuracy: 0.8399 - val_loss: 0.4170 - val_accuracy: 0.8380\n",
      "Epoch 130/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3921 - accuracy: 0.8441 - val_loss: 0.4161 - val_accuracy: 0.8380\n",
      "Epoch 131/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3899 - accuracy: 0.8441 - val_loss: 0.4157 - val_accuracy: 0.8324\n",
      "Epoch 132/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3842 - accuracy: 0.8497 - val_loss: 0.4149 - val_accuracy: 0.8324\n",
      "Epoch 133/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3938 - accuracy: 0.8371 - val_loss: 0.4166 - val_accuracy: 0.8380\n",
      "Epoch 134/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3966 - accuracy: 0.8399 - val_loss: 0.4151 - val_accuracy: 0.8324\n",
      "Epoch 135/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3968 - accuracy: 0.8385 - val_loss: 0.4154 - val_accuracy: 0.8324\n",
      "Epoch 136/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3913 - accuracy: 0.8469 - val_loss: 0.4184 - val_accuracy: 0.8324\n",
      "Epoch 137/400\n",
      "712/712 [==============================] - 0s 226us/sample - loss: 0.3824 - accuracy: 0.8427 - val_loss: 0.4202 - val_accuracy: 0.8324\n",
      "Epoch 138/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3910 - accuracy: 0.8399 - val_loss: 0.4163 - val_accuracy: 0.8324\n",
      "Epoch 139/400\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.3933 - accuracy: 0.8329 - val_loss: 0.4173 - val_accuracy: 0.8324\n",
      "Epoch 140/400\n",
      "712/712 [==============================] - 0s 204us/sample - loss: 0.3874 - accuracy: 0.8497 - val_loss: 0.4148 - val_accuracy: 0.8324\n",
      "Epoch 141/400\n",
      "712/712 [==============================] - 0s 245us/sample - loss: 0.3893 - accuracy: 0.8455 - val_loss: 0.4144 - val_accuracy: 0.8324\n",
      "Epoch 142/400\n",
      "712/712 [==============================] - 0s 231us/sample - loss: 0.3960 - accuracy: 0.8301 - val_loss: 0.4148 - val_accuracy: 0.8380\n",
      "Epoch 143/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3958 - accuracy: 0.8343 - val_loss: 0.4169 - val_accuracy: 0.8324\n",
      "Epoch 144/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3883 - accuracy: 0.8427 - val_loss: 0.4154 - val_accuracy: 0.8324\n",
      "Epoch 145/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3854 - accuracy: 0.8567 - val_loss: 0.4148 - val_accuracy: 0.8324\n",
      "Epoch 146/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3905 - accuracy: 0.8427 - val_loss: 0.4170 - val_accuracy: 0.8324\n",
      "Epoch 147/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3854 - accuracy: 0.8553 - val_loss: 0.4183 - val_accuracy: 0.8324\n",
      "Epoch 148/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4002 - accuracy: 0.8258 - val_loss: 0.4167 - val_accuracy: 0.8324\n",
      "Epoch 149/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3886 - accuracy: 0.8427 - val_loss: 0.4147 - val_accuracy: 0.8324\n",
      "Epoch 150/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3868 - accuracy: 0.8483 - val_loss: 0.4154 - val_accuracy: 0.8324\n",
      "Epoch 151/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3919 - accuracy: 0.8371 - val_loss: 0.4144 - val_accuracy: 0.8268\n",
      "Epoch 152/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4000 - accuracy: 0.8301 - val_loss: 0.4156 - val_accuracy: 0.8268\n",
      "Epoch 153/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3937 - accuracy: 0.8272 - val_loss: 0.4174 - val_accuracy: 0.8268\n",
      "Epoch 154/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3942 - accuracy: 0.8315 - val_loss: 0.4183 - val_accuracy: 0.8268\n",
      "Epoch 155/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3901 - accuracy: 0.8357 - val_loss: 0.4169 - val_accuracy: 0.8268\n",
      "Epoch 156/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3800 - accuracy: 0.8427 - val_loss: 0.4142 - val_accuracy: 0.8268\n",
      "Epoch 157/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3864 - accuracy: 0.8427 - val_loss: 0.4129 - val_accuracy: 0.8324\n",
      "Epoch 158/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3860 - accuracy: 0.8413 - val_loss: 0.4129 - val_accuracy: 0.8324\n",
      "Epoch 159/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3797 - accuracy: 0.8427 - val_loss: 0.4151 - val_accuracy: 0.8324\n",
      "Epoch 160/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3831 - accuracy: 0.8385 - val_loss: 0.4151 - val_accuracy: 0.8324\n",
      "Epoch 161/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3878 - accuracy: 0.8455 - val_loss: 0.4148 - val_accuracy: 0.8324\n",
      "Epoch 162/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3825 - accuracy: 0.8469 - val_loss: 0.4148 - val_accuracy: 0.8324\n",
      "Epoch 163/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3922 - accuracy: 0.8441 - val_loss: 0.4159 - val_accuracy: 0.8324\n",
      "Epoch 164/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3849 - accuracy: 0.8483 - val_loss: 0.4166 - val_accuracy: 0.8324\n",
      "Epoch 165/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3881 - accuracy: 0.8441 - val_loss: 0.4181 - val_accuracy: 0.8268\n",
      "Epoch 166/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3871 - accuracy: 0.8385 - val_loss: 0.4153 - val_accuracy: 0.8324\n",
      "Epoch 167/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3888 - accuracy: 0.8441 - val_loss: 0.4171 - val_accuracy: 0.8212\n",
      "Epoch 168/400\n",
      "712/712 [==============================] - 0s 336us/sample - loss: 0.3864 - accuracy: 0.8483 - val_loss: 0.4140 - val_accuracy: 0.8268\n",
      "Epoch 169/400\n",
      "712/712 [==============================] - 0s 277us/sample - loss: 0.3866 - accuracy: 0.8441 - val_loss: 0.4158 - val_accuracy: 0.8324\n",
      "Epoch 170/400\n",
      "712/712 [==============================] - 0s 290us/sample - loss: 0.3891 - accuracy: 0.8399 - val_loss: 0.4160 - val_accuracy: 0.8324\n",
      "Epoch 171/400\n",
      "712/712 [==============================] - 0s 244us/sample - loss: 0.3785 - accuracy: 0.8497 - val_loss: 0.4189 - val_accuracy: 0.8324\n",
      "Epoch 172/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3871 - accuracy: 0.8413 - val_loss: 0.4234 - val_accuracy: 0.8268\n",
      "Epoch 173/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3896 - accuracy: 0.8385 - val_loss: 0.4192 - val_accuracy: 0.8268\n",
      "Epoch 174/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3853 - accuracy: 0.8539 - val_loss: 0.4163 - val_accuracy: 0.8324\n",
      "Epoch 175/400\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.3816 - accuracy: 0.8427 - val_loss: 0.4191 - val_accuracy: 0.8380\n",
      "Epoch 176/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3797 - accuracy: 0.8497 - val_loss: 0.4221 - val_accuracy: 0.8268\n",
      "Epoch 177/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3822 - accuracy: 0.8455 - val_loss: 0.4216 - val_accuracy: 0.8212\n",
      "Epoch 178/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3795 - accuracy: 0.8511 - val_loss: 0.4205 - val_accuracy: 0.8268\n",
      "Epoch 179/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3884 - accuracy: 0.8371 - val_loss: 0.4199 - val_accuracy: 0.8156\n",
      "Epoch 180/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3775 - accuracy: 0.8455 - val_loss: 0.4194 - val_accuracy: 0.8268\n",
      "Epoch 181/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3855 - accuracy: 0.8371 - val_loss: 0.4207 - val_accuracy: 0.8212\n",
      "Epoch 182/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3847 - accuracy: 0.8315 - val_loss: 0.4223 - val_accuracy: 0.8212\n",
      "Epoch 183/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3770 - accuracy: 0.8497 - val_loss: 0.4245 - val_accuracy: 0.8212\n",
      "Epoch 184/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3806 - accuracy: 0.8483 - val_loss: 0.4157 - val_accuracy: 0.8268\n",
      "Epoch 185/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3840 - accuracy: 0.8399 - val_loss: 0.4191 - val_accuracy: 0.8212\n",
      "Epoch 186/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3852 - accuracy: 0.8427 - val_loss: 0.4137 - val_accuracy: 0.8268\n",
      "Epoch 187/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3837 - accuracy: 0.8469 - val_loss: 0.4126 - val_accuracy: 0.8268\n",
      "Epoch 188/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3756 - accuracy: 0.8371 - val_loss: 0.4128 - val_accuracy: 0.8268\n",
      "Epoch 189/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3847 - accuracy: 0.8427 - val_loss: 0.4157 - val_accuracy: 0.8324\n",
      "Epoch 190/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3867 - accuracy: 0.8357 - val_loss: 0.4155 - val_accuracy: 0.8212\n",
      "Epoch 191/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3936 - accuracy: 0.8385 - val_loss: 0.4142 - val_accuracy: 0.8268\n",
      "Epoch 192/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3839 - accuracy: 0.8441 - val_loss: 0.4146 - val_accuracy: 0.8324\n",
      "Epoch 193/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3821 - accuracy: 0.8343 - val_loss: 0.4172 - val_accuracy: 0.8268\n",
      "Epoch 194/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.3900 - accuracy: 0.8399 - val_loss: 0.4189 - val_accuracy: 0.8268\n",
      "Epoch 195/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3931 - accuracy: 0.8371 - val_loss: 0.4183 - val_accuracy: 0.8324\n",
      "Epoch 196/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3799 - accuracy: 0.8455 - val_loss: 0.4173 - val_accuracy: 0.8380\n",
      "Epoch 197/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3848 - accuracy: 0.8301 - val_loss: 0.4172 - val_accuracy: 0.8324\n",
      "Epoch 198/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3824 - accuracy: 0.8469 - val_loss: 0.4168 - val_accuracy: 0.8268\n",
      "Epoch 199/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3866 - accuracy: 0.8441 - val_loss: 0.4202 - val_accuracy: 0.8324\n",
      "Epoch 200/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3803 - accuracy: 0.8427 - val_loss: 0.4197 - val_accuracy: 0.8324\n",
      "Epoch 201/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3908 - accuracy: 0.8343 - val_loss: 0.4179 - val_accuracy: 0.8324\n",
      "Epoch 202/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3903 - accuracy: 0.8413 - val_loss: 0.4175 - val_accuracy: 0.8268\n",
      "Epoch 203/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3765 - accuracy: 0.8596 - val_loss: 0.4177 - val_accuracy: 0.8268\n",
      "Epoch 204/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3766 - accuracy: 0.8427 - val_loss: 0.4214 - val_accuracy: 0.8268\n",
      "Epoch 205/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3684 - accuracy: 0.8638 - val_loss: 0.4207 - val_accuracy: 0.8268\n",
      "Epoch 206/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3834 - accuracy: 0.8371 - val_loss: 0.4180 - val_accuracy: 0.8268\n",
      "Epoch 207/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3736 - accuracy: 0.8413 - val_loss: 0.4168 - val_accuracy: 0.8324\n",
      "Epoch 208/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3868 - accuracy: 0.8399 - val_loss: 0.4172 - val_accuracy: 0.8324\n",
      "Epoch 209/400\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.3823 - accuracy: 0.8441 - val_loss: 0.4177 - val_accuracy: 0.8324\n",
      "Epoch 210/400\n",
      "712/712 [==============================] - 0s 321us/sample - loss: 0.3777 - accuracy: 0.8553 - val_loss: 0.4178 - val_accuracy: 0.8212\n",
      "Epoch 211/400\n",
      "712/712 [==============================] - 0s 280us/sample - loss: 0.3775 - accuracy: 0.8455 - val_loss: 0.4174 - val_accuracy: 0.8324\n",
      "Epoch 212/400\n",
      "712/712 [==============================] - 0s 238us/sample - loss: 0.3757 - accuracy: 0.8385 - val_loss: 0.4172 - val_accuracy: 0.8212\n",
      "Epoch 213/400\n",
      "712/712 [==============================] - 0s 225us/sample - loss: 0.3702 - accuracy: 0.8497 - val_loss: 0.4158 - val_accuracy: 0.8324\n",
      "Epoch 214/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.3728 - accuracy: 0.8483 - val_loss: 0.4179 - val_accuracy: 0.8324\n",
      "Epoch 215/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3867 - accuracy: 0.8441 - val_loss: 0.4185 - val_accuracy: 0.8268\n",
      "Epoch 216/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3643 - accuracy: 0.8525 - val_loss: 0.4153 - val_accuracy: 0.8380\n",
      "Epoch 217/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3720 - accuracy: 0.8581 - val_loss: 0.4197 - val_accuracy: 0.8324\n",
      "Epoch 218/400\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.3796 - accuracy: 0.8329 - val_loss: 0.4128 - val_accuracy: 0.8212\n",
      "Epoch 219/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3831 - accuracy: 0.8441 - val_loss: 0.4127 - val_accuracy: 0.8324\n",
      "Epoch 220/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3825 - accuracy: 0.8427 - val_loss: 0.4166 - val_accuracy: 0.8212\n",
      "Epoch 221/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3830 - accuracy: 0.8385 - val_loss: 0.4128 - val_accuracy: 0.8324\n",
      "Epoch 222/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3681 - accuracy: 0.8469 - val_loss: 0.4116 - val_accuracy: 0.8324\n",
      "Epoch 223/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3757 - accuracy: 0.8455 - val_loss: 0.4112 - val_accuracy: 0.8324\n",
      "Epoch 224/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3767 - accuracy: 0.8455 - val_loss: 0.4136 - val_accuracy: 0.8268\n",
      "Epoch 225/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3786 - accuracy: 0.8497 - val_loss: 0.4121 - val_accuracy: 0.8324\n",
      "Epoch 226/400\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.3824 - accuracy: 0.8497 - val_loss: 0.4128 - val_accuracy: 0.8324\n",
      "Epoch 227/400\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.3751 - accuracy: 0.8455 - val_loss: 0.4148 - val_accuracy: 0.8324\n",
      "Epoch 228/400\n",
      "712/712 [==============================] - 0s 226us/sample - loss: 0.3797 - accuracy: 0.8441 - val_loss: 0.4144 - val_accuracy: 0.8268\n",
      "Epoch 229/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3831 - accuracy: 0.8399 - val_loss: 0.4134 - val_accuracy: 0.8324\n",
      "Epoch 230/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3821 - accuracy: 0.8427 - val_loss: 0.4150 - val_accuracy: 0.8212\n",
      "Epoch 231/400\n",
      "712/712 [==============================] - 0s 231us/sample - loss: 0.3855 - accuracy: 0.8441 - val_loss: 0.4172 - val_accuracy: 0.8268\n",
      "Epoch 232/400\n",
      "712/712 [==============================] - 0s 237us/sample - loss: 0.3913 - accuracy: 0.8385 - val_loss: 0.4141 - val_accuracy: 0.8324\n",
      "Epoch 233/400\n",
      "712/712 [==============================] - 0s 269us/sample - loss: 0.3755 - accuracy: 0.8483 - val_loss: 0.4149 - val_accuracy: 0.8268\n",
      "Epoch 234/400\n",
      "712/712 [==============================] - 0s 195us/sample - loss: 0.3796 - accuracy: 0.8315 - val_loss: 0.4173 - val_accuracy: 0.8268\n",
      "Epoch 235/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.3831 - accuracy: 0.8385 - val_loss: 0.4179 - val_accuracy: 0.8268\n",
      "Epoch 236/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3857 - accuracy: 0.8371 - val_loss: 0.4178 - val_accuracy: 0.8324\n",
      "Epoch 237/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3884 - accuracy: 0.8301 - val_loss: 0.4176 - val_accuracy: 0.8324\n",
      "Epoch 238/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3726 - accuracy: 0.8483 - val_loss: 0.4189 - val_accuracy: 0.8268\n",
      "Epoch 239/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3787 - accuracy: 0.8497 - val_loss: 0.4206 - val_accuracy: 0.8268\n",
      "Epoch 240/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3883 - accuracy: 0.8329 - val_loss: 0.4202 - val_accuracy: 0.8324\n",
      "Epoch 241/400\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.3799 - accuracy: 0.8427 - val_loss: 0.4205 - val_accuracy: 0.8268\n",
      "Epoch 242/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3943 - accuracy: 0.8357 - val_loss: 0.4193 - val_accuracy: 0.8268\n",
      "Epoch 243/400\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.3763 - accuracy: 0.8441 - val_loss: 0.4165 - val_accuracy: 0.8324\n",
      "Epoch 244/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.3862 - accuracy: 0.8427 - val_loss: 0.4175 - val_accuracy: 0.8212\n",
      "Epoch 245/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3810 - accuracy: 0.8385 - val_loss: 0.4139 - val_accuracy: 0.8268\n",
      "Epoch 246/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3775 - accuracy: 0.8385 - val_loss: 0.4127 - val_accuracy: 0.8324\n",
      "Epoch 247/400\n",
      "712/712 [==============================] - 0s 224us/sample - loss: 0.3931 - accuracy: 0.8315 - val_loss: 0.4136 - val_accuracy: 0.8324\n",
      "Epoch 248/400\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.3758 - accuracy: 0.8469 - val_loss: 0.4137 - val_accuracy: 0.8324\n",
      "Epoch 249/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3781 - accuracy: 0.8385 - val_loss: 0.4132 - val_accuracy: 0.8324\n",
      "Epoch 250/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3700 - accuracy: 0.8553 - val_loss: 0.4132 - val_accuracy: 0.8324\n",
      "Epoch 251/400\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.3775 - accuracy: 0.8469 - val_loss: 0.4130 - val_accuracy: 0.8268\n",
      "Epoch 252/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3831 - accuracy: 0.8385 - val_loss: 0.4133 - val_accuracy: 0.8324\n",
      "Epoch 253/400\n",
      "712/712 [==============================] - 0s 204us/sample - loss: 0.3769 - accuracy: 0.8483 - val_loss: 0.4143 - val_accuracy: 0.8324\n",
      "Epoch 254/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.3804 - accuracy: 0.8511 - val_loss: 0.4139 - val_accuracy: 0.8324\n",
      "Epoch 255/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3804 - accuracy: 0.8525 - val_loss: 0.4155 - val_accuracy: 0.8324\n",
      "Epoch 256/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3705 - accuracy: 0.8427 - val_loss: 0.4159 - val_accuracy: 0.8268\n",
      "Epoch 257/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3779 - accuracy: 0.8301 - val_loss: 0.4189 - val_accuracy: 0.8268\n",
      "Epoch 258/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3713 - accuracy: 0.8469 - val_loss: 0.4167 - val_accuracy: 0.8324\n",
      "Epoch 259/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3819 - accuracy: 0.8399 - val_loss: 0.4153 - val_accuracy: 0.8268\n",
      "Epoch 260/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3851 - accuracy: 0.8371 - val_loss: 0.4147 - val_accuracy: 0.8268\n",
      "Epoch 261/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3771 - accuracy: 0.8329 - val_loss: 0.4153 - val_accuracy: 0.8324\n",
      "Epoch 262/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3788 - accuracy: 0.8385 - val_loss: 0.4145 - val_accuracy: 0.8324\n",
      "Epoch 263/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3816 - accuracy: 0.8441 - val_loss: 0.4132 - val_accuracy: 0.8268\n",
      "Epoch 264/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3693 - accuracy: 0.8455 - val_loss: 0.4158 - val_accuracy: 0.8268\n",
      "Epoch 265/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3855 - accuracy: 0.8413 - val_loss: 0.4178 - val_accuracy: 0.8268\n",
      "Epoch 266/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3837 - accuracy: 0.8371 - val_loss: 0.4184 - val_accuracy: 0.8324\n",
      "Epoch 267/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3815 - accuracy: 0.8427 - val_loss: 0.4169 - val_accuracy: 0.8324\n",
      "Epoch 268/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3736 - accuracy: 0.8441 - val_loss: 0.4166 - val_accuracy: 0.8268\n",
      "Epoch 269/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3827 - accuracy: 0.8399 - val_loss: 0.4162 - val_accuracy: 0.8268\n",
      "Epoch 270/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3700 - accuracy: 0.8441 - val_loss: 0.4164 - val_accuracy: 0.8268\n",
      "Epoch 271/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3761 - accuracy: 0.8455 - val_loss: 0.4190 - val_accuracy: 0.8268\n",
      "Epoch 272/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3751 - accuracy: 0.8567 - val_loss: 0.4236 - val_accuracy: 0.8156\n",
      "Epoch 273/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3839 - accuracy: 0.8413 - val_loss: 0.4171 - val_accuracy: 0.8268\n",
      "Epoch 274/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3816 - accuracy: 0.8441 - val_loss: 0.4166 - val_accuracy: 0.8212\n",
      "Epoch 275/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3719 - accuracy: 0.8511 - val_loss: 0.4160 - val_accuracy: 0.8268\n",
      "Epoch 276/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3798 - accuracy: 0.8497 - val_loss: 0.4172 - val_accuracy: 0.8268\n",
      "Epoch 277/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.3840 - accuracy: 0.8483 - val_loss: 0.4139 - val_accuracy: 0.8324\n",
      "Epoch 278/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3747 - accuracy: 0.8441 - val_loss: 0.4120 - val_accuracy: 0.8324\n",
      "Epoch 279/400\n",
      "712/712 [==============================] - 0s 221us/sample - loss: 0.3703 - accuracy: 0.8497 - val_loss: 0.4098 - val_accuracy: 0.8324\n",
      "Epoch 280/400\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.3847 - accuracy: 0.8357 - val_loss: 0.4127 - val_accuracy: 0.8324\n",
      "Epoch 281/400\n",
      "712/712 [==============================] - 0s 252us/sample - loss: 0.3740 - accuracy: 0.8385 - val_loss: 0.4109 - val_accuracy: 0.8324\n",
      "Epoch 282/400\n",
      "712/712 [==============================] - 0s 193us/sample - loss: 0.3670 - accuracy: 0.8553 - val_loss: 0.4154 - val_accuracy: 0.8268\n",
      "Epoch 283/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3734 - accuracy: 0.8385 - val_loss: 0.4154 - val_accuracy: 0.8324\n",
      "Epoch 284/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3777 - accuracy: 0.8357 - val_loss: 0.4166 - val_accuracy: 0.8324\n",
      "Epoch 285/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3814 - accuracy: 0.8385 - val_loss: 0.4169 - val_accuracy: 0.8324\n",
      "Epoch 286/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3740 - accuracy: 0.8469 - val_loss: 0.4184 - val_accuracy: 0.8268\n",
      "Epoch 287/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3701 - accuracy: 0.8539 - val_loss: 0.4161 - val_accuracy: 0.8212\n",
      "Epoch 288/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3866 - accuracy: 0.8427 - val_loss: 0.4142 - val_accuracy: 0.8212\n",
      "Epoch 289/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3830 - accuracy: 0.8385 - val_loss: 0.4135 - val_accuracy: 0.8268\n",
      "Epoch 290/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3773 - accuracy: 0.8497 - val_loss: 0.4123 - val_accuracy: 0.8268\n",
      "Epoch 291/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3703 - accuracy: 0.8441 - val_loss: 0.4177 - val_accuracy: 0.8268\n",
      "Epoch 292/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3858 - accuracy: 0.8357 - val_loss: 0.4155 - val_accuracy: 0.8268\n",
      "Epoch 293/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3747 - accuracy: 0.8441 - val_loss: 0.4132 - val_accuracy: 0.8324\n",
      "Epoch 294/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3592 - accuracy: 0.8581 - val_loss: 0.4180 - val_accuracy: 0.8268\n",
      "Epoch 295/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3770 - accuracy: 0.8525 - val_loss: 0.4167 - val_accuracy: 0.8324\n",
      "Epoch 296/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3720 - accuracy: 0.8567 - val_loss: 0.4164 - val_accuracy: 0.8324\n",
      "Epoch 297/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3643 - accuracy: 0.8427 - val_loss: 0.4154 - val_accuracy: 0.8380\n",
      "Epoch 298/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3747 - accuracy: 0.8441 - val_loss: 0.4175 - val_accuracy: 0.8101\n",
      "Epoch 299/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3809 - accuracy: 0.8315 - val_loss: 0.4119 - val_accuracy: 0.8268\n",
      "Epoch 300/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3747 - accuracy: 0.8455 - val_loss: 0.4098 - val_accuracy: 0.8324\n",
      "Epoch 301/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3654 - accuracy: 0.8441 - val_loss: 0.4074 - val_accuracy: 0.8324\n",
      "Epoch 302/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3824 - accuracy: 0.8399 - val_loss: 0.4109 - val_accuracy: 0.8212\n",
      "Epoch 303/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3685 - accuracy: 0.8357 - val_loss: 0.4072 - val_accuracy: 0.8268\n",
      "Epoch 304/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3662 - accuracy: 0.8652 - val_loss: 0.4072 - val_accuracy: 0.8324\n",
      "Epoch 305/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3759 - accuracy: 0.8399 - val_loss: 0.4088 - val_accuracy: 0.8268\n",
      "Epoch 306/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3853 - accuracy: 0.8413 - val_loss: 0.4096 - val_accuracy: 0.8324\n",
      "Epoch 307/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3786 - accuracy: 0.8427 - val_loss: 0.4097 - val_accuracy: 0.8268\n",
      "Epoch 308/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3807 - accuracy: 0.8287 - val_loss: 0.4088 - val_accuracy: 0.8268\n",
      "Epoch 309/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3846 - accuracy: 0.8371 - val_loss: 0.4120 - val_accuracy: 0.8212\n",
      "Epoch 310/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3777 - accuracy: 0.8343 - val_loss: 0.4112 - val_accuracy: 0.8268\n",
      "Epoch 311/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3813 - accuracy: 0.8343 - val_loss: 0.4121 - val_accuracy: 0.8268\n",
      "Epoch 312/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3740 - accuracy: 0.8357 - val_loss: 0.4122 - val_accuracy: 0.8268\n",
      "Epoch 313/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3732 - accuracy: 0.8427 - val_loss: 0.4121 - val_accuracy: 0.8156\n",
      "Epoch 314/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3814 - accuracy: 0.8399 - val_loss: 0.4120 - val_accuracy: 0.8212\n",
      "Epoch 315/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3856 - accuracy: 0.8371 - val_loss: 0.4122 - val_accuracy: 0.8212\n",
      "Epoch 316/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3771 - accuracy: 0.8413 - val_loss: 0.4115 - val_accuracy: 0.8324\n",
      "Epoch 317/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3791 - accuracy: 0.8455 - val_loss: 0.4113 - val_accuracy: 0.8324\n",
      "Epoch 318/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3746 - accuracy: 0.8455 - val_loss: 0.4126 - val_accuracy: 0.8212\n",
      "Epoch 319/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3809 - accuracy: 0.8469 - val_loss: 0.4101 - val_accuracy: 0.8268\n",
      "Epoch 320/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3716 - accuracy: 0.8455 - val_loss: 0.4097 - val_accuracy: 0.8268\n",
      "Epoch 321/400\n",
      "712/712 [==============================] - 0s 205us/sample - loss: 0.3690 - accuracy: 0.8399 - val_loss: 0.4102 - val_accuracy: 0.8380\n",
      "Epoch 322/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3834 - accuracy: 0.8272 - val_loss: 0.4111 - val_accuracy: 0.8324\n",
      "Epoch 323/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3796 - accuracy: 0.8469 - val_loss: 0.4112 - val_accuracy: 0.8324\n",
      "Epoch 324/400\n",
      "712/712 [==============================] - 0s 260us/sample - loss: 0.3641 - accuracy: 0.8596 - val_loss: 0.4154 - val_accuracy: 0.8212\n",
      "Epoch 325/400\n",
      "712/712 [==============================] - 0s 245us/sample - loss: 0.3731 - accuracy: 0.8497 - val_loss: 0.4131 - val_accuracy: 0.8156\n",
      "Epoch 326/400\n",
      "712/712 [==============================] - 0s 220us/sample - loss: 0.3748 - accuracy: 0.8539 - val_loss: 0.4121 - val_accuracy: 0.8324\n",
      "Epoch 327/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3674 - accuracy: 0.8441 - val_loss: 0.4134 - val_accuracy: 0.8268\n",
      "Epoch 328/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3668 - accuracy: 0.8539 - val_loss: 0.4151 - val_accuracy: 0.8324\n",
      "Epoch 329/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3736 - accuracy: 0.8455 - val_loss: 0.4169 - val_accuracy: 0.8268\n",
      "Epoch 330/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3740 - accuracy: 0.8441 - val_loss: 0.4137 - val_accuracy: 0.8268\n",
      "Epoch 331/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3732 - accuracy: 0.8525 - val_loss: 0.4145 - val_accuracy: 0.8212\n",
      "Epoch 332/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3676 - accuracy: 0.8525 - val_loss: 0.4100 - val_accuracy: 0.8324\n",
      "Epoch 333/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3776 - accuracy: 0.8357 - val_loss: 0.4061 - val_accuracy: 0.8324\n",
      "Epoch 334/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3648 - accuracy: 0.8525 - val_loss: 0.4074 - val_accuracy: 0.8268\n",
      "Epoch 335/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3750 - accuracy: 0.8385 - val_loss: 0.4092 - val_accuracy: 0.8380\n",
      "Epoch 336/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3765 - accuracy: 0.8497 - val_loss: 0.4135 - val_accuracy: 0.8268\n",
      "Epoch 337/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3689 - accuracy: 0.8371 - val_loss: 0.4104 - val_accuracy: 0.8324\n",
      "Epoch 338/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3734 - accuracy: 0.8413 - val_loss: 0.4102 - val_accuracy: 0.8380\n",
      "Epoch 339/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3792 - accuracy: 0.8371 - val_loss: 0.4070 - val_accuracy: 0.8324\n",
      "Epoch 340/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3667 - accuracy: 0.8427 - val_loss: 0.4093 - val_accuracy: 0.8212\n",
      "Epoch 341/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3741 - accuracy: 0.8455 - val_loss: 0.4080 - val_accuracy: 0.8324\n",
      "Epoch 342/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3712 - accuracy: 0.8553 - val_loss: 0.4088 - val_accuracy: 0.8212\n",
      "Epoch 343/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3663 - accuracy: 0.8497 - val_loss: 0.4111 - val_accuracy: 0.8212\n",
      "Epoch 344/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3624 - accuracy: 0.8553 - val_loss: 0.4114 - val_accuracy: 0.8324\n",
      "Epoch 345/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3737 - accuracy: 0.8469 - val_loss: 0.4130 - val_accuracy: 0.8268\n",
      "Epoch 346/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3725 - accuracy: 0.8539 - val_loss: 0.4170 - val_accuracy: 0.8156\n",
      "Epoch 347/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3771 - accuracy: 0.8385 - val_loss: 0.4131 - val_accuracy: 0.8212\n",
      "Epoch 348/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3781 - accuracy: 0.8399 - val_loss: 0.4122 - val_accuracy: 0.8268\n",
      "Epoch 349/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3682 - accuracy: 0.8483 - val_loss: 0.4134 - val_accuracy: 0.8324\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3809 - accuracy: 0.8301 - val_loss: 0.4130 - val_accuracy: 0.8212\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3628 - accuracy: 0.8567 - val_loss: 0.4125 - val_accuracy: 0.8268\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3698 - accuracy: 0.8483 - val_loss: 0.4116 - val_accuracy: 0.8212\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3871 - accuracy: 0.8371 - val_loss: 0.4120 - val_accuracy: 0.8212\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3756 - accuracy: 0.8483 - val_loss: 0.4108 - val_accuracy: 0.8212\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3742 - accuracy: 0.8469 - val_loss: 0.4104 - val_accuracy: 0.8268\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3808 - accuracy: 0.8427 - val_loss: 0.4116 - val_accuracy: 0.8268\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3755 - accuracy: 0.8455 - val_loss: 0.4137 - val_accuracy: 0.8212\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3678 - accuracy: 0.8413 - val_loss: 0.4156 - val_accuracy: 0.8212\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3716 - accuracy: 0.8455 - val_loss: 0.4110 - val_accuracy: 0.8324\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3728 - accuracy: 0.8441 - val_loss: 0.4146 - val_accuracy: 0.8156\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3627 - accuracy: 0.8427 - val_loss: 0.4110 - val_accuracy: 0.8156\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3754 - accuracy: 0.8399 - val_loss: 0.4130 - val_accuracy: 0.8212\n",
      "Epoch 363/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3806 - accuracy: 0.8399 - val_loss: 0.4119 - val_accuracy: 0.8268\n",
      "Epoch 364/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3670 - accuracy: 0.8525 - val_loss: 0.4099 - val_accuracy: 0.8268\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3734 - accuracy: 0.8371 - val_loss: 0.4149 - val_accuracy: 0.8212\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3634 - accuracy: 0.8497 - val_loss: 0.4168 - val_accuracy: 0.8268\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3754 - accuracy: 0.8427 - val_loss: 0.4101 - val_accuracy: 0.8324\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3727 - accuracy: 0.8455 - val_loss: 0.4151 - val_accuracy: 0.8268\n",
      "Epoch 369/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3745 - accuracy: 0.8385 - val_loss: 0.4161 - val_accuracy: 0.8324\n",
      "Epoch 370/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3597 - accuracy: 0.8596 - val_loss: 0.4153 - val_accuracy: 0.8380\n",
      "Epoch 371/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3746 - accuracy: 0.8371 - val_loss: 0.4111 - val_accuracy: 0.8380\n",
      "Epoch 372/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3694 - accuracy: 0.8399 - val_loss: 0.4099 - val_accuracy: 0.8324\n",
      "Epoch 373/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3775 - accuracy: 0.8441 - val_loss: 0.4094 - val_accuracy: 0.8324\n",
      "Epoch 374/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3727 - accuracy: 0.8469 - val_loss: 0.4132 - val_accuracy: 0.8324\n",
      "Epoch 375/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3814 - accuracy: 0.8357 - val_loss: 0.4111 - val_accuracy: 0.8324\n",
      "Epoch 376/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3683 - accuracy: 0.8497 - val_loss: 0.4135 - val_accuracy: 0.8268\n",
      "Epoch 377/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3755 - accuracy: 0.8497 - val_loss: 0.4108 - val_accuracy: 0.8324\n",
      "Epoch 378/400\n",
      "712/712 [==============================] - 0s 225us/sample - loss: 0.3732 - accuracy: 0.8385 - val_loss: 0.4072 - val_accuracy: 0.8324\n",
      "Epoch 379/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3733 - accuracy: 0.8427 - val_loss: 0.4081 - val_accuracy: 0.8268\n",
      "Epoch 380/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3582 - accuracy: 0.8497 - val_loss: 0.4084 - val_accuracy: 0.8380\n",
      "Epoch 381/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3710 - accuracy: 0.8469 - val_loss: 0.4081 - val_accuracy: 0.8212\n",
      "Epoch 382/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3711 - accuracy: 0.8497 - val_loss: 0.4112 - val_accuracy: 0.8212\n",
      "Epoch 383/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3795 - accuracy: 0.8399 - val_loss: 0.4108 - val_accuracy: 0.8268\n",
      "Epoch 384/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3788 - accuracy: 0.8244 - val_loss: 0.4091 - val_accuracy: 0.8268\n",
      "Epoch 385/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.3774 - accuracy: 0.8399 - val_loss: 0.4105 - val_accuracy: 0.8268\n",
      "Epoch 386/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3656 - accuracy: 0.8469 - val_loss: 0.4121 - val_accuracy: 0.8268\n",
      "Epoch 387/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3708 - accuracy: 0.8441 - val_loss: 0.4097 - val_accuracy: 0.8212\n",
      "Epoch 388/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3621 - accuracy: 0.8427 - val_loss: 0.4106 - val_accuracy: 0.8268\n",
      "Epoch 389/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3720 - accuracy: 0.8539 - val_loss: 0.4129 - val_accuracy: 0.8268\n",
      "Epoch 390/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3781 - accuracy: 0.8441 - val_loss: 0.4129 - val_accuracy: 0.8268\n",
      "Epoch 391/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3753 - accuracy: 0.8497 - val_loss: 0.4086 - val_accuracy: 0.8212\n",
      "Epoch 392/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3722 - accuracy: 0.8497 - val_loss: 0.4152 - val_accuracy: 0.8212\n",
      "Epoch 393/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3627 - accuracy: 0.8553 - val_loss: 0.4271 - val_accuracy: 0.8212\n",
      "Epoch 394/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3752 - accuracy: 0.8553 - val_loss: 0.4186 - val_accuracy: 0.8212\n",
      "Epoch 395/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3787 - accuracy: 0.8413 - val_loss: 0.4119 - val_accuracy: 0.8268\n",
      "Epoch 396/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3770 - accuracy: 0.8413 - val_loss: 0.4116 - val_accuracy: 0.8268\n",
      "Epoch 397/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3712 - accuracy: 0.8497 - val_loss: 0.4118 - val_accuracy: 0.8324\n",
      "Epoch 398/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3677 - accuracy: 0.8469 - val_loss: 0.4148 - val_accuracy: 0.8268\n",
      "Epoch 399/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3703 - accuracy: 0.8511 - val_loss: 0.4102 - val_accuracy: 0.8324\n",
      "Epoch 400/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3785 - accuracy: 0.8441 - val_loss: 0.4096 - val_accuracy: 0.8324\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/400\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.6647 - accuracy: 0.6264 - val_loss: 0.6726 - val_accuracy: 0.5866\n",
      "Epoch 2/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6501 - accuracy: 0.6236 - val_loss: 0.6616 - val_accuracy: 0.5866\n",
      "Epoch 3/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6499 - accuracy: 0.6236 - val_loss: 0.6387 - val_accuracy: 0.5866\n",
      "Epoch 4/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6280 - accuracy: 0.6334 - val_loss: 0.6033 - val_accuracy: 0.5866\n",
      "Epoch 5/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6024 - accuracy: 0.6447 - val_loss: 0.5643 - val_accuracy: 0.7933\n",
      "Epoch 6/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5693 - accuracy: 0.6882 - val_loss: 0.5275 - val_accuracy: 0.8045\n",
      "Epoch 7/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5450 - accuracy: 0.7416 - val_loss: 0.4987 - val_accuracy: 0.8101\n",
      "Epoch 8/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5182 - accuracy: 0.7669 - val_loss: 0.4771 - val_accuracy: 0.8268\n",
      "Epoch 9/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5037 - accuracy: 0.7935 - val_loss: 0.4629 - val_accuracy: 0.8324\n",
      "Epoch 10/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4845 - accuracy: 0.7963 - val_loss: 0.4538 - val_accuracy: 0.8324\n",
      "Epoch 11/400\n",
      "712/712 [==============================] - 0s 202us/sample - loss: 0.4858 - accuracy: 0.7921 - val_loss: 0.4512 - val_accuracy: 0.8268\n",
      "Epoch 12/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4773 - accuracy: 0.8006 - val_loss: 0.4473 - val_accuracy: 0.8268\n",
      "Epoch 13/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4674 - accuracy: 0.8174 - val_loss: 0.4468 - val_accuracy: 0.8268\n",
      "Epoch 14/400\n",
      "712/712 [==============================] - 0s 209us/sample - loss: 0.4726 - accuracy: 0.8048 - val_loss: 0.4437 - val_accuracy: 0.8212\n",
      "Epoch 15/400\n",
      "712/712 [==============================] - 0s 225us/sample - loss: 0.4678 - accuracy: 0.8146 - val_loss: 0.4442 - val_accuracy: 0.8268\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 245us/sample - loss: 0.4663 - accuracy: 0.8104 - val_loss: 0.4432 - val_accuracy: 0.8324\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4591 - accuracy: 0.8216 - val_loss: 0.4493 - val_accuracy: 0.8324\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4678 - accuracy: 0.8104 - val_loss: 0.4501 - val_accuracy: 0.8324\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4642 - accuracy: 0.8188 - val_loss: 0.4448 - val_accuracy: 0.8324\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4719 - accuracy: 0.8090 - val_loss: 0.4459 - val_accuracy: 0.8268\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4573 - accuracy: 0.8174 - val_loss: 0.4430 - val_accuracy: 0.8268\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4626 - accuracy: 0.8146 - val_loss: 0.4441 - val_accuracy: 0.8268\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4640 - accuracy: 0.8132 - val_loss: 0.4439 - val_accuracy: 0.8212\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4616 - accuracy: 0.8118 - val_loss: 0.4475 - val_accuracy: 0.8212\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4487 - accuracy: 0.8104 - val_loss: 0.4443 - val_accuracy: 0.8212\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4509 - accuracy: 0.8244 - val_loss: 0.4471 - val_accuracy: 0.8324\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4644 - accuracy: 0.8132 - val_loss: 0.4444 - val_accuracy: 0.8324\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4690 - accuracy: 0.8090 - val_loss: 0.4419 - val_accuracy: 0.8268\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4651 - accuracy: 0.8160 - val_loss: 0.4420 - val_accuracy: 0.8212\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4617 - accuracy: 0.8104 - val_loss: 0.4427 - val_accuracy: 0.8212\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4477 - accuracy: 0.8230 - val_loss: 0.4424 - val_accuracy: 0.8268\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4538 - accuracy: 0.8132 - val_loss: 0.4439 - val_accuracy: 0.8268\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4597 - accuracy: 0.8160 - val_loss: 0.4483 - val_accuracy: 0.8324\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4515 - accuracy: 0.8244 - val_loss: 0.4472 - val_accuracy: 0.8101\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4570 - accuracy: 0.8132 - val_loss: 0.4428 - val_accuracy: 0.8212\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4528 - accuracy: 0.8132 - val_loss: 0.4384 - val_accuracy: 0.8268\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4533 - accuracy: 0.8188 - val_loss: 0.4361 - val_accuracy: 0.8324\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4562 - accuracy: 0.8146 - val_loss: 0.4344 - val_accuracy: 0.8268\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4645 - accuracy: 0.8076 - val_loss: 0.4316 - val_accuracy: 0.8324\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4497 - accuracy: 0.8258 - val_loss: 0.4314 - val_accuracy: 0.8380\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4462 - accuracy: 0.8244 - val_loss: 0.4286 - val_accuracy: 0.8324\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4482 - accuracy: 0.8230 - val_loss: 0.4250 - val_accuracy: 0.8380\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4409 - accuracy: 0.8244 - val_loss: 0.4214 - val_accuracy: 0.8380\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4386 - accuracy: 0.8230 - val_loss: 0.4229 - val_accuracy: 0.8380\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4525 - accuracy: 0.8202 - val_loss: 0.4209 - val_accuracy: 0.8380\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4407 - accuracy: 0.8230 - val_loss: 0.4201 - val_accuracy: 0.8380\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4405 - accuracy: 0.8244 - val_loss: 0.4192 - val_accuracy: 0.8380\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.4344 - accuracy: 0.8315 - val_loss: 0.4187 - val_accuracy: 0.8492\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4459 - accuracy: 0.8174 - val_loss: 0.4169 - val_accuracy: 0.8492\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4377 - accuracy: 0.8258 - val_loss: 0.4157 - val_accuracy: 0.8380\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4304 - accuracy: 0.8301 - val_loss: 0.4171 - val_accuracy: 0.8492\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4220 - accuracy: 0.8216 - val_loss: 0.4180 - val_accuracy: 0.8492\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4363 - accuracy: 0.8258 - val_loss: 0.4181 - val_accuracy: 0.8380\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4254 - accuracy: 0.8258 - val_loss: 0.4178 - val_accuracy: 0.8436\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4221 - accuracy: 0.8244 - val_loss: 0.4172 - val_accuracy: 0.8492\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.4301 - accuracy: 0.8258 - val_loss: 0.4168 - val_accuracy: 0.8547\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4144 - accuracy: 0.8244 - val_loss: 0.4158 - val_accuracy: 0.8547\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4086 - accuracy: 0.8343 - val_loss: 0.4164 - val_accuracy: 0.8492\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4191 - accuracy: 0.8258 - val_loss: 0.4166 - val_accuracy: 0.8492\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4205 - accuracy: 0.8287 - val_loss: 0.4148 - val_accuracy: 0.8492\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.4160 - accuracy: 0.8301 - val_loss: 0.4158 - val_accuracy: 0.8436\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4217 - accuracy: 0.8230 - val_loss: 0.4129 - val_accuracy: 0.8492\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4108 - accuracy: 0.8258 - val_loss: 0.4146 - val_accuracy: 0.8492\n",
      "Epoch 64/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4126 - accuracy: 0.8413 - val_loss: 0.4175 - val_accuracy: 0.8324\n",
      "Epoch 65/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4003 - accuracy: 0.8427 - val_loss: 0.4177 - val_accuracy: 0.8436\n",
      "Epoch 66/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3881 - accuracy: 0.8596 - val_loss: 0.4168 - val_accuracy: 0.8492\n",
      "Epoch 67/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4181 - accuracy: 0.8272 - val_loss: 0.4179 - val_accuracy: 0.8436\n",
      "Epoch 68/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3936 - accuracy: 0.8581 - val_loss: 0.4182 - val_accuracy: 0.8436\n",
      "Epoch 69/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4121 - accuracy: 0.8216 - val_loss: 0.4176 - val_accuracy: 0.8436\n",
      "Epoch 70/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4184 - accuracy: 0.8315 - val_loss: 0.4164 - val_accuracy: 0.8492\n",
      "Epoch 71/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4004 - accuracy: 0.8371 - val_loss: 0.4164 - val_accuracy: 0.8436\n",
      "Epoch 72/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4185 - accuracy: 0.8329 - val_loss: 0.4176 - val_accuracy: 0.8380\n",
      "Epoch 73/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4089 - accuracy: 0.8343 - val_loss: 0.4189 - val_accuracy: 0.8324\n",
      "Epoch 74/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4103 - accuracy: 0.8315 - val_loss: 0.4170 - val_accuracy: 0.8436\n",
      "Epoch 75/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4128 - accuracy: 0.8315 - val_loss: 0.4188 - val_accuracy: 0.8492\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4070 - accuracy: 0.8343 - val_loss: 0.4186 - val_accuracy: 0.8436\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4049 - accuracy: 0.8413 - val_loss: 0.4186 - val_accuracy: 0.8492\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3942 - accuracy: 0.8525 - val_loss: 0.4192 - val_accuracy: 0.8436\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4159 - accuracy: 0.8315 - val_loss: 0.4163 - val_accuracy: 0.8436\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4008 - accuracy: 0.8427 - val_loss: 0.4173 - val_accuracy: 0.8492\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4057 - accuracy: 0.8357 - val_loss: 0.4217 - val_accuracy: 0.8380\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4043 - accuracy: 0.8371 - val_loss: 0.4187 - val_accuracy: 0.8380\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3963 - accuracy: 0.8413 - val_loss: 0.4176 - val_accuracy: 0.8380\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4007 - accuracy: 0.8287 - val_loss: 0.4166 - val_accuracy: 0.8436\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4093 - accuracy: 0.8343 - val_loss: 0.4186 - val_accuracy: 0.8324\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4064 - accuracy: 0.8385 - val_loss: 0.4204 - val_accuracy: 0.8380\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4100 - accuracy: 0.8287 - val_loss: 0.4182 - val_accuracy: 0.8380\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4012 - accuracy: 0.8385 - val_loss: 0.4175 - val_accuracy: 0.8436\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4119 - accuracy: 0.8258 - val_loss: 0.4191 - val_accuracy: 0.8380\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4058 - accuracy: 0.8385 - val_loss: 0.4163 - val_accuracy: 0.8380\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4001 - accuracy: 0.8399 - val_loss: 0.4157 - val_accuracy: 0.8324\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4040 - accuracy: 0.8413 - val_loss: 0.4153 - val_accuracy: 0.8324\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4083 - accuracy: 0.8385 - val_loss: 0.4137 - val_accuracy: 0.8380\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4010 - accuracy: 0.8343 - val_loss: 0.4134 - val_accuracy: 0.8324\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4074 - accuracy: 0.8371 - val_loss: 0.4133 - val_accuracy: 0.8324\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3999 - accuracy: 0.8371 - val_loss: 0.4139 - val_accuracy: 0.8324\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3983 - accuracy: 0.8287 - val_loss: 0.4148 - val_accuracy: 0.8324\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4009 - accuracy: 0.8399 - val_loss: 0.4158 - val_accuracy: 0.8380\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4021 - accuracy: 0.8371 - val_loss: 0.4170 - val_accuracy: 0.8380\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3943 - accuracy: 0.8469 - val_loss: 0.4192 - val_accuracy: 0.8324\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3954 - accuracy: 0.8329 - val_loss: 0.4172 - val_accuracy: 0.8380\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3992 - accuracy: 0.8427 - val_loss: 0.4198 - val_accuracy: 0.8324\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3991 - accuracy: 0.8413 - val_loss: 0.4184 - val_accuracy: 0.8380\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3920 - accuracy: 0.8455 - val_loss: 0.4205 - val_accuracy: 0.8324\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4110 - accuracy: 0.8258 - val_loss: 0.4146 - val_accuracy: 0.8324\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4014 - accuracy: 0.8413 - val_loss: 0.4211 - val_accuracy: 0.8324\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3988 - accuracy: 0.8287 - val_loss: 0.4173 - val_accuracy: 0.8324\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3970 - accuracy: 0.8343 - val_loss: 0.4249 - val_accuracy: 0.8268\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3971 - accuracy: 0.8399 - val_loss: 0.4166 - val_accuracy: 0.8324\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.3990 - accuracy: 0.8413 - val_loss: 0.4181 - val_accuracy: 0.8324\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.3956 - accuracy: 0.8427 - val_loss: 0.4199 - val_accuracy: 0.8324\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3888 - accuracy: 0.8497 - val_loss: 0.4245 - val_accuracy: 0.8324\n",
      "Epoch 113/400\n",
      "712/712 [==============================] - 0s 215us/sample - loss: 0.3961 - accuracy: 0.8399 - val_loss: 0.4159 - val_accuracy: 0.8380\n",
      "Epoch 114/400\n",
      "712/712 [==============================] - 0s 254us/sample - loss: 0.3930 - accuracy: 0.8357 - val_loss: 0.4131 - val_accuracy: 0.8324\n",
      "Epoch 115/400\n",
      "712/712 [==============================] - 0s 221us/sample - loss: 0.4004 - accuracy: 0.8441 - val_loss: 0.4159 - val_accuracy: 0.8380\n",
      "Epoch 116/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4038 - accuracy: 0.8315 - val_loss: 0.4159 - val_accuracy: 0.8380\n",
      "Epoch 117/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.3777 - accuracy: 0.8567 - val_loss: 0.4126 - val_accuracy: 0.8380\n",
      "Epoch 118/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3967 - accuracy: 0.8441 - val_loss: 0.4138 - val_accuracy: 0.8268\n",
      "Epoch 119/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3925 - accuracy: 0.8413 - val_loss: 0.4165 - val_accuracy: 0.8268\n",
      "Epoch 120/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3984 - accuracy: 0.8413 - val_loss: 0.4152 - val_accuracy: 0.8324\n",
      "Epoch 121/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3859 - accuracy: 0.8511 - val_loss: 0.4166 - val_accuracy: 0.8324\n",
      "Epoch 122/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4055 - accuracy: 0.8272 - val_loss: 0.4161 - val_accuracy: 0.8268\n",
      "Epoch 123/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3910 - accuracy: 0.8413 - val_loss: 0.4118 - val_accuracy: 0.8380\n",
      "Epoch 124/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3879 - accuracy: 0.8455 - val_loss: 0.4155 - val_accuracy: 0.8324\n",
      "Epoch 125/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3976 - accuracy: 0.8413 - val_loss: 0.4182 - val_accuracy: 0.8380\n",
      "Epoch 126/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3846 - accuracy: 0.8441 - val_loss: 0.4203 - val_accuracy: 0.8380\n",
      "Epoch 127/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3982 - accuracy: 0.8371 - val_loss: 0.4157 - val_accuracy: 0.8380\n",
      "Epoch 128/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3976 - accuracy: 0.8427 - val_loss: 0.4136 - val_accuracy: 0.8324\n",
      "Epoch 129/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3955 - accuracy: 0.8427 - val_loss: 0.4245 - val_accuracy: 0.8324\n",
      "Epoch 130/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3902 - accuracy: 0.8441 - val_loss: 0.4216 - val_accuracy: 0.8324\n",
      "Epoch 131/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3919 - accuracy: 0.8483 - val_loss: 0.4182 - val_accuracy: 0.8324\n",
      "Epoch 132/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3965 - accuracy: 0.8413 - val_loss: 0.4157 - val_accuracy: 0.8380\n",
      "Epoch 133/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3974 - accuracy: 0.8441 - val_loss: 0.4149 - val_accuracy: 0.8324\n",
      "Epoch 134/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3932 - accuracy: 0.8413 - val_loss: 0.4154 - val_accuracy: 0.8324\n",
      "Epoch 135/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3923 - accuracy: 0.8301 - val_loss: 0.4185 - val_accuracy: 0.8380\n",
      "Epoch 136/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3831 - accuracy: 0.8539 - val_loss: 0.4234 - val_accuracy: 0.8380\n",
      "Epoch 137/400\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.4085 - accuracy: 0.8230 - val_loss: 0.4132 - val_accuracy: 0.8380\n",
      "Epoch 138/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3879 - accuracy: 0.8441 - val_loss: 0.4143 - val_accuracy: 0.8380\n",
      "Epoch 139/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3969 - accuracy: 0.8469 - val_loss: 0.4159 - val_accuracy: 0.8380\n",
      "Epoch 140/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3957 - accuracy: 0.8385 - val_loss: 0.4152 - val_accuracy: 0.8380\n",
      "Epoch 141/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3904 - accuracy: 0.8343 - val_loss: 0.4196 - val_accuracy: 0.8324\n",
      "Epoch 142/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4016 - accuracy: 0.8315 - val_loss: 0.4205 - val_accuracy: 0.8380\n",
      "Epoch 143/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3927 - accuracy: 0.8455 - val_loss: 0.4261 - val_accuracy: 0.8324\n",
      "Epoch 144/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3945 - accuracy: 0.8413 - val_loss: 0.4231 - val_accuracy: 0.8324\n",
      "Epoch 145/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3959 - accuracy: 0.8427 - val_loss: 0.4234 - val_accuracy: 0.8324\n",
      "Epoch 146/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4063 - accuracy: 0.8413 - val_loss: 0.4227 - val_accuracy: 0.8324\n",
      "Epoch 147/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3885 - accuracy: 0.8343 - val_loss: 0.4278 - val_accuracy: 0.8268\n",
      "Epoch 148/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3944 - accuracy: 0.8427 - val_loss: 0.4237 - val_accuracy: 0.8324\n",
      "Epoch 149/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.3905 - accuracy: 0.8399 - val_loss: 0.4218 - val_accuracy: 0.8324\n",
      "Epoch 150/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4161 - accuracy: 0.8188 - val_loss: 0.4172 - val_accuracy: 0.8380\n",
      "Epoch 151/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3978 - accuracy: 0.8413 - val_loss: 0.4170 - val_accuracy: 0.8324\n",
      "Epoch 152/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3799 - accuracy: 0.8497 - val_loss: 0.4197 - val_accuracy: 0.8324\n",
      "Epoch 153/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3959 - accuracy: 0.8329 - val_loss: 0.4261 - val_accuracy: 0.8324\n",
      "Epoch 154/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3917 - accuracy: 0.8413 - val_loss: 0.4240 - val_accuracy: 0.8380\n",
      "Epoch 155/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3974 - accuracy: 0.8385 - val_loss: 0.4250 - val_accuracy: 0.8380\n",
      "Epoch 156/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3975 - accuracy: 0.8427 - val_loss: 0.4240 - val_accuracy: 0.8436\n",
      "Epoch 157/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4007 - accuracy: 0.8315 - val_loss: 0.4229 - val_accuracy: 0.8324\n",
      "Epoch 158/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3856 - accuracy: 0.8455 - val_loss: 0.4238 - val_accuracy: 0.8436\n",
      "Epoch 159/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3830 - accuracy: 0.8511 - val_loss: 0.4267 - val_accuracy: 0.8380\n",
      "Epoch 160/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4006 - accuracy: 0.8315 - val_loss: 0.4222 - val_accuracy: 0.8324\n",
      "Epoch 161/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3911 - accuracy: 0.8427 - val_loss: 0.4244 - val_accuracy: 0.8324\n",
      "Epoch 162/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3848 - accuracy: 0.8567 - val_loss: 0.4269 - val_accuracy: 0.8380\n",
      "Epoch 163/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3909 - accuracy: 0.8455 - val_loss: 0.4199 - val_accuracy: 0.8324\n",
      "Epoch 164/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3897 - accuracy: 0.8413 - val_loss: 0.4189 - val_accuracy: 0.8380\n",
      "Epoch 165/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3906 - accuracy: 0.8497 - val_loss: 0.4207 - val_accuracy: 0.8436\n",
      "Epoch 166/400\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.3793 - accuracy: 0.8441 - val_loss: 0.4185 - val_accuracy: 0.8380\n",
      "Epoch 167/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3899 - accuracy: 0.8385 - val_loss: 0.4138 - val_accuracy: 0.8324\n",
      "Epoch 168/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3950 - accuracy: 0.8343 - val_loss: 0.4179 - val_accuracy: 0.8324\n",
      "Epoch 169/400\n",
      "712/712 [==============================] - 0s 212us/sample - loss: 0.3925 - accuracy: 0.8497 - val_loss: 0.4199 - val_accuracy: 0.8324\n",
      "Epoch 170/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3877 - accuracy: 0.8525 - val_loss: 0.4257 - val_accuracy: 0.8324\n",
      "Epoch 171/400\n",
      "712/712 [==============================] - 0s 314us/sample - loss: 0.3913 - accuracy: 0.8399 - val_loss: 0.4239 - val_accuracy: 0.8324\n",
      "Epoch 172/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3921 - accuracy: 0.8455 - val_loss: 0.4262 - val_accuracy: 0.8324\n",
      "Epoch 173/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3960 - accuracy: 0.8483 - val_loss: 0.4226 - val_accuracy: 0.8380\n",
      "Epoch 174/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3844 - accuracy: 0.8427 - val_loss: 0.4242 - val_accuracy: 0.8324\n",
      "Epoch 175/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3875 - accuracy: 0.8469 - val_loss: 0.4269 - val_accuracy: 0.8324\n",
      "Epoch 176/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3877 - accuracy: 0.8399 - val_loss: 0.4255 - val_accuracy: 0.8324\n",
      "Epoch 177/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3944 - accuracy: 0.8441 - val_loss: 0.4188 - val_accuracy: 0.8324\n",
      "Epoch 178/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3915 - accuracy: 0.8469 - val_loss: 0.4207 - val_accuracy: 0.8380\n",
      "Epoch 179/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3893 - accuracy: 0.8441 - val_loss: 0.4207 - val_accuracy: 0.8380\n",
      "Epoch 180/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3918 - accuracy: 0.8497 - val_loss: 0.4250 - val_accuracy: 0.8268\n",
      "Epoch 181/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3851 - accuracy: 0.8483 - val_loss: 0.4229 - val_accuracy: 0.8380\n",
      "Epoch 182/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3983 - accuracy: 0.8385 - val_loss: 0.4223 - val_accuracy: 0.8324\n",
      "Epoch 183/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3812 - accuracy: 0.8511 - val_loss: 0.4208 - val_accuracy: 0.8324\n",
      "Epoch 184/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3942 - accuracy: 0.8357 - val_loss: 0.4223 - val_accuracy: 0.8324\n",
      "Epoch 185/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3969 - accuracy: 0.8343 - val_loss: 0.4222 - val_accuracy: 0.8324\n",
      "Epoch 186/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3932 - accuracy: 0.8371 - val_loss: 0.4231 - val_accuracy: 0.8324\n",
      "Epoch 187/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3933 - accuracy: 0.8441 - val_loss: 0.4215 - val_accuracy: 0.8324\n",
      "Epoch 188/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3871 - accuracy: 0.8483 - val_loss: 0.4262 - val_accuracy: 0.8380\n",
      "Epoch 189/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3931 - accuracy: 0.8441 - val_loss: 0.4202 - val_accuracy: 0.8324\n",
      "Epoch 190/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3891 - accuracy: 0.8399 - val_loss: 0.4170 - val_accuracy: 0.8380\n",
      "Epoch 191/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3984 - accuracy: 0.8343 - val_loss: 0.4148 - val_accuracy: 0.8324\n",
      "Epoch 192/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3902 - accuracy: 0.8455 - val_loss: 0.4144 - val_accuracy: 0.8324\n",
      "Epoch 193/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3798 - accuracy: 0.8455 - val_loss: 0.4175 - val_accuracy: 0.8380\n",
      "Epoch 194/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3931 - accuracy: 0.8399 - val_loss: 0.4196 - val_accuracy: 0.8324\n",
      "Epoch 195/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3869 - accuracy: 0.8497 - val_loss: 0.4203 - val_accuracy: 0.8436\n",
      "Epoch 196/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3859 - accuracy: 0.8483 - val_loss: 0.4230 - val_accuracy: 0.8324\n",
      "Epoch 197/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.3828 - accuracy: 0.8399 - val_loss: 0.4246 - val_accuracy: 0.8324\n",
      "Epoch 198/400\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.3787 - accuracy: 0.8497 - val_loss: 0.4237 - val_accuracy: 0.8324\n",
      "Epoch 199/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3894 - accuracy: 0.8413 - val_loss: 0.4249 - val_accuracy: 0.8324\n",
      "Epoch 200/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3915 - accuracy: 0.8357 - val_loss: 0.4241 - val_accuracy: 0.8268\n",
      "Epoch 201/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3961 - accuracy: 0.8371 - val_loss: 0.4247 - val_accuracy: 0.8268\n",
      "Epoch 202/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3880 - accuracy: 0.8399 - val_loss: 0.4226 - val_accuracy: 0.8324\n",
      "Epoch 203/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3775 - accuracy: 0.8553 - val_loss: 0.4268 - val_accuracy: 0.8324\n",
      "Epoch 204/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3858 - accuracy: 0.8497 - val_loss: 0.4250 - val_accuracy: 0.8324\n",
      "Epoch 205/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3896 - accuracy: 0.8315 - val_loss: 0.4246 - val_accuracy: 0.8268\n",
      "Epoch 206/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3837 - accuracy: 0.8385 - val_loss: 0.4255 - val_accuracy: 0.8324\n",
      "Epoch 207/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3921 - accuracy: 0.8371 - val_loss: 0.4204 - val_accuracy: 0.8324\n",
      "Epoch 208/400\n",
      "712/712 [==============================] - 0s 209us/sample - loss: 0.3722 - accuracy: 0.8413 - val_loss: 0.4231 - val_accuracy: 0.8324\n",
      "Epoch 209/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3882 - accuracy: 0.8399 - val_loss: 0.4259 - val_accuracy: 0.8380\n",
      "Epoch 210/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3902 - accuracy: 0.8483 - val_loss: 0.4242 - val_accuracy: 0.8324\n",
      "Epoch 211/400\n",
      "712/712 [==============================] - 0s 274us/sample - loss: 0.3835 - accuracy: 0.8441 - val_loss: 0.4245 - val_accuracy: 0.8324\n",
      "Epoch 212/400\n",
      "712/712 [==============================] - 0s 226us/sample - loss: 0.3818 - accuracy: 0.8483 - val_loss: 0.4247 - val_accuracy: 0.8324\n",
      "Epoch 213/400\n",
      "712/712 [==============================] - 0s 236us/sample - loss: 0.3771 - accuracy: 0.8483 - val_loss: 0.4254 - val_accuracy: 0.8324\n",
      "Epoch 214/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3834 - accuracy: 0.8553 - val_loss: 0.4239 - val_accuracy: 0.8324\n",
      "Epoch 215/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3837 - accuracy: 0.8357 - val_loss: 0.4227 - val_accuracy: 0.8324\n",
      "Epoch 216/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3861 - accuracy: 0.8385 - val_loss: 0.4220 - val_accuracy: 0.8324\n",
      "Epoch 217/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3790 - accuracy: 0.8329 - val_loss: 0.4217 - val_accuracy: 0.8324\n",
      "Epoch 218/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3917 - accuracy: 0.8399 - val_loss: 0.4246 - val_accuracy: 0.8380\n",
      "Epoch 219/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3934 - accuracy: 0.8413 - val_loss: 0.4270 - val_accuracy: 0.8324\n",
      "Epoch 220/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3837 - accuracy: 0.8483 - val_loss: 0.4279 - val_accuracy: 0.8324\n",
      "Epoch 221/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3927 - accuracy: 0.8413 - val_loss: 0.4282 - val_accuracy: 0.8324\n",
      "Epoch 222/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3816 - accuracy: 0.8525 - val_loss: 0.4257 - val_accuracy: 0.8324\n",
      "Epoch 223/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3900 - accuracy: 0.8427 - val_loss: 0.4309 - val_accuracy: 0.8324\n",
      "Epoch 224/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3756 - accuracy: 0.8497 - val_loss: 0.4286 - val_accuracy: 0.8380\n",
      "Epoch 225/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3863 - accuracy: 0.8399 - val_loss: 0.4293 - val_accuracy: 0.8380\n",
      "Epoch 226/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3895 - accuracy: 0.8272 - val_loss: 0.4278 - val_accuracy: 0.8324\n",
      "Epoch 227/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3774 - accuracy: 0.8413 - val_loss: 0.4248 - val_accuracy: 0.8324\n",
      "Epoch 228/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3850 - accuracy: 0.8413 - val_loss: 0.4272 - val_accuracy: 0.8324\n",
      "Epoch 229/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3840 - accuracy: 0.8413 - val_loss: 0.4255 - val_accuracy: 0.8324\n",
      "Epoch 230/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3882 - accuracy: 0.8511 - val_loss: 0.4260 - val_accuracy: 0.8324\n",
      "Epoch 231/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3825 - accuracy: 0.8441 - val_loss: 0.4278 - val_accuracy: 0.8380\n",
      "Epoch 232/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3905 - accuracy: 0.8427 - val_loss: 0.4325 - val_accuracy: 0.8380\n",
      "Epoch 233/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3904 - accuracy: 0.8413 - val_loss: 0.4298 - val_accuracy: 0.8324\n",
      "Epoch 234/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3873 - accuracy: 0.8357 - val_loss: 0.4268 - val_accuracy: 0.8380\n",
      "Epoch 235/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3898 - accuracy: 0.8413 - val_loss: 0.4271 - val_accuracy: 0.8324\n",
      "Epoch 236/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3777 - accuracy: 0.8399 - val_loss: 0.4267 - val_accuracy: 0.8380\n",
      "Epoch 237/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3893 - accuracy: 0.8385 - val_loss: 0.4244 - val_accuracy: 0.8380\n",
      "Epoch 238/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3837 - accuracy: 0.8511 - val_loss: 0.4238 - val_accuracy: 0.8324\n",
      "Epoch 239/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3856 - accuracy: 0.8567 - val_loss: 0.4242 - val_accuracy: 0.8324\n",
      "Epoch 240/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3767 - accuracy: 0.8596 - val_loss: 0.4305 - val_accuracy: 0.8268\n",
      "Epoch 241/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3877 - accuracy: 0.8371 - val_loss: 0.4304 - val_accuracy: 0.8324\n",
      "Epoch 242/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3831 - accuracy: 0.8399 - val_loss: 0.4258 - val_accuracy: 0.8324\n",
      "Epoch 243/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3812 - accuracy: 0.8413 - val_loss: 0.4270 - val_accuracy: 0.8324\n",
      "Epoch 244/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3826 - accuracy: 0.8399 - val_loss: 0.4287 - val_accuracy: 0.8380\n",
      "Epoch 245/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3906 - accuracy: 0.8455 - val_loss: 0.4310 - val_accuracy: 0.8324\n",
      "Epoch 246/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3875 - accuracy: 0.8427 - val_loss: 0.4321 - val_accuracy: 0.8380\n",
      "Epoch 247/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3795 - accuracy: 0.8469 - val_loss: 0.4277 - val_accuracy: 0.8380\n",
      "Epoch 248/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3817 - accuracy: 0.8539 - val_loss: 0.4250 - val_accuracy: 0.8324\n",
      "Epoch 249/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3750 - accuracy: 0.8525 - val_loss: 0.4286 - val_accuracy: 0.8324\n",
      "Epoch 250/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3815 - accuracy: 0.8483 - val_loss: 0.4305 - val_accuracy: 0.8268\n",
      "Epoch 251/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3782 - accuracy: 0.8413 - val_loss: 0.4295 - val_accuracy: 0.8268\n",
      "Epoch 252/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3807 - accuracy: 0.8385 - val_loss: 0.4273 - val_accuracy: 0.8380\n",
      "Epoch 253/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3925 - accuracy: 0.8427 - val_loss: 0.4299 - val_accuracy: 0.8324\n",
      "Epoch 254/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3902 - accuracy: 0.8413 - val_loss: 0.4294 - val_accuracy: 0.8324\n",
      "Epoch 255/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3761 - accuracy: 0.8455 - val_loss: 0.4312 - val_accuracy: 0.8324\n",
      "Epoch 256/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3870 - accuracy: 0.8553 - val_loss: 0.4263 - val_accuracy: 0.8324\n",
      "Epoch 257/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3797 - accuracy: 0.8525 - val_loss: 0.4347 - val_accuracy: 0.8324\n",
      "Epoch 258/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3878 - accuracy: 0.8441 - val_loss: 0.4259 - val_accuracy: 0.8380\n",
      "Epoch 259/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3956 - accuracy: 0.8258 - val_loss: 0.4270 - val_accuracy: 0.8324\n",
      "Epoch 260/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3875 - accuracy: 0.8511 - val_loss: 0.4264 - val_accuracy: 0.8324\n",
      "Epoch 261/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3818 - accuracy: 0.8427 - val_loss: 0.4238 - val_accuracy: 0.8324\n",
      "Epoch 262/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3836 - accuracy: 0.8427 - val_loss: 0.4266 - val_accuracy: 0.8324\n",
      "Epoch 263/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3895 - accuracy: 0.8483 - val_loss: 0.4248 - val_accuracy: 0.8324\n",
      "Epoch 264/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3826 - accuracy: 0.8483 - val_loss: 0.4252 - val_accuracy: 0.8380\n",
      "Epoch 265/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3900 - accuracy: 0.8399 - val_loss: 0.4322 - val_accuracy: 0.8324\n",
      "Epoch 266/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3883 - accuracy: 0.8469 - val_loss: 0.4351 - val_accuracy: 0.8324\n",
      "Epoch 267/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3909 - accuracy: 0.8357 - val_loss: 0.4310 - val_accuracy: 0.8380\n",
      "Epoch 268/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3813 - accuracy: 0.8427 - val_loss: 0.4312 - val_accuracy: 0.8324\n",
      "Epoch 269/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3845 - accuracy: 0.8469 - val_loss: 0.4297 - val_accuracy: 0.8324\n",
      "Epoch 270/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3886 - accuracy: 0.8441 - val_loss: 0.4300 - val_accuracy: 0.8324\n",
      "Epoch 271/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3774 - accuracy: 0.8455 - val_loss: 0.4292 - val_accuracy: 0.8380\n",
      "Epoch 272/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3826 - accuracy: 0.8497 - val_loss: 0.4335 - val_accuracy: 0.8268\n",
      "Epoch 273/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3799 - accuracy: 0.8455 - val_loss: 0.4276 - val_accuracy: 0.8380\n",
      "Epoch 274/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3812 - accuracy: 0.8399 - val_loss: 0.4301 - val_accuracy: 0.8380\n",
      "Epoch 275/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3867 - accuracy: 0.8441 - val_loss: 0.4300 - val_accuracy: 0.8324\n",
      "Epoch 276/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3817 - accuracy: 0.8497 - val_loss: 0.4284 - val_accuracy: 0.8324\n",
      "Epoch 277/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3794 - accuracy: 0.8469 - val_loss: 0.4294 - val_accuracy: 0.8324\n",
      "Epoch 278/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3809 - accuracy: 0.8441 - val_loss: 0.4295 - val_accuracy: 0.8324\n",
      "Epoch 279/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3873 - accuracy: 0.8483 - val_loss: 0.4311 - val_accuracy: 0.8324\n",
      "Epoch 280/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3943 - accuracy: 0.8371 - val_loss: 0.4287 - val_accuracy: 0.8324\n",
      "Epoch 281/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3803 - accuracy: 0.8441 - val_loss: 0.4270 - val_accuracy: 0.8324\n",
      "Epoch 282/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3841 - accuracy: 0.8427 - val_loss: 0.4267 - val_accuracy: 0.8324\n",
      "Epoch 283/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3810 - accuracy: 0.8455 - val_loss: 0.4294 - val_accuracy: 0.8268\n",
      "Epoch 284/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3765 - accuracy: 0.8385 - val_loss: 0.4317 - val_accuracy: 0.8268\n",
      "Epoch 285/400\n",
      "712/712 [==============================] - 0s 327us/sample - loss: 0.3819 - accuracy: 0.8427 - val_loss: 0.4297 - val_accuracy: 0.8324\n",
      "Epoch 286/400\n",
      "712/712 [==============================] - 0s 263us/sample - loss: 0.3859 - accuracy: 0.8357 - val_loss: 0.4330 - val_accuracy: 0.8324\n",
      "Epoch 287/400\n",
      "712/712 [==============================] - 0s 262us/sample - loss: 0.3874 - accuracy: 0.8343 - val_loss: 0.4314 - val_accuracy: 0.8324\n",
      "Epoch 288/400\n",
      "712/712 [==============================] - 0s 251us/sample - loss: 0.3844 - accuracy: 0.8469 - val_loss: 0.4375 - val_accuracy: 0.8268\n",
      "Epoch 289/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.3729 - accuracy: 0.8469 - val_loss: 0.4438 - val_accuracy: 0.8324\n",
      "Epoch 290/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3783 - accuracy: 0.8427 - val_loss: 0.4380 - val_accuracy: 0.8268\n",
      "Epoch 291/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3792 - accuracy: 0.8497 - val_loss: 0.4317 - val_accuracy: 0.8380\n",
      "Epoch 292/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3742 - accuracy: 0.8455 - val_loss: 0.4311 - val_accuracy: 0.8324\n",
      "Epoch 293/400\n",
      "712/712 [==============================] - 0s 203us/sample - loss: 0.3829 - accuracy: 0.8427 - val_loss: 0.4296 - val_accuracy: 0.8324\n",
      "Epoch 294/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3813 - accuracy: 0.8413 - val_loss: 0.4254 - val_accuracy: 0.8380\n",
      "Epoch 295/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3834 - accuracy: 0.8413 - val_loss: 0.4315 - val_accuracy: 0.8324\n",
      "Epoch 296/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3758 - accuracy: 0.8497 - val_loss: 0.4307 - val_accuracy: 0.8380\n",
      "Epoch 297/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3822 - accuracy: 0.8497 - val_loss: 0.4291 - val_accuracy: 0.8380\n",
      "Epoch 298/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3873 - accuracy: 0.8399 - val_loss: 0.4287 - val_accuracy: 0.8380\n",
      "Epoch 299/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3812 - accuracy: 0.8511 - val_loss: 0.4359 - val_accuracy: 0.8101\n",
      "Epoch 300/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3916 - accuracy: 0.8371 - val_loss: 0.4331 - val_accuracy: 0.8380\n",
      "Epoch 301/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3805 - accuracy: 0.8511 - val_loss: 0.4318 - val_accuracy: 0.8380\n",
      "Epoch 302/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3869 - accuracy: 0.8343 - val_loss: 0.4348 - val_accuracy: 0.8324\n",
      "Epoch 303/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3826 - accuracy: 0.8455 - val_loss: 0.4366 - val_accuracy: 0.8324\n",
      "Epoch 304/400\n",
      "712/712 [==============================] - 0s 223us/sample - loss: 0.3849 - accuracy: 0.8497 - val_loss: 0.4358 - val_accuracy: 0.8380\n",
      "Epoch 305/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3888 - accuracy: 0.8441 - val_loss: 0.4328 - val_accuracy: 0.8324\n",
      "Epoch 306/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3812 - accuracy: 0.8427 - val_loss: 0.4324 - val_accuracy: 0.8324\n",
      "Epoch 307/400\n",
      "712/712 [==============================] - 0s 288us/sample - loss: 0.3791 - accuracy: 0.8441 - val_loss: 0.4333 - val_accuracy: 0.8380\n",
      "Epoch 308/400\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.3767 - accuracy: 0.8525 - val_loss: 0.4282 - val_accuracy: 0.8324\n",
      "Epoch 309/400\n",
      "712/712 [==============================] - 0s 237us/sample - loss: 0.3826 - accuracy: 0.8469 - val_loss: 0.4306 - val_accuracy: 0.8324\n",
      "Epoch 310/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3708 - accuracy: 0.8638 - val_loss: 0.4304 - val_accuracy: 0.8380\n",
      "Epoch 311/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3788 - accuracy: 0.8399 - val_loss: 0.4281 - val_accuracy: 0.8380\n",
      "Epoch 312/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3713 - accuracy: 0.8483 - val_loss: 0.4298 - val_accuracy: 0.8380\n",
      "Epoch 313/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3840 - accuracy: 0.8441 - val_loss: 0.4274 - val_accuracy: 0.8380\n",
      "Epoch 314/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3848 - accuracy: 0.8399 - val_loss: 0.4225 - val_accuracy: 0.8380\n",
      "Epoch 315/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3833 - accuracy: 0.8427 - val_loss: 0.4269 - val_accuracy: 0.8324\n",
      "Epoch 316/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3845 - accuracy: 0.8441 - val_loss: 0.4336 - val_accuracy: 0.8268\n",
      "Epoch 317/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3728 - accuracy: 0.8441 - val_loss: 0.4302 - val_accuracy: 0.8324\n",
      "Epoch 318/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3864 - accuracy: 0.8469 - val_loss: 0.4312 - val_accuracy: 0.8324\n",
      "Epoch 319/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3856 - accuracy: 0.8497 - val_loss: 0.4332 - val_accuracy: 0.8268\n",
      "Epoch 320/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3793 - accuracy: 0.8371 - val_loss: 0.4320 - val_accuracy: 0.8380\n",
      "Epoch 321/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3804 - accuracy: 0.8497 - val_loss: 0.4257 - val_accuracy: 0.8324\n",
      "Epoch 322/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3794 - accuracy: 0.8455 - val_loss: 0.4298 - val_accuracy: 0.8380\n",
      "Epoch 323/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.3792 - accuracy: 0.8511 - val_loss: 0.4367 - val_accuracy: 0.8324\n",
      "Epoch 324/400\n",
      "712/712 [==============================] - 0s 258us/sample - loss: 0.3772 - accuracy: 0.8525 - val_loss: 0.4355 - val_accuracy: 0.8380\n",
      "Epoch 325/400\n",
      "712/712 [==============================] - 0s 264us/sample - loss: 0.3838 - accuracy: 0.8413 - val_loss: 0.4338 - val_accuracy: 0.8380\n",
      "Epoch 326/400\n",
      "712/712 [==============================] - 0s 294us/sample - loss: 0.3753 - accuracy: 0.8553 - val_loss: 0.4316 - val_accuracy: 0.8324\n",
      "Epoch 327/400\n",
      "712/712 [==============================] - 0s 233us/sample - loss: 0.3821 - accuracy: 0.8441 - val_loss: 0.4345 - val_accuracy: 0.8268\n",
      "Epoch 328/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.3812 - accuracy: 0.8455 - val_loss: 0.4349 - val_accuracy: 0.8380\n",
      "Epoch 329/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3804 - accuracy: 0.8567 - val_loss: 0.4382 - val_accuracy: 0.8212\n",
      "Epoch 330/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3851 - accuracy: 0.8385 - val_loss: 0.4327 - val_accuracy: 0.8324\n",
      "Epoch 331/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3808 - accuracy: 0.8413 - val_loss: 0.4313 - val_accuracy: 0.8324\n",
      "Epoch 332/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3676 - accuracy: 0.8581 - val_loss: 0.4288 - val_accuracy: 0.8268\n",
      "Epoch 333/400\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.3872 - accuracy: 0.8497 - val_loss: 0.4370 - val_accuracy: 0.8212\n",
      "Epoch 334/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3811 - accuracy: 0.8399 - val_loss: 0.4344 - val_accuracy: 0.8268\n",
      "Epoch 335/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3851 - accuracy: 0.8329 - val_loss: 0.4335 - val_accuracy: 0.8324\n",
      "Epoch 336/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3828 - accuracy: 0.8455 - val_loss: 0.4308 - val_accuracy: 0.8324\n",
      "Epoch 337/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3843 - accuracy: 0.8441 - val_loss: 0.4321 - val_accuracy: 0.8324\n",
      "Epoch 338/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3785 - accuracy: 0.8567 - val_loss: 0.4381 - val_accuracy: 0.8324\n",
      "Epoch 339/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3774 - accuracy: 0.8511 - val_loss: 0.4327 - val_accuracy: 0.8268\n",
      "Epoch 340/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3858 - accuracy: 0.8357 - val_loss: 0.4272 - val_accuracy: 0.8324\n",
      "Epoch 341/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3826 - accuracy: 0.8497 - val_loss: 0.4312 - val_accuracy: 0.8324\n",
      "Epoch 342/400\n",
      "712/712 [==============================] - 0s 228us/sample - loss: 0.3761 - accuracy: 0.8596 - val_loss: 0.4265 - val_accuracy: 0.8324\n",
      "Epoch 343/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3830 - accuracy: 0.8427 - val_loss: 0.4271 - val_accuracy: 0.8324\n",
      "Epoch 344/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3770 - accuracy: 0.8455 - val_loss: 0.4366 - val_accuracy: 0.8324\n",
      "Epoch 345/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3758 - accuracy: 0.8483 - val_loss: 0.4359 - val_accuracy: 0.8268\n",
      "Epoch 346/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3840 - accuracy: 0.8469 - val_loss: 0.4308 - val_accuracy: 0.8380\n",
      "Epoch 347/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3818 - accuracy: 0.8525 - val_loss: 0.4299 - val_accuracy: 0.8324\n",
      "Epoch 348/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3789 - accuracy: 0.8343 - val_loss: 0.4318 - val_accuracy: 0.8324\n",
      "Epoch 349/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3803 - accuracy: 0.8525 - val_loss: 0.4319 - val_accuracy: 0.8268\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3809 - accuracy: 0.8469 - val_loss: 0.4286 - val_accuracy: 0.8380\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3827 - accuracy: 0.8441 - val_loss: 0.4309 - val_accuracy: 0.8380\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.3742 - accuracy: 0.8567 - val_loss: 0.4238 - val_accuracy: 0.8324\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3747 - accuracy: 0.8469 - val_loss: 0.4255 - val_accuracy: 0.8324\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3774 - accuracy: 0.8539 - val_loss: 0.4330 - val_accuracy: 0.8324\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3852 - accuracy: 0.8399 - val_loss: 0.4324 - val_accuracy: 0.8324\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3744 - accuracy: 0.8497 - val_loss: 0.4317 - val_accuracy: 0.8380\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3803 - accuracy: 0.8539 - val_loss: 0.4333 - val_accuracy: 0.8268\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3823 - accuracy: 0.8469 - val_loss: 0.4358 - val_accuracy: 0.8268\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3738 - accuracy: 0.8511 - val_loss: 0.4345 - val_accuracy: 0.8324\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.3710 - accuracy: 0.8539 - val_loss: 0.4269 - val_accuracy: 0.8324\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.3843 - accuracy: 0.8385 - val_loss: 0.4258 - val_accuracy: 0.8324\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.3785 - accuracy: 0.8525 - val_loss: 0.4300 - val_accuracy: 0.8380\n",
      "Epoch 363/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3765 - accuracy: 0.8553 - val_loss: 0.4296 - val_accuracy: 0.8324\n",
      "Epoch 364/400\n",
      "712/712 [==============================] - 0s 199us/sample - loss: 0.3821 - accuracy: 0.8427 - val_loss: 0.4300 - val_accuracy: 0.8380\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.3793 - accuracy: 0.8469 - val_loss: 0.4293 - val_accuracy: 0.8380\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3850 - accuracy: 0.8483 - val_loss: 0.4308 - val_accuracy: 0.8268\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3767 - accuracy: 0.8525 - val_loss: 0.4303 - val_accuracy: 0.8380\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3720 - accuracy: 0.8638 - val_loss: 0.4327 - val_accuracy: 0.8268\n",
      "Epoch 369/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3790 - accuracy: 0.8427 - val_loss: 0.4271 - val_accuracy: 0.8324\n",
      "Epoch 370/400\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.3793 - accuracy: 0.8511 - val_loss: 0.4329 - val_accuracy: 0.8268\n",
      "Epoch 371/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3731 - accuracy: 0.8525 - val_loss: 0.4318 - val_accuracy: 0.8324\n",
      "Epoch 372/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3828 - accuracy: 0.8413 - val_loss: 0.4294 - val_accuracy: 0.8324\n",
      "Epoch 373/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3817 - accuracy: 0.8427 - val_loss: 0.4310 - val_accuracy: 0.8380\n",
      "Epoch 374/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3877 - accuracy: 0.8427 - val_loss: 0.4366 - val_accuracy: 0.8324\n",
      "Epoch 375/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3805 - accuracy: 0.8441 - val_loss: 0.4346 - val_accuracy: 0.8268\n",
      "Epoch 376/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3685 - accuracy: 0.8581 - val_loss: 0.4339 - val_accuracy: 0.8324\n",
      "Epoch 377/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3822 - accuracy: 0.8511 - val_loss: 0.4378 - val_accuracy: 0.8268\n",
      "Epoch 378/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3873 - accuracy: 0.8399 - val_loss: 0.4313 - val_accuracy: 0.8324\n",
      "Epoch 379/400\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.3815 - accuracy: 0.8497 - val_loss: 0.4333 - val_accuracy: 0.8324\n",
      "Epoch 380/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3802 - accuracy: 0.8469 - val_loss: 0.4283 - val_accuracy: 0.8324\n",
      "Epoch 381/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3825 - accuracy: 0.8455 - val_loss: 0.4305 - val_accuracy: 0.8268\n",
      "Epoch 382/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.3732 - accuracy: 0.8413 - val_loss: 0.4337 - val_accuracy: 0.8268\n",
      "Epoch 383/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3807 - accuracy: 0.8469 - val_loss: 0.4284 - val_accuracy: 0.8324\n",
      "Epoch 384/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3830 - accuracy: 0.8483 - val_loss: 0.4253 - val_accuracy: 0.8324\n",
      "Epoch 385/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3803 - accuracy: 0.8427 - val_loss: 0.4296 - val_accuracy: 0.8324\n",
      "Epoch 386/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3801 - accuracy: 0.8441 - val_loss: 0.4267 - val_accuracy: 0.8324\n",
      "Epoch 387/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3880 - accuracy: 0.8441 - val_loss: 0.4261 - val_accuracy: 0.8380\n",
      "Epoch 388/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.3842 - accuracy: 0.8455 - val_loss: 0.4251 - val_accuracy: 0.8380\n",
      "Epoch 389/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3771 - accuracy: 0.8511 - val_loss: 0.4282 - val_accuracy: 0.8380\n",
      "Epoch 390/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3780 - accuracy: 0.8539 - val_loss: 0.4302 - val_accuracy: 0.8380\n",
      "Epoch 391/400\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.3789 - accuracy: 0.8427 - val_loss: 0.4262 - val_accuracy: 0.8324\n",
      "Epoch 392/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3787 - accuracy: 0.8525 - val_loss: 0.4267 - val_accuracy: 0.8324\n",
      "Epoch 393/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3645 - accuracy: 0.8567 - val_loss: 0.4282 - val_accuracy: 0.8324\n",
      "Epoch 394/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3888 - accuracy: 0.8343 - val_loss: 0.4264 - val_accuracy: 0.8324\n",
      "Epoch 395/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3825 - accuracy: 0.8385 - val_loss: 0.4274 - val_accuracy: 0.8268\n",
      "Epoch 396/400\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.3810 - accuracy: 0.8469 - val_loss: 0.4288 - val_accuracy: 0.8436\n",
      "Epoch 397/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3804 - accuracy: 0.8385 - val_loss: 0.4239 - val_accuracy: 0.8436\n",
      "Epoch 398/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3762 - accuracy: 0.8511 - val_loss: 0.4213 - val_accuracy: 0.8380\n",
      "Epoch 399/400\n",
      "712/712 [==============================] - 0s 239us/sample - loss: 0.3780 - accuracy: 0.8441 - val_loss: 0.4225 - val_accuracy: 0.8380\n",
      "Epoch 400/400\n",
      "712/712 [==============================] - 0s 239us/sample - loss: 0.3773 - accuracy: 0.8469 - val_loss: 0.4234 - val_accuracy: 0.8324\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/400\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.6667 - accuracy: 0.6110 - val_loss: 0.6770 - val_accuracy: 0.5866\n",
      "Epoch 2/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6595 - accuracy: 0.6236 - val_loss: 0.6728 - val_accuracy: 0.5866\n",
      "Epoch 3/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.6510 - accuracy: 0.6222 - val_loss: 0.6453 - val_accuracy: 0.5866\n",
      "Epoch 4/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6310 - accuracy: 0.6320 - val_loss: 0.6073 - val_accuracy: 0.5866\n",
      "Epoch 5/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5975 - accuracy: 0.6503 - val_loss: 0.5665 - val_accuracy: 0.7430\n",
      "Epoch 6/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5639 - accuracy: 0.7402 - val_loss: 0.5222 - val_accuracy: 0.8101\n",
      "Epoch 7/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5340 - accuracy: 0.7542 - val_loss: 0.4897 - val_accuracy: 0.8156\n",
      "Epoch 8/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5139 - accuracy: 0.7823 - val_loss: 0.4707 - val_accuracy: 0.8101\n",
      "Epoch 9/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4907 - accuracy: 0.7893 - val_loss: 0.4629 - val_accuracy: 0.8156\n",
      "Epoch 10/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4861 - accuracy: 0.8048 - val_loss: 0.4562 - val_accuracy: 0.8156\n",
      "Epoch 11/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4836 - accuracy: 0.8104 - val_loss: 0.4543 - val_accuracy: 0.8212\n",
      "Epoch 12/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4739 - accuracy: 0.8048 - val_loss: 0.4522 - val_accuracy: 0.8101\n",
      "Epoch 13/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4782 - accuracy: 0.8062 - val_loss: 0.4498 - val_accuracy: 0.8156\n",
      "Epoch 14/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4570 - accuracy: 0.8132 - val_loss: 0.4518 - val_accuracy: 0.8101\n",
      "Epoch 15/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4617 - accuracy: 0.8132 - val_loss: 0.4492 - val_accuracy: 0.8101\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.4565 - accuracy: 0.8188 - val_loss: 0.4464 - val_accuracy: 0.8156\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4556 - accuracy: 0.8216 - val_loss: 0.4484 - val_accuracy: 0.8212\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4489 - accuracy: 0.8202 - val_loss: 0.4504 - val_accuracy: 0.8156\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4600 - accuracy: 0.8118 - val_loss: 0.4472 - val_accuracy: 0.8212\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4472 - accuracy: 0.8160 - val_loss: 0.4474 - val_accuracy: 0.8156\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4396 - accuracy: 0.8230 - val_loss: 0.4427 - val_accuracy: 0.8212\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4436 - accuracy: 0.8301 - val_loss: 0.4420 - val_accuracy: 0.8268\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4437 - accuracy: 0.8301 - val_loss: 0.4405 - val_accuracy: 0.8268\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4360 - accuracy: 0.8230 - val_loss: 0.4421 - val_accuracy: 0.8212\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4431 - accuracy: 0.8216 - val_loss: 0.4478 - val_accuracy: 0.8156\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4303 - accuracy: 0.8258 - val_loss: 0.4410 - val_accuracy: 0.8268\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4278 - accuracy: 0.8357 - val_loss: 0.4404 - val_accuracy: 0.8212\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4344 - accuracy: 0.8188 - val_loss: 0.4416 - val_accuracy: 0.8101\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4267 - accuracy: 0.8357 - val_loss: 0.4389 - val_accuracy: 0.8212\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4145 - accuracy: 0.8301 - val_loss: 0.4391 - val_accuracy: 0.8156\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4398 - accuracy: 0.8174 - val_loss: 0.4392 - val_accuracy: 0.8268\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4202 - accuracy: 0.8399 - val_loss: 0.4384 - val_accuracy: 0.8324\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4115 - accuracy: 0.8371 - val_loss: 0.4387 - val_accuracy: 0.8156\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4228 - accuracy: 0.8244 - val_loss: 0.4359 - val_accuracy: 0.8324\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4143 - accuracy: 0.8287 - val_loss: 0.4355 - val_accuracy: 0.8380\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4154 - accuracy: 0.8385 - val_loss: 0.4366 - val_accuracy: 0.8324\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4050 - accuracy: 0.8399 - val_loss: 0.4385 - val_accuracy: 0.8268\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4111 - accuracy: 0.8287 - val_loss: 0.4384 - val_accuracy: 0.8324\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4299 - accuracy: 0.8104 - val_loss: 0.4379 - val_accuracy: 0.8380\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4125 - accuracy: 0.8272 - val_loss: 0.4374 - val_accuracy: 0.8212\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.4159 - accuracy: 0.8244 - val_loss: 0.4380 - val_accuracy: 0.8212\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4203 - accuracy: 0.8244 - val_loss: 0.4388 - val_accuracy: 0.8101\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.4277 - accuracy: 0.8174 - val_loss: 0.4381 - val_accuracy: 0.8380\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3996 - accuracy: 0.8343 - val_loss: 0.4402 - val_accuracy: 0.8101\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 205us/sample - loss: 0.4197 - accuracy: 0.8329 - val_loss: 0.4394 - val_accuracy: 0.8268\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 247us/sample - loss: 0.4074 - accuracy: 0.8413 - val_loss: 0.4412 - val_accuracy: 0.8156\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4070 - accuracy: 0.8272 - val_loss: 0.4433 - val_accuracy: 0.8156\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4170 - accuracy: 0.8272 - val_loss: 0.4424 - val_accuracy: 0.8101\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4192 - accuracy: 0.8357 - val_loss: 0.4421 - val_accuracy: 0.8212\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3979 - accuracy: 0.8399 - val_loss: 0.4433 - val_accuracy: 0.8101\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4214 - accuracy: 0.8230 - val_loss: 0.4388 - val_accuracy: 0.8156\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3940 - accuracy: 0.8371 - val_loss: 0.4373 - val_accuracy: 0.8212\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4239 - accuracy: 0.8160 - val_loss: 0.4370 - val_accuracy: 0.8156\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3993 - accuracy: 0.8385 - val_loss: 0.4377 - val_accuracy: 0.8212\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4052 - accuracy: 0.8357 - val_loss: 0.4384 - val_accuracy: 0.8268\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4077 - accuracy: 0.8202 - val_loss: 0.4363 - val_accuracy: 0.8212\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4035 - accuracy: 0.8357 - val_loss: 0.4383 - val_accuracy: 0.8212\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4031 - accuracy: 0.8315 - val_loss: 0.4395 - val_accuracy: 0.8212\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4101 - accuracy: 0.8315 - val_loss: 0.4420 - val_accuracy: 0.8156\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4173 - accuracy: 0.8216 - val_loss: 0.4423 - val_accuracy: 0.8324\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4088 - accuracy: 0.8315 - val_loss: 0.4441 - val_accuracy: 0.8101\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3968 - accuracy: 0.8469 - val_loss: 0.4469 - val_accuracy: 0.8101\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3944 - accuracy: 0.8427 - val_loss: 0.4502 - val_accuracy: 0.7989\n",
      "Epoch 64/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4012 - accuracy: 0.8441 - val_loss: 0.4535 - val_accuracy: 0.8045\n",
      "Epoch 65/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4252 - accuracy: 0.8202 - val_loss: 0.4457 - val_accuracy: 0.8324\n",
      "Epoch 66/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3956 - accuracy: 0.8441 - val_loss: 0.4430 - val_accuracy: 0.8268\n",
      "Epoch 67/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4173 - accuracy: 0.8216 - val_loss: 0.4413 - val_accuracy: 0.8212\n",
      "Epoch 68/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4077 - accuracy: 0.8230 - val_loss: 0.4423 - val_accuracy: 0.8212\n",
      "Epoch 69/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3993 - accuracy: 0.8413 - val_loss: 0.4399 - val_accuracy: 0.8380\n",
      "Epoch 70/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3864 - accuracy: 0.8553 - val_loss: 0.4394 - val_accuracy: 0.8380\n",
      "Epoch 71/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4031 - accuracy: 0.8287 - val_loss: 0.4405 - val_accuracy: 0.8268\n",
      "Epoch 72/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3818 - accuracy: 0.8539 - val_loss: 0.4441 - val_accuracy: 0.8212\n",
      "Epoch 73/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3972 - accuracy: 0.8539 - val_loss: 0.4467 - val_accuracy: 0.8268\n",
      "Epoch 74/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4086 - accuracy: 0.8329 - val_loss: 0.4422 - val_accuracy: 0.8324\n",
      "Epoch 75/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3936 - accuracy: 0.8385 - val_loss: 0.4431 - val_accuracy: 0.8156\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4028 - accuracy: 0.8315 - val_loss: 0.4413 - val_accuracy: 0.8156\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3965 - accuracy: 0.8371 - val_loss: 0.4447 - val_accuracy: 0.8212\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3936 - accuracy: 0.8399 - val_loss: 0.4451 - val_accuracy: 0.8156\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4142 - accuracy: 0.8258 - val_loss: 0.4396 - val_accuracy: 0.8212\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3918 - accuracy: 0.8427 - val_loss: 0.4426 - val_accuracy: 0.8156\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4077 - accuracy: 0.8343 - val_loss: 0.4367 - val_accuracy: 0.8268\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4107 - accuracy: 0.8287 - val_loss: 0.4401 - val_accuracy: 0.8156\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4019 - accuracy: 0.8287 - val_loss: 0.4375 - val_accuracy: 0.8156\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3916 - accuracy: 0.8441 - val_loss: 0.4400 - val_accuracy: 0.8156\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 216us/sample - loss: 0.4007 - accuracy: 0.8287 - val_loss: 0.4385 - val_accuracy: 0.8156\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4006 - accuracy: 0.8371 - val_loss: 0.4382 - val_accuracy: 0.8212\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 220us/sample - loss: 0.4131 - accuracy: 0.8202 - val_loss: 0.4373 - val_accuracy: 0.8156\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 239us/sample - loss: 0.3950 - accuracy: 0.8427 - val_loss: 0.4393 - val_accuracy: 0.8156\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 221us/sample - loss: 0.3910 - accuracy: 0.8399 - val_loss: 0.4399 - val_accuracy: 0.8212\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.3823 - accuracy: 0.8567 - val_loss: 0.4389 - val_accuracy: 0.8212\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3885 - accuracy: 0.8469 - val_loss: 0.4415 - val_accuracy: 0.8156\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4050 - accuracy: 0.8230 - val_loss: 0.4421 - val_accuracy: 0.8156\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3999 - accuracy: 0.8385 - val_loss: 0.4419 - val_accuracy: 0.8156\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4028 - accuracy: 0.8244 - val_loss: 0.4405 - val_accuracy: 0.8156\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3973 - accuracy: 0.8315 - val_loss: 0.4423 - val_accuracy: 0.8156\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3955 - accuracy: 0.8343 - val_loss: 0.4397 - val_accuracy: 0.8156\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3900 - accuracy: 0.8357 - val_loss: 0.4404 - val_accuracy: 0.8156\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3908 - accuracy: 0.8399 - val_loss: 0.4419 - val_accuracy: 0.8212\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4019 - accuracy: 0.8188 - val_loss: 0.4399 - val_accuracy: 0.8156\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3956 - accuracy: 0.8301 - val_loss: 0.4395 - val_accuracy: 0.8156\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3946 - accuracy: 0.8357 - val_loss: 0.4401 - val_accuracy: 0.8212\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3960 - accuracy: 0.8329 - val_loss: 0.4414 - val_accuracy: 0.8156\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3843 - accuracy: 0.8483 - val_loss: 0.4401 - val_accuracy: 0.8156\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3874 - accuracy: 0.8413 - val_loss: 0.4380 - val_accuracy: 0.8156\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3828 - accuracy: 0.8385 - val_loss: 0.4418 - val_accuracy: 0.8156\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3921 - accuracy: 0.8315 - val_loss: 0.4431 - val_accuracy: 0.8156\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3933 - accuracy: 0.8329 - val_loss: 0.4423 - val_accuracy: 0.8045\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3844 - accuracy: 0.8483 - val_loss: 0.4460 - val_accuracy: 0.8156\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3985 - accuracy: 0.8258 - val_loss: 0.4458 - val_accuracy: 0.8101\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3953 - accuracy: 0.8371 - val_loss: 0.4416 - val_accuracy: 0.8156\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4041 - accuracy: 0.8399 - val_loss: 0.4376 - val_accuracy: 0.8212\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3954 - accuracy: 0.8343 - val_loss: 0.4378 - val_accuracy: 0.8156\n",
      "Epoch 113/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3959 - accuracy: 0.8427 - val_loss: 0.4348 - val_accuracy: 0.8156\n",
      "Epoch 114/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3906 - accuracy: 0.8343 - val_loss: 0.4331 - val_accuracy: 0.8212\n",
      "Epoch 115/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3823 - accuracy: 0.8385 - val_loss: 0.4373 - val_accuracy: 0.8156\n",
      "Epoch 116/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3921 - accuracy: 0.8343 - val_loss: 0.4395 - val_accuracy: 0.8101\n",
      "Epoch 117/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3903 - accuracy: 0.8441 - val_loss: 0.4404 - val_accuracy: 0.8156\n",
      "Epoch 118/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3960 - accuracy: 0.8413 - val_loss: 0.4450 - val_accuracy: 0.8101\n",
      "Epoch 119/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3938 - accuracy: 0.8357 - val_loss: 0.4395 - val_accuracy: 0.8324\n",
      "Epoch 120/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3904 - accuracy: 0.8385 - val_loss: 0.4377 - val_accuracy: 0.8324\n",
      "Epoch 121/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3856 - accuracy: 0.8469 - val_loss: 0.4380 - val_accuracy: 0.8045\n",
      "Epoch 122/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3997 - accuracy: 0.8301 - val_loss: 0.4386 - val_accuracy: 0.8101\n",
      "Epoch 123/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4091 - accuracy: 0.8188 - val_loss: 0.4389 - val_accuracy: 0.8212\n",
      "Epoch 124/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3918 - accuracy: 0.8427 - val_loss: 0.4398 - val_accuracy: 0.8045\n",
      "Epoch 125/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3881 - accuracy: 0.8399 - val_loss: 0.4385 - val_accuracy: 0.8045\n",
      "Epoch 126/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3844 - accuracy: 0.8511 - val_loss: 0.4386 - val_accuracy: 0.8045\n",
      "Epoch 127/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3773 - accuracy: 0.8539 - val_loss: 0.4383 - val_accuracy: 0.8045\n",
      "Epoch 128/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3863 - accuracy: 0.8413 - val_loss: 0.4366 - val_accuracy: 0.8156\n",
      "Epoch 129/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3875 - accuracy: 0.8455 - val_loss: 0.4405 - val_accuracy: 0.8101\n",
      "Epoch 130/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3823 - accuracy: 0.8427 - val_loss: 0.4406 - val_accuracy: 0.8101\n",
      "Epoch 131/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3973 - accuracy: 0.8343 - val_loss: 0.4402 - val_accuracy: 0.7989\n",
      "Epoch 132/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3954 - accuracy: 0.8427 - val_loss: 0.4404 - val_accuracy: 0.8045\n",
      "Epoch 133/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3962 - accuracy: 0.8427 - val_loss: 0.4399 - val_accuracy: 0.8101\n",
      "Epoch 134/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3805 - accuracy: 0.8427 - val_loss: 0.4408 - val_accuracy: 0.8101\n",
      "Epoch 135/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.3785 - accuracy: 0.8371 - val_loss: 0.4396 - val_accuracy: 0.8156\n",
      "Epoch 136/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3838 - accuracy: 0.8385 - val_loss: 0.4420 - val_accuracy: 0.8156\n",
      "Epoch 137/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3796 - accuracy: 0.8511 - val_loss: 0.4385 - val_accuracy: 0.8101\n",
      "Epoch 138/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4023 - accuracy: 0.8399 - val_loss: 0.4371 - val_accuracy: 0.8156\n",
      "Epoch 139/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3878 - accuracy: 0.8315 - val_loss: 0.4381 - val_accuracy: 0.8268\n",
      "Epoch 140/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3815 - accuracy: 0.8483 - val_loss: 0.4381 - val_accuracy: 0.8101\n",
      "Epoch 141/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3916 - accuracy: 0.8413 - val_loss: 0.4362 - val_accuracy: 0.8156\n",
      "Epoch 142/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3859 - accuracy: 0.8483 - val_loss: 0.4401 - val_accuracy: 0.8212\n",
      "Epoch 143/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3876 - accuracy: 0.8413 - val_loss: 0.4426 - val_accuracy: 0.8268\n",
      "Epoch 144/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3818 - accuracy: 0.8469 - val_loss: 0.4409 - val_accuracy: 0.8156\n",
      "Epoch 145/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3794 - accuracy: 0.8413 - val_loss: 0.4435 - val_accuracy: 0.8156\n",
      "Epoch 146/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3837 - accuracy: 0.8343 - val_loss: 0.4393 - val_accuracy: 0.8156\n",
      "Epoch 147/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3677 - accuracy: 0.8511 - val_loss: 0.4441 - val_accuracy: 0.8156\n",
      "Epoch 148/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3774 - accuracy: 0.8511 - val_loss: 0.4452 - val_accuracy: 0.8156\n",
      "Epoch 149/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3775 - accuracy: 0.8441 - val_loss: 0.4463 - val_accuracy: 0.8156\n",
      "Epoch 150/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3848 - accuracy: 0.8413 - val_loss: 0.4421 - val_accuracy: 0.8101\n",
      "Epoch 151/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3903 - accuracy: 0.8287 - val_loss: 0.4364 - val_accuracy: 0.8101\n",
      "Epoch 152/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3825 - accuracy: 0.8525 - val_loss: 0.4384 - val_accuracy: 0.8045\n",
      "Epoch 153/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3871 - accuracy: 0.8469 - val_loss: 0.4390 - val_accuracy: 0.7989\n",
      "Epoch 154/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3906 - accuracy: 0.8315 - val_loss: 0.4390 - val_accuracy: 0.8101\n",
      "Epoch 155/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3748 - accuracy: 0.8539 - val_loss: 0.4397 - val_accuracy: 0.8101\n",
      "Epoch 156/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3852 - accuracy: 0.8399 - val_loss: 0.4400 - val_accuracy: 0.8101\n",
      "Epoch 157/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3717 - accuracy: 0.8553 - val_loss: 0.4432 - val_accuracy: 0.8101\n",
      "Epoch 158/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3836 - accuracy: 0.8511 - val_loss: 0.4521 - val_accuracy: 0.8156\n",
      "Epoch 159/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3762 - accuracy: 0.8455 - val_loss: 0.4470 - val_accuracy: 0.8156\n",
      "Epoch 160/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3872 - accuracy: 0.8413 - val_loss: 0.4444 - val_accuracy: 0.8101\n",
      "Epoch 161/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3814 - accuracy: 0.8385 - val_loss: 0.4461 - val_accuracy: 0.8101\n",
      "Epoch 162/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3870 - accuracy: 0.8315 - val_loss: 0.4467 - val_accuracy: 0.8156\n",
      "Epoch 163/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3962 - accuracy: 0.8399 - val_loss: 0.4442 - val_accuracy: 0.8101\n",
      "Epoch 164/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3717 - accuracy: 0.8497 - val_loss: 0.4468 - val_accuracy: 0.8156\n",
      "Epoch 165/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3832 - accuracy: 0.8455 - val_loss: 0.4468 - val_accuracy: 0.8156\n",
      "Epoch 166/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3802 - accuracy: 0.8469 - val_loss: 0.4516 - val_accuracy: 0.8156\n",
      "Epoch 167/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3846 - accuracy: 0.8539 - val_loss: 0.4468 - val_accuracy: 0.8101\n",
      "Epoch 168/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3778 - accuracy: 0.8497 - val_loss: 0.4431 - val_accuracy: 0.8101\n",
      "Epoch 169/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3824 - accuracy: 0.8483 - val_loss: 0.4442 - val_accuracy: 0.8101\n",
      "Epoch 170/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3928 - accuracy: 0.8371 - val_loss: 0.4436 - val_accuracy: 0.8101\n",
      "Epoch 171/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3727 - accuracy: 0.8539 - val_loss: 0.4431 - val_accuracy: 0.8101\n",
      "Epoch 172/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3848 - accuracy: 0.8385 - val_loss: 0.4404 - val_accuracy: 0.8101\n",
      "Epoch 173/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3899 - accuracy: 0.8329 - val_loss: 0.4449 - val_accuracy: 0.8101\n",
      "Epoch 174/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3747 - accuracy: 0.8413 - val_loss: 0.4463 - val_accuracy: 0.8101\n",
      "Epoch 175/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3855 - accuracy: 0.8455 - val_loss: 0.4464 - val_accuracy: 0.8045\n",
      "Epoch 176/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3754 - accuracy: 0.8539 - val_loss: 0.4484 - val_accuracy: 0.8101\n",
      "Epoch 177/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3781 - accuracy: 0.8427 - val_loss: 0.4447 - val_accuracy: 0.8101\n",
      "Epoch 178/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3865 - accuracy: 0.8469 - val_loss: 0.4450 - val_accuracy: 0.8101\n",
      "Epoch 179/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3810 - accuracy: 0.8455 - val_loss: 0.4460 - val_accuracy: 0.8101\n",
      "Epoch 180/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3870 - accuracy: 0.8497 - val_loss: 0.4454 - val_accuracy: 0.8101\n",
      "Epoch 181/400\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.3757 - accuracy: 0.8455 - val_loss: 0.4442 - val_accuracy: 0.8045\n",
      "Epoch 182/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3784 - accuracy: 0.8413 - val_loss: 0.4375 - val_accuracy: 0.8101\n",
      "Epoch 183/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3810 - accuracy: 0.8427 - val_loss: 0.4386 - val_accuracy: 0.8101\n",
      "Epoch 184/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3700 - accuracy: 0.8511 - val_loss: 0.4428 - val_accuracy: 0.8156\n",
      "Epoch 185/400\n",
      "712/712 [==============================] - 0s 213us/sample - loss: 0.3708 - accuracy: 0.8511 - val_loss: 0.4471 - val_accuracy: 0.8156\n",
      "Epoch 186/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3737 - accuracy: 0.8567 - val_loss: 0.4497 - val_accuracy: 0.8156\n",
      "Epoch 187/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3822 - accuracy: 0.8455 - val_loss: 0.4496 - val_accuracy: 0.8156\n",
      "Epoch 188/400\n",
      "712/712 [==============================] - 0s 242us/sample - loss: 0.3820 - accuracy: 0.8399 - val_loss: 0.4504 - val_accuracy: 0.8156\n",
      "Epoch 189/400\n",
      "712/712 [==============================] - 0s 219us/sample - loss: 0.3889 - accuracy: 0.8441 - val_loss: 0.4500 - val_accuracy: 0.8156\n",
      "Epoch 190/400\n",
      "712/712 [==============================] - 0s 215us/sample - loss: 0.3721 - accuracy: 0.8553 - val_loss: 0.4492 - val_accuracy: 0.8212\n",
      "Epoch 191/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3789 - accuracy: 0.8455 - val_loss: 0.4470 - val_accuracy: 0.8212\n",
      "Epoch 192/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3762 - accuracy: 0.8567 - val_loss: 0.4412 - val_accuracy: 0.8101\n",
      "Epoch 193/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3784 - accuracy: 0.8441 - val_loss: 0.4424 - val_accuracy: 0.8156\n",
      "Epoch 194/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3756 - accuracy: 0.8413 - val_loss: 0.4451 - val_accuracy: 0.8212\n",
      "Epoch 195/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3943 - accuracy: 0.8427 - val_loss: 0.4464 - val_accuracy: 0.8101\n",
      "Epoch 196/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3825 - accuracy: 0.8343 - val_loss: 0.4473 - val_accuracy: 0.8045\n",
      "Epoch 197/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3742 - accuracy: 0.8371 - val_loss: 0.4487 - val_accuracy: 0.8212\n",
      "Epoch 198/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3787 - accuracy: 0.8497 - val_loss: 0.4493 - val_accuracy: 0.8101\n",
      "Epoch 199/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3930 - accuracy: 0.8441 - val_loss: 0.4438 - val_accuracy: 0.8156\n",
      "Epoch 200/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3644 - accuracy: 0.8624 - val_loss: 0.4421 - val_accuracy: 0.8101\n",
      "Epoch 201/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3783 - accuracy: 0.8469 - val_loss: 0.4411 - val_accuracy: 0.8212\n",
      "Epoch 202/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3906 - accuracy: 0.8357 - val_loss: 0.4398 - val_accuracy: 0.8045\n",
      "Epoch 203/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3892 - accuracy: 0.8371 - val_loss: 0.4378 - val_accuracy: 0.8156\n",
      "Epoch 204/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3813 - accuracy: 0.8525 - val_loss: 0.4391 - val_accuracy: 0.8101\n",
      "Epoch 205/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3697 - accuracy: 0.8511 - val_loss: 0.4390 - val_accuracy: 0.8101\n",
      "Epoch 206/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3794 - accuracy: 0.8385 - val_loss: 0.4405 - val_accuracy: 0.8101\n",
      "Epoch 207/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3699 - accuracy: 0.8385 - val_loss: 0.4437 - val_accuracy: 0.8101\n",
      "Epoch 208/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3741 - accuracy: 0.8483 - val_loss: 0.4491 - val_accuracy: 0.8101\n",
      "Epoch 209/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3780 - accuracy: 0.8497 - val_loss: 0.4482 - val_accuracy: 0.8101\n",
      "Epoch 210/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3832 - accuracy: 0.8455 - val_loss: 0.4527 - val_accuracy: 0.8212\n",
      "Epoch 211/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3761 - accuracy: 0.8483 - val_loss: 0.4524 - val_accuracy: 0.8212\n",
      "Epoch 212/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3808 - accuracy: 0.8539 - val_loss: 0.4489 - val_accuracy: 0.8101\n",
      "Epoch 213/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3732 - accuracy: 0.8483 - val_loss: 0.4461 - val_accuracy: 0.8101\n",
      "Epoch 214/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3720 - accuracy: 0.8596 - val_loss: 0.4499 - val_accuracy: 0.8101\n",
      "Epoch 215/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3737 - accuracy: 0.8455 - val_loss: 0.4481 - val_accuracy: 0.8101\n",
      "Epoch 216/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3832 - accuracy: 0.8343 - val_loss: 0.4495 - val_accuracy: 0.8101\n",
      "Epoch 217/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3814 - accuracy: 0.8455 - val_loss: 0.4498 - val_accuracy: 0.8101\n",
      "Epoch 218/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3765 - accuracy: 0.8441 - val_loss: 0.4490 - val_accuracy: 0.8156\n",
      "Epoch 219/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3788 - accuracy: 0.8455 - val_loss: 0.4504 - val_accuracy: 0.8156\n",
      "Epoch 220/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3889 - accuracy: 0.8427 - val_loss: 0.4431 - val_accuracy: 0.8101\n",
      "Epoch 221/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3796 - accuracy: 0.8469 - val_loss: 0.4418 - val_accuracy: 0.8101\n",
      "Epoch 222/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3900 - accuracy: 0.8539 - val_loss: 0.4420 - val_accuracy: 0.8101\n",
      "Epoch 223/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3670 - accuracy: 0.8497 - val_loss: 0.4443 - val_accuracy: 0.8156\n",
      "Epoch 224/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3638 - accuracy: 0.8553 - val_loss: 0.4469 - val_accuracy: 0.8101\n",
      "Epoch 225/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3841 - accuracy: 0.8413 - val_loss: 0.4470 - val_accuracy: 0.8101\n",
      "Epoch 226/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3721 - accuracy: 0.8483 - val_loss: 0.4454 - val_accuracy: 0.8101\n",
      "Epoch 227/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3808 - accuracy: 0.8329 - val_loss: 0.4467 - val_accuracy: 0.8101\n",
      "Epoch 228/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3756 - accuracy: 0.8497 - val_loss: 0.4498 - val_accuracy: 0.8212\n",
      "Epoch 229/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3773 - accuracy: 0.8385 - val_loss: 0.4497 - val_accuracy: 0.8212\n",
      "Epoch 230/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3803 - accuracy: 0.8357 - val_loss: 0.4510 - val_accuracy: 0.8212\n",
      "Epoch 231/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3848 - accuracy: 0.8413 - val_loss: 0.4459 - val_accuracy: 0.8156\n",
      "Epoch 232/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3711 - accuracy: 0.8427 - val_loss: 0.4473 - val_accuracy: 0.8212\n",
      "Epoch 233/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3739 - accuracy: 0.8511 - val_loss: 0.4499 - val_accuracy: 0.8212\n",
      "Epoch 234/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3713 - accuracy: 0.8497 - val_loss: 0.4503 - val_accuracy: 0.8156\n",
      "Epoch 235/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3748 - accuracy: 0.8539 - val_loss: 0.4495 - val_accuracy: 0.8156\n",
      "Epoch 236/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3796 - accuracy: 0.8441 - val_loss: 0.4488 - val_accuracy: 0.8212\n",
      "Epoch 237/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3790 - accuracy: 0.8427 - val_loss: 0.4494 - val_accuracy: 0.8156\n",
      "Epoch 238/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3782 - accuracy: 0.8399 - val_loss: 0.4467 - val_accuracy: 0.8101\n",
      "Epoch 239/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3715 - accuracy: 0.8596 - val_loss: 0.4520 - val_accuracy: 0.8101\n",
      "Epoch 240/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3855 - accuracy: 0.8441 - val_loss: 0.4506 - val_accuracy: 0.8156\n",
      "Epoch 241/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3809 - accuracy: 0.8455 - val_loss: 0.4493 - val_accuracy: 0.8156\n",
      "Epoch 242/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3727 - accuracy: 0.8511 - val_loss: 0.4520 - val_accuracy: 0.8101\n",
      "Epoch 243/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3726 - accuracy: 0.8497 - val_loss: 0.4514 - val_accuracy: 0.8156\n",
      "Epoch 244/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3711 - accuracy: 0.8539 - val_loss: 0.4526 - val_accuracy: 0.8101\n",
      "Epoch 245/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3782 - accuracy: 0.8427 - val_loss: 0.4487 - val_accuracy: 0.8212\n",
      "Epoch 246/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3731 - accuracy: 0.8525 - val_loss: 0.4515 - val_accuracy: 0.8101\n",
      "Epoch 247/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3788 - accuracy: 0.8441 - val_loss: 0.4488 - val_accuracy: 0.8156\n",
      "Epoch 248/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3848 - accuracy: 0.8385 - val_loss: 0.4488 - val_accuracy: 0.8156\n",
      "Epoch 249/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3729 - accuracy: 0.8483 - val_loss: 0.4453 - val_accuracy: 0.8156\n",
      "Epoch 250/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3697 - accuracy: 0.8469 - val_loss: 0.4465 - val_accuracy: 0.8212\n",
      "Epoch 251/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3706 - accuracy: 0.8567 - val_loss: 0.4466 - val_accuracy: 0.8101\n",
      "Epoch 252/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3736 - accuracy: 0.8469 - val_loss: 0.4478 - val_accuracy: 0.8156\n",
      "Epoch 253/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3784 - accuracy: 0.8511 - val_loss: 0.4468 - val_accuracy: 0.8156\n",
      "Epoch 254/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3926 - accuracy: 0.8399 - val_loss: 0.4468 - val_accuracy: 0.8212\n",
      "Epoch 255/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3764 - accuracy: 0.8596 - val_loss: 0.4472 - val_accuracy: 0.8156\n",
      "Epoch 256/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3754 - accuracy: 0.8497 - val_loss: 0.4467 - val_accuracy: 0.8212\n",
      "Epoch 257/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3742 - accuracy: 0.8441 - val_loss: 0.4474 - val_accuracy: 0.8156\n",
      "Epoch 258/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3800 - accuracy: 0.8483 - val_loss: 0.4480 - val_accuracy: 0.8156\n",
      "Epoch 259/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3753 - accuracy: 0.8469 - val_loss: 0.4487 - val_accuracy: 0.8156\n",
      "Epoch 260/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3845 - accuracy: 0.8441 - val_loss: 0.4486 - val_accuracy: 0.8156\n",
      "Epoch 261/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3646 - accuracy: 0.8469 - val_loss: 0.4485 - val_accuracy: 0.8101\n",
      "Epoch 262/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3652 - accuracy: 0.8596 - val_loss: 0.4521 - val_accuracy: 0.8101\n",
      "Epoch 263/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3717 - accuracy: 0.8511 - val_loss: 0.4512 - val_accuracy: 0.8101\n",
      "Epoch 264/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3819 - accuracy: 0.8469 - val_loss: 0.4482 - val_accuracy: 0.8101\n",
      "Epoch 265/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3677 - accuracy: 0.8539 - val_loss: 0.4503 - val_accuracy: 0.8212\n",
      "Epoch 266/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3748 - accuracy: 0.8483 - val_loss: 0.4512 - val_accuracy: 0.8212\n",
      "Epoch 267/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3599 - accuracy: 0.8666 - val_loss: 0.4544 - val_accuracy: 0.8156\n",
      "Epoch 268/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3767 - accuracy: 0.8469 - val_loss: 0.4543 - val_accuracy: 0.8045\n",
      "Epoch 269/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3742 - accuracy: 0.8357 - val_loss: 0.4535 - val_accuracy: 0.8156\n",
      "Epoch 270/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3711 - accuracy: 0.8567 - val_loss: 0.4542 - val_accuracy: 0.8101\n",
      "Epoch 271/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3818 - accuracy: 0.8287 - val_loss: 0.4503 - val_accuracy: 0.8156\n",
      "Epoch 272/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3746 - accuracy: 0.8511 - val_loss: 0.4474 - val_accuracy: 0.8212\n",
      "Epoch 273/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3700 - accuracy: 0.8497 - val_loss: 0.4483 - val_accuracy: 0.8156\n",
      "Epoch 274/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3832 - accuracy: 0.8371 - val_loss: 0.4503 - val_accuracy: 0.8156\n",
      "Epoch 275/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3797 - accuracy: 0.8399 - val_loss: 0.4477 - val_accuracy: 0.8156\n",
      "Epoch 276/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3792 - accuracy: 0.8483 - val_loss: 0.4517 - val_accuracy: 0.8045\n",
      "Epoch 277/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3747 - accuracy: 0.8553 - val_loss: 0.4525 - val_accuracy: 0.8101\n",
      "Epoch 278/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3669 - accuracy: 0.8497 - val_loss: 0.4511 - val_accuracy: 0.8101\n",
      "Epoch 279/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3739 - accuracy: 0.8469 - val_loss: 0.4488 - val_accuracy: 0.8045\n",
      "Epoch 280/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3736 - accuracy: 0.8469 - val_loss: 0.4498 - val_accuracy: 0.8101\n",
      "Epoch 281/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3618 - accuracy: 0.8511 - val_loss: 0.4502 - val_accuracy: 0.8212\n",
      "Epoch 282/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3733 - accuracy: 0.8399 - val_loss: 0.4510 - val_accuracy: 0.8212\n",
      "Epoch 283/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3819 - accuracy: 0.8329 - val_loss: 0.4548 - val_accuracy: 0.8212\n",
      "Epoch 284/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3620 - accuracy: 0.8638 - val_loss: 0.4522 - val_accuracy: 0.8156\n",
      "Epoch 285/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3647 - accuracy: 0.8567 - val_loss: 0.4502 - val_accuracy: 0.8156\n",
      "Epoch 286/400\n",
      "712/712 [==============================] - 0s 217us/sample - loss: 0.3712 - accuracy: 0.8511 - val_loss: 0.4495 - val_accuracy: 0.8101\n",
      "Epoch 287/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3776 - accuracy: 0.8511 - val_loss: 0.4484 - val_accuracy: 0.8101\n",
      "Epoch 288/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.3590 - accuracy: 0.8581 - val_loss: 0.4518 - val_accuracy: 0.8212\n",
      "Epoch 289/400\n",
      "712/712 [==============================] - 0s 269us/sample - loss: 0.3734 - accuracy: 0.8455 - val_loss: 0.4515 - val_accuracy: 0.8156\n",
      "Epoch 290/400\n",
      "712/712 [==============================] - 0s 221us/sample - loss: 0.3780 - accuracy: 0.8511 - val_loss: 0.4486 - val_accuracy: 0.8156\n",
      "Epoch 291/400\n",
      "712/712 [==============================] - 0s 203us/sample - loss: 0.3838 - accuracy: 0.8441 - val_loss: 0.4480 - val_accuracy: 0.8101\n",
      "Epoch 292/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3759 - accuracy: 0.8385 - val_loss: 0.4515 - val_accuracy: 0.8156\n",
      "Epoch 293/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3741 - accuracy: 0.8497 - val_loss: 0.4535 - val_accuracy: 0.8156\n",
      "Epoch 294/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3670 - accuracy: 0.8610 - val_loss: 0.4546 - val_accuracy: 0.8212\n",
      "Epoch 295/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3648 - accuracy: 0.8455 - val_loss: 0.4535 - val_accuracy: 0.8212\n",
      "Epoch 296/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3690 - accuracy: 0.8539 - val_loss: 0.4486 - val_accuracy: 0.8156\n",
      "Epoch 297/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3704 - accuracy: 0.8525 - val_loss: 0.4476 - val_accuracy: 0.8212\n",
      "Epoch 298/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3765 - accuracy: 0.8511 - val_loss: 0.4484 - val_accuracy: 0.8156\n",
      "Epoch 299/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.3595 - accuracy: 0.8539 - val_loss: 0.4470 - val_accuracy: 0.8156\n",
      "Epoch 300/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3697 - accuracy: 0.8427 - val_loss: 0.4471 - val_accuracy: 0.8156\n",
      "Epoch 301/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3747 - accuracy: 0.8469 - val_loss: 0.4486 - val_accuracy: 0.8156\n",
      "Epoch 302/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3642 - accuracy: 0.8553 - val_loss: 0.4487 - val_accuracy: 0.8156\n",
      "Epoch 303/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3717 - accuracy: 0.8567 - val_loss: 0.4466 - val_accuracy: 0.8101\n",
      "Epoch 304/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3873 - accuracy: 0.8343 - val_loss: 0.4374 - val_accuracy: 0.8101\n",
      "Epoch 305/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3688 - accuracy: 0.8441 - val_loss: 0.4402 - val_accuracy: 0.8101\n",
      "Epoch 306/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3592 - accuracy: 0.8610 - val_loss: 0.4443 - val_accuracy: 0.8101\n",
      "Epoch 307/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3687 - accuracy: 0.8511 - val_loss: 0.4442 - val_accuracy: 0.8101\n",
      "Epoch 308/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3726 - accuracy: 0.8483 - val_loss: 0.4437 - val_accuracy: 0.8212\n",
      "Epoch 309/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3722 - accuracy: 0.8553 - val_loss: 0.4458 - val_accuracy: 0.8156\n",
      "Epoch 310/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3675 - accuracy: 0.8511 - val_loss: 0.4488 - val_accuracy: 0.8212\n",
      "Epoch 311/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3662 - accuracy: 0.8596 - val_loss: 0.4472 - val_accuracy: 0.8101\n",
      "Epoch 312/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3771 - accuracy: 0.8413 - val_loss: 0.4467 - val_accuracy: 0.8101\n",
      "Epoch 313/400\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.3761 - accuracy: 0.8455 - val_loss: 0.4463 - val_accuracy: 0.8101\n",
      "Epoch 314/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3767 - accuracy: 0.8441 - val_loss: 0.4435 - val_accuracy: 0.8101\n",
      "Epoch 315/400\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.3755 - accuracy: 0.8497 - val_loss: 0.4440 - val_accuracy: 0.8101\n",
      "Epoch 316/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3676 - accuracy: 0.8553 - val_loss: 0.4453 - val_accuracy: 0.8212\n",
      "Epoch 317/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3655 - accuracy: 0.8469 - val_loss: 0.4477 - val_accuracy: 0.8156\n",
      "Epoch 318/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3739 - accuracy: 0.8399 - val_loss: 0.4510 - val_accuracy: 0.8212\n",
      "Epoch 319/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3777 - accuracy: 0.8455 - val_loss: 0.4491 - val_accuracy: 0.8156\n",
      "Epoch 320/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3698 - accuracy: 0.8483 - val_loss: 0.4479 - val_accuracy: 0.8101\n",
      "Epoch 321/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3711 - accuracy: 0.8469 - val_loss: 0.4472 - val_accuracy: 0.8156\n",
      "Epoch 322/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3746 - accuracy: 0.8539 - val_loss: 0.4469 - val_accuracy: 0.8101\n",
      "Epoch 323/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3699 - accuracy: 0.8483 - val_loss: 0.4483 - val_accuracy: 0.8101\n",
      "Epoch 324/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3642 - accuracy: 0.8539 - val_loss: 0.4502 - val_accuracy: 0.8101\n",
      "Epoch 325/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3627 - accuracy: 0.8553 - val_loss: 0.4495 - val_accuracy: 0.8101\n",
      "Epoch 326/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3603 - accuracy: 0.8652 - val_loss: 0.4527 - val_accuracy: 0.8156\n",
      "Epoch 327/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3811 - accuracy: 0.8357 - val_loss: 0.4514 - val_accuracy: 0.8101\n",
      "Epoch 328/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3843 - accuracy: 0.8244 - val_loss: 0.4534 - val_accuracy: 0.8101\n",
      "Epoch 329/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3795 - accuracy: 0.8371 - val_loss: 0.4560 - val_accuracy: 0.8101\n",
      "Epoch 330/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3787 - accuracy: 0.8329 - val_loss: 0.4535 - val_accuracy: 0.8101\n",
      "Epoch 331/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3841 - accuracy: 0.8315 - val_loss: 0.4479 - val_accuracy: 0.8156\n",
      "Epoch 332/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3698 - accuracy: 0.8455 - val_loss: 0.4472 - val_accuracy: 0.8156\n",
      "Epoch 333/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3820 - accuracy: 0.8357 - val_loss: 0.4470 - val_accuracy: 0.8101\n",
      "Epoch 334/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3718 - accuracy: 0.8413 - val_loss: 0.4439 - val_accuracy: 0.8156\n",
      "Epoch 335/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3659 - accuracy: 0.8539 - val_loss: 0.4420 - val_accuracy: 0.8156\n",
      "Epoch 336/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3687 - accuracy: 0.8511 - val_loss: 0.4416 - val_accuracy: 0.8156\n",
      "Epoch 337/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3709 - accuracy: 0.8497 - val_loss: 0.4395 - val_accuracy: 0.8156\n",
      "Epoch 338/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3561 - accuracy: 0.8624 - val_loss: 0.4488 - val_accuracy: 0.8212\n",
      "Epoch 339/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3670 - accuracy: 0.8483 - val_loss: 0.4530 - val_accuracy: 0.8101\n",
      "Epoch 340/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.3630 - accuracy: 0.8596 - val_loss: 0.4512 - val_accuracy: 0.8101\n",
      "Epoch 341/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3782 - accuracy: 0.8483 - val_loss: 0.4511 - val_accuracy: 0.8156\n",
      "Epoch 342/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3680 - accuracy: 0.8469 - val_loss: 0.4493 - val_accuracy: 0.8156\n",
      "Epoch 343/400\n",
      "712/712 [==============================] - 0s 227us/sample - loss: 0.3694 - accuracy: 0.8399 - val_loss: 0.4503 - val_accuracy: 0.8156\n",
      "Epoch 344/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3742 - accuracy: 0.8371 - val_loss: 0.4460 - val_accuracy: 0.8156\n",
      "Epoch 345/400\n",
      "712/712 [==============================] - 0s 275us/sample - loss: 0.3812 - accuracy: 0.8315 - val_loss: 0.4500 - val_accuracy: 0.8101\n",
      "Epoch 346/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3625 - accuracy: 0.8610 - val_loss: 0.4491 - val_accuracy: 0.8156\n",
      "Epoch 347/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3746 - accuracy: 0.8539 - val_loss: 0.4513 - val_accuracy: 0.8156\n",
      "Epoch 348/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3689 - accuracy: 0.8539 - val_loss: 0.4508 - val_accuracy: 0.8156\n",
      "Epoch 349/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3599 - accuracy: 0.8567 - val_loss: 0.4537 - val_accuracy: 0.8101\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3758 - accuracy: 0.8441 - val_loss: 0.4532 - val_accuracy: 0.8156\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3714 - accuracy: 0.8539 - val_loss: 0.4549 - val_accuracy: 0.8156\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3696 - accuracy: 0.8399 - val_loss: 0.4522 - val_accuracy: 0.8156\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3702 - accuracy: 0.8483 - val_loss: 0.4535 - val_accuracy: 0.8156\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3694 - accuracy: 0.8511 - val_loss: 0.4546 - val_accuracy: 0.8156\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3643 - accuracy: 0.8553 - val_loss: 0.4505 - val_accuracy: 0.8156\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3617 - accuracy: 0.8497 - val_loss: 0.4534 - val_accuracy: 0.8156\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3627 - accuracy: 0.8511 - val_loss: 0.4544 - val_accuracy: 0.8156\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3608 - accuracy: 0.8581 - val_loss: 0.4590 - val_accuracy: 0.8101\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.3578 - accuracy: 0.8539 - val_loss: 0.4591 - val_accuracy: 0.8101\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3620 - accuracy: 0.8525 - val_loss: 0.4594 - val_accuracy: 0.8101\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3722 - accuracy: 0.8525 - val_loss: 0.4491 - val_accuracy: 0.8101\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3672 - accuracy: 0.8399 - val_loss: 0.4515 - val_accuracy: 0.8101\n",
      "Epoch 363/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3665 - accuracy: 0.8497 - val_loss: 0.4540 - val_accuracy: 0.8101\n",
      "Epoch 364/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3666 - accuracy: 0.8441 - val_loss: 0.4540 - val_accuracy: 0.8101\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3753 - accuracy: 0.8427 - val_loss: 0.4494 - val_accuracy: 0.8045\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3708 - accuracy: 0.8385 - val_loss: 0.4482 - val_accuracy: 0.8156\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3698 - accuracy: 0.8455 - val_loss: 0.4485 - val_accuracy: 0.8156\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3782 - accuracy: 0.8357 - val_loss: 0.4513 - val_accuracy: 0.8212\n",
      "Epoch 369/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3702 - accuracy: 0.8511 - val_loss: 0.4481 - val_accuracy: 0.8101\n",
      "Epoch 370/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3585 - accuracy: 0.8581 - val_loss: 0.4538 - val_accuracy: 0.8212\n",
      "Epoch 371/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3624 - accuracy: 0.8511 - val_loss: 0.4540 - val_accuracy: 0.8212\n",
      "Epoch 372/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3593 - accuracy: 0.8539 - val_loss: 0.4569 - val_accuracy: 0.8156\n",
      "Epoch 373/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3657 - accuracy: 0.8525 - val_loss: 0.4557 - val_accuracy: 0.8101\n",
      "Epoch 374/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3663 - accuracy: 0.8455 - val_loss: 0.4525 - val_accuracy: 0.8212\n",
      "Epoch 375/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3664 - accuracy: 0.8497 - val_loss: 0.4526 - val_accuracy: 0.8101\n",
      "Epoch 376/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.2634 - accuracy: 0.8736 - val_loss: 0.8264 - val_accuracy: 0.7765\n",
      "Epoch 336/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.2616 - accuracy: 0.8764 - val_loss: 0.7870 - val_accuracy: 0.7989\n",
      "Epoch 337/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.2613 - accuracy: 0.8876 - val_loss: 0.7820 - val_accuracy: 0.7989\n",
      "Epoch 338/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.2563 - accuracy: 0.8848 - val_loss: 0.7933 - val_accuracy: 0.8101\n",
      "Epoch 339/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.2617 - accuracy: 0.8876 - val_loss: 0.8115 - val_accuracy: 0.8045\n",
      "Epoch 340/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.2603 - accuracy: 0.8848 - val_loss: 0.8217 - val_accuracy: 0.7877\n",
      "Epoch 341/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.2746 - accuracy: 0.8736 - val_loss: 0.8022 - val_accuracy: 0.8045\n",
      "Epoch 342/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.2627 - accuracy: 0.8820 - val_loss: 0.8175 - val_accuracy: 0.8045\n",
      "Epoch 343/400\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.2539 - accuracy: 0.8834 - val_loss: 0.8079 - val_accuracy: 0.8045\n",
      "Epoch 344/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.2647 - accuracy: 0.8820 - val_loss: 0.8402 - val_accuracy: 0.7933\n",
      "Epoch 345/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.2678 - accuracy: 0.8848 - val_loss: 0.7941 - val_accuracy: 0.8156\n",
      "Epoch 346/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.2666 - accuracy: 0.8750 - val_loss: 0.8122 - val_accuracy: 0.8101\n",
      "Epoch 347/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.2704 - accuracy: 0.8708 - val_loss: 0.7760 - val_accuracy: 0.7989\n",
      "Epoch 348/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.2658 - accuracy: 0.8750 - val_loss: 0.7699 - val_accuracy: 0.7989\n",
      "Epoch 349/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.2635 - accuracy: 0.8862 - val_loss: 0.7669 - val_accuracy: 0.8045\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.2667 - accuracy: 0.8736 - val_loss: 0.7803 - val_accuracy: 0.8045\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.2648 - accuracy: 0.8750 - val_loss: 0.7889 - val_accuracy: 0.8101\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.2676 - accuracy: 0.8778 - val_loss: 0.7997 - val_accuracy: 0.8101\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.2623 - accuracy: 0.8806 - val_loss: 0.8044 - val_accuracy: 0.8045\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.2616 - accuracy: 0.8820 - val_loss: 0.8167 - val_accuracy: 0.8045\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.2584 - accuracy: 0.8694 - val_loss: 0.8248 - val_accuracy: 0.8045\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.2476 - accuracy: 0.8961 - val_loss: 0.8364 - val_accuracy: 0.8156\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.2625 - accuracy: 0.8848 - val_loss: 0.7584 - val_accuracy: 0.8212\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.2698 - accuracy: 0.8834 - val_loss: 0.7432 - val_accuracy: 0.8045\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3050 - accuracy: 0.8694 - val_loss: 0.5677 - val_accuracy: 0.7989\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.2960 - accuracy: 0.8806 - val_loss: 0.7114 - val_accuracy: 0.8045\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.2850 - accuracy: 0.8750 - val_loss: 0.7924 - val_accuracy: 0.7877\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.2663 - accuracy: 0.8778 - val_loss: 0.8359 - val_accuracy: 0.8045\n",
      "Epoch 363/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.2744 - accuracy: 0.8820 - val_loss: 0.6576 - val_accuracy: 0.8101\n",
      "Epoch 364/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.2933 - accuracy: 0.8834 - val_loss: 0.7220 - val_accuracy: 0.8268\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.2768 - accuracy: 0.8750 - val_loss: 0.7496 - val_accuracy: 0.8101\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.2809 - accuracy: 0.8736 - val_loss: 0.5989 - val_accuracy: 0.8268\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.2779 - accuracy: 0.8792 - val_loss: 0.6667 - val_accuracy: 0.8212\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.2714 - accuracy: 0.8792 - val_loss: 0.7311 - val_accuracy: 0.8045\n",
      "Epoch 369/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.2699 - accuracy: 0.8862 - val_loss: 0.7262 - val_accuracy: 0.8212\n",
      "Epoch 370/400\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.2751 - accuracy: 0.8736 - val_loss: 0.7536 - val_accuracy: 0.8268\n",
      "Epoch 371/400\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.2808 - accuracy: 0.8708 - val_loss: 0.6968 - val_accuracy: 0.8324\n",
      "Epoch 372/400\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.2903 - accuracy: 0.8806 - val_loss: 0.6969 - val_accuracy: 0.8101\n",
      "Epoch 373/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4143 - accuracy: 0.8230 - val_loss: 0.4156 - val_accuracy: 0.8268\n",
      "Epoch 324/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4282 - accuracy: 0.8272 - val_loss: 0.4269 - val_accuracy: 0.8268\n",
      "Epoch 325/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4206 - accuracy: 0.8174 - val_loss: 0.4071 - val_accuracy: 0.8268\n",
      "Epoch 326/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4165 - accuracy: 0.8118 - val_loss: 0.4105 - val_accuracy: 0.8212\n",
      "Epoch 327/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4459 - accuracy: 0.8160 - val_loss: 0.4118 - val_accuracy: 0.7933\n",
      "Epoch 328/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4240 - accuracy: 0.8301 - val_loss: 0.4251 - val_accuracy: 0.8101\n",
      "Epoch 329/400\n",
      "712/712 [==============================] - 0s 265us/sample - loss: 0.4578 - accuracy: 0.8020 - val_loss: 0.4161 - val_accuracy: 0.8380\n",
      "Epoch 330/400\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.4604 - accuracy: 0.8062 - val_loss: 0.4147 - val_accuracy: 0.8380\n",
      "Epoch 331/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4424 - accuracy: 0.8216 - val_loss: 0.4180 - val_accuracy: 0.8324\n",
      "Epoch 332/400\n",
      "712/712 [==============================] - 0s 221us/sample - loss: 0.4713 - accuracy: 0.8048 - val_loss: 0.4245 - val_accuracy: 0.8380\n",
      "Epoch 333/400\n",
      "712/712 [==============================] - 0s 209us/sample - loss: 0.4607 - accuracy: 0.7949 - val_loss: 0.4541 - val_accuracy: 0.8268\n",
      "Epoch 334/400\n",
      "712/712 [==============================] - 0s 212us/sample - loss: 0.4550 - accuracy: 0.8090 - val_loss: 0.4271 - val_accuracy: 0.8268\n",
      "Epoch 335/400\n",
      "712/712 [==============================] - 0s 224us/sample - loss: 0.4308 - accuracy: 0.8258 - val_loss: 0.4233 - val_accuracy: 0.8212\n",
      "Epoch 336/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4463 - accuracy: 0.8244 - val_loss: 0.4239 - val_accuracy: 0.8268\n",
      "Epoch 337/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4236 - accuracy: 0.8188 - val_loss: 0.4266 - val_accuracy: 0.8268\n",
      "Epoch 338/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4408 - accuracy: 0.8104 - val_loss: 0.4146 - val_accuracy: 0.8045\n",
      "Epoch 339/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4381 - accuracy: 0.8160 - val_loss: 0.4129 - val_accuracy: 0.8324\n",
      "Epoch 340/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4497 - accuracy: 0.8020 - val_loss: 0.4119 - val_accuracy: 0.8380\n",
      "Epoch 341/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4367 - accuracy: 0.8188 - val_loss: 0.4054 - val_accuracy: 0.8380\n",
      "Epoch 342/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4467 - accuracy: 0.8090 - val_loss: 0.4158 - val_accuracy: 0.8380\n",
      "Epoch 343/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4282 - accuracy: 0.8301 - val_loss: 0.4164 - val_accuracy: 0.8324\n",
      "Epoch 344/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4511 - accuracy: 0.8006 - val_loss: 0.4207 - val_accuracy: 0.8380\n",
      "Epoch 345/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4536 - accuracy: 0.7963 - val_loss: 0.4475 - val_accuracy: 0.8212\n",
      "Epoch 346/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4633 - accuracy: 0.7992 - val_loss: 0.4249 - val_accuracy: 0.8045\n",
      "Epoch 347/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4359 - accuracy: 0.8048 - val_loss: 0.4271 - val_accuracy: 0.7989\n",
      "Epoch 348/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4389 - accuracy: 0.8104 - val_loss: 0.4186 - val_accuracy: 0.8380\n",
      "Epoch 349/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4513 - accuracy: 0.8034 - val_loss: 0.4293 - val_accuracy: 0.8324\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4438 - accuracy: 0.8062 - val_loss: 0.4384 - val_accuracy: 0.8268\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4251 - accuracy: 0.8244 - val_loss: 0.4299 - val_accuracy: 0.8212\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.4395 - accuracy: 0.8090 - val_loss: 0.4299 - val_accuracy: 0.8101\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4420 - accuracy: 0.8146 - val_loss: 0.4343 - val_accuracy: 0.7765\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4565 - accuracy: 0.8006 - val_loss: 0.4367 - val_accuracy: 0.8101\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4382 - accuracy: 0.8034 - val_loss: 0.4339 - val_accuracy: 0.7821\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4387 - accuracy: 0.7949 - val_loss: 0.4453 - val_accuracy: 0.7821\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4381 - accuracy: 0.8006 - val_loss: 0.4254 - val_accuracy: 0.8101\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4272 - accuracy: 0.8090 - val_loss: 0.4132 - val_accuracy: 0.8101\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4307 - accuracy: 0.8146 - val_loss: 0.4141 - val_accuracy: 0.8101\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4399 - accuracy: 0.7978 - val_loss: 0.4352 - val_accuracy: 0.8101\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4112 - accuracy: 0.8315 - val_loss: 0.4353 - val_accuracy: 0.8101\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4224 - accuracy: 0.8146 - val_loss: 0.4245 - val_accuracy: 0.8212\n",
      "Epoch 363/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4329 - accuracy: 0.7992 - val_loss: 0.4203 - val_accuracy: 0.8156\n",
      "Epoch 364/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4259 - accuracy: 0.8062 - val_loss: 0.4238 - val_accuracy: 0.8212\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4328 - accuracy: 0.8006 - val_loss: 0.4283 - val_accuracy: 0.8156\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4328 - accuracy: 0.8076 - val_loss: 0.4325 - val_accuracy: 0.8156\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4275 - accuracy: 0.8006 - val_loss: 0.4305 - val_accuracy: 0.8156\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4201 - accuracy: 0.7992 - val_loss: 0.4476 - val_accuracy: 0.8156\n",
      "Epoch 369/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4114 - accuracy: 0.8258 - val_loss: 0.4330 - val_accuracy: 0.8156\n",
      "Epoch 370/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4177 - accuracy: 0.8244 - val_loss: 0.4438 - val_accuracy: 0.8101\n",
      "Epoch 371/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4146 - accuracy: 0.7978 - val_loss: 0.4380 - val_accuracy: 0.8212\n",
      "Epoch 372/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4445 - accuracy: 0.7935 - val_loss: 0.4249 - val_accuracy: 0.8156\n",
      "Epoch 373/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4301 - accuracy: 0.8062 - val_loss: 0.4352 - val_accuracy: 0.8156\n",
      "Epoch 374/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4337 - accuracy: 0.8118 - val_loss: 0.4413 - val_accuracy: 0.8212\n",
      "Epoch 375/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4192 - accuracy: 0.8272 - val_loss: 0.4243 - val_accuracy: 0.8212\n",
      "Epoch 376/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4448 - accuracy: 0.8076 - val_loss: 0.4299 - val_accuracy: 0.7821\n",
      "Epoch 377/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4098 - accuracy: 0.8174 - val_loss: 0.4464 - val_accuracy: 0.8156\n",
      "Epoch 378/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4309 - accuracy: 0.8118 - val_loss: 0.4446 - val_accuracy: 0.7765\n",
      "Epoch 379/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4302 - accuracy: 0.8160 - val_loss: 0.4351 - val_accuracy: 0.7709\n",
      "Epoch 380/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4254 - accuracy: 0.8146 - val_loss: 0.4453 - val_accuracy: 0.8268\n",
      "Epoch 381/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.4282 - accuracy: 0.8146 - val_loss: 0.4470 - val_accuracy: 0.8268\n",
      "Epoch 382/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4185 - accuracy: 0.8301 - val_loss: 0.4623 - val_accuracy: 0.8324\n",
      "Epoch 383/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4143 - accuracy: 0.8301 - val_loss: 0.4645 - val_accuracy: 0.8268\n",
      "Epoch 384/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4190 - accuracy: 0.8343 - val_loss: 0.4548 - val_accuracy: 0.8324\n",
      "Epoch 385/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4423 - accuracy: 0.8202 - val_loss: 0.4581 - val_accuracy: 0.8268\n",
      "Epoch 386/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4405 - accuracy: 0.8301 - val_loss: 0.4686 - val_accuracy: 0.8268\n",
      "Epoch 387/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4358 - accuracy: 0.8202 - val_loss: 0.4822 - val_accuracy: 0.8101\n",
      "Epoch 388/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4328 - accuracy: 0.8258 - val_loss: 0.4386 - val_accuracy: 0.8268\n",
      "Epoch 389/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4271 - accuracy: 0.8258 - val_loss: 0.4410 - val_accuracy: 0.8156\n",
      "Epoch 390/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4468 - accuracy: 0.8146 - val_loss: 0.4478 - val_accuracy: 0.8268\n",
      "Epoch 391/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4280 - accuracy: 0.8258 - val_loss: 0.4598 - val_accuracy: 0.8212\n",
      "Epoch 392/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4367 - accuracy: 0.8160 - val_loss: 0.4516 - val_accuracy: 0.8045\n",
      "Epoch 393/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4445 - accuracy: 0.8188 - val_loss: 0.4536 - val_accuracy: 0.8101\n",
      "Epoch 394/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4284 - accuracy: 0.8202 - val_loss: 0.4385 - val_accuracy: 0.8156\n",
      "Epoch 395/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4290 - accuracy: 0.8160 - val_loss: 0.4756 - val_accuracy: 0.8045\n",
      "Epoch 396/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4186 - accuracy: 0.8329 - val_loss: 0.4644 - val_accuracy: 0.7989\n",
      "Epoch 397/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4334 - accuracy: 0.8202 - val_loss: 0.4560 - val_accuracy: 0.8212\n",
      "Epoch 398/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4357 - accuracy: 0.8258 - val_loss: 0.4629 - val_accuracy: 0.8212\n",
      "Epoch 399/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4400 - accuracy: 0.8132 - val_loss: 0.4383 - val_accuracy: 0.8156\n",
      "Epoch 400/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4500 - accuracy: 0.8258 - val_loss: 0.4422 - val_accuracy: 0.7877\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/400\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.6845 - accuracy: 0.5997 - val_loss: 0.6752 - val_accuracy: 0.5866\n",
      "Epoch 2/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6824 - accuracy: 0.5815 - val_loss: 0.6799 - val_accuracy: 0.5866\n",
      "Epoch 3/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6628 - accuracy: 0.6278 - val_loss: 0.5318 - val_accuracy: 0.7095\n",
      "Epoch 4/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5584 - accuracy: 0.7303 - val_loss: 0.4748 - val_accuracy: 0.7989\n",
      "Epoch 5/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5125 - accuracy: 0.7851 - val_loss: 0.4630 - val_accuracy: 0.8156\n",
      "Epoch 6/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5092 - accuracy: 0.7963 - val_loss: 0.4558 - val_accuracy: 0.8101\n",
      "Epoch 7/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4830 - accuracy: 0.8020 - val_loss: 0.4523 - val_accuracy: 0.8212\n",
      "Epoch 8/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4737 - accuracy: 0.8160 - val_loss: 0.4816 - val_accuracy: 0.8268\n",
      "Epoch 9/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4879 - accuracy: 0.8104 - val_loss: 0.4732 - val_accuracy: 0.8156\n",
      "Epoch 10/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4906 - accuracy: 0.7992 - val_loss: 0.4597 - val_accuracy: 0.8268\n",
      "Epoch 11/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4647 - accuracy: 0.8118 - val_loss: 0.4766 - val_accuracy: 0.8101\n",
      "Epoch 12/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4754 - accuracy: 0.8188 - val_loss: 0.4632 - val_accuracy: 0.8212\n",
      "Epoch 13/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4649 - accuracy: 0.8118 - val_loss: 0.4591 - val_accuracy: 0.8156\n",
      "Epoch 14/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4640 - accuracy: 0.8160 - val_loss: 0.4449 - val_accuracy: 0.8268\n",
      "Epoch 15/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4829 - accuracy: 0.8076 - val_loss: 0.4489 - val_accuracy: 0.8212\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 222us/sample - loss: 0.4743 - accuracy: 0.8132 - val_loss: 0.4555 - val_accuracy: 0.8324\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4514 - accuracy: 0.8188 - val_loss: 0.4415 - val_accuracy: 0.8324\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.4473 - accuracy: 0.8244 - val_loss: 0.4482 - val_accuracy: 0.8324\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 234us/sample - loss: 0.4430 - accuracy: 0.8146 - val_loss: 0.4400 - val_accuracy: 0.8324\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 210us/sample - loss: 0.4388 - accuracy: 0.8315 - val_loss: 0.4551 - val_accuracy: 0.8268\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 253us/sample - loss: 0.4307 - accuracy: 0.8315 - val_loss: 0.4584 - val_accuracy: 0.8324\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4487 - accuracy: 0.8244 - val_loss: 0.4439 - val_accuracy: 0.8212\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4471 - accuracy: 0.8146 - val_loss: 0.4435 - val_accuracy: 0.8324\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4392 - accuracy: 0.8216 - val_loss: 0.4554 - val_accuracy: 0.8324\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4243 - accuracy: 0.8399 - val_loss: 0.5121 - val_accuracy: 0.8324\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4469 - accuracy: 0.8230 - val_loss: 0.4642 - val_accuracy: 0.8324\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4397 - accuracy: 0.8315 - val_loss: 0.4486 - val_accuracy: 0.8324\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4422 - accuracy: 0.8287 - val_loss: 0.4561 - val_accuracy: 0.8324\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4206 - accuracy: 0.8329 - val_loss: 0.4650 - val_accuracy: 0.8212\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4402 - accuracy: 0.8301 - val_loss: 0.4447 - val_accuracy: 0.8268\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4258 - accuracy: 0.8301 - val_loss: 0.4628 - val_accuracy: 0.8324\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4273 - accuracy: 0.8301 - val_loss: 0.4800 - val_accuracy: 0.8268\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4389 - accuracy: 0.8287 - val_loss: 0.4810 - val_accuracy: 0.7821\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4354 - accuracy: 0.8174 - val_loss: 0.4802 - val_accuracy: 0.7821\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4408 - accuracy: 0.8104 - val_loss: 0.4868 - val_accuracy: 0.7821\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4239 - accuracy: 0.8399 - val_loss: 0.4807 - val_accuracy: 0.7877\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4130 - accuracy: 0.8329 - val_loss: 0.4769 - val_accuracy: 0.7821\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4382 - accuracy: 0.8329 - val_loss: 0.4552 - val_accuracy: 0.7877\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4346 - accuracy: 0.8301 - val_loss: 0.4486 - val_accuracy: 0.7933\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4388 - accuracy: 0.7949 - val_loss: 0.4350 - val_accuracy: 0.8156\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4305 - accuracy: 0.8146 - val_loss: 0.4410 - val_accuracy: 0.7877\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4108 - accuracy: 0.8315 - val_loss: 0.4490 - val_accuracy: 0.7765\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4274 - accuracy: 0.8258 - val_loss: 0.4526 - val_accuracy: 0.8156\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4113 - accuracy: 0.8287 - val_loss: 0.4595 - val_accuracy: 0.8324\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4212 - accuracy: 0.8301 - val_loss: 0.4835 - val_accuracy: 0.7877\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4307 - accuracy: 0.8202 - val_loss: 0.4659 - val_accuracy: 0.8324\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4270 - accuracy: 0.8329 - val_loss: 0.4526 - val_accuracy: 0.8324\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4373 - accuracy: 0.8343 - val_loss: 0.4562 - val_accuracy: 0.8324\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4264 - accuracy: 0.8287 - val_loss: 0.4918 - val_accuracy: 0.8268\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4386 - accuracy: 0.8202 - val_loss: 0.4786 - val_accuracy: 0.7821\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4302 - accuracy: 0.8343 - val_loss: 0.4610 - val_accuracy: 0.8324\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4307 - accuracy: 0.8287 - val_loss: 0.4615 - val_accuracy: 0.8324\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4172 - accuracy: 0.8357 - val_loss: 0.4965 - val_accuracy: 0.7765\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4093 - accuracy: 0.8301 - val_loss: 0.4602 - val_accuracy: 0.8324\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4269 - accuracy: 0.8272 - val_loss: 0.4469 - val_accuracy: 0.8212\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4280 - accuracy: 0.8287 - val_loss: 0.4522 - val_accuracy: 0.8268\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4188 - accuracy: 0.8357 - val_loss: 0.4668 - val_accuracy: 0.8268\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4175 - accuracy: 0.8329 - val_loss: 0.4688 - val_accuracy: 0.8212\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4326 - accuracy: 0.8174 - val_loss: 0.4450 - val_accuracy: 0.8268\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4129 - accuracy: 0.8343 - val_loss: 0.4621 - val_accuracy: 0.8324\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4277 - accuracy: 0.8118 - val_loss: 0.4625 - val_accuracy: 0.8324\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4390 - accuracy: 0.8202 - val_loss: 0.4398 - val_accuracy: 0.8324\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.4327 - accuracy: 0.8174 - val_loss: 0.4470 - val_accuracy: 0.7877\n",
      "Epoch 64/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4353 - accuracy: 0.8104 - val_loss: 0.4472 - val_accuracy: 0.8324\n",
      "Epoch 65/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4440 - accuracy: 0.8174 - val_loss: 0.4365 - val_accuracy: 0.8324\n",
      "Epoch 66/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4218 - accuracy: 0.8202 - val_loss: 0.4386 - val_accuracy: 0.8324\n",
      "Epoch 67/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4118 - accuracy: 0.8385 - val_loss: 0.4485 - val_accuracy: 0.8324\n",
      "Epoch 68/400\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.4323 - accuracy: 0.8216 - val_loss: 0.4543 - val_accuracy: 0.8268\n",
      "Epoch 69/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4282 - accuracy: 0.8034 - val_loss: 0.4900 - val_accuracy: 0.7765\n",
      "Epoch 70/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.4299 - accuracy: 0.8301 - val_loss: 0.4714 - val_accuracy: 0.8324\n",
      "Epoch 71/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4474 - accuracy: 0.8132 - val_loss: 0.4480 - val_accuracy: 0.7877\n",
      "Epoch 72/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4304 - accuracy: 0.8202 - val_loss: 0.4373 - val_accuracy: 0.8324\n",
      "Epoch 73/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4364 - accuracy: 0.8272 - val_loss: 0.4277 - val_accuracy: 0.8324\n",
      "Epoch 74/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4220 - accuracy: 0.8244 - val_loss: 0.4513 - val_accuracy: 0.8045\n",
      "Epoch 75/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4335 - accuracy: 0.8216 - val_loss: 0.4429 - val_accuracy: 0.8268\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4219 - accuracy: 0.8371 - val_loss: 0.4560 - val_accuracy: 0.8045\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4196 - accuracy: 0.8244 - val_loss: 0.4490 - val_accuracy: 0.8268\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4238 - accuracy: 0.8272 - val_loss: 0.4655 - val_accuracy: 0.7821\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4463 - accuracy: 0.8216 - val_loss: 0.4461 - val_accuracy: 0.8324\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4357 - accuracy: 0.8174 - val_loss: 0.4489 - val_accuracy: 0.7933\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4362 - accuracy: 0.8244 - val_loss: 0.4422 - val_accuracy: 0.8324\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4318 - accuracy: 0.8202 - val_loss: 0.4384 - val_accuracy: 0.8324\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4240 - accuracy: 0.8315 - val_loss: 0.4563 - val_accuracy: 0.8324\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4317 - accuracy: 0.8244 - val_loss: 0.4387 - val_accuracy: 0.8324\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4311 - accuracy: 0.8272 - val_loss: 0.4681 - val_accuracy: 0.8324\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4284 - accuracy: 0.8315 - val_loss: 0.4380 - val_accuracy: 0.8324\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4197 - accuracy: 0.8301 - val_loss: 0.4418 - val_accuracy: 0.8268\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4229 - accuracy: 0.8357 - val_loss: 0.4595 - val_accuracy: 0.7765\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4548 - accuracy: 0.8118 - val_loss: 0.4704 - val_accuracy: 0.8212\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4269 - accuracy: 0.8230 - val_loss: 0.4585 - val_accuracy: 0.8212\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4339 - accuracy: 0.8272 - val_loss: 0.4752 - val_accuracy: 0.8268\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4261 - accuracy: 0.8272 - val_loss: 0.4609 - val_accuracy: 0.8324\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4369 - accuracy: 0.8202 - val_loss: 0.4426 - val_accuracy: 0.8380\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4376 - accuracy: 0.8216 - val_loss: 0.4749 - val_accuracy: 0.8324\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4366 - accuracy: 0.8258 - val_loss: 0.4446 - val_accuracy: 0.8380\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4309 - accuracy: 0.8272 - val_loss: 0.4389 - val_accuracy: 0.8436\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4146 - accuracy: 0.8258 - val_loss: 0.4432 - val_accuracy: 0.8324\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4205 - accuracy: 0.8272 - val_loss: 0.4396 - val_accuracy: 0.8324\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4182 - accuracy: 0.8258 - val_loss: 0.4456 - val_accuracy: 0.8324\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4267 - accuracy: 0.8287 - val_loss: 0.4519 - val_accuracy: 0.8324\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4613 - accuracy: 0.8329 - val_loss: 0.4618 - val_accuracy: 0.8268\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4609 - accuracy: 0.8301 - val_loss: 0.4748 - val_accuracy: 0.8324\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4568 - accuracy: 0.8315 - val_loss: 0.4670 - val_accuracy: 0.8268\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4327 - accuracy: 0.8357 - val_loss: 0.4677 - val_accuracy: 0.7821\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4216 - accuracy: 0.8315 - val_loss: 0.4815 - val_accuracy: 0.7654\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4392 - accuracy: 0.8160 - val_loss: 0.4411 - val_accuracy: 0.8324\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4252 - accuracy: 0.8174 - val_loss: 0.4573 - val_accuracy: 0.8324\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4226 - accuracy: 0.8287 - val_loss: 0.4367 - val_accuracy: 0.8324\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4334 - accuracy: 0.8146 - val_loss: 0.4822 - val_accuracy: 0.7877\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4305 - accuracy: 0.8230 - val_loss: 0.4771 - val_accuracy: 0.7877\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4256 - accuracy: 0.8104 - val_loss: 0.4537 - val_accuracy: 0.8156\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 207us/sample - loss: 0.3081 - accuracy: 0.8750 - val_loss: 0.6531 - val_accuracy: 0.7989\n",
      "Epoch 325/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.3048 - accuracy: 0.8708 - val_loss: 0.6530 - val_accuracy: 0.8045\n",
      "Epoch 326/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.3021 - accuracy: 0.8736 - val_loss: 0.6595 - val_accuracy: 0.7933\n",
      "Epoch 327/400\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.3098 - accuracy: 0.8680 - val_loss: 0.6611 - val_accuracy: 0.8045\n",
      "Epoch 328/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3145 - accuracy: 0.8652 - val_loss: 0.6566 - val_accuracy: 0.7933\n",
      "Epoch 329/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3042 - accuracy: 0.8778 - val_loss: 0.6461 - val_accuracy: 0.8101\n",
      "Epoch 330/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.3081 - accuracy: 0.8722 - val_loss: 0.6274 - val_accuracy: 0.7989\n",
      "Epoch 331/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3118 - accuracy: 0.8694 - val_loss: 0.6447 - val_accuracy: 0.8045\n",
      "Epoch 332/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3107 - accuracy: 0.8638 - val_loss: 0.6573 - val_accuracy: 0.7933\n",
      "Epoch 333/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.2905 - accuracy: 0.8806 - val_loss: 0.6521 - val_accuracy: 0.8045\n",
      "Epoch 334/400\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.2860 - accuracy: 0.8792 - val_loss: 0.6557 - val_accuracy: 0.8101\n",
      "Epoch 335/400\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.3072 - accuracy: 0.8764 - val_loss: 0.6689 - val_accuracy: 0.7933\n",
      "Epoch 336/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3071 - accuracy: 0.8764 - val_loss: 0.6463 - val_accuracy: 0.8045\n",
      "Epoch 337/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.2991 - accuracy: 0.8792 - val_loss: 0.6378 - val_accuracy: 0.8045\n",
      "Epoch 338/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.2995 - accuracy: 0.8806 - val_loss: 0.6490 - val_accuracy: 0.8101\n",
      "Epoch 339/400\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.2900 - accuracy: 0.8792 - val_loss: 0.6642 - val_accuracy: 0.7989\n",
      "Epoch 340/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.2970 - accuracy: 0.8778 - val_loss: 0.6743 - val_accuracy: 0.8101\n",
      "Epoch 341/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3193 - accuracy: 0.8638 - val_loss: 0.6754 - val_accuracy: 0.7933\n",
      "Epoch 342/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3046 - accuracy: 0.8694 - val_loss: 0.6521 - val_accuracy: 0.8045\n",
      "Epoch 343/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3143 - accuracy: 0.8708 - val_loss: 0.6767 - val_accuracy: 0.7933\n",
      "Epoch 344/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3028 - accuracy: 0.8694 - val_loss: 0.6380 - val_accuracy: 0.8101\n",
      "Epoch 345/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.2922 - accuracy: 0.8694 - val_loss: 0.6767 - val_accuracy: 0.7989\n",
      "Epoch 346/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.3006 - accuracy: 0.8680 - val_loss: 0.6682 - val_accuracy: 0.7989\n",
      "Epoch 347/400\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.3037 - accuracy: 0.8694 - val_loss: 0.6719 - val_accuracy: 0.7989\n",
      "Epoch 348/400\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.2992 - accuracy: 0.8792 - val_loss: 0.6425 - val_accuracy: 0.7989\n",
      "Epoch 349/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.3002 - accuracy: 0.8694 - val_loss: 0.6704 - val_accuracy: 0.7989\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.2992 - accuracy: 0.8792 - val_loss: 0.6508 - val_accuracy: 0.8045\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.2922 - accuracy: 0.8750 - val_loss: 0.6627 - val_accuracy: 0.7989\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.3057 - accuracy: 0.8680 - val_loss: 0.6567 - val_accuracy: 0.8045\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3007 - accuracy: 0.8736 - val_loss: 0.6614 - val_accuracy: 0.8101\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3013 - accuracy: 0.8736 - val_loss: 0.6780 - val_accuracy: 0.7989\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3112 - accuracy: 0.8596 - val_loss: 0.6639 - val_accuracy: 0.8045\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.2973 - accuracy: 0.8708 - val_loss: 0.6697 - val_accuracy: 0.8045\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.2954 - accuracy: 0.8722 - val_loss: 0.6820 - val_accuracy: 0.7989\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.3018 - accuracy: 0.8694 - val_loss: 0.6530 - val_accuracy: 0.8101\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3043 - accuracy: 0.8708 - val_loss: 0.6714 - val_accuracy: 0.7989\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3001 - accuracy: 0.8778 - val_loss: 0.6594 - val_accuracy: 0.8101\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.2987 - accuracy: 0.8820 - val_loss: 0.6594 - val_accuracy: 0.7989\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 1s 912us/sample - loss: 0.8512 - accuracy: 0.3764 - val_loss: 0.7786 - val_accuracy: 0.4134\n",
      "Epoch 2/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7742 - accuracy: 0.3764 - val_loss: 0.7265 - val_accuracy: 0.4134\n",
      "Epoch 3/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.7205 - accuracy: 0.4593 - val_loss: 0.6958 - val_accuracy: 0.4134\n",
      "Epoch 4/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6971 - accuracy: 0.5197 - val_loss: 0.6811 - val_accuracy: 0.5866\n",
      "Epoch 5/400\n",
      "712/712 [==============================] - 0s 216us/sample - loss: 0.6817 - accuracy: 0.5632 - val_loss: 0.6755 - val_accuracy: 0.5866\n",
      "Epoch 6/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6730 - accuracy: 0.6152 - val_loss: 0.6735 - val_accuracy: 0.5866\n",
      "Epoch 7/400\n",
      "712/712 [==============================] - 0s 220us/sample - loss: 0.6713 - accuracy: 0.6152 - val_loss: 0.6727 - val_accuracy: 0.5866\n",
      "Epoch 8/400\n",
      "712/712 [==============================] - 0s 214us/sample - loss: 0.6658 - accuracy: 0.6166 - val_loss: 0.6728 - val_accuracy: 0.5866\n",
      "Epoch 9/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6639 - accuracy: 0.6152 - val_loss: 0.6723 - val_accuracy: 0.5866\n",
      "Epoch 10/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6676 - accuracy: 0.6053 - val_loss: 0.6717 - val_accuracy: 0.5866\n",
      "Epoch 11/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6667 - accuracy: 0.6110 - val_loss: 0.6709 - val_accuracy: 0.5866\n",
      "Epoch 12/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6662 - accuracy: 0.6138 - val_loss: 0.6703 - val_accuracy: 0.5866\n",
      "Epoch 13/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6603 - accuracy: 0.6306 - val_loss: 0.6694 - val_accuracy: 0.5866\n",
      "Epoch 14/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6572 - accuracy: 0.6250 - val_loss: 0.6686 - val_accuracy: 0.5866\n",
      "Epoch 15/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6563 - accuracy: 0.6194 - val_loss: 0.6672 - val_accuracy: 0.5866\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6596 - accuracy: 0.6222 - val_loss: 0.6649 - val_accuracy: 0.5866\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6514 - accuracy: 0.6278 - val_loss: 0.6637 - val_accuracy: 0.5866\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6496 - accuracy: 0.6306 - val_loss: 0.6612 - val_accuracy: 0.5866\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6500 - accuracy: 0.6376 - val_loss: 0.6589 - val_accuracy: 0.5866\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6533 - accuracy: 0.6250 - val_loss: 0.6564 - val_accuracy: 0.5866\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6533 - accuracy: 0.6320 - val_loss: 0.6535 - val_accuracy: 0.5866\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6483 - accuracy: 0.6208 - val_loss: 0.6507 - val_accuracy: 0.5866\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6539 - accuracy: 0.6124 - val_loss: 0.6478 - val_accuracy: 0.5866\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6385 - accuracy: 0.6334 - val_loss: 0.6455 - val_accuracy: 0.5866\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6379 - accuracy: 0.6320 - val_loss: 0.6417 - val_accuracy: 0.5866\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6360 - accuracy: 0.6362 - val_loss: 0.6378 - val_accuracy: 0.5866\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6416 - accuracy: 0.6306 - val_loss: 0.6329 - val_accuracy: 0.5866\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6319 - accuracy: 0.6447 - val_loss: 0.6301 - val_accuracy: 0.5866\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6317 - accuracy: 0.6292 - val_loss: 0.6260 - val_accuracy: 0.5866\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 381us/sample - loss: 0.6280 - accuracy: 0.6390 - val_loss: 0.6199 - val_accuracy: 0.6089\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 244us/sample - loss: 0.6173 - accuracy: 0.6728 - val_loss: 0.6151 - val_accuracy: 0.6257\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 293us/sample - loss: 0.6266 - accuracy: 0.6531 - val_loss: 0.6093 - val_accuracy: 0.6480\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 261us/sample - loss: 0.6174 - accuracy: 0.6601 - val_loss: 0.6031 - val_accuracy: 0.6648\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.6086 - accuracy: 0.6784 - val_loss: 0.5973 - val_accuracy: 0.6704\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 225us/sample - loss: 0.6044 - accuracy: 0.6728 - val_loss: 0.5915 - val_accuracy: 0.6816\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4038 - accuracy: 0.8371 - val_loss: 0.4243 - val_accuracy: 0.8268\n",
      "Epoch 186/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3914 - accuracy: 0.8413 - val_loss: 0.4224 - val_accuracy: 0.8268\n",
      "Epoch 187/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3890 - accuracy: 0.8385 - val_loss: 0.4291 - val_accuracy: 0.8268\n",
      "Epoch 188/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3938 - accuracy: 0.8483 - val_loss: 0.4292 - val_accuracy: 0.8268\n",
      "Epoch 189/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3854 - accuracy: 0.8455 - val_loss: 0.4354 - val_accuracy: 0.7989\n",
      "Epoch 190/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3861 - accuracy: 0.8455 - val_loss: 0.4381 - val_accuracy: 0.8045\n",
      "Epoch 191/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3916 - accuracy: 0.8371 - val_loss: 0.4298 - val_accuracy: 0.8268\n",
      "Epoch 192/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3899 - accuracy: 0.8413 - val_loss: 0.4339 - val_accuracy: 0.8268\n",
      "Epoch 193/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3888 - accuracy: 0.8469 - val_loss: 0.4373 - val_accuracy: 0.8268\n",
      "Epoch 194/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3867 - accuracy: 0.8371 - val_loss: 0.4406 - val_accuracy: 0.8268\n",
      "Epoch 195/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3900 - accuracy: 0.8371 - val_loss: 0.4363 - val_accuracy: 0.8268\n",
      "Epoch 196/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4013 - accuracy: 0.8371 - val_loss: 0.4332 - val_accuracy: 0.8268\n",
      "Epoch 197/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3890 - accuracy: 0.8371 - val_loss: 0.4348 - val_accuracy: 0.8324\n",
      "Epoch 198/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3958 - accuracy: 0.8258 - val_loss: 0.4383 - val_accuracy: 0.8268\n",
      "Epoch 199/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3786 - accuracy: 0.8511 - val_loss: 0.4389 - val_accuracy: 0.8268\n",
      "Epoch 200/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3806 - accuracy: 0.8469 - val_loss: 0.4465 - val_accuracy: 0.7933\n",
      "Epoch 201/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4079 - accuracy: 0.8315 - val_loss: 0.4364 - val_accuracy: 0.8268\n",
      "Epoch 202/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3975 - accuracy: 0.8244 - val_loss: 0.4233 - val_accuracy: 0.7989\n",
      "Epoch 203/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3929 - accuracy: 0.8413 - val_loss: 0.4330 - val_accuracy: 0.8268\n",
      "Epoch 204/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4027 - accuracy: 0.8371 - val_loss: 0.4207 - val_accuracy: 0.8268\n",
      "Epoch 205/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3862 - accuracy: 0.8469 - val_loss: 0.4370 - val_accuracy: 0.7877\n",
      "Epoch 206/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3958 - accuracy: 0.8301 - val_loss: 0.4294 - val_accuracy: 0.8268\n",
      "Epoch 207/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3842 - accuracy: 0.8343 - val_loss: 0.4256 - val_accuracy: 0.8212\n",
      "Epoch 208/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3826 - accuracy: 0.8441 - val_loss: 0.4246 - val_accuracy: 0.8268\n",
      "Epoch 209/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3949 - accuracy: 0.8301 - val_loss: 0.4404 - val_accuracy: 0.8101\n",
      "Epoch 210/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3694 - accuracy: 0.8553 - val_loss: 0.4343 - val_accuracy: 0.8268\n",
      "Epoch 211/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3818 - accuracy: 0.8483 - val_loss: 0.4375 - val_accuracy: 0.8324\n",
      "Epoch 212/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3925 - accuracy: 0.8413 - val_loss: 0.4317 - val_accuracy: 0.8268\n",
      "Epoch 213/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4066 - accuracy: 0.8258 - val_loss: 0.4247 - val_accuracy: 0.8268\n",
      "Epoch 214/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3882 - accuracy: 0.8567 - val_loss: 0.4206 - val_accuracy: 0.8268\n",
      "Epoch 215/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3888 - accuracy: 0.8441 - val_loss: 0.4209 - val_accuracy: 0.8212\n",
      "Epoch 216/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3917 - accuracy: 0.8371 - val_loss: 0.4207 - val_accuracy: 0.8268\n",
      "Epoch 217/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3836 - accuracy: 0.8441 - val_loss: 0.4259 - val_accuracy: 0.8268\n",
      "Epoch 218/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3850 - accuracy: 0.8497 - val_loss: 0.4193 - val_accuracy: 0.8268\n",
      "Epoch 219/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.3939 - accuracy: 0.8413 - val_loss: 0.4272 - val_accuracy: 0.8268\n",
      "Epoch 220/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3929 - accuracy: 0.8244 - val_loss: 0.4231 - val_accuracy: 0.8324\n",
      "Epoch 221/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3979 - accuracy: 0.8399 - val_loss: 0.4188 - val_accuracy: 0.8324\n",
      "Epoch 222/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3833 - accuracy: 0.8399 - val_loss: 0.4346 - val_accuracy: 0.8268\n",
      "Epoch 223/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4318 - accuracy: 0.8216 - val_loss: 0.4334 - val_accuracy: 0.8268\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4450 - accuracy: 0.8357 - val_loss: 0.4344 - val_accuracy: 0.8212\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4243 - accuracy: 0.8385 - val_loss: 0.4345 - val_accuracy: 0.8324\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4308 - accuracy: 0.8244 - val_loss: 0.4409 - val_accuracy: 0.7877\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4327 - accuracy: 0.8343 - val_loss: 0.4392 - val_accuracy: 0.8268\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4402 - accuracy: 0.8258 - val_loss: 0.4318 - val_accuracy: 0.8380\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4370 - accuracy: 0.8118 - val_loss: 0.4284 - val_accuracy: 0.8380\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4254 - accuracy: 0.8357 - val_loss: 0.4330 - val_accuracy: 0.8324\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4251 - accuracy: 0.8272 - val_loss: 0.4286 - val_accuracy: 0.8324\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4510 - accuracy: 0.8272 - val_loss: 0.4305 - val_accuracy: 0.8324\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4299 - accuracy: 0.8244 - val_loss: 0.4317 - val_accuracy: 0.8268\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4169 - accuracy: 0.8315 - val_loss: 0.4280 - val_accuracy: 0.8324\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4196 - accuracy: 0.8301 - val_loss: 0.4293 - val_accuracy: 0.8212\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4231 - accuracy: 0.8146 - val_loss: 0.4311 - val_accuracy: 0.8324\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4159 - accuracy: 0.8413 - val_loss: 0.4362 - val_accuracy: 0.8156\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4353 - accuracy: 0.8244 - val_loss: 0.4267 - val_accuracy: 0.8380\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4189 - accuracy: 0.8272 - val_loss: 0.4331 - val_accuracy: 0.8324\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4151 - accuracy: 0.8301 - val_loss: 0.4399 - val_accuracy: 0.8268\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4378 - accuracy: 0.8174 - val_loss: 0.4287 - val_accuracy: 0.8380\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4175 - accuracy: 0.8399 - val_loss: 0.4297 - val_accuracy: 0.8324\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4215 - accuracy: 0.8315 - val_loss: 0.4281 - val_accuracy: 0.8324\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4156 - accuracy: 0.8385 - val_loss: 0.4294 - val_accuracy: 0.8324\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4276 - accuracy: 0.8287 - val_loss: 0.4202 - val_accuracy: 0.8380\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4326 - accuracy: 0.8272 - val_loss: 0.4223 - val_accuracy: 0.8324\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4224 - accuracy: 0.8315 - val_loss: 0.4234 - val_accuracy: 0.8324\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4239 - accuracy: 0.8413 - val_loss: 0.4243 - val_accuracy: 0.8324\n",
      "Epoch 64/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4313 - accuracy: 0.8272 - val_loss: 0.4282 - val_accuracy: 0.8324\n",
      "Epoch 65/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4073 - accuracy: 0.8287 - val_loss: 0.4282 - val_accuracy: 0.8380\n",
      "Epoch 66/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4148 - accuracy: 0.8357 - val_loss: 0.4296 - val_accuracy: 0.8324\n",
      "Epoch 67/400\n",
      "712/712 [==============================] - 0s 246us/sample - loss: 0.4305 - accuracy: 0.8287 - val_loss: 0.4302 - val_accuracy: 0.8380\n",
      "Epoch 68/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4282 - accuracy: 0.8272 - val_loss: 0.4211 - val_accuracy: 0.8380\n",
      "Epoch 69/400\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.4072 - accuracy: 0.8385 - val_loss: 0.4299 - val_accuracy: 0.8324\n",
      "Epoch 70/400\n",
      "712/712 [==============================] - 0s 241us/sample - loss: 0.4341 - accuracy: 0.8118 - val_loss: 0.4214 - val_accuracy: 0.8380\n",
      "Epoch 71/400\n",
      "712/712 [==============================] - 0s 217us/sample - loss: 0.4085 - accuracy: 0.8301 - val_loss: 0.4230 - val_accuracy: 0.8324\n",
      "Epoch 72/400\n",
      "712/712 [==============================] - 0s 231us/sample - loss: 0.4125 - accuracy: 0.8272 - val_loss: 0.4275 - val_accuracy: 0.8380\n",
      "Epoch 73/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4177 - accuracy: 0.8258 - val_loss: 0.4304 - val_accuracy: 0.8324\n",
      "Epoch 74/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4154 - accuracy: 0.8301 - val_loss: 0.4263 - val_accuracy: 0.8212\n",
      "Epoch 75/400\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.4237 - accuracy: 0.8329 - val_loss: 0.4250 - val_accuracy: 0.8380\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.4205 - accuracy: 0.8287 - val_loss: 0.4250 - val_accuracy: 0.8268\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4042 - accuracy: 0.8399 - val_loss: 0.4313 - val_accuracy: 0.8324\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4118 - accuracy: 0.8202 - val_loss: 0.4303 - val_accuracy: 0.8268\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.4316 - accuracy: 0.8244 - val_loss: 0.4275 - val_accuracy: 0.8268\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4049 - accuracy: 0.8329 - val_loss: 0.4196 - val_accuracy: 0.8324\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4259 - accuracy: 0.8146 - val_loss: 0.4244 - val_accuracy: 0.8268\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4055 - accuracy: 0.8497 - val_loss: 0.4269 - val_accuracy: 0.8268\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4183 - accuracy: 0.8315 - val_loss: 0.4233 - val_accuracy: 0.8324\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4108 - accuracy: 0.8357 - val_loss: 0.4182 - val_accuracy: 0.8324\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4204 - accuracy: 0.8301 - val_loss: 0.4196 - val_accuracy: 0.8212\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4202 - accuracy: 0.8188 - val_loss: 0.4166 - val_accuracy: 0.8324\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4452 - accuracy: 0.8188 - val_loss: 0.4190 - val_accuracy: 0.8324\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4294 - accuracy: 0.8118 - val_loss: 0.4206 - val_accuracy: 0.8324\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4077 - accuracy: 0.8287 - val_loss: 0.4188 - val_accuracy: 0.8324\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.4110 - accuracy: 0.8301 - val_loss: 0.4193 - val_accuracy: 0.8380\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4052 - accuracy: 0.8230 - val_loss: 0.4250 - val_accuracy: 0.8380\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4207 - accuracy: 0.8315 - val_loss: 0.4261 - val_accuracy: 0.8380\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4067 - accuracy: 0.8230 - val_loss: 0.4186 - val_accuracy: 0.8324\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4205 - accuracy: 0.8343 - val_loss: 0.4189 - val_accuracy: 0.8380\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4109 - accuracy: 0.8258 - val_loss: 0.4239 - val_accuracy: 0.8324\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4114 - accuracy: 0.8357 - val_loss: 0.4268 - val_accuracy: 0.8324\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4071 - accuracy: 0.8371 - val_loss: 0.4208 - val_accuracy: 0.8380\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4297 - accuracy: 0.8272 - val_loss: 0.4150 - val_accuracy: 0.8324\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4134 - accuracy: 0.8258 - val_loss: 0.4173 - val_accuracy: 0.8268\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4016 - accuracy: 0.8329 - val_loss: 0.4178 - val_accuracy: 0.8380\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4145 - accuracy: 0.8343 - val_loss: 0.4158 - val_accuracy: 0.8380\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4092 - accuracy: 0.8371 - val_loss: 0.4186 - val_accuracy: 0.8268\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 195us/sample - loss: 0.4032 - accuracy: 0.8301 - val_loss: 0.4174 - val_accuracy: 0.8436\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4302 - accuracy: 0.8343 - val_loss: 0.4225 - val_accuracy: 0.8212\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4123 - accuracy: 0.8287 - val_loss: 0.4250 - val_accuracy: 0.8324\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4071 - accuracy: 0.8441 - val_loss: 0.4339 - val_accuracy: 0.8268\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4105 - accuracy: 0.8399 - val_loss: 0.4205 - val_accuracy: 0.8268\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4313 - accuracy: 0.8315 - val_loss: 0.4187 - val_accuracy: 0.8380\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4095 - accuracy: 0.8230 - val_loss: 0.4171 - val_accuracy: 0.8324\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3903 - accuracy: 0.8525 - val_loss: 0.4211 - val_accuracy: 0.8324\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4123 - accuracy: 0.8301 - val_loss: 0.4253 - val_accuracy: 0.8268\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3973 - accuracy: 0.8371 - val_loss: 0.4242 - val_accuracy: 0.8268\n",
      "Epoch 113/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4007 - accuracy: 0.8427 - val_loss: 0.4247 - val_accuracy: 0.8324\n",
      "Epoch 114/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4161 - accuracy: 0.8272 - val_loss: 0.4174 - val_accuracy: 0.8324\n",
      "Epoch 115/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4242 - accuracy: 0.8357 - val_loss: 0.4188 - val_accuracy: 0.8324\n",
      "Epoch 116/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4116 - accuracy: 0.8244 - val_loss: 0.4218 - val_accuracy: 0.8324\n",
      "Epoch 117/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4097 - accuracy: 0.8315 - val_loss: 0.4185 - val_accuracy: 0.8380\n",
      "Epoch 118/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3943 - accuracy: 0.8455 - val_loss: 0.4175 - val_accuracy: 0.8324\n",
      "Epoch 119/400\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.4165 - accuracy: 0.8202 - val_loss: 0.4280 - val_accuracy: 0.8324\n",
      "Epoch 120/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4030 - accuracy: 0.8287 - val_loss: 0.4226 - val_accuracy: 0.8380\n",
      "Epoch 121/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4039 - accuracy: 0.8357 - val_loss: 0.4231 - val_accuracy: 0.8268\n",
      "Epoch 122/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4262 - accuracy: 0.8315 - val_loss: 0.4237 - val_accuracy: 0.8268\n",
      "Epoch 123/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4105 - accuracy: 0.8483 - val_loss: 0.4253 - val_accuracy: 0.8324\n",
      "Epoch 124/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4232 - accuracy: 0.8287 - val_loss: 0.4170 - val_accuracy: 0.8268\n",
      "Epoch 125/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4119 - accuracy: 0.8258 - val_loss: 0.4152 - val_accuracy: 0.8324\n",
      "Epoch 126/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4132 - accuracy: 0.8343 - val_loss: 0.4167 - val_accuracy: 0.8324\n",
      "Epoch 127/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.3963 - accuracy: 0.8427 - val_loss: 0.4164 - val_accuracy: 0.8380\n",
      "Epoch 128/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4072 - accuracy: 0.8329 - val_loss: 0.4251 - val_accuracy: 0.8324\n",
      "Epoch 129/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4150 - accuracy: 0.8287 - val_loss: 0.4182 - val_accuracy: 0.8324\n",
      "Epoch 130/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4104 - accuracy: 0.8329 - val_loss: 0.4233 - val_accuracy: 0.8268\n",
      "Epoch 131/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4193 - accuracy: 0.8329 - val_loss: 0.4231 - val_accuracy: 0.8324\n",
      "Epoch 132/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4019 - accuracy: 0.8385 - val_loss: 0.4290 - val_accuracy: 0.8324\n",
      "Epoch 133/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4149 - accuracy: 0.8287 - val_loss: 0.4261 - val_accuracy: 0.8212\n",
      "Epoch 134/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4133 - accuracy: 0.8371 - val_loss: 0.4268 - val_accuracy: 0.8324\n",
      "Epoch 135/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4085 - accuracy: 0.8413 - val_loss: 0.4242 - val_accuracy: 0.8324\n",
      "Epoch 136/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4111 - accuracy: 0.8385 - val_loss: 0.4259 - val_accuracy: 0.8324\n",
      "Epoch 137/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4105 - accuracy: 0.8427 - val_loss: 0.4202 - val_accuracy: 0.8324\n",
      "Epoch 138/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4141 - accuracy: 0.8315 - val_loss: 0.4220 - val_accuracy: 0.8268\n",
      "Epoch 139/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4088 - accuracy: 0.8371 - val_loss: 0.4269 - val_accuracy: 0.8268\n",
      "Epoch 140/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4103 - accuracy: 0.8272 - val_loss: 0.4174 - val_accuracy: 0.8324\n",
      "Epoch 141/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4094 - accuracy: 0.8357 - val_loss: 0.4172 - val_accuracy: 0.8324\n",
      "Epoch 142/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4058 - accuracy: 0.8371 - val_loss: 0.4182 - val_accuracy: 0.8324\n",
      "Epoch 143/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3928 - accuracy: 0.8497 - val_loss: 0.4221 - val_accuracy: 0.8324\n",
      "Epoch 144/400\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.4146 - accuracy: 0.8258 - val_loss: 0.4165 - val_accuracy: 0.8324\n",
      "Epoch 145/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4075 - accuracy: 0.8357 - val_loss: 0.4158 - val_accuracy: 0.8324\n",
      "Epoch 146/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.4091 - accuracy: 0.8357 - val_loss: 0.4170 - val_accuracy: 0.8268\n",
      "Epoch 147/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4064 - accuracy: 0.8385 - val_loss: 0.4195 - val_accuracy: 0.8324\n",
      "Epoch 148/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4183 - accuracy: 0.8329 - val_loss: 0.4204 - val_accuracy: 0.8324\n",
      "Epoch 149/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4066 - accuracy: 0.8371 - val_loss: 0.4189 - val_accuracy: 0.8324\n",
      "Epoch 150/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4015 - accuracy: 0.8413 - val_loss: 0.4214 - val_accuracy: 0.8212\n",
      "Epoch 151/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4102 - accuracy: 0.8272 - val_loss: 0.4291 - val_accuracy: 0.8324\n",
      "Epoch 152/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3988 - accuracy: 0.8427 - val_loss: 0.4240 - val_accuracy: 0.8268\n",
      "Epoch 153/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.4067 - accuracy: 0.8441 - val_loss: 0.4182 - val_accuracy: 0.8324\n",
      "Epoch 154/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4130 - accuracy: 0.8343 - val_loss: 0.4221 - val_accuracy: 0.8268\n",
      "Epoch 155/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4063 - accuracy: 0.8385 - val_loss: 0.4235 - val_accuracy: 0.8212\n",
      "Epoch 156/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4008 - accuracy: 0.8497 - val_loss: 0.4234 - val_accuracy: 0.8212\n",
      "Epoch 157/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3993 - accuracy: 0.8469 - val_loss: 0.4208 - val_accuracy: 0.8324\n",
      "Epoch 158/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4173 - accuracy: 0.8272 - val_loss: 0.4153 - val_accuracy: 0.8268\n",
      "Epoch 159/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4037 - accuracy: 0.8399 - val_loss: 0.4169 - val_accuracy: 0.8268\n",
      "Epoch 160/400\n",
      "712/712 [==============================] - 0s 222us/sample - loss: 0.4132 - accuracy: 0.8287 - val_loss: 0.4161 - val_accuracy: 0.8324\n",
      "Epoch 161/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4203 - accuracy: 0.8301 - val_loss: 0.4156 - val_accuracy: 0.8268\n",
      "Epoch 162/400\n",
      "712/712 [==============================] - 0s 260us/sample - loss: 0.4031 - accuracy: 0.8413 - val_loss: 0.4216 - val_accuracy: 0.8212\n",
      "Epoch 163/400\n",
      "712/712 [==============================] - 0s 273us/sample - loss: 0.3979 - accuracy: 0.8441 - val_loss: 0.4332 - val_accuracy: 0.8324\n",
      "Epoch 164/400\n",
      "712/712 [==============================] - 0s 209us/sample - loss: 0.4169 - accuracy: 0.8329 - val_loss: 0.4228 - val_accuracy: 0.8380\n",
      "Epoch 165/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4139 - accuracy: 0.8357 - val_loss: 0.4183 - val_accuracy: 0.8268\n",
      "Epoch 166/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3923 - accuracy: 0.8371 - val_loss: 0.4155 - val_accuracy: 0.8268\n",
      "Epoch 167/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4028 - accuracy: 0.8385 - val_loss: 0.4151 - val_accuracy: 0.8268\n",
      "Epoch 168/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3948 - accuracy: 0.8441 - val_loss: 0.4185 - val_accuracy: 0.8324\n",
      "Epoch 169/400\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.4108 - accuracy: 0.8301 - val_loss: 0.4195 - val_accuracy: 0.8156\n",
      "Epoch 170/400\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.4035 - accuracy: 0.8399 - val_loss: 0.4175 - val_accuracy: 0.8324\n",
      "Epoch 171/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4121 - accuracy: 0.8385 - val_loss: 0.4176 - val_accuracy: 0.8324\n",
      "Epoch 172/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4087 - accuracy: 0.8343 - val_loss: 0.4217 - val_accuracy: 0.8268\n",
      "Epoch 173/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4097 - accuracy: 0.8343 - val_loss: 0.4157 - val_accuracy: 0.8268\n",
      "Epoch 174/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3923 - accuracy: 0.8455 - val_loss: 0.4176 - val_accuracy: 0.8212\n",
      "Epoch 175/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3975 - accuracy: 0.8301 - val_loss: 0.4145 - val_accuracy: 0.8380\n",
      "Epoch 176/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4063 - accuracy: 0.8272 - val_loss: 0.4154 - val_accuracy: 0.8324\n",
      "Epoch 177/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4143 - accuracy: 0.8315 - val_loss: 0.4146 - val_accuracy: 0.8268\n",
      "Epoch 178/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3899 - accuracy: 0.8329 - val_loss: 0.4193 - val_accuracy: 0.8268\n",
      "Epoch 179/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4045 - accuracy: 0.8539 - val_loss: 0.4349 - val_accuracy: 0.8268\n",
      "Epoch 180/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3986 - accuracy: 0.8441 - val_loss: 0.4179 - val_accuracy: 0.8324\n",
      "Epoch 181/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4206 - accuracy: 0.8244 - val_loss: 0.4172 - val_accuracy: 0.8324\n",
      "Epoch 182/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4071 - accuracy: 0.8469 - val_loss: 0.4230 - val_accuracy: 0.8268\n",
      "Epoch 183/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3991 - accuracy: 0.8343 - val_loss: 0.4245 - val_accuracy: 0.8268\n",
      "Epoch 184/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4095 - accuracy: 0.8371 - val_loss: 0.4188 - val_accuracy: 0.8212\n",
      "Epoch 185/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3942 - accuracy: 0.8455 - val_loss: 0.4260 - val_accuracy: 0.8212\n",
      "Epoch 186/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4107 - accuracy: 0.8455 - val_loss: 0.4204 - val_accuracy: 0.8212\n",
      "Epoch 187/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4030 - accuracy: 0.8455 - val_loss: 0.4247 - val_accuracy: 0.8156\n",
      "Epoch 188/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4042 - accuracy: 0.8357 - val_loss: 0.4275 - val_accuracy: 0.8212\n",
      "Epoch 189/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4036 - accuracy: 0.8343 - val_loss: 0.4256 - val_accuracy: 0.8324\n",
      "Epoch 190/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3997 - accuracy: 0.8497 - val_loss: 0.4332 - val_accuracy: 0.8212\n",
      "Epoch 191/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4047 - accuracy: 0.8329 - val_loss: 0.4342 - val_accuracy: 0.8101\n",
      "Epoch 192/400\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.4056 - accuracy: 0.8455 - val_loss: 0.4231 - val_accuracy: 0.8212\n",
      "Epoch 193/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4087 - accuracy: 0.8343 - val_loss: 0.4150 - val_accuracy: 0.8212\n",
      "Epoch 194/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4047 - accuracy: 0.8469 - val_loss: 0.4184 - val_accuracy: 0.8268\n",
      "Epoch 195/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3994 - accuracy: 0.8258 - val_loss: 0.4162 - val_accuracy: 0.8212\n",
      "Epoch 196/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3976 - accuracy: 0.8343 - val_loss: 0.4173 - val_accuracy: 0.8268\n",
      "Epoch 197/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4094 - accuracy: 0.8343 - val_loss: 0.4240 - val_accuracy: 0.8212\n",
      "Epoch 198/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4039 - accuracy: 0.8357 - val_loss: 0.4326 - val_accuracy: 0.8268\n",
      "Epoch 199/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4128 - accuracy: 0.8385 - val_loss: 0.4180 - val_accuracy: 0.8212\n",
      "Epoch 200/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4067 - accuracy: 0.8357 - val_loss: 0.4164 - val_accuracy: 0.8212\n",
      "Epoch 201/400\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.4165 - accuracy: 0.8287 - val_loss: 0.4168 - val_accuracy: 0.8212\n",
      "Epoch 202/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4018 - accuracy: 0.8258 - val_loss: 0.4240 - val_accuracy: 0.8268\n",
      "Epoch 203/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3937 - accuracy: 0.8301 - val_loss: 0.4281 - val_accuracy: 0.8156\n",
      "Epoch 204/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3935 - accuracy: 0.8427 - val_loss: 0.4279 - val_accuracy: 0.8212\n",
      "Epoch 205/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4050 - accuracy: 0.8315 - val_loss: 0.4279 - val_accuracy: 0.8212\n",
      "Epoch 206/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4014 - accuracy: 0.8385 - val_loss: 0.4282 - val_accuracy: 0.8324\n",
      "Epoch 207/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4069 - accuracy: 0.8329 - val_loss: 0.4279 - val_accuracy: 0.8212\n",
      "Epoch 208/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4050 - accuracy: 0.8469 - val_loss: 0.4329 - val_accuracy: 0.8156\n",
      "Epoch 209/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3940 - accuracy: 0.8399 - val_loss: 0.4247 - val_accuracy: 0.8212\n",
      "Epoch 210/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4008 - accuracy: 0.8371 - val_loss: 0.4245 - val_accuracy: 0.8212\n",
      "Epoch 211/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3969 - accuracy: 0.8399 - val_loss: 0.4262 - val_accuracy: 0.8268\n",
      "Epoch 212/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4121 - accuracy: 0.8343 - val_loss: 0.4235 - val_accuracy: 0.8156\n",
      "Epoch 213/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3879 - accuracy: 0.8539 - val_loss: 0.4228 - val_accuracy: 0.8212\n",
      "Epoch 214/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3985 - accuracy: 0.8399 - val_loss: 0.4215 - val_accuracy: 0.8212\n",
      "Epoch 215/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4032 - accuracy: 0.8343 - val_loss: 0.4257 - val_accuracy: 0.8268\n",
      "Epoch 216/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4142 - accuracy: 0.8483 - val_loss: 0.4230 - val_accuracy: 0.8212\n",
      "Epoch 217/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3967 - accuracy: 0.8343 - val_loss: 0.4271 - val_accuracy: 0.8212\n",
      "Epoch 218/400\n",
      "712/712 [==============================] - 0s 195us/sample - loss: 0.3989 - accuracy: 0.8371 - val_loss: 0.4308 - val_accuracy: 0.8156\n",
      "Epoch 219/400\n",
      "712/712 [==============================] - 0s 599us/sample - loss: 0.4072 - accuracy: 0.8413 - val_loss: 0.4227 - val_accuracy: 0.8212\n",
      "Epoch 220/400\n",
      "712/712 [==============================] - 0s 561us/sample - loss: 0.3961 - accuracy: 0.8413 - val_loss: 0.4224 - val_accuracy: 0.8212\n",
      "Epoch 221/400\n",
      "712/712 [==============================] - 0s 193us/sample - loss: 0.4168 - accuracy: 0.8441 - val_loss: 0.4228 - val_accuracy: 0.8212\n",
      "Epoch 222/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3993 - accuracy: 0.8511 - val_loss: 0.4288 - val_accuracy: 0.8268\n",
      "Epoch 223/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3913 - accuracy: 0.8371 - val_loss: 0.4336 - val_accuracy: 0.8268\n",
      "Epoch 224/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4421 - accuracy: 0.8006 - val_loss: 0.4327 - val_accuracy: 0.8156\n",
      "Epoch 140/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4614 - accuracy: 0.8230 - val_loss: 0.4323 - val_accuracy: 0.8101\n",
      "Epoch 141/400\n",
      "712/712 [==============================] - 0s 254us/sample - loss: 0.4399 - accuracy: 0.8090 - val_loss: 0.4323 - val_accuracy: 0.8101\n",
      "Epoch 142/400\n",
      "712/712 [==============================] - 0s 244us/sample - loss: 0.4593 - accuracy: 0.8062 - val_loss: 0.4332 - val_accuracy: 0.8156\n",
      "Epoch 143/400\n",
      "712/712 [==============================] - 0s 310us/sample - loss: 0.4513 - accuracy: 0.8104 - val_loss: 0.4330 - val_accuracy: 0.8156\n",
      "Epoch 144/400\n",
      "712/712 [==============================] - 0s 309us/sample - loss: 0.4474 - accuracy: 0.8244 - val_loss: 0.4347 - val_accuracy: 0.8101\n",
      "Epoch 145/400\n",
      "712/712 [==============================] - 0s 201us/sample - loss: 0.4502 - accuracy: 0.8118 - val_loss: 0.4334 - val_accuracy: 0.8101\n",
      "Epoch 146/400\n",
      "712/712 [==============================] - 0s 217us/sample - loss: 0.4517 - accuracy: 0.7992 - val_loss: 0.4320 - val_accuracy: 0.8156\n",
      "Epoch 147/400\n",
      "712/712 [==============================] - 0s 261us/sample - loss: 0.4473 - accuracy: 0.8104 - val_loss: 0.4318 - val_accuracy: 0.8101\n",
      "Epoch 148/400\n",
      "712/712 [==============================] - 0s 267us/sample - loss: 0.4447 - accuracy: 0.8090 - val_loss: 0.4330 - val_accuracy: 0.8156\n",
      "Epoch 149/400\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.4605 - accuracy: 0.8132 - val_loss: 0.4330 - val_accuracy: 0.8156\n",
      "Epoch 150/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4529 - accuracy: 0.8146 - val_loss: 0.4333 - val_accuracy: 0.8156\n",
      "Epoch 151/400\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.4564 - accuracy: 0.8076 - val_loss: 0.4337 - val_accuracy: 0.8156\n",
      "Epoch 152/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4508 - accuracy: 0.8202 - val_loss: 0.4340 - val_accuracy: 0.8156\n",
      "Epoch 153/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4413 - accuracy: 0.8006 - val_loss: 0.4325 - val_accuracy: 0.8156\n",
      "Epoch 154/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4502 - accuracy: 0.8006 - val_loss: 0.4320 - val_accuracy: 0.8101\n",
      "Epoch 155/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4316 - accuracy: 0.8174 - val_loss: 0.4321 - val_accuracy: 0.8156\n",
      "Epoch 156/400\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.4524 - accuracy: 0.8006 - val_loss: 0.4316 - val_accuracy: 0.8156\n",
      "Epoch 157/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4411 - accuracy: 0.8202 - val_loss: 0.4315 - val_accuracy: 0.8156\n",
      "Epoch 158/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4561 - accuracy: 0.8076 - val_loss: 0.4318 - val_accuracy: 0.8101\n",
      "Epoch 159/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4606 - accuracy: 0.8118 - val_loss: 0.4313 - val_accuracy: 0.8156\n",
      "Epoch 160/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4407 - accuracy: 0.8188 - val_loss: 0.4310 - val_accuracy: 0.8101\n",
      "Epoch 161/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4420 - accuracy: 0.8188 - val_loss: 0.4319 - val_accuracy: 0.8156\n",
      "Epoch 162/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4392 - accuracy: 0.8174 - val_loss: 0.4313 - val_accuracy: 0.8156\n",
      "Epoch 163/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4433 - accuracy: 0.8244 - val_loss: 0.4319 - val_accuracy: 0.8156\n",
      "Epoch 164/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4469 - accuracy: 0.8202 - val_loss: 0.4322 - val_accuracy: 0.8156\n",
      "Epoch 165/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4593 - accuracy: 0.8132 - val_loss: 0.4324 - val_accuracy: 0.8156\n",
      "Epoch 166/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4410 - accuracy: 0.8272 - val_loss: 0.4329 - val_accuracy: 0.8156\n",
      "Epoch 167/400\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.4645 - accuracy: 0.8188 - val_loss: 0.4327 - val_accuracy: 0.8156\n",
      "Epoch 168/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4459 - accuracy: 0.8188 - val_loss: 0.4322 - val_accuracy: 0.8156\n",
      "Epoch 169/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4497 - accuracy: 0.8076 - val_loss: 0.4321 - val_accuracy: 0.8156\n",
      "Epoch 170/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4375 - accuracy: 0.8216 - val_loss: 0.4339 - val_accuracy: 0.8156\n",
      "Epoch 171/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4307 - accuracy: 0.8146 - val_loss: 0.4326 - val_accuracy: 0.8156\n",
      "Epoch 172/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4338 - accuracy: 0.8258 - val_loss: 0.4318 - val_accuracy: 0.8156\n",
      "Epoch 173/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4583 - accuracy: 0.8132 - val_loss: 0.4316 - val_accuracy: 0.8156\n",
      "Epoch 174/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3908 - accuracy: 0.8343 - val_loss: 0.4327 - val_accuracy: 0.8156\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3979 - accuracy: 0.8427 - val_loss: 0.4261 - val_accuracy: 0.8380\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3818 - accuracy: 0.8539 - val_loss: 0.4380 - val_accuracy: 0.8212\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3927 - accuracy: 0.8427 - val_loss: 0.4339 - val_accuracy: 0.8268\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3850 - accuracy: 0.8315 - val_loss: 0.4347 - val_accuracy: 0.8324\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3836 - accuracy: 0.8525 - val_loss: 0.4367 - val_accuracy: 0.8268\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3972 - accuracy: 0.8385 - val_loss: 0.4253 - val_accuracy: 0.8380\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3852 - accuracy: 0.8399 - val_loss: 0.4336 - val_accuracy: 0.8324\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3810 - accuracy: 0.8483 - val_loss: 0.4322 - val_accuracy: 0.8380\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.3790 - accuracy: 0.8469 - val_loss: 0.4357 - val_accuracy: 0.8380\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3731 - accuracy: 0.8483 - val_loss: 0.4347 - val_accuracy: 0.8380\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3910 - accuracy: 0.8483 - val_loss: 0.4256 - val_accuracy: 0.8380\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3742 - accuracy: 0.8413 - val_loss: 0.4172 - val_accuracy: 0.8324\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3798 - accuracy: 0.8483 - val_loss: 0.4214 - val_accuracy: 0.8380\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3883 - accuracy: 0.8413 - val_loss: 0.4277 - val_accuracy: 0.8268\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3844 - accuracy: 0.8483 - val_loss: 0.4290 - val_accuracy: 0.8436\n",
      "Epoch 64/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3945 - accuracy: 0.8399 - val_loss: 0.4231 - val_accuracy: 0.8380\n",
      "Epoch 65/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3745 - accuracy: 0.8315 - val_loss: 0.4264 - val_accuracy: 0.8380\n",
      "Epoch 66/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3793 - accuracy: 0.8483 - val_loss: 0.4274 - val_accuracy: 0.8324\n",
      "Epoch 67/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3731 - accuracy: 0.8497 - val_loss: 0.4322 - val_accuracy: 0.8324\n",
      "Epoch 68/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3812 - accuracy: 0.8483 - val_loss: 0.4274 - val_accuracy: 0.8268\n",
      "Epoch 69/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3760 - accuracy: 0.8553 - val_loss: 0.4301 - val_accuracy: 0.8324\n",
      "Epoch 70/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3812 - accuracy: 0.8469 - val_loss: 0.4285 - val_accuracy: 0.8324\n",
      "Epoch 71/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3710 - accuracy: 0.8483 - val_loss: 0.4343 - val_accuracy: 0.8156\n",
      "Epoch 72/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3867 - accuracy: 0.8413 - val_loss: 0.4297 - val_accuracy: 0.8436\n",
      "Epoch 73/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3793 - accuracy: 0.8539 - val_loss: 0.4380 - val_accuracy: 0.8324\n",
      "Epoch 74/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3828 - accuracy: 0.8497 - val_loss: 0.4366 - val_accuracy: 0.8380\n",
      "Epoch 75/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3856 - accuracy: 0.8525 - val_loss: 0.4391 - val_accuracy: 0.8268\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3780 - accuracy: 0.8525 - val_loss: 0.4373 - val_accuracy: 0.8324\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3671 - accuracy: 0.8567 - val_loss: 0.4469 - val_accuracy: 0.8156\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3602 - accuracy: 0.8511 - val_loss: 0.4416 - val_accuracy: 0.8380\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3794 - accuracy: 0.8469 - val_loss: 0.4426 - val_accuracy: 0.8212\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3676 - accuracy: 0.8497 - val_loss: 0.4379 - val_accuracy: 0.8380\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3762 - accuracy: 0.8567 - val_loss: 0.4374 - val_accuracy: 0.8324\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3761 - accuracy: 0.8553 - val_loss: 0.4364 - val_accuracy: 0.8380\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3707 - accuracy: 0.8610 - val_loss: 0.4348 - val_accuracy: 0.8268\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3761 - accuracy: 0.8455 - val_loss: 0.4299 - val_accuracy: 0.8380\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3763 - accuracy: 0.8427 - val_loss: 0.4286 - val_accuracy: 0.8436\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 221us/sample - loss: 0.3877 - accuracy: 0.8441 - val_loss: 0.4211 - val_accuracy: 0.8212\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3799 - accuracy: 0.8413 - val_loss: 0.4698 - val_accuracy: 0.8101\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3916 - accuracy: 0.8455 - val_loss: 0.4267 - val_accuracy: 0.8268\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.3919 - accuracy: 0.8371 - val_loss: 0.4446 - val_accuracy: 0.8212\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.3829 - accuracy: 0.8497 - val_loss: 0.4282 - val_accuracy: 0.8212\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3768 - accuracy: 0.8427 - val_loss: 0.4409 - val_accuracy: 0.8212\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3829 - accuracy: 0.8539 - val_loss: 0.4581 - val_accuracy: 0.8045\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.3886 - accuracy: 0.8511 - val_loss: 0.4451 - val_accuracy: 0.8268\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.3783 - accuracy: 0.8525 - val_loss: 0.4690 - val_accuracy: 0.8156\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3626 - accuracy: 0.8511 - val_loss: 0.4678 - val_accuracy: 0.8101\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3777 - accuracy: 0.8483 - val_loss: 0.4526 - val_accuracy: 0.8212\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3639 - accuracy: 0.8511 - val_loss: 0.4748 - val_accuracy: 0.7933\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.3723 - accuracy: 0.8427 - val_loss: 0.4571 - val_accuracy: 0.8156\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3825 - accuracy: 0.8469 - val_loss: 0.5196 - val_accuracy: 0.7877\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3781 - accuracy: 0.8567 - val_loss: 0.4497 - val_accuracy: 0.8101\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3718 - accuracy: 0.8511 - val_loss: 0.4595 - val_accuracy: 0.8212\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3688 - accuracy: 0.8539 - val_loss: 0.4524 - val_accuracy: 0.8324\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3798 - accuracy: 0.8427 - val_loss: 0.4543 - val_accuracy: 0.8156\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.3615 - accuracy: 0.8511 - val_loss: 0.4642 - val_accuracy: 0.8101\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.3763 - accuracy: 0.8385 - val_loss: 0.4408 - val_accuracy: 0.8101\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.3698 - accuracy: 0.8525 - val_loss: 0.4694 - val_accuracy: 0.8101\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3634 - accuracy: 0.8567 - val_loss: 0.4605 - val_accuracy: 0.8101\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3597 - accuracy: 0.8596 - val_loss: 0.4534 - val_accuracy: 0.8156\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3814 - accuracy: 0.8413 - val_loss: 0.4615 - val_accuracy: 0.8045\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3711 - accuracy: 0.8455 - val_loss: 0.4977 - val_accuracy: 0.7989\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3668 - accuracy: 0.8483 - val_loss: 0.4455 - val_accuracy: 0.8156\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3446 - accuracy: 0.8567 - val_loss: 0.4670 - val_accuracy: 0.8212\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3619 - accuracy: 0.8511 - val_loss: 0.4624 - val_accuracy: 0.8212\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.3503 - accuracy: 0.8441 - val_loss: 0.4540 - val_accuracy: 0.8156\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.3721 - accuracy: 0.8511 - val_loss: 0.4482 - val_accuracy: 0.8101\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3642 - accuracy: 0.8567 - val_loss: 0.4455 - val_accuracy: 0.8268\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3634 - accuracy: 0.8525 - val_loss: 0.4778 - val_accuracy: 0.8156\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3639 - accuracy: 0.8497 - val_loss: 0.4952 - val_accuracy: 0.8101\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3721 - accuracy: 0.8497 - val_loss: 0.4843 - val_accuracy: 0.8101\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3767 - accuracy: 0.8511 - val_loss: 0.4605 - val_accuracy: 0.8212\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3610 - accuracy: 0.8469 - val_loss: 0.4598 - val_accuracy: 0.8268\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.3613 - accuracy: 0.8525 - val_loss: 0.4710 - val_accuracy: 0.8156\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.3574 - accuracy: 0.8483 - val_loss: 0.4794 - val_accuracy: 0.8101\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3646 - accuracy: 0.8441 - val_loss: 0.4739 - val_accuracy: 0.8156\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4119 - accuracy: 0.8469 - val_loss: 0.4316 - val_accuracy: 0.8268\n",
      "Epoch 222/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4055 - accuracy: 0.8357 - val_loss: 0.4319 - val_accuracy: 0.8156\n",
      "Epoch 223/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3982 - accuracy: 0.8413 - val_loss: 0.4323 - val_accuracy: 0.8156\n",
      "Epoch 224/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4013 - accuracy: 0.8371 - val_loss: 0.4317 - val_accuracy: 0.8156\n",
      "Epoch 225/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4075 - accuracy: 0.8413 - val_loss: 0.4326 - val_accuracy: 0.8156\n",
      "Epoch 226/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4161 - accuracy: 0.8244 - val_loss: 0.4334 - val_accuracy: 0.8212\n",
      "Epoch 227/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4087 - accuracy: 0.8230 - val_loss: 0.4332 - val_accuracy: 0.8212\n",
      "Epoch 228/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4001 - accuracy: 0.8343 - val_loss: 0.4333 - val_accuracy: 0.8212\n",
      "Epoch 229/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4018 - accuracy: 0.8441 - val_loss: 0.4336 - val_accuracy: 0.8156\n",
      "Epoch 230/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4147 - accuracy: 0.8427 - val_loss: 0.4323 - val_accuracy: 0.8156\n",
      "Epoch 231/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4054 - accuracy: 0.8329 - val_loss: 0.4320 - val_accuracy: 0.8156\n",
      "Epoch 232/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4158 - accuracy: 0.8315 - val_loss: 0.4334 - val_accuracy: 0.8156\n",
      "Epoch 233/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4151 - accuracy: 0.8230 - val_loss: 0.4336 - val_accuracy: 0.8156\n",
      "Epoch 234/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.4070 - accuracy: 0.8385 - val_loss: 0.4323 - val_accuracy: 0.8156\n",
      "Epoch 235/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4032 - accuracy: 0.8301 - val_loss: 0.4324 - val_accuracy: 0.8156\n",
      "Epoch 236/400\n",
      "712/712 [==============================] - 0s 235us/sample - loss: 0.4177 - accuracy: 0.8315 - val_loss: 0.4322 - val_accuracy: 0.8156\n",
      "Epoch 237/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4326 - accuracy: 0.8343 - val_loss: 0.4311 - val_accuracy: 0.8212\n",
      "Epoch 238/400\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.4325 - accuracy: 0.8329 - val_loss: 0.4308 - val_accuracy: 0.8268\n",
      "Epoch 239/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4217 - accuracy: 0.8287 - val_loss: 0.4296 - val_accuracy: 0.8212\n",
      "Epoch 240/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4006 - accuracy: 0.8385 - val_loss: 0.4305 - val_accuracy: 0.8156\n",
      "Epoch 241/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3958 - accuracy: 0.8371 - val_loss: 0.4316 - val_accuracy: 0.8156\n",
      "Epoch 242/400\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.4009 - accuracy: 0.8301 - val_loss: 0.4316 - val_accuracy: 0.8156\n",
      "Epoch 243/400\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.4190 - accuracy: 0.8202 - val_loss: 0.4310 - val_accuracy: 0.8268\n",
      "Epoch 244/400\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.4032 - accuracy: 0.8329 - val_loss: 0.4322 - val_accuracy: 0.8212\n",
      "Epoch 245/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.4010 - accuracy: 0.8315 - val_loss: 0.4328 - val_accuracy: 0.8212\n",
      "Epoch 246/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4129 - accuracy: 0.8385 - val_loss: 0.4334 - val_accuracy: 0.8212\n",
      "Epoch 247/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4180 - accuracy: 0.8413 - val_loss: 0.4311 - val_accuracy: 0.8268\n",
      "Epoch 248/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4139 - accuracy: 0.8427 - val_loss: 0.4316 - val_accuracy: 0.8268\n",
      "Epoch 249/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3981 - accuracy: 0.8483 - val_loss: 0.4329 - val_accuracy: 0.8212\n",
      "Epoch 250/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4202 - accuracy: 0.8272 - val_loss: 0.4334 - val_accuracy: 0.8212\n",
      "Epoch 251/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4038 - accuracy: 0.8357 - val_loss: 0.4334 - val_accuracy: 0.8156\n",
      "Epoch 252/400\n",
      "712/712 [==============================] - 0s 215us/sample - loss: 0.4056 - accuracy: 0.8315 - val_loss: 0.4346 - val_accuracy: 0.8156\n",
      "Epoch 253/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4065 - accuracy: 0.8315 - val_loss: 0.4345 - val_accuracy: 0.8212\n",
      "Epoch 254/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3962 - accuracy: 0.8287 - val_loss: 0.4360 - val_accuracy: 0.8156\n",
      "Epoch 255/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4031 - accuracy: 0.8343 - val_loss: 0.4352 - val_accuracy: 0.8156\n",
      "Epoch 256/400\n",
      "712/712 [==============================] - 0s 219us/sample - loss: 0.4152 - accuracy: 0.8329 - val_loss: 0.4355 - val_accuracy: 0.8156\n",
      "Epoch 257/400\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.4223 - accuracy: 0.8230 - val_loss: 0.4358 - val_accuracy: 0.8156\n",
      "Epoch 258/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4170 - accuracy: 0.8315 - val_loss: 0.4346 - val_accuracy: 0.8156\n",
      "Epoch 259/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3881 - accuracy: 0.8441 - val_loss: 0.4414 - val_accuracy: 0.8268\n",
      "Epoch 176/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4036 - accuracy: 0.8357 - val_loss: 0.4374 - val_accuracy: 0.8156\n",
      "Epoch 177/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3963 - accuracy: 0.8357 - val_loss: 0.4413 - val_accuracy: 0.8212\n",
      "Epoch 178/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3869 - accuracy: 0.8399 - val_loss: 0.4364 - val_accuracy: 0.8156\n",
      "Epoch 179/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3793 - accuracy: 0.8511 - val_loss: 0.4422 - val_accuracy: 0.8156\n",
      "Epoch 180/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.3881 - accuracy: 0.8413 - val_loss: 0.4468 - val_accuracy: 0.8156\n",
      "Epoch 181/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.3902 - accuracy: 0.8385 - val_loss: 0.4414 - val_accuracy: 0.8268\n",
      "Epoch 182/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.3890 - accuracy: 0.8329 - val_loss: 0.4511 - val_accuracy: 0.8156\n",
      "Epoch 183/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3876 - accuracy: 0.8301 - val_loss: 0.4435 - val_accuracy: 0.8156\n",
      "Epoch 184/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3926 - accuracy: 0.8315 - val_loss: 0.4380 - val_accuracy: 0.8156\n",
      "Epoch 185/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.3930 - accuracy: 0.8399 - val_loss: 0.4422 - val_accuracy: 0.8212\n",
      "Epoch 186/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3950 - accuracy: 0.8427 - val_loss: 0.4447 - val_accuracy: 0.8212\n",
      "Epoch 187/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3833 - accuracy: 0.8497 - val_loss: 0.4373 - val_accuracy: 0.8268\n",
      "Epoch 188/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3881 - accuracy: 0.8455 - val_loss: 0.4482 - val_accuracy: 0.8268\n",
      "Epoch 189/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3828 - accuracy: 0.8357 - val_loss: 0.4464 - val_accuracy: 0.8156\n",
      "Epoch 190/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3923 - accuracy: 0.8441 - val_loss: 0.4466 - val_accuracy: 0.8156\n",
      "Epoch 191/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3842 - accuracy: 0.8399 - val_loss: 0.4536 - val_accuracy: 0.8212\n",
      "Epoch 192/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3922 - accuracy: 0.8427 - val_loss: 0.4431 - val_accuracy: 0.8156\n",
      "Epoch 193/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3818 - accuracy: 0.8483 - val_loss: 0.4393 - val_accuracy: 0.8156\n",
      "Epoch 194/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3866 - accuracy: 0.8315 - val_loss: 0.4440 - val_accuracy: 0.8101\n",
      "Epoch 195/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3878 - accuracy: 0.8329 - val_loss: 0.4481 - val_accuracy: 0.8212\n",
      "Epoch 196/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3909 - accuracy: 0.8399 - val_loss: 0.4395 - val_accuracy: 0.8212\n",
      "Epoch 197/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3962 - accuracy: 0.8371 - val_loss: 0.4422 - val_accuracy: 0.8156\n",
      "Epoch 198/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3882 - accuracy: 0.8357 - val_loss: 0.4459 - val_accuracy: 0.8156\n",
      "Epoch 199/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3895 - accuracy: 0.8413 - val_loss: 0.4430 - val_accuracy: 0.8156\n",
      "Epoch 200/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3860 - accuracy: 0.8455 - val_loss: 0.4404 - val_accuracy: 0.8156\n",
      "Epoch 201/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3907 - accuracy: 0.8357 - val_loss: 0.4430 - val_accuracy: 0.8156\n",
      "Epoch 202/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3884 - accuracy: 0.8441 - val_loss: 0.4386 - val_accuracy: 0.8212\n",
      "Epoch 203/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3843 - accuracy: 0.8455 - val_loss: 0.4502 - val_accuracy: 0.8045\n",
      "Epoch 204/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3839 - accuracy: 0.8329 - val_loss: 0.4461 - val_accuracy: 0.8101\n",
      "Epoch 205/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3755 - accuracy: 0.8581 - val_loss: 0.4459 - val_accuracy: 0.8212\n",
      "Epoch 206/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3932 - accuracy: 0.8385 - val_loss: 0.4427 - val_accuracy: 0.8156\n",
      "Epoch 207/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3962 - accuracy: 0.8357 - val_loss: 0.4429 - val_accuracy: 0.8268\n",
      "Epoch 208/400\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.3879 - accuracy: 0.8399 - val_loss: 0.4383 - val_accuracy: 0.8212\n",
      "Epoch 209/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3836 - accuracy: 0.8371 - val_loss: 0.4413 - val_accuracy: 0.8212\n",
      "Epoch 210/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.3947 - accuracy: 0.8455 - val_loss: 0.4424 - val_accuracy: 0.8156\n",
      "Epoch 211/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4016 - accuracy: 0.8357 - val_loss: 0.4387 - val_accuracy: 0.8156\n",
      "Epoch 212/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3869 - accuracy: 0.8385 - val_loss: 0.4487 - val_accuracy: 0.8212\n",
      "Epoch 213/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3759 - accuracy: 0.8483 - val_loss: 0.4827 - val_accuracy: 0.8045\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.3679 - accuracy: 0.8483 - val_loss: 0.5363 - val_accuracy: 0.8156\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.3579 - accuracy: 0.8525 - val_loss: 0.5436 - val_accuracy: 0.8045\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 223us/sample - loss: 0.3593 - accuracy: 0.8399 - val_loss: 0.4948 - val_accuracy: 0.8212\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3717 - accuracy: 0.8483 - val_loss: 0.5828 - val_accuracy: 0.8045\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 206us/sample - loss: 0.3617 - accuracy: 0.8553 - val_loss: 0.4823 - val_accuracy: 0.8212\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 244us/sample - loss: 0.3761 - accuracy: 0.8483 - val_loss: 0.5392 - val_accuracy: 0.7989\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.3619 - accuracy: 0.8567 - val_loss: 0.4944 - val_accuracy: 0.8156\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.3717 - accuracy: 0.8567 - val_loss: 0.5438 - val_accuracy: 0.7933\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3575 - accuracy: 0.8525 - val_loss: 0.5544 - val_accuracy: 0.8101\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3613 - accuracy: 0.8525 - val_loss: 0.5968 - val_accuracy: 0.7933\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3752 - accuracy: 0.8525 - val_loss: 0.4718 - val_accuracy: 0.8156\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3808 - accuracy: 0.8455 - val_loss: 0.4759 - val_accuracy: 0.8156\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3613 - accuracy: 0.8624 - val_loss: 0.5070 - val_accuracy: 0.8212\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3737 - accuracy: 0.8539 - val_loss: 0.5204 - val_accuracy: 0.8101\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3426 - accuracy: 0.8666 - val_loss: 0.5507 - val_accuracy: 0.8156\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3538 - accuracy: 0.8539 - val_loss: 0.6218 - val_accuracy: 0.7821\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3524 - accuracy: 0.8455 - val_loss: 0.5399 - val_accuracy: 0.8045\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3592 - accuracy: 0.8525 - val_loss: 0.5177 - val_accuracy: 0.7989\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3455 - accuracy: 0.8553 - val_loss: 0.5577 - val_accuracy: 0.8156\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3812 - accuracy: 0.8525 - val_loss: 0.5065 - val_accuracy: 0.7933\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3852 - accuracy: 0.8329 - val_loss: 0.4551 - val_accuracy: 0.8045\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.4009 - accuracy: 0.8511 - val_loss: 0.4535 - val_accuracy: 0.8156\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3659 - accuracy: 0.8399 - val_loss: 0.4843 - val_accuracy: 0.8156\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3613 - accuracy: 0.8455 - val_loss: 0.4708 - val_accuracy: 0.8101\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 223us/sample - loss: 0.3509 - accuracy: 0.8497 - val_loss: 0.5384 - val_accuracy: 0.8101\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3626 - accuracy: 0.8525 - val_loss: 0.4952 - val_accuracy: 0.8101\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.3884 - accuracy: 0.8385 - val_loss: 0.5845 - val_accuracy: 0.8101\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 246us/sample - loss: 0.3688 - accuracy: 0.8441 - val_loss: 0.6920 - val_accuracy: 0.7989\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 250us/sample - loss: 0.3428 - accuracy: 0.8596 - val_loss: 0.5496 - val_accuracy: 0.8212\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 216us/sample - loss: 0.3622 - accuracy: 0.8567 - val_loss: 0.6192 - val_accuracy: 0.8101\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3542 - accuracy: 0.8539 - val_loss: 0.5198 - val_accuracy: 0.8101\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3453 - accuracy: 0.8596 - val_loss: 0.5693 - val_accuracy: 0.8045\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3613 - accuracy: 0.8483 - val_loss: 0.5998 - val_accuracy: 0.8045\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3685 - accuracy: 0.8525 - val_loss: 0.5944 - val_accuracy: 0.8156\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3537 - accuracy: 0.8567 - val_loss: 0.6676 - val_accuracy: 0.7989\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3563 - accuracy: 0.8483 - val_loss: 0.5429 - val_accuracy: 0.8101\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.3513 - accuracy: 0.8638 - val_loss: 0.5579 - val_accuracy: 0.7989\n",
      "Epoch 113/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.3584 - accuracy: 0.8469 - val_loss: 0.5503 - val_accuracy: 0.8045\n",
      "Epoch 114/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3690 - accuracy: 0.8483 - val_loss: 0.5508 - val_accuracy: 0.7877\n",
      "Epoch 115/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3496 - accuracy: 0.8525 - val_loss: 0.6342 - val_accuracy: 0.7933\n",
      "Epoch 116/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3681 - accuracy: 0.8511 - val_loss: 0.5792 - val_accuracy: 0.7989\n",
      "Epoch 117/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3538 - accuracy: 0.8596 - val_loss: 0.5839 - val_accuracy: 0.7989\n",
      "Epoch 118/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.3446 - accuracy: 0.8553 - val_loss: 0.7047 - val_accuracy: 0.7989\n",
      "Epoch 119/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3497 - accuracy: 0.8666 - val_loss: 0.6073 - val_accuracy: 0.8045\n",
      "Epoch 120/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3561 - accuracy: 0.8511 - val_loss: 0.6318 - val_accuracy: 0.7989\n",
      "Epoch 121/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3495 - accuracy: 0.8553 - val_loss: 0.6431 - val_accuracy: 0.8156\n",
      "Epoch 122/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.3519 - accuracy: 0.8455 - val_loss: 0.6687 - val_accuracy: 0.8045\n",
      "Epoch 123/400\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.3546 - accuracy: 0.8441 - val_loss: 0.5854 - val_accuracy: 0.7989\n",
      "Epoch 124/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3659 - accuracy: 0.8610 - val_loss: 0.6149 - val_accuracy: 0.7989\n",
      "Epoch 125/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3513 - accuracy: 0.8539 - val_loss: 0.6213 - val_accuracy: 0.8045\n",
      "Epoch 126/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3365 - accuracy: 0.8736 - val_loss: 0.6499 - val_accuracy: 0.8101\n",
      "Epoch 127/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3250 - accuracy: 0.8708 - val_loss: 0.7494 - val_accuracy: 0.7989\n",
      "Epoch 128/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3450 - accuracy: 0.8610 - val_loss: 0.6626 - val_accuracy: 0.7877\n",
      "Epoch 129/400\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.3512 - accuracy: 0.8680 - val_loss: 0.7144 - val_accuracy: 0.7933\n",
      "Epoch 130/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3571 - accuracy: 0.8525 - val_loss: 0.6124 - val_accuracy: 0.7877\n",
      "Epoch 131/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3475 - accuracy: 0.8652 - val_loss: 0.7078 - val_accuracy: 0.7933\n",
      "Epoch 132/400\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.3434 - accuracy: 0.8610 - val_loss: 0.6887 - val_accuracy: 0.8156\n",
      "Epoch 133/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3415 - accuracy: 0.8539 - val_loss: 0.7580 - val_accuracy: 0.8045\n",
      "Epoch 134/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3477 - accuracy: 0.8553 - val_loss: 0.7142 - val_accuracy: 0.8045\n",
      "Epoch 135/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3587 - accuracy: 0.8567 - val_loss: 0.7430 - val_accuracy: 0.7989\n",
      "Epoch 136/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3794 - accuracy: 0.8413 - val_loss: 0.5767 - val_accuracy: 0.7989\n",
      "Epoch 137/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3489 - accuracy: 0.8624 - val_loss: 0.5842 - val_accuracy: 0.8101\n",
      "Epoch 138/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3476 - accuracy: 0.8539 - val_loss: 0.5425 - val_accuracy: 0.8101\n",
      "Epoch 139/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3496 - accuracy: 0.8525 - val_loss: 0.6591 - val_accuracy: 0.8045\n",
      "Epoch 140/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3313 - accuracy: 0.8567 - val_loss: 0.7256 - val_accuracy: 0.7933\n",
      "Epoch 141/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3395 - accuracy: 0.8596 - val_loss: 0.7118 - val_accuracy: 0.8045\n",
      "Epoch 142/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3409 - accuracy: 0.8553 - val_loss: 0.7352 - val_accuracy: 0.7989\n",
      "Epoch 143/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3487 - accuracy: 0.8567 - val_loss: 0.5822 - val_accuracy: 0.8045\n",
      "Epoch 144/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3667 - accuracy: 0.8483 - val_loss: 0.5569 - val_accuracy: 0.8156\n",
      "Epoch 145/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3594 - accuracy: 0.8497 - val_loss: 0.7286 - val_accuracy: 0.8045\n",
      "Epoch 146/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3548 - accuracy: 0.8539 - val_loss: 0.6981 - val_accuracy: 0.8101\n",
      "Epoch 147/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3442 - accuracy: 0.8539 - val_loss: 0.7019 - val_accuracy: 0.8101\n",
      "Epoch 148/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3699 - accuracy: 0.8455 - val_loss: 0.6411 - val_accuracy: 0.7989\n",
      "Epoch 149/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3378 - accuracy: 0.8581 - val_loss: 0.7198 - val_accuracy: 0.8045\n",
      "Epoch 150/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3455 - accuracy: 0.8624 - val_loss: 0.7419 - val_accuracy: 0.8045\n",
      "Epoch 151/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3571 - accuracy: 0.8455 - val_loss: 0.6491 - val_accuracy: 0.7989\n",
      "Epoch 152/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3389 - accuracy: 0.8596 - val_loss: 0.8174 - val_accuracy: 0.8156\n",
      "Epoch 153/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3261 - accuracy: 0.8652 - val_loss: 0.8633 - val_accuracy: 0.8045\n",
      "Epoch 154/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3286 - accuracy: 0.8553 - val_loss: 0.8947 - val_accuracy: 0.7877\n",
      "Epoch 155/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3360 - accuracy: 0.8680 - val_loss: 0.8392 - val_accuracy: 0.7989\n",
      "Epoch 156/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3383 - accuracy: 0.8567 - val_loss: 0.8045 - val_accuracy: 0.7989\n",
      "Epoch 157/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3216 - accuracy: 0.8764 - val_loss: 0.8211 - val_accuracy: 0.8156\n",
      "Epoch 158/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3460 - accuracy: 0.8581 - val_loss: 0.7421 - val_accuracy: 0.8212\n",
      "Epoch 159/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3278 - accuracy: 0.8750 - val_loss: 0.7901 - val_accuracy: 0.8156\n",
      "Epoch 160/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.3624 - accuracy: 0.8553 - val_loss: 0.6027 - val_accuracy: 0.7989\n",
      "Epoch 161/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3524 - accuracy: 0.8624 - val_loss: 0.5683 - val_accuracy: 0.8045\n",
      "Epoch 162/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3295 - accuracy: 0.8553 - val_loss: 0.6467 - val_accuracy: 0.8101\n",
      "Epoch 163/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3487 - accuracy: 0.8539 - val_loss: 0.6290 - val_accuracy: 0.8101\n",
      "Epoch 164/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3418 - accuracy: 0.8539 - val_loss: 0.6988 - val_accuracy: 0.8101\n",
      "Epoch 165/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3200 - accuracy: 0.8638 - val_loss: 0.8467 - val_accuracy: 0.8101\n",
      "Epoch 166/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3487 - accuracy: 0.8567 - val_loss: 0.6107 - val_accuracy: 0.7933\n",
      "Epoch 167/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3397 - accuracy: 0.8624 - val_loss: 0.7037 - val_accuracy: 0.7989\n",
      "Epoch 168/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3223 - accuracy: 0.8722 - val_loss: 0.8700 - val_accuracy: 0.8045\n",
      "Epoch 169/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3154 - accuracy: 0.8722 - val_loss: 0.8479 - val_accuracy: 0.8045\n",
      "Epoch 170/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3223 - accuracy: 0.8722 - val_loss: 0.8358 - val_accuracy: 0.8156\n",
      "Epoch 171/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3580 - accuracy: 0.8624 - val_loss: 0.5794 - val_accuracy: 0.8156\n",
      "Epoch 172/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3352 - accuracy: 0.8652 - val_loss: 0.6812 - val_accuracy: 0.8156\n",
      "Epoch 173/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3428 - accuracy: 0.8722 - val_loss: 0.5999 - val_accuracy: 0.8101\n",
      "Epoch 174/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3326 - accuracy: 0.8652 - val_loss: 0.7628 - val_accuracy: 0.7989\n",
      "Epoch 175/400\n",
      "712/712 [==============================] - 0s 348us/sample - loss: 0.3437 - accuracy: 0.8610 - val_loss: 0.6364 - val_accuracy: 0.8045\n",
      "Epoch 176/400\n",
      "712/712 [==============================] - 0s 288us/sample - loss: 0.3387 - accuracy: 0.8553 - val_loss: 0.6371 - val_accuracy: 0.8156\n",
      "Epoch 177/400\n",
      "712/712 [==============================] - 0s 280us/sample - loss: 0.3294 - accuracy: 0.8694 - val_loss: 0.8892 - val_accuracy: 0.7989\n",
      "Epoch 178/400\n",
      "712/712 [==============================] - 0s 208us/sample - loss: 0.3489 - accuracy: 0.8511 - val_loss: 0.6077 - val_accuracy: 0.8045\n",
      "Epoch 179/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3361 - accuracy: 0.8638 - val_loss: 0.6406 - val_accuracy: 0.8101\n",
      "Epoch 180/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3542 - accuracy: 0.8567 - val_loss: 0.6123 - val_accuracy: 0.8212\n",
      "Epoch 181/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3288 - accuracy: 0.8694 - val_loss: 0.8136 - val_accuracy: 0.8156\n",
      "Epoch 182/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3244 - accuracy: 0.8680 - val_loss: 0.7902 - val_accuracy: 0.8045\n",
      "Epoch 183/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3401 - accuracy: 0.8596 - val_loss: 0.7368 - val_accuracy: 0.8101\n",
      "Epoch 184/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3260 - accuracy: 0.8638 - val_loss: 0.7811 - val_accuracy: 0.8101\n",
      "Epoch 185/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3078 - accuracy: 0.8750 - val_loss: 0.8372 - val_accuracy: 0.8212\n",
      "Epoch 186/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3233 - accuracy: 0.8666 - val_loss: 0.7114 - val_accuracy: 0.8156\n",
      "Epoch 187/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3189 - accuracy: 0.8750 - val_loss: 0.8664 - val_accuracy: 0.8045\n",
      "Epoch 188/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3166 - accuracy: 0.8736 - val_loss: 0.7790 - val_accuracy: 0.8212\n",
      "Epoch 189/400\n",
      "712/712 [==============================] - 0s 192us/sample - loss: 0.3407 - accuracy: 0.8652 - val_loss: 0.8061 - val_accuracy: 0.8212\n",
      "Epoch 190/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.3450 - accuracy: 0.8483 - val_loss: 0.7219 - val_accuracy: 0.8212\n",
      "Epoch 191/400\n",
      "712/712 [==============================] - 0s 212us/sample - loss: 0.3227 - accuracy: 0.8680 - val_loss: 0.7100 - val_accuracy: 0.8045\n",
      "Epoch 192/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3300 - accuracy: 0.8610 - val_loss: 0.7992 - val_accuracy: 0.8156\n",
      "Epoch 193/400\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.3322 - accuracy: 0.8581 - val_loss: 0.7238 - val_accuracy: 0.8156\n",
      "Epoch 194/400\n",
      "712/712 [==============================] - 0s 231us/sample - loss: 0.3299 - accuracy: 0.8553 - val_loss: 0.8153 - val_accuracy: 0.7989\n",
      "Epoch 195/400\n",
      "712/712 [==============================] - 0s 220us/sample - loss: 0.3296 - accuracy: 0.8708 - val_loss: 0.7165 - val_accuracy: 0.8156\n",
      "Epoch 196/400\n",
      "712/712 [==============================] - 0s 225us/sample - loss: 0.3235 - accuracy: 0.8652 - val_loss: 0.7337 - val_accuracy: 0.8101\n",
      "Epoch 197/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3144 - accuracy: 0.8666 - val_loss: 0.8451 - val_accuracy: 0.7989\n",
      "Epoch 198/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3459 - accuracy: 0.8680 - val_loss: 0.6533 - val_accuracy: 0.8045\n",
      "Epoch 199/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3571 - accuracy: 0.8525 - val_loss: 0.6196 - val_accuracy: 0.8212\n",
      "Epoch 200/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3369 - accuracy: 0.8567 - val_loss: 0.7022 - val_accuracy: 0.8212\n",
      "Epoch 201/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3389 - accuracy: 0.8581 - val_loss: 0.7343 - val_accuracy: 0.7933\n",
      "Epoch 202/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3332 - accuracy: 0.8638 - val_loss: 0.8087 - val_accuracy: 0.8101\n",
      "Epoch 203/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3362 - accuracy: 0.8610 - val_loss: 0.7379 - val_accuracy: 0.8156\n",
      "Epoch 204/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3186 - accuracy: 0.8666 - val_loss: 0.9115 - val_accuracy: 0.8101\n",
      "Epoch 205/400\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.3342 - accuracy: 0.8596 - val_loss: 0.7059 - val_accuracy: 0.8268\n",
      "Epoch 206/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3186 - accuracy: 0.8638 - val_loss: 0.7227 - val_accuracy: 0.8101\n",
      "Epoch 207/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3153 - accuracy: 0.8666 - val_loss: 0.8907 - val_accuracy: 0.8212\n",
      "Epoch 208/400\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.3327 - accuracy: 0.8581 - val_loss: 0.8340 - val_accuracy: 0.8212\n",
      "Epoch 209/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3421 - accuracy: 0.8624 - val_loss: 0.6234 - val_accuracy: 0.8156\n",
      "Epoch 210/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3469 - accuracy: 0.8525 - val_loss: 0.6816 - val_accuracy: 0.8212\n",
      "Epoch 211/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3148 - accuracy: 0.8610 - val_loss: 0.7564 - val_accuracy: 0.8101\n",
      "Epoch 212/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.3544 - accuracy: 0.8525 - val_loss: 0.6552 - val_accuracy: 0.8268\n",
      "Epoch 213/400\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.3386 - accuracy: 0.8539 - val_loss: 0.7251 - val_accuracy: 0.8268\n",
      "Epoch 214/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3284 - accuracy: 0.8610 - val_loss: 0.6671 - val_accuracy: 0.8268\n",
      "Epoch 215/400\n",
      "712/712 [==============================] - 0s 295us/sample - loss: 0.3410 - accuracy: 0.8567 - val_loss: 0.7079 - val_accuracy: 0.8268\n",
      "Epoch 216/400\n",
      "712/712 [==============================] - 0s 280us/sample - loss: 0.3322 - accuracy: 0.8708 - val_loss: 0.7334 - val_accuracy: 0.8045\n",
      "Epoch 217/400\n",
      "712/712 [==============================] - 0s 246us/sample - loss: 0.3274 - accuracy: 0.8610 - val_loss: 0.7269 - val_accuracy: 0.8101\n",
      "Epoch 218/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3122 - accuracy: 0.8666 - val_loss: 0.8764 - val_accuracy: 0.8101\n",
      "Epoch 219/400\n",
      "712/712 [==============================] - 0s 201us/sample - loss: 0.3338 - accuracy: 0.8581 - val_loss: 0.5801 - val_accuracy: 0.8212\n",
      "Epoch 220/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3237 - accuracy: 0.8638 - val_loss: 0.7594 - val_accuracy: 0.8324\n",
      "Epoch 221/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3244 - accuracy: 0.8638 - val_loss: 0.7192 - val_accuracy: 0.8156\n",
      "Epoch 222/400\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.3556 - accuracy: 0.8413 - val_loss: 0.6272 - val_accuracy: 0.8436\n",
      "Epoch 223/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3797 - accuracy: 0.8511 - val_loss: 0.4961 - val_accuracy: 0.8212\n",
      "Epoch 224/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3565 - accuracy: 0.8539 - val_loss: 0.5595 - val_accuracy: 0.8101\n",
      "Epoch 225/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3219 - accuracy: 0.8666 - val_loss: 0.6554 - val_accuracy: 0.8101\n",
      "Epoch 226/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3346 - accuracy: 0.8539 - val_loss: 0.7107 - val_accuracy: 0.8045\n",
      "Epoch 227/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3281 - accuracy: 0.8553 - val_loss: 0.7078 - val_accuracy: 0.8156\n",
      "Epoch 228/400\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.3650 - accuracy: 0.8455 - val_loss: 0.5287 - val_accuracy: 0.7933\n",
      "Epoch 229/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3368 - accuracy: 0.8469 - val_loss: 0.5892 - val_accuracy: 0.8212\n",
      "Epoch 230/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3261 - accuracy: 0.8553 - val_loss: 0.6099 - val_accuracy: 0.7989\n",
      "Epoch 231/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3306 - accuracy: 0.8708 - val_loss: 0.6304 - val_accuracy: 0.8045\n",
      "Epoch 232/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3120 - accuracy: 0.8806 - val_loss: 0.7154 - val_accuracy: 0.7933\n",
      "Epoch 233/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3260 - accuracy: 0.8596 - val_loss: 0.6680 - val_accuracy: 0.8156\n",
      "Epoch 234/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3124 - accuracy: 0.8694 - val_loss: 0.7039 - val_accuracy: 0.8268\n",
      "Epoch 235/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3183 - accuracy: 0.8722 - val_loss: 0.7807 - val_accuracy: 0.8212\n",
      "Epoch 236/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3375 - accuracy: 0.8596 - val_loss: 0.6812 - val_accuracy: 0.7821\n",
      "Epoch 237/400\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.3348 - accuracy: 0.8497 - val_loss: 0.7441 - val_accuracy: 0.8101\n",
      "Epoch 238/400\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.3358 - accuracy: 0.8680 - val_loss: 0.6846 - val_accuracy: 0.8045\n",
      "Epoch 239/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.3543 - accuracy: 0.8610 - val_loss: 0.6018 - val_accuracy: 0.8045\n",
      "Epoch 240/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3258 - accuracy: 0.8694 - val_loss: 0.6677 - val_accuracy: 0.8045\n",
      "Epoch 241/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3255 - accuracy: 0.8581 - val_loss: 0.7530 - val_accuracy: 0.8045\n",
      "Epoch 242/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3131 - accuracy: 0.8736 - val_loss: 0.7712 - val_accuracy: 0.8045\n",
      "Epoch 243/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3217 - accuracy: 0.8553 - val_loss: 0.7352 - val_accuracy: 0.7709\n",
      "Epoch 244/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3202 - accuracy: 0.8581 - val_loss: 0.7712 - val_accuracy: 0.8156\n",
      "Epoch 245/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3218 - accuracy: 0.8610 - val_loss: 0.8503 - val_accuracy: 0.8324\n",
      "Epoch 246/400\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.3338 - accuracy: 0.8553 - val_loss: 0.7377 - val_accuracy: 0.8101\n",
      "Epoch 247/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3324 - accuracy: 0.8596 - val_loss: 0.7855 - val_accuracy: 0.8212\n",
      "Epoch 248/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3184 - accuracy: 0.8708 - val_loss: 0.6682 - val_accuracy: 0.8045\n",
      "Epoch 249/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3226 - accuracy: 0.8610 - val_loss: 0.7033 - val_accuracy: 0.8101\n",
      "Epoch 250/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3183 - accuracy: 0.8708 - val_loss: 0.7570 - val_accuracy: 0.8156\n",
      "Epoch 251/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3120 - accuracy: 0.8610 - val_loss: 0.7129 - val_accuracy: 0.8156\n",
      "Epoch 252/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3176 - accuracy: 0.8722 - val_loss: 0.7430 - val_accuracy: 0.8045\n",
      "Epoch 253/400\n",
      "712/712 [==============================] - 0s 223us/sample - loss: 0.3103 - accuracy: 0.8666 - val_loss: 0.8262 - val_accuracy: 0.8212\n",
      "Epoch 254/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3241 - accuracy: 0.8581 - val_loss: 0.8659 - val_accuracy: 0.8268\n",
      "Epoch 255/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3468 - accuracy: 0.8553 - val_loss: 0.6876 - val_accuracy: 0.8212\n",
      "Epoch 256/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3136 - accuracy: 0.8666 - val_loss: 0.8151 - val_accuracy: 0.8156\n",
      "Epoch 257/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3217 - accuracy: 0.8722 - val_loss: 0.7764 - val_accuracy: 0.8101\n",
      "Epoch 258/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3326 - accuracy: 0.8666 - val_loss: 0.8758 - val_accuracy: 0.8045\n",
      "Epoch 259/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3261 - accuracy: 0.8525 - val_loss: 0.7487 - val_accuracy: 0.7933\n",
      "Epoch 260/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3314 - accuracy: 0.8694 - val_loss: 0.4500 - val_accuracy: 0.8212\n",
      "Epoch 285/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3357 - accuracy: 0.8610 - val_loss: 0.4730 - val_accuracy: 0.8045\n",
      "Epoch 286/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3360 - accuracy: 0.8638 - val_loss: 0.4684 - val_accuracy: 0.7989\n",
      "Epoch 287/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3356 - accuracy: 0.8722 - val_loss: 0.4872 - val_accuracy: 0.8045\n",
      "Epoch 288/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3280 - accuracy: 0.8652 - val_loss: 0.4569 - val_accuracy: 0.7989\n",
      "Epoch 289/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3278 - accuracy: 0.8610 - val_loss: 0.4841 - val_accuracy: 0.7989\n",
      "Epoch 290/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3327 - accuracy: 0.8596 - val_loss: 0.4776 - val_accuracy: 0.8101\n",
      "Epoch 291/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3215 - accuracy: 0.8680 - val_loss: 0.4914 - val_accuracy: 0.7989\n",
      "Epoch 292/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.3308 - accuracy: 0.8708 - val_loss: 0.4565 - val_accuracy: 0.8101\n",
      "Epoch 293/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3381 - accuracy: 0.8581 - val_loss: 0.4756 - val_accuracy: 0.8045\n",
      "Epoch 294/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3320 - accuracy: 0.8666 - val_loss: 0.4831 - val_accuracy: 0.7989\n",
      "Epoch 295/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3219 - accuracy: 0.8666 - val_loss: 0.4801 - val_accuracy: 0.8045\n",
      "Epoch 296/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3209 - accuracy: 0.8680 - val_loss: 0.4780 - val_accuracy: 0.8101\n",
      "Epoch 297/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3226 - accuracy: 0.8680 - val_loss: 0.4651 - val_accuracy: 0.8101\n",
      "Epoch 298/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3331 - accuracy: 0.8596 - val_loss: 0.4913 - val_accuracy: 0.7989\n",
      "Epoch 299/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3262 - accuracy: 0.8638 - val_loss: 0.4710 - val_accuracy: 0.8045\n",
      "Epoch 300/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3268 - accuracy: 0.8694 - val_loss: 0.4873 - val_accuracy: 0.8045\n",
      "Epoch 301/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3228 - accuracy: 0.8680 - val_loss: 0.4789 - val_accuracy: 0.8101\n",
      "Epoch 302/400\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.3272 - accuracy: 0.8596 - val_loss: 0.4986 - val_accuracy: 0.8045\n",
      "Epoch 303/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3231 - accuracy: 0.8680 - val_loss: 0.4903 - val_accuracy: 0.8045\n",
      "Epoch 304/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3224 - accuracy: 0.8680 - val_loss: 0.4817 - val_accuracy: 0.8212\n",
      "Epoch 305/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3291 - accuracy: 0.8553 - val_loss: 0.4815 - val_accuracy: 0.8045\n",
      "Epoch 306/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3235 - accuracy: 0.8708 - val_loss: 0.4869 - val_accuracy: 0.8045\n",
      "Epoch 307/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3223 - accuracy: 0.8680 - val_loss: 0.4708 - val_accuracy: 0.8045\n",
      "Epoch 308/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3168 - accuracy: 0.8680 - val_loss: 0.4976 - val_accuracy: 0.8045\n",
      "Epoch 309/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3258 - accuracy: 0.8610 - val_loss: 0.4760 - val_accuracy: 0.8101\n",
      "Epoch 310/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3346 - accuracy: 0.8610 - val_loss: 0.4825 - val_accuracy: 0.8101\n",
      "Epoch 311/400\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.3276 - accuracy: 0.8624 - val_loss: 0.5051 - val_accuracy: 0.8156\n",
      "Epoch 312/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3350 - accuracy: 0.8567 - val_loss: 0.4860 - val_accuracy: 0.8045\n",
      "Epoch 313/400\n",
      "712/712 [==============================] - 0s 207us/sample - loss: 0.3175 - accuracy: 0.8652 - val_loss: 0.4983 - val_accuracy: 0.8045\n",
      "Epoch 314/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3237 - accuracy: 0.8736 - val_loss: 0.4841 - val_accuracy: 0.8101\n",
      "Epoch 315/400\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.3249 - accuracy: 0.8610 - val_loss: 0.5033 - val_accuracy: 0.8101\n",
      "Epoch 316/400\n",
      "712/712 [==============================] - 0s 221us/sample - loss: 0.3194 - accuracy: 0.8666 - val_loss: 0.5070 - val_accuracy: 0.8045\n",
      "Epoch 317/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3192 - accuracy: 0.8596 - val_loss: 0.4746 - val_accuracy: 0.8268\n",
      "Epoch 318/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3180 - accuracy: 0.8652 - val_loss: 0.4852 - val_accuracy: 0.8045\n",
      "Epoch 319/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3245 - accuracy: 0.8722 - val_loss: 0.5062 - val_accuracy: 0.8212\n",
      "Epoch 320/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.3272 - accuracy: 0.8652 - val_loss: 0.4962 - val_accuracy: 0.7989\n",
      "Epoch 321/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3306 - accuracy: 0.8680 - val_loss: 0.5056 - val_accuracy: 0.8045\n",
      "Epoch 322/400\n",
      "712/712 [==============================] - 0s 223us/sample - loss: 0.5511 - accuracy: 0.7205 - val_loss: 0.4694 - val_accuracy: 0.7989\n",
      "Epoch 71/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5353 - accuracy: 0.7556 - val_loss: 0.4686 - val_accuracy: 0.7989\n",
      "Epoch 72/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5415 - accuracy: 0.7472 - val_loss: 0.4664 - val_accuracy: 0.7989\n",
      "Epoch 73/400\n",
      "712/712 [==============================] - 0s 231us/sample - loss: 0.5538 - accuracy: 0.7570 - val_loss: 0.4657 - val_accuracy: 0.7989\n",
      "Epoch 74/400\n",
      "712/712 [==============================] - 0s 228us/sample - loss: 0.5367 - accuracy: 0.7416 - val_loss: 0.4653 - val_accuracy: 0.7989\n",
      "Epoch 75/400\n",
      "712/712 [==============================] - 0s 219us/sample - loss: 0.5335 - accuracy: 0.7570 - val_loss: 0.4640 - val_accuracy: 0.7989\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.5333 - accuracy: 0.7500 - val_loss: 0.4626 - val_accuracy: 0.7989\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5334 - accuracy: 0.7654 - val_loss: 0.4605 - val_accuracy: 0.7989\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5196 - accuracy: 0.7654 - val_loss: 0.4592 - val_accuracy: 0.7989\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5392 - accuracy: 0.7430 - val_loss: 0.4586 - val_accuracy: 0.7989\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5341 - accuracy: 0.7570 - val_loss: 0.4580 - val_accuracy: 0.7989\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5261 - accuracy: 0.7514 - val_loss: 0.4571 - val_accuracy: 0.7989\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.5293 - accuracy: 0.7654 - val_loss: 0.4566 - val_accuracy: 0.7989\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5220 - accuracy: 0.7809 - val_loss: 0.4545 - val_accuracy: 0.7989\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5367 - accuracy: 0.7654 - val_loss: 0.4539 - val_accuracy: 0.7989\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5145 - accuracy: 0.7697 - val_loss: 0.4532 - val_accuracy: 0.7989\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5289 - accuracy: 0.7626 - val_loss: 0.4523 - val_accuracy: 0.8101\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5165 - accuracy: 0.7598 - val_loss: 0.4523 - val_accuracy: 0.8101\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5093 - accuracy: 0.7725 - val_loss: 0.4518 - val_accuracy: 0.8101\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5163 - accuracy: 0.7795 - val_loss: 0.4512 - val_accuracy: 0.8101\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5174 - accuracy: 0.7640 - val_loss: 0.4505 - val_accuracy: 0.8101\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5170 - accuracy: 0.7570 - val_loss: 0.4508 - val_accuracy: 0.8101\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5047 - accuracy: 0.7795 - val_loss: 0.4497 - val_accuracy: 0.8101\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5109 - accuracy: 0.7725 - val_loss: 0.4489 - val_accuracy: 0.8101\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.5177 - accuracy: 0.7598 - val_loss: 0.4477 - val_accuracy: 0.8101\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4924 - accuracy: 0.7809 - val_loss: 0.4471 - val_accuracy: 0.8101\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5241 - accuracy: 0.7669 - val_loss: 0.4475 - val_accuracy: 0.8101\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5054 - accuracy: 0.7753 - val_loss: 0.4469 - val_accuracy: 0.8101\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5042 - accuracy: 0.7907 - val_loss: 0.4463 - val_accuracy: 0.8101\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5156 - accuracy: 0.7823 - val_loss: 0.4455 - val_accuracy: 0.8101\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5042 - accuracy: 0.7669 - val_loss: 0.4450 - val_accuracy: 0.8101\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5202 - accuracy: 0.7725 - val_loss: 0.4451 - val_accuracy: 0.8101\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5017 - accuracy: 0.7837 - val_loss: 0.4456 - val_accuracy: 0.8101\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5352 - accuracy: 0.7683 - val_loss: 0.4463 - val_accuracy: 0.8101\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5137 - accuracy: 0.7767 - val_loss: 0.4459 - val_accuracy: 0.8101\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4997 - accuracy: 0.7795 - val_loss: 0.4458 - val_accuracy: 0.8101\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5367 - accuracy: 0.7640 - val_loss: 0.4462 - val_accuracy: 0.8101\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.3810 - accuracy: 0.8469 - val_loss: 0.4425 - val_accuracy: 0.8324\n",
      "Epoch 336/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3838 - accuracy: 0.8399 - val_loss: 0.4425 - val_accuracy: 0.8324\n",
      "Epoch 337/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3858 - accuracy: 0.8511 - val_loss: 0.4432 - val_accuracy: 0.8324\n",
      "Epoch 338/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3833 - accuracy: 0.8581 - val_loss: 0.4421 - val_accuracy: 0.8324\n",
      "Epoch 339/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3869 - accuracy: 0.8455 - val_loss: 0.4411 - val_accuracy: 0.8324\n",
      "Epoch 340/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3802 - accuracy: 0.8455 - val_loss: 0.4418 - val_accuracy: 0.8324\n",
      "Epoch 341/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3844 - accuracy: 0.8385 - val_loss: 0.4417 - val_accuracy: 0.8268\n",
      "Epoch 342/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3806 - accuracy: 0.8469 - val_loss: 0.4423 - val_accuracy: 0.8268\n",
      "Epoch 343/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3867 - accuracy: 0.8455 - val_loss: 0.4417 - val_accuracy: 0.8324\n",
      "Epoch 344/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3984 - accuracy: 0.8371 - val_loss: 0.4415 - val_accuracy: 0.8156\n",
      "Epoch 345/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3803 - accuracy: 0.8553 - val_loss: 0.4423 - val_accuracy: 0.8268\n",
      "Epoch 346/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3752 - accuracy: 0.8581 - val_loss: 0.4435 - val_accuracy: 0.8324\n",
      "Epoch 347/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3742 - accuracy: 0.8666 - val_loss: 0.4446 - val_accuracy: 0.8324\n",
      "Epoch 348/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3932 - accuracy: 0.8357 - val_loss: 0.4452 - val_accuracy: 0.8324\n",
      "Epoch 349/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3785 - accuracy: 0.8413 - val_loss: 0.4442 - val_accuracy: 0.8268\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3747 - accuracy: 0.8525 - val_loss: 0.4450 - val_accuracy: 0.8324\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3791 - accuracy: 0.8539 - val_loss: 0.4458 - val_accuracy: 0.8324\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3875 - accuracy: 0.8455 - val_loss: 0.4453 - val_accuracy: 0.8324\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3854 - accuracy: 0.8455 - val_loss: 0.4435 - val_accuracy: 0.8268\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3906 - accuracy: 0.8525 - val_loss: 0.4415 - val_accuracy: 0.8268\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3809 - accuracy: 0.8441 - val_loss: 0.4422 - val_accuracy: 0.8268\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3770 - accuracy: 0.8539 - val_loss: 0.4441 - val_accuracy: 0.8268\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3837 - accuracy: 0.8497 - val_loss: 0.4448 - val_accuracy: 0.8324\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4014 - accuracy: 0.8315 - val_loss: 0.4435 - val_accuracy: 0.8324\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3758 - accuracy: 0.8497 - val_loss: 0.4424 - val_accuracy: 0.8324\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3713 - accuracy: 0.8497 - val_loss: 0.4414 - val_accuracy: 0.8324\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3862 - accuracy: 0.8413 - val_loss: 0.4428 - val_accuracy: 0.8324\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3840 - accuracy: 0.8357 - val_loss: 0.4413 - val_accuracy: 0.8324\n",
      "Epoch 363/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3800 - accuracy: 0.8469 - val_loss: 0.4411 - val_accuracy: 0.8324\n",
      "Epoch 364/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3913 - accuracy: 0.8497 - val_loss: 0.4411 - val_accuracy: 0.8324\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.3858 - accuracy: 0.8441 - val_loss: 0.4420 - val_accuracy: 0.8324\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3833 - accuracy: 0.8624 - val_loss: 0.4416 - val_accuracy: 0.8324\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3926 - accuracy: 0.8385 - val_loss: 0.4399 - val_accuracy: 0.8324\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3923 - accuracy: 0.8469 - val_loss: 0.4372 - val_accuracy: 0.8268\n",
      "Epoch 369/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3837 - accuracy: 0.8469 - val_loss: 0.4377 - val_accuracy: 0.8324\n",
      "Epoch 370/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3844 - accuracy: 0.8343 - val_loss: 0.4361 - val_accuracy: 0.8212\n",
      "Epoch 371/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4029 - accuracy: 0.8371 - val_loss: 0.4340 - val_accuracy: 0.8212\n",
      "Epoch 372/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3838 - accuracy: 0.8427 - val_loss: 0.4341 - val_accuracy: 0.8268\n",
      "Epoch 373/400\n",
      "712/712 [==============================] - 0s 246us/sample - loss: 0.4040 - accuracy: 0.8287 - val_loss: 0.4137 - val_accuracy: 0.8212\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 205us/sample - loss: 0.3919 - accuracy: 0.8357 - val_loss: 0.4229 - val_accuracy: 0.8324\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4018 - accuracy: 0.8427 - val_loss: 0.4293 - val_accuracy: 0.8324\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4063 - accuracy: 0.8315 - val_loss: 0.4257 - val_accuracy: 0.8212\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4029 - accuracy: 0.8329 - val_loss: 0.4212 - val_accuracy: 0.8212\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3863 - accuracy: 0.8511 - val_loss: 0.4209 - val_accuracy: 0.8268\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3869 - accuracy: 0.8441 - val_loss: 0.4194 - val_accuracy: 0.8324\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3967 - accuracy: 0.8371 - val_loss: 0.4241 - val_accuracy: 0.8156\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3885 - accuracy: 0.8539 - val_loss: 0.4159 - val_accuracy: 0.8380\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3952 - accuracy: 0.8469 - val_loss: 0.4242 - val_accuracy: 0.8380\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4007 - accuracy: 0.8329 - val_loss: 0.4219 - val_accuracy: 0.8324\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3900 - accuracy: 0.8301 - val_loss: 0.4225 - val_accuracy: 0.8212\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3850 - accuracy: 0.8441 - val_loss: 0.4242 - val_accuracy: 0.8156\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3841 - accuracy: 0.8469 - val_loss: 0.4292 - val_accuracy: 0.8212\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.3774 - accuracy: 0.8525 - val_loss: 0.4309 - val_accuracy: 0.8268\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3826 - accuracy: 0.8525 - val_loss: 0.4307 - val_accuracy: 0.8268\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3773 - accuracy: 0.8413 - val_loss: 0.4281 - val_accuracy: 0.8212\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3913 - accuracy: 0.8455 - val_loss: 0.4222 - val_accuracy: 0.8324\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3862 - accuracy: 0.8413 - val_loss: 0.4218 - val_accuracy: 0.8324\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3759 - accuracy: 0.8581 - val_loss: 0.4287 - val_accuracy: 0.8212\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3757 - accuracy: 0.8483 - val_loss: 0.4298 - val_accuracy: 0.8268\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3668 - accuracy: 0.8511 - val_loss: 0.4302 - val_accuracy: 0.8324\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3679 - accuracy: 0.8427 - val_loss: 0.4421 - val_accuracy: 0.8156\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3788 - accuracy: 0.8455 - val_loss: 0.4295 - val_accuracy: 0.8212\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3846 - accuracy: 0.8483 - val_loss: 0.4263 - val_accuracy: 0.8268\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3883 - accuracy: 0.8497 - val_loss: 0.4321 - val_accuracy: 0.8268\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3784 - accuracy: 0.8399 - val_loss: 0.4301 - val_accuracy: 0.8268\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3771 - accuracy: 0.8427 - val_loss: 0.4265 - val_accuracy: 0.8268\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3734 - accuracy: 0.8483 - val_loss: 0.4276 - val_accuracy: 0.8156\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3826 - accuracy: 0.8455 - val_loss: 0.4312 - val_accuracy: 0.8156\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3732 - accuracy: 0.8469 - val_loss: 0.4301 - val_accuracy: 0.8156\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3854 - accuracy: 0.8427 - val_loss: 0.4298 - val_accuracy: 0.8212\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3726 - accuracy: 0.8525 - val_loss: 0.4316 - val_accuracy: 0.8212\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3585 - accuracy: 0.8596 - val_loss: 0.4365 - val_accuracy: 0.8212\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3854 - accuracy: 0.8539 - val_loss: 0.4396 - val_accuracy: 0.8156\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3709 - accuracy: 0.8455 - val_loss: 0.4325 - val_accuracy: 0.8212\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3754 - accuracy: 0.8511 - val_loss: 0.4345 - val_accuracy: 0.8156\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3855 - accuracy: 0.8301 - val_loss: 0.4291 - val_accuracy: 0.8156\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3738 - accuracy: 0.8624 - val_loss: 0.4628 - val_accuracy: 0.8101\n",
      "Epoch 332/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3535 - accuracy: 0.8596 - val_loss: 0.4677 - val_accuracy: 0.8045\n",
      "Epoch 333/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3659 - accuracy: 0.8539 - val_loss: 0.4616 - val_accuracy: 0.8212\n",
      "Epoch 334/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3778 - accuracy: 0.8413 - val_loss: 0.4459 - val_accuracy: 0.8101\n",
      "Epoch 335/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3687 - accuracy: 0.8596 - val_loss: 0.4518 - val_accuracy: 0.8045\n",
      "Epoch 336/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3617 - accuracy: 0.8553 - val_loss: 0.4762 - val_accuracy: 0.8045\n",
      "Epoch 337/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3699 - accuracy: 0.8455 - val_loss: 0.4586 - val_accuracy: 0.8045\n",
      "Epoch 338/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3556 - accuracy: 0.8497 - val_loss: 0.4620 - val_accuracy: 0.8045\n",
      "Epoch 339/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3522 - accuracy: 0.8610 - val_loss: 0.4701 - val_accuracy: 0.8156\n",
      "Epoch 340/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3774 - accuracy: 0.8525 - val_loss: 0.4424 - val_accuracy: 0.8101\n",
      "Epoch 341/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3725 - accuracy: 0.8427 - val_loss: 0.4754 - val_accuracy: 0.8045\n",
      "Epoch 342/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3830 - accuracy: 0.8455 - val_loss: 0.4549 - val_accuracy: 0.7989\n",
      "Epoch 343/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3588 - accuracy: 0.8455 - val_loss: 0.4685 - val_accuracy: 0.8045\n",
      "Epoch 344/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3597 - accuracy: 0.8483 - val_loss: 0.4802 - val_accuracy: 0.8101\n",
      "Epoch 345/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3635 - accuracy: 0.8638 - val_loss: 0.4662 - val_accuracy: 0.8045\n",
      "Epoch 346/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3687 - accuracy: 0.8469 - val_loss: 0.4497 - val_accuracy: 0.7933\n",
      "Epoch 347/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3698 - accuracy: 0.8511 - val_loss: 0.4720 - val_accuracy: 0.7989\n",
      "Epoch 348/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3862 - accuracy: 0.8399 - val_loss: 0.4434 - val_accuracy: 0.8045\n",
      "Epoch 349/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3686 - accuracy: 0.8511 - val_loss: 0.4702 - val_accuracy: 0.7989\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3533 - accuracy: 0.8596 - val_loss: 0.4889 - val_accuracy: 0.8045\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3582 - accuracy: 0.8539 - val_loss: 0.4710 - val_accuracy: 0.8045\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3730 - accuracy: 0.8413 - val_loss: 0.4559 - val_accuracy: 0.7989\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3746 - accuracy: 0.8483 - val_loss: 0.4603 - val_accuracy: 0.8045\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3718 - accuracy: 0.8483 - val_loss: 0.4508 - val_accuracy: 0.7989\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3573 - accuracy: 0.8483 - val_loss: 0.4640 - val_accuracy: 0.8045\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3701 - accuracy: 0.8581 - val_loss: 0.4674 - val_accuracy: 0.8101\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3635 - accuracy: 0.8371 - val_loss: 0.4711 - val_accuracy: 0.8045\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3622 - accuracy: 0.8553 - val_loss: 0.4683 - val_accuracy: 0.8045\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3774 - accuracy: 0.8525 - val_loss: 0.4638 - val_accuracy: 0.8045\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3694 - accuracy: 0.8399 - val_loss: 0.4899 - val_accuracy: 0.7989\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.3610 - accuracy: 0.8497 - val_loss: 0.4746 - val_accuracy: 0.7989\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3672 - accuracy: 0.8455 - val_loss: 0.4529 - val_accuracy: 0.8045\n",
      "Epoch 363/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3557 - accuracy: 0.8539 - val_loss: 0.4699 - val_accuracy: 0.8045\n",
      "Epoch 364/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3601 - accuracy: 0.8610 - val_loss: 0.4708 - val_accuracy: 0.8045\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3694 - accuracy: 0.8455 - val_loss: 0.4681 - val_accuracy: 0.8045\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3803 - accuracy: 0.8441 - val_loss: 0.4595 - val_accuracy: 0.8101\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3618 - accuracy: 0.8638 - val_loss: 0.4882 - val_accuracy: 0.7989\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3694 - accuracy: 0.8624 - val_loss: 0.4722 - val_accuracy: 0.8045\n",
      "Epoch 369/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3819 - accuracy: 0.8469 - val_loss: 0.4652 - val_accuracy: 0.7989\n",
      "Epoch 370/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3689 - accuracy: 0.8497 - val_loss: 0.4905 - val_accuracy: 0.8045\n",
      "Epoch 371/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3781 - accuracy: 0.8553 - val_loss: 0.4378 - val_accuracy: 0.8045\n",
      "Epoch 372/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3640 - accuracy: 0.8525 - val_loss: 0.4782 - val_accuracy: 0.7989\n",
      "Epoch 373/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3772 - accuracy: 0.8469 - val_loss: 0.4680 - val_accuracy: 0.7989\n",
      "Epoch 374/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3675 - accuracy: 0.8483 - val_loss: 0.4690 - val_accuracy: 0.8045\n",
      "Epoch 375/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3563 - accuracy: 0.8553 - val_loss: 0.4782 - val_accuracy: 0.7933\n",
      "Epoch 376/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3840 - accuracy: 0.8413 - val_loss: 0.4517 - val_accuracy: 0.7989\n",
      "Epoch 377/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3689 - accuracy: 0.8427 - val_loss: 0.4729 - val_accuracy: 0.8045\n",
      "Epoch 378/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3774 - accuracy: 0.8399 - val_loss: 0.4600 - val_accuracy: 0.8101\n",
      "Epoch 379/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3717 - accuracy: 0.8441 - val_loss: 0.4615 - val_accuracy: 0.7989\n",
      "Epoch 380/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3687 - accuracy: 0.8455 - val_loss: 0.4806 - val_accuracy: 0.7989\n",
      "Epoch 381/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3704 - accuracy: 0.8511 - val_loss: 0.4997 - val_accuracy: 0.7989\n",
      "Epoch 382/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3637 - accuracy: 0.8469 - val_loss: 0.4657 - val_accuracy: 0.8101\n",
      "Epoch 383/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3646 - accuracy: 0.8371 - val_loss: 0.4770 - val_accuracy: 0.7989\n",
      "Epoch 384/400\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.3730 - accuracy: 0.8399 - val_loss: 0.4689 - val_accuracy: 0.8101\n",
      "Epoch 385/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3672 - accuracy: 0.8357 - val_loss: 0.4693 - val_accuracy: 0.8045\n",
      "Epoch 386/400\n",
      "712/712 [==============================] - 0s 202us/sample - loss: 0.3542 - accuracy: 0.8441 - val_loss: 0.4837 - val_accuracy: 0.8045\n",
      "Epoch 387/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3692 - accuracy: 0.8511 - val_loss: 0.4534 - val_accuracy: 0.8101\n",
      "Epoch 388/400\n",
      "712/712 [==============================] - 0s 214us/sample - loss: 0.3668 - accuracy: 0.8371 - val_loss: 0.4563 - val_accuracy: 0.8101\n",
      "Epoch 389/400\n",
      "712/712 [==============================] - 0s 244us/sample - loss: 0.3635 - accuracy: 0.8553 - val_loss: 0.4707 - val_accuracy: 0.7989\n",
      "Epoch 390/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3614 - accuracy: 0.8553 - val_loss: 0.4563 - val_accuracy: 0.8101\n",
      "Epoch 391/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3623 - accuracy: 0.8455 - val_loss: 0.4670 - val_accuracy: 0.7989\n",
      "Epoch 392/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3667 - accuracy: 0.8497 - val_loss: 0.4629 - val_accuracy: 0.8101\n",
      "Epoch 393/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3728 - accuracy: 0.8371 - val_loss: 0.4622 - val_accuracy: 0.7989\n",
      "Epoch 394/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3838 - accuracy: 0.8455 - val_loss: 0.4656 - val_accuracy: 0.8101\n",
      "Epoch 395/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3546 - accuracy: 0.8638 - val_loss: 0.4722 - val_accuracy: 0.7877\n",
      "Epoch 396/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3699 - accuracy: 0.8553 - val_loss: 0.4584 - val_accuracy: 0.8045\n",
      "Epoch 397/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3694 - accuracy: 0.8497 - val_loss: 0.4881 - val_accuracy: 0.7989\n",
      "Epoch 398/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3625 - accuracy: 0.8441 - val_loss: 0.4513 - val_accuracy: 0.8101\n",
      "Epoch 399/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3638 - accuracy: 0.8427 - val_loss: 0.4712 - val_accuracy: 0.7933\n",
      "Epoch 400/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3660 - accuracy: 0.8539 - val_loss: 0.4651 - val_accuracy: 0.8101\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/400\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.6730 - accuracy: 0.6067 - val_loss: 0.6760 - val_accuracy: 0.5866\n",
      "Epoch 2/400\n",
      "712/712 [==============================] - 0s 231us/sample - loss: 0.6608 - accuracy: 0.6053 - val_loss: 0.6466 - val_accuracy: 0.5866\n",
      "Epoch 3/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6445 - accuracy: 0.6292 - val_loss: 0.5601 - val_accuracy: 0.7151\n",
      "Epoch 4/400\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.5666 - accuracy: 0.7163 - val_loss: 0.4738 - val_accuracy: 0.7709\n",
      "Epoch 5/400\n",
      "712/712 [==============================] - 0s 212us/sample - loss: 0.5241 - accuracy: 0.7556 - val_loss: 0.4378 - val_accuracy: 0.7989\n",
      "Epoch 6/400\n",
      "712/712 [==============================] - 0s 256us/sample - loss: 0.4768 - accuracy: 0.7978 - val_loss: 0.4263 - val_accuracy: 0.8212\n",
      "Epoch 7/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.4738 - accuracy: 0.8104 - val_loss: 0.4718 - val_accuracy: 0.8045\n",
      "Epoch 8/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4758 - accuracy: 0.8034 - val_loss: 0.4357 - val_accuracy: 0.8101\n",
      "Epoch 9/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4666 - accuracy: 0.8174 - val_loss: 0.4346 - val_accuracy: 0.8156\n",
      "Epoch 10/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4744 - accuracy: 0.8104 - val_loss: 0.4415 - val_accuracy: 0.8045\n",
      "Epoch 11/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4471 - accuracy: 0.8216 - val_loss: 0.4435 - val_accuracy: 0.8101\n",
      "Epoch 12/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4574 - accuracy: 0.8202 - val_loss: 0.4373 - val_accuracy: 0.8101\n",
      "Epoch 13/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4536 - accuracy: 0.8258 - val_loss: 0.4377 - val_accuracy: 0.8212\n",
      "Epoch 14/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4424 - accuracy: 0.8202 - val_loss: 0.4376 - val_accuracy: 0.8101\n",
      "Epoch 15/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4359 - accuracy: 0.8230 - val_loss: 0.4428 - val_accuracy: 0.8212\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4344 - accuracy: 0.8188 - val_loss: 0.4451 - val_accuracy: 0.7877\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4442 - accuracy: 0.8202 - val_loss: 0.4468 - val_accuracy: 0.8212\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4218 - accuracy: 0.8258 - val_loss: 0.4430 - val_accuracy: 0.8045\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4293 - accuracy: 0.8272 - val_loss: 0.4508 - val_accuracy: 0.8156\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4323 - accuracy: 0.8301 - val_loss: 0.4329 - val_accuracy: 0.8268\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4360 - accuracy: 0.8315 - val_loss: 0.4316 - val_accuracy: 0.8212\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4223 - accuracy: 0.8371 - val_loss: 0.4325 - val_accuracy: 0.8380\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4502 - accuracy: 0.8343 - val_loss: 0.4372 - val_accuracy: 0.8268\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4308 - accuracy: 0.8244 - val_loss: 0.4268 - val_accuracy: 0.8324\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4262 - accuracy: 0.8301 - val_loss: 0.4328 - val_accuracy: 0.8212\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4313 - accuracy: 0.8301 - val_loss: 0.4375 - val_accuracy: 0.8268\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4328 - accuracy: 0.8371 - val_loss: 0.4265 - val_accuracy: 0.8268\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4250 - accuracy: 0.8188 - val_loss: 0.4381 - val_accuracy: 0.8156\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4121 - accuracy: 0.8272 - val_loss: 0.4283 - val_accuracy: 0.8324\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4302 - accuracy: 0.8202 - val_loss: 0.4332 - val_accuracy: 0.8268\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4067 - accuracy: 0.8399 - val_loss: 0.4358 - val_accuracy: 0.8324\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4295 - accuracy: 0.8315 - val_loss: 0.4305 - val_accuracy: 0.8212\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4195 - accuracy: 0.8343 - val_loss: 0.4442 - val_accuracy: 0.8212\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4284 - accuracy: 0.8188 - val_loss: 0.4316 - val_accuracy: 0.8268\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4251 - accuracy: 0.8216 - val_loss: 0.4314 - val_accuracy: 0.8212\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4173 - accuracy: 0.8343 - val_loss: 0.4358 - val_accuracy: 0.8156\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4285 - accuracy: 0.8230 - val_loss: 0.4372 - val_accuracy: 0.8212\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4192 - accuracy: 0.8329 - val_loss: 0.4355 - val_accuracy: 0.8212\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4109 - accuracy: 0.8315 - val_loss: 0.4291 - val_accuracy: 0.8212\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4037 - accuracy: 0.8343 - val_loss: 0.4538 - val_accuracy: 0.8268\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4157 - accuracy: 0.8272 - val_loss: 0.4259 - val_accuracy: 0.8212\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4133 - accuracy: 0.8202 - val_loss: 0.4297 - val_accuracy: 0.8212\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4121 - accuracy: 0.8301 - val_loss: 0.4314 - val_accuracy: 0.8268\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4027 - accuracy: 0.8399 - val_loss: 0.4323 - val_accuracy: 0.8156\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3962 - accuracy: 0.8427 - val_loss: 0.4467 - val_accuracy: 0.8268\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4124 - accuracy: 0.8371 - val_loss: 0.4321 - val_accuracy: 0.8101\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4019 - accuracy: 0.8357 - val_loss: 0.4381 - val_accuracy: 0.8212\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4031 - accuracy: 0.8385 - val_loss: 0.4383 - val_accuracy: 0.8268\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3939 - accuracy: 0.8329 - val_loss: 0.4366 - val_accuracy: 0.8156\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4223 - accuracy: 0.8174 - val_loss: 0.4349 - val_accuracy: 0.8324\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4182 - accuracy: 0.8258 - val_loss: 0.4306 - val_accuracy: 0.8212\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4069 - accuracy: 0.8329 - val_loss: 0.4463 - val_accuracy: 0.8212\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4040 - accuracy: 0.8329 - val_loss: 0.4341 - val_accuracy: 0.8156\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4105 - accuracy: 0.8301 - val_loss: 0.4425 - val_accuracy: 0.8324\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4112 - accuracy: 0.8399 - val_loss: 0.4329 - val_accuracy: 0.8101\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4058 - accuracy: 0.8315 - val_loss: 0.4397 - val_accuracy: 0.8268\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4045 - accuracy: 0.8385 - val_loss: 0.4323 - val_accuracy: 0.8324\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4040 - accuracy: 0.8357 - val_loss: 0.4241 - val_accuracy: 0.8101\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4050 - accuracy: 0.8371 - val_loss: 0.4309 - val_accuracy: 0.8380\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4076 - accuracy: 0.8329 - val_loss: 0.4238 - val_accuracy: 0.8324\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3966 - accuracy: 0.8371 - val_loss: 0.4273 - val_accuracy: 0.8268\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3944 - accuracy: 0.8315 - val_loss: 0.4324 - val_accuracy: 0.8324\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4108 - accuracy: 0.8413 - val_loss: 0.4252 - val_accuracy: 0.8212\n",
      "Epoch 64/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4203 - accuracy: 0.8287 - val_loss: 0.4357 - val_accuracy: 0.8212\n",
      "Epoch 65/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4058 - accuracy: 0.8258 - val_loss: 0.4376 - val_accuracy: 0.8156\n",
      "Epoch 66/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4050 - accuracy: 0.8357 - val_loss: 0.4329 - val_accuracy: 0.8268\n",
      "Epoch 67/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3982 - accuracy: 0.8371 - val_loss: 0.4351 - val_accuracy: 0.8212\n",
      "Epoch 68/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3968 - accuracy: 0.8441 - val_loss: 0.4322 - val_accuracy: 0.8324\n",
      "Epoch 69/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4084 - accuracy: 0.8230 - val_loss: 0.4276 - val_accuracy: 0.8212\n",
      "Epoch 70/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3926 - accuracy: 0.8343 - val_loss: 0.4469 - val_accuracy: 0.8324\n",
      "Epoch 71/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3947 - accuracy: 0.8427 - val_loss: 0.4312 - val_accuracy: 0.8212\n",
      "Epoch 72/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4050 - accuracy: 0.8315 - val_loss: 0.4369 - val_accuracy: 0.8324\n",
      "Epoch 73/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3957 - accuracy: 0.8385 - val_loss: 0.4196 - val_accuracy: 0.8324\n",
      "Epoch 74/400\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.4085 - accuracy: 0.8329 - val_loss: 0.4309 - val_accuracy: 0.8268\n",
      "Epoch 75/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4249 - accuracy: 0.8062 - val_loss: 0.4378 - val_accuracy: 0.8212\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3869 - accuracy: 0.8357 - val_loss: 0.4537 - val_accuracy: 0.8156\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.4018 - accuracy: 0.8399 - val_loss: 0.4385 - val_accuracy: 0.8268\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3951 - accuracy: 0.8455 - val_loss: 0.4362 - val_accuracy: 0.8101\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4013 - accuracy: 0.8301 - val_loss: 0.4434 - val_accuracy: 0.8324\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3978 - accuracy: 0.8525 - val_loss: 0.4363 - val_accuracy: 0.8156\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4111 - accuracy: 0.8287 - val_loss: 0.4449 - val_accuracy: 0.8212\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3992 - accuracy: 0.8343 - val_loss: 0.4374 - val_accuracy: 0.8156\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3885 - accuracy: 0.8343 - val_loss: 0.4407 - val_accuracy: 0.8156\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4090 - accuracy: 0.8301 - val_loss: 0.4271 - val_accuracy: 0.8212\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4201 - accuracy: 0.8357 - val_loss: 0.4409 - val_accuracy: 0.8212\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4001 - accuracy: 0.8272 - val_loss: 0.4404 - val_accuracy: 0.8156\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3942 - accuracy: 0.8343 - val_loss: 0.4412 - val_accuracy: 0.8156\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3971 - accuracy: 0.8329 - val_loss: 0.4436 - val_accuracy: 0.8268\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3806 - accuracy: 0.8399 - val_loss: 0.4468 - val_accuracy: 0.8156\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3799 - accuracy: 0.8385 - val_loss: 0.4501 - val_accuracy: 0.8212\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3955 - accuracy: 0.8301 - val_loss: 0.4355 - val_accuracy: 0.8101\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3980 - accuracy: 0.8371 - val_loss: 0.4377 - val_accuracy: 0.8101\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3892 - accuracy: 0.8399 - val_loss: 0.4545 - val_accuracy: 0.8212\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3899 - accuracy: 0.8385 - val_loss: 0.4448 - val_accuracy: 0.8156\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3951 - accuracy: 0.8301 - val_loss: 0.4345 - val_accuracy: 0.8156\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3960 - accuracy: 0.8441 - val_loss: 0.4366 - val_accuracy: 0.8101\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3947 - accuracy: 0.8399 - val_loss: 0.4450 - val_accuracy: 0.8212\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4001 - accuracy: 0.8427 - val_loss: 0.4358 - val_accuracy: 0.8045\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3858 - accuracy: 0.8469 - val_loss: 0.4564 - val_accuracy: 0.8101\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3971 - accuracy: 0.8202 - val_loss: 0.4515 - val_accuracy: 0.8156\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3908 - accuracy: 0.8343 - val_loss: 0.4423 - val_accuracy: 0.8156\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3844 - accuracy: 0.8385 - val_loss: 0.4267 - val_accuracy: 0.8212\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.3927 - accuracy: 0.8301 - val_loss: 0.4396 - val_accuracy: 0.8212\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3912 - accuracy: 0.8497 - val_loss: 0.4282 - val_accuracy: 0.8156\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4081 - accuracy: 0.8371 - val_loss: 0.4438 - val_accuracy: 0.8156\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 210us/sample - loss: 0.4038 - accuracy: 0.8385 - val_loss: 0.4354 - val_accuracy: 0.8101\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.3871 - accuracy: 0.8413 - val_loss: 0.4335 - val_accuracy: 0.8156\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.3863 - accuracy: 0.8343 - val_loss: 0.4364 - val_accuracy: 0.8268\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 239us/sample - loss: 0.3921 - accuracy: 0.8399 - val_loss: 0.4504 - val_accuracy: 0.8101\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.3883 - accuracy: 0.8483 - val_loss: 0.4375 - val_accuracy: 0.8101\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3887 - accuracy: 0.8483 - val_loss: 0.4314 - val_accuracy: 0.8156\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3949 - accuracy: 0.8427 - val_loss: 0.4330 - val_accuracy: 0.8156\n",
      "Epoch 113/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3888 - accuracy: 0.8413 - val_loss: 0.4500 - val_accuracy: 0.8324\n",
      "Epoch 114/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3893 - accuracy: 0.8469 - val_loss: 0.4333 - val_accuracy: 0.8101\n",
      "Epoch 115/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3827 - accuracy: 0.8455 - val_loss: 0.4346 - val_accuracy: 0.8212\n",
      "Epoch 116/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3828 - accuracy: 0.8483 - val_loss: 0.4663 - val_accuracy: 0.8045\n",
      "Epoch 117/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.3897 - accuracy: 0.8385 - val_loss: 0.4413 - val_accuracy: 0.8101\n",
      "Epoch 118/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3913 - accuracy: 0.8371 - val_loss: 0.4557 - val_accuracy: 0.8101\n",
      "Epoch 119/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3856 - accuracy: 0.8413 - val_loss: 0.4264 - val_accuracy: 0.8212\n",
      "Epoch 120/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3948 - accuracy: 0.8385 - val_loss: 0.4556 - val_accuracy: 0.8156\n",
      "Epoch 121/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4076 - accuracy: 0.8230 - val_loss: 0.4102 - val_accuracy: 0.8268\n",
      "Epoch 149/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4109 - accuracy: 0.8230 - val_loss: 0.4172 - val_accuracy: 0.8324\n",
      "Epoch 150/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4136 - accuracy: 0.8188 - val_loss: 0.4209 - val_accuracy: 0.8324\n",
      "Epoch 151/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4204 - accuracy: 0.8090 - val_loss: 0.4215 - val_accuracy: 0.8380\n",
      "Epoch 152/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4090 - accuracy: 0.8160 - val_loss: 0.4384 - val_accuracy: 0.8268\n",
      "Epoch 153/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4081 - accuracy: 0.8258 - val_loss: 0.4294 - val_accuracy: 0.8436\n",
      "Epoch 154/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4391 - accuracy: 0.8315 - val_loss: 0.4432 - val_accuracy: 0.8268\n",
      "Epoch 155/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4404 - accuracy: 0.8272 - val_loss: 0.4422 - val_accuracy: 0.8268\n",
      "Epoch 156/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4297 - accuracy: 0.8315 - val_loss: 0.4496 - val_accuracy: 0.8156\n",
      "Epoch 157/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4206 - accuracy: 0.8371 - val_loss: 0.4424 - val_accuracy: 0.8268\n",
      "Epoch 158/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4192 - accuracy: 0.8287 - val_loss: 0.4459 - val_accuracy: 0.8268\n",
      "Epoch 159/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3938 - accuracy: 0.8427 - val_loss: 0.4299 - val_accuracy: 0.8212\n",
      "Epoch 160/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4222 - accuracy: 0.8258 - val_loss: 0.4144 - val_accuracy: 0.8268\n",
      "Epoch 161/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3949 - accuracy: 0.8441 - val_loss: 0.4188 - val_accuracy: 0.8268\n",
      "Epoch 162/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3922 - accuracy: 0.8399 - val_loss: 0.4349 - val_accuracy: 0.8212\n",
      "Epoch 163/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4189 - accuracy: 0.8160 - val_loss: 0.4245 - val_accuracy: 0.8212\n",
      "Epoch 164/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4077 - accuracy: 0.8329 - val_loss: 0.4175 - val_accuracy: 0.8156\n",
      "Epoch 165/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4052 - accuracy: 0.8272 - val_loss: 0.4403 - val_accuracy: 0.8101\n",
      "Epoch 166/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4050 - accuracy: 0.8272 - val_loss: 0.4404 - val_accuracy: 0.8212\n",
      "Epoch 167/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4127 - accuracy: 0.8146 - val_loss: 0.4206 - val_accuracy: 0.8156\n",
      "Epoch 168/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.3993 - accuracy: 0.8230 - val_loss: 0.4407 - val_accuracy: 0.8268\n",
      "Epoch 169/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4116 - accuracy: 0.8427 - val_loss: 0.4350 - val_accuracy: 0.8268\n",
      "Epoch 170/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4276 - accuracy: 0.8146 - val_loss: 0.4246 - val_accuracy: 0.8268\n",
      "Epoch 171/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3863 - accuracy: 0.8497 - val_loss: 0.4228 - val_accuracy: 0.8156\n",
      "Epoch 172/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3887 - accuracy: 0.8385 - val_loss: 0.4208 - val_accuracy: 0.8212\n",
      "Epoch 173/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4293 - accuracy: 0.8048 - val_loss: 0.4235 - val_accuracy: 0.8268\n",
      "Epoch 174/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4262 - accuracy: 0.8034 - val_loss: 0.4121 - val_accuracy: 0.8380\n",
      "Epoch 175/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4089 - accuracy: 0.8132 - val_loss: 0.4163 - val_accuracy: 0.8212\n",
      "Epoch 176/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3897 - accuracy: 0.8230 - val_loss: 0.4201 - val_accuracy: 0.8212\n",
      "Epoch 177/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4020 - accuracy: 0.8174 - val_loss: 0.4191 - val_accuracy: 0.8101\n",
      "Epoch 178/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4017 - accuracy: 0.8174 - val_loss: 0.4269 - val_accuracy: 0.8212\n",
      "Epoch 179/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4028 - accuracy: 0.8174 - val_loss: 0.4206 - val_accuracy: 0.8212\n",
      "Epoch 180/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4119 - accuracy: 0.8034 - val_loss: 0.4436 - val_accuracy: 0.8156\n",
      "Epoch 181/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4110 - accuracy: 0.8244 - val_loss: 0.4430 - val_accuracy: 0.8212\n",
      "Epoch 182/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3920 - accuracy: 0.8216 - val_loss: 0.4521 - val_accuracy: 0.8212\n",
      "Epoch 183/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3930 - accuracy: 0.8244 - val_loss: 0.4467 - val_accuracy: 0.8324\n",
      "Epoch 184/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4136 - accuracy: 0.8343 - val_loss: 0.4676 - val_accuracy: 0.8045\n",
      "Epoch 185/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4170 - accuracy: 0.8399 - val_loss: 0.4693 - val_accuracy: 0.8268\n",
      "Epoch 186/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4711 - accuracy: 0.8132 - val_loss: 0.4271 - val_accuracy: 0.8212\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4631 - accuracy: 0.8146 - val_loss: 0.4271 - val_accuracy: 0.8212\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4537 - accuracy: 0.8244 - val_loss: 0.4270 - val_accuracy: 0.8156\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4515 - accuracy: 0.8090 - val_loss: 0.4268 - val_accuracy: 0.8156\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4690 - accuracy: 0.8048 - val_loss: 0.4266 - val_accuracy: 0.8156\n",
      "Epoch 369/400\n",
      "712/712 [==============================] - 0s 244us/sample - loss: 0.4774 - accuracy: 0.7865 - val_loss: 0.4266 - val_accuracy: 0.8212\n",
      "Epoch 370/400\n",
      "712/712 [==============================] - 0s 261us/sample - loss: 0.4648 - accuracy: 0.8006 - val_loss: 0.4265 - val_accuracy: 0.8212\n",
      "Epoch 371/400\n",
      "712/712 [==============================] - 0s 253us/sample - loss: 0.4815 - accuracy: 0.7935 - val_loss: 0.4265 - val_accuracy: 0.8212\n",
      "Epoch 372/400\n",
      "712/712 [==============================] - 0s 338us/sample - loss: 0.4580 - accuracy: 0.8230 - val_loss: 0.4264 - val_accuracy: 0.8212\n",
      "Epoch 373/400\n",
      "712/712 [==============================] - 0s 206us/sample - loss: 0.4816 - accuracy: 0.8020 - val_loss: 0.4264 - val_accuracy: 0.8212\n",
      "Epoch 374/400\n",
      "712/712 [==============================] - 0s 250us/sample - loss: 0.4544 - accuracy: 0.8090 - val_loss: 0.4263 - val_accuracy: 0.8212\n",
      "Epoch 375/400\n",
      "712/712 [==============================] - 0s 197us/sample - loss: 0.4669 - accuracy: 0.8062 - val_loss: 0.4263 - val_accuracy: 0.8212\n",
      "Epoch 376/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4670 - accuracy: 0.8020 - val_loss: 0.4264 - val_accuracy: 0.8212\n",
      "Epoch 377/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4733 - accuracy: 0.7978 - val_loss: 0.4264 - val_accuracy: 0.8212\n",
      "Epoch 378/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4700 - accuracy: 0.7837 - val_loss: 0.4264 - val_accuracy: 0.8212\n",
      "Epoch 379/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4732 - accuracy: 0.7978 - val_loss: 0.4263 - val_accuracy: 0.8212\n",
      "Epoch 380/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4644 - accuracy: 0.8090 - val_loss: 0.4262 - val_accuracy: 0.8156\n",
      "Epoch 381/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4813 - accuracy: 0.8076 - val_loss: 0.4261 - val_accuracy: 0.8156\n",
      "Epoch 382/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4654 - accuracy: 0.8146 - val_loss: 0.4261 - val_accuracy: 0.8156\n",
      "Epoch 383/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4618 - accuracy: 0.8048 - val_loss: 0.4260 - val_accuracy: 0.8156\n",
      "Epoch 384/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4745 - accuracy: 0.8076 - val_loss: 0.4259 - val_accuracy: 0.8156\n",
      "Epoch 385/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4793 - accuracy: 0.7921 - val_loss: 0.4258 - val_accuracy: 0.8156\n",
      "Epoch 386/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4701 - accuracy: 0.8132 - val_loss: 0.4258 - val_accuracy: 0.8212\n",
      "Epoch 387/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4475 - accuracy: 0.8272 - val_loss: 0.4257 - val_accuracy: 0.8212\n",
      "Epoch 388/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4736 - accuracy: 0.7992 - val_loss: 0.4257 - val_accuracy: 0.8156\n",
      "Epoch 389/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4702 - accuracy: 0.7978 - val_loss: 0.4257 - val_accuracy: 0.8212\n",
      "Epoch 390/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4499 - accuracy: 0.8301 - val_loss: 0.4257 - val_accuracy: 0.8212\n",
      "Epoch 391/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4837 - accuracy: 0.7992 - val_loss: 0.4257 - val_accuracy: 0.8212\n",
      "Epoch 392/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4559 - accuracy: 0.8132 - val_loss: 0.4257 - val_accuracy: 0.8212\n",
      "Epoch 393/400\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.4584 - accuracy: 0.8118 - val_loss: 0.4256 - val_accuracy: 0.8212\n",
      "Epoch 394/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4850 - accuracy: 0.7851 - val_loss: 0.4256 - val_accuracy: 0.8212\n",
      "Epoch 395/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4800 - accuracy: 0.7921 - val_loss: 0.4256 - val_accuracy: 0.8212\n",
      "Epoch 396/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4656 - accuracy: 0.7963 - val_loss: 0.4255 - val_accuracy: 0.8212\n",
      "Epoch 397/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4552 - accuracy: 0.8174 - val_loss: 0.4255 - val_accuracy: 0.8212\n",
      "Epoch 398/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4643 - accuracy: 0.8104 - val_loss: 0.4255 - val_accuracy: 0.8212\n",
      "Epoch 399/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4805 - accuracy: 0.8062 - val_loss: 0.4255 - val_accuracy: 0.8212\n",
      "Epoch 400/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4579 - accuracy: 0.8020 - val_loss: 0.4253 - val_accuracy: 0.8212\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3569 - accuracy: 0.8483 - val_loss: 0.5030 - val_accuracy: 0.8212\n",
      "Epoch 389/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3845 - accuracy: 0.8441 - val_loss: 0.4893 - val_accuracy: 0.8101\n",
      "Epoch 390/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3702 - accuracy: 0.8441 - val_loss: 0.5045 - val_accuracy: 0.8101\n",
      "Epoch 391/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3806 - accuracy: 0.8258 - val_loss: 0.4771 - val_accuracy: 0.8156\n",
      "Epoch 392/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3729 - accuracy: 0.8301 - val_loss: 0.5165 - val_accuracy: 0.8156\n",
      "Epoch 393/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3812 - accuracy: 0.8371 - val_loss: 0.5255 - val_accuracy: 0.8101\n",
      "Epoch 394/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3640 - accuracy: 0.8525 - val_loss: 0.5170 - val_accuracy: 0.8101\n",
      "Epoch 395/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3817 - accuracy: 0.8399 - val_loss: 0.4757 - val_accuracy: 0.8212\n",
      "Epoch 396/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3598 - accuracy: 0.8567 - val_loss: 0.4748 - val_accuracy: 0.8156\n",
      "Epoch 397/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3675 - accuracy: 0.8455 - val_loss: 0.4985 - val_accuracy: 0.8156\n",
      "Epoch 398/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3660 - accuracy: 0.8483 - val_loss: 0.4838 - val_accuracy: 0.8212\n",
      "Epoch 399/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3636 - accuracy: 0.8497 - val_loss: 0.4925 - val_accuracy: 0.8212\n",
      "Epoch 400/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3641 - accuracy: 0.8511 - val_loss: 0.4964 - val_accuracy: 0.8156\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/400\n",
      "712/712 [==============================] - 1s 920us/sample - loss: 0.6653 - accuracy: 0.6138 - val_loss: 0.5958 - val_accuracy: 0.6983\n",
      "Epoch 2/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5914 - accuracy: 0.6896 - val_loss: 0.5237 - val_accuracy: 0.7598\n",
      "Epoch 3/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5592 - accuracy: 0.7331 - val_loss: 0.4635 - val_accuracy: 0.8380\n",
      "Epoch 4/400\n",
      "712/712 [==============================] - 0s 192us/sample - loss: 0.5351 - accuracy: 0.7416 - val_loss: 0.4484 - val_accuracy: 0.8380\n",
      "Epoch 5/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5227 - accuracy: 0.7570 - val_loss: 0.4414 - val_accuracy: 0.8268\n",
      "Epoch 6/400\n",
      "712/712 [==============================] - 0s 210us/sample - loss: 0.5149 - accuracy: 0.7612 - val_loss: 0.4320 - val_accuracy: 0.8156\n",
      "Epoch 7/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5065 - accuracy: 0.7669 - val_loss: 0.4359 - val_accuracy: 0.8156\n",
      "Epoch 8/400\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.5200 - accuracy: 0.7654 - val_loss: 0.4353 - val_accuracy: 0.8212\n",
      "Epoch 9/400\n",
      "712/712 [==============================] - 0s 246us/sample - loss: 0.4794 - accuracy: 0.7879 - val_loss: 0.4239 - val_accuracy: 0.8268\n",
      "Epoch 10/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4885 - accuracy: 0.7725 - val_loss: 0.4206 - val_accuracy: 0.8212\n",
      "Epoch 11/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5033 - accuracy: 0.7500 - val_loss: 0.4292 - val_accuracy: 0.8268\n",
      "Epoch 12/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4834 - accuracy: 0.7584 - val_loss: 0.4234 - val_accuracy: 0.8324\n",
      "Epoch 13/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4870 - accuracy: 0.7584 - val_loss: 0.4219 - val_accuracy: 0.8324\n",
      "Epoch 14/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4584 - accuracy: 0.7795 - val_loss: 0.4204 - val_accuracy: 0.8380\n",
      "Epoch 15/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4657 - accuracy: 0.7907 - val_loss: 0.4225 - val_accuracy: 0.8268\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4578 - accuracy: 0.7963 - val_loss: 0.4120 - val_accuracy: 0.8436\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4897 - accuracy: 0.7739 - val_loss: 0.4110 - val_accuracy: 0.8324\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4782 - accuracy: 0.7837 - val_loss: 0.4149 - val_accuracy: 0.8324\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4548 - accuracy: 0.7795 - val_loss: 0.4083 - val_accuracy: 0.8436\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4575 - accuracy: 0.8006 - val_loss: 0.4038 - val_accuracy: 0.8324\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4657 - accuracy: 0.7893 - val_loss: 0.4173 - val_accuracy: 0.8380\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4738 - accuracy: 0.7823 - val_loss: 0.4138 - val_accuracy: 0.8380\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4527 - accuracy: 0.7683 - val_loss: 0.4146 - val_accuracy: 0.8268\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4626 - accuracy: 0.8006 - val_loss: 0.4127 - val_accuracy: 0.8324\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4324 - accuracy: 0.7935 - val_loss: 0.4157 - val_accuracy: 0.8324\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4567 - accuracy: 0.7725 - val_loss: 0.4089 - val_accuracy: 0.8380\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4465 - accuracy: 0.7837 - val_loss: 0.4109 - val_accuracy: 0.8436\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4472 - accuracy: 0.7921 - val_loss: 0.4156 - val_accuracy: 0.8380\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 217us/sample - loss: 0.4615 - accuracy: 0.7949 - val_loss: 0.4125 - val_accuracy: 0.8436\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4516 - accuracy: 0.7795 - val_loss: 0.4147 - val_accuracy: 0.8324\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.4767 - accuracy: 0.7739 - val_loss: 0.4125 - val_accuracy: 0.8492\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 229us/sample - loss: 0.4399 - accuracy: 0.7879 - val_loss: 0.4082 - val_accuracy: 0.8324\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 199us/sample - loss: 0.4571 - accuracy: 0.7556 - val_loss: 0.4061 - val_accuracy: 0.8436\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 250us/sample - loss: 0.4349 - accuracy: 0.7809 - val_loss: 0.4039 - val_accuracy: 0.8380\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4655 - accuracy: 0.7893 - val_loss: 0.4079 - val_accuracy: 0.8324\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4503 - accuracy: 0.7893 - val_loss: 0.4139 - val_accuracy: 0.8324\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4610 - accuracy: 0.7851 - val_loss: 0.4226 - val_accuracy: 0.8324\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4669 - accuracy: 0.7795 - val_loss: 0.4235 - val_accuracy: 0.8268\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4255 - accuracy: 0.7907 - val_loss: 0.4113 - val_accuracy: 0.8436\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4482 - accuracy: 0.7935 - val_loss: 0.4129 - val_accuracy: 0.8380\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4423 - accuracy: 0.7823 - val_loss: 0.4052 - val_accuracy: 0.8380\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4448 - accuracy: 0.7795 - val_loss: 0.4084 - val_accuracy: 0.8324\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4405 - accuracy: 0.7879 - val_loss: 0.4143 - val_accuracy: 0.8268\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4434 - accuracy: 0.8006 - val_loss: 0.4180 - val_accuracy: 0.8268\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4552 - accuracy: 0.7753 - val_loss: 0.4150 - val_accuracy: 0.8324\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4538 - accuracy: 0.7781 - val_loss: 0.4080 - val_accuracy: 0.8268\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4542 - accuracy: 0.7767 - val_loss: 0.4043 - val_accuracy: 0.8380\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4461 - accuracy: 0.7697 - val_loss: 0.4088 - val_accuracy: 0.8380\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4516 - accuracy: 0.7907 - val_loss: 0.4161 - val_accuracy: 0.8212\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4401 - accuracy: 0.7907 - val_loss: 0.4173 - val_accuracy: 0.8268\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4414 - accuracy: 0.7837 - val_loss: 0.4131 - val_accuracy: 0.8268\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4694 - accuracy: 0.7851 - val_loss: 0.4206 - val_accuracy: 0.8268\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4341 - accuracy: 0.7837 - val_loss: 0.4245 - val_accuracy: 0.8212\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4424 - accuracy: 0.7837 - val_loss: 0.4211 - val_accuracy: 0.8156\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4549 - accuracy: 0.7781 - val_loss: 0.4158 - val_accuracy: 0.8324\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4333 - accuracy: 0.7978 - val_loss: 0.4120 - val_accuracy: 0.8156\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4476 - accuracy: 0.7640 - val_loss: 0.4208 - val_accuracy: 0.8268\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4467 - accuracy: 0.7809 - val_loss: 0.4224 - val_accuracy: 0.8212\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4473 - accuracy: 0.7837 - val_loss: 0.4173 - val_accuracy: 0.8212\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4502 - accuracy: 0.7865 - val_loss: 0.4189 - val_accuracy: 0.8212\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4636 - accuracy: 0.7711 - val_loss: 0.4218 - val_accuracy: 0.8212\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4375 - accuracy: 0.7809 - val_loss: 0.4061 - val_accuracy: 0.8324\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3753 - accuracy: 0.8581 - val_loss: 0.4562 - val_accuracy: 0.8212\n",
      "Epoch 329/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3829 - accuracy: 0.8553 - val_loss: 0.4580 - val_accuracy: 0.8156\n",
      "Epoch 330/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3820 - accuracy: 0.8469 - val_loss: 0.4568 - val_accuracy: 0.8156\n",
      "Epoch 331/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3840 - accuracy: 0.8666 - val_loss: 0.4568 - val_accuracy: 0.8156\n",
      "Epoch 332/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3875 - accuracy: 0.8469 - val_loss: 0.4571 - val_accuracy: 0.8156\n",
      "Epoch 333/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3824 - accuracy: 0.8581 - val_loss: 0.4577 - val_accuracy: 0.8156\n",
      "Epoch 334/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3909 - accuracy: 0.8385 - val_loss: 0.4558 - val_accuracy: 0.8156\n",
      "Epoch 335/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3873 - accuracy: 0.8511 - val_loss: 0.4588 - val_accuracy: 0.8212\n",
      "Epoch 336/400\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.3697 - accuracy: 0.8581 - val_loss: 0.4581 - val_accuracy: 0.8212\n",
      "Epoch 337/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3884 - accuracy: 0.8525 - val_loss: 0.4575 - val_accuracy: 0.8268\n",
      "Epoch 338/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3796 - accuracy: 0.8567 - val_loss: 0.4533 - val_accuracy: 0.8156\n",
      "Epoch 339/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3991 - accuracy: 0.8455 - val_loss: 0.4550 - val_accuracy: 0.8212\n",
      "Epoch 340/400\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.3845 - accuracy: 0.8553 - val_loss: 0.4543 - val_accuracy: 0.8156\n",
      "Epoch 341/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3795 - accuracy: 0.8567 - val_loss: 0.4567 - val_accuracy: 0.8156\n",
      "Epoch 342/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.3816 - accuracy: 0.8483 - val_loss: 0.4568 - val_accuracy: 0.8156\n",
      "Epoch 343/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3797 - accuracy: 0.8567 - val_loss: 0.4554 - val_accuracy: 0.8156\n",
      "Epoch 344/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3773 - accuracy: 0.8525 - val_loss: 0.4577 - val_accuracy: 0.8156\n",
      "Epoch 345/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3959 - accuracy: 0.8483 - val_loss: 0.4592 - val_accuracy: 0.8212\n",
      "Epoch 346/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3723 - accuracy: 0.8427 - val_loss: 0.4586 - val_accuracy: 0.8212\n",
      "Epoch 347/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3752 - accuracy: 0.8539 - val_loss: 0.4601 - val_accuracy: 0.8212\n",
      "Epoch 348/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3748 - accuracy: 0.8596 - val_loss: 0.4576 - val_accuracy: 0.8156\n",
      "Epoch 349/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3861 - accuracy: 0.8525 - val_loss: 0.4576 - val_accuracy: 0.8156\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3978 - accuracy: 0.8385 - val_loss: 0.4574 - val_accuracy: 0.8156\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3791 - accuracy: 0.8469 - val_loss: 0.4555 - val_accuracy: 0.8156\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3799 - accuracy: 0.8525 - val_loss: 0.4555 - val_accuracy: 0.8156\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.3751 - accuracy: 0.8581 - val_loss: 0.4567 - val_accuracy: 0.8156\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3789 - accuracy: 0.8469 - val_loss: 0.4592 - val_accuracy: 0.8268\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.3813 - accuracy: 0.8525 - val_loss: 0.4592 - val_accuracy: 0.8268\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3720 - accuracy: 0.8497 - val_loss: 0.4571 - val_accuracy: 0.8212\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3770 - accuracy: 0.8581 - val_loss: 0.4579 - val_accuracy: 0.8268\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3853 - accuracy: 0.8511 - val_loss: 0.4579 - val_accuracy: 0.8156\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3848 - accuracy: 0.8511 - val_loss: 0.4584 - val_accuracy: 0.8268\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3684 - accuracy: 0.8624 - val_loss: 0.4596 - val_accuracy: 0.8268\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3966 - accuracy: 0.8469 - val_loss: 0.4572 - val_accuracy: 0.8156\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3790 - accuracy: 0.8553 - val_loss: 0.4582 - val_accuracy: 0.8156\n",
      "Epoch 363/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3782 - accuracy: 0.8455 - val_loss: 0.4581 - val_accuracy: 0.8212\n",
      "Epoch 364/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3692 - accuracy: 0.8581 - val_loss: 0.4579 - val_accuracy: 0.8268\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3727 - accuracy: 0.8539 - val_loss: 0.4573 - val_accuracy: 0.8156\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3831 - accuracy: 0.8525 - val_loss: 0.4582 - val_accuracy: 0.8156\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3924 - accuracy: 0.8511 - val_loss: 0.4597 - val_accuracy: 0.8268\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3697 - accuracy: 0.8596 - val_loss: 0.4612 - val_accuracy: 0.8268\n",
      "Epoch 369/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3738 - accuracy: 0.8539 - val_loss: 0.4641 - val_accuracy: 0.8212\n",
      "Epoch 370/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3784 - accuracy: 0.8567 - val_loss: 0.4604 - val_accuracy: 0.8212\n",
      "Epoch 371/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3697 - accuracy: 0.8581 - val_loss: 0.4590 - val_accuracy: 0.8212\n",
      "Epoch 372/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3765 - accuracy: 0.8610 - val_loss: 0.4609 - val_accuracy: 0.8268\n",
      "Epoch 373/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3793 - accuracy: 0.8525 - val_loss: 0.4615 - val_accuracy: 0.8268\n",
      "Epoch 374/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3648 - accuracy: 0.8610 - val_loss: 0.4621 - val_accuracy: 0.8268\n",
      "Epoch 375/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3823 - accuracy: 0.8483 - val_loss: 0.4619 - val_accuracy: 0.8212\n",
      "Epoch 376/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3755 - accuracy: 0.8567 - val_loss: 0.4615 - val_accuracy: 0.8101\n",
      "Epoch 377/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.3743 - accuracy: 0.8525 - val_loss: 0.4619 - val_accuracy: 0.8101\n",
      "Epoch 378/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.3928 - accuracy: 0.8399 - val_loss: 0.4635 - val_accuracy: 0.8212\n",
      "Epoch 379/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.3795 - accuracy: 0.8497 - val_loss: 0.4623 - val_accuracy: 0.8156\n",
      "Epoch 380/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3694 - accuracy: 0.8624 - val_loss: 0.4621 - val_accuracy: 0.8268\n",
      "Epoch 381/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3779 - accuracy: 0.8581 - val_loss: 0.4602 - val_accuracy: 0.8156\n",
      "Epoch 382/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3847 - accuracy: 0.8511 - val_loss: 0.4602 - val_accuracy: 0.8156\n",
      "Epoch 383/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3808 - accuracy: 0.8525 - val_loss: 0.4597 - val_accuracy: 0.8156\n",
      "Epoch 384/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3883 - accuracy: 0.8525 - val_loss: 0.4600 - val_accuracy: 0.8156\n",
      "Epoch 385/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3909 - accuracy: 0.8511 - val_loss: 0.4594 - val_accuracy: 0.8156\n",
      "Epoch 386/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3807 - accuracy: 0.8652 - val_loss: 0.4597 - val_accuracy: 0.8156\n",
      "Epoch 387/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3751 - accuracy: 0.8539 - val_loss: 0.4626 - val_accuracy: 0.8212\n",
      "Epoch 388/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3685 - accuracy: 0.8581 - val_loss: 0.4653 - val_accuracy: 0.8212\n",
      "Epoch 389/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3677 - accuracy: 0.8652 - val_loss: 0.4627 - val_accuracy: 0.8156\n",
      "Epoch 390/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3702 - accuracy: 0.8596 - val_loss: 0.4636 - val_accuracy: 0.8156\n",
      "Epoch 391/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3766 - accuracy: 0.8567 - val_loss: 0.4650 - val_accuracy: 0.8268\n",
      "Epoch 392/400\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.3876 - accuracy: 0.8525 - val_loss: 0.4615 - val_accuracy: 0.8156\n",
      "Epoch 393/400\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.3830 - accuracy: 0.8553 - val_loss: 0.4618 - val_accuracy: 0.8212\n",
      "Epoch 394/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3680 - accuracy: 0.8610 - val_loss: 0.4671 - val_accuracy: 0.8212\n",
      "Epoch 395/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3822 - accuracy: 0.8525 - val_loss: 0.4651 - val_accuracy: 0.8212\n",
      "Epoch 396/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.3708 - accuracy: 0.8624 - val_loss: 0.4659 - val_accuracy: 0.8212\n",
      "Epoch 397/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3886 - accuracy: 0.8610 - val_loss: 0.4647 - val_accuracy: 0.8156\n",
      "Epoch 398/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3686 - accuracy: 0.8525 - val_loss: 0.4654 - val_accuracy: 0.8156\n",
      "Epoch 399/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3700 - accuracy: 0.8525 - val_loss: 0.4669 - val_accuracy: 0.8212\n",
      "Epoch 400/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3751 - accuracy: 0.8553 - val_loss: 0.4658 - val_accuracy: 0.8156\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/400\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.8005 - accuracy: 0.4185 - val_loss: 0.7104 - val_accuracy: 0.4134\n",
      "Epoch 2/400\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.7400 - accuracy: 0.4551 - val_loss: 0.6838 - val_accuracy: 0.5866\n",
      "Epoch 3/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.7005 - accuracy: 0.5674 - val_loss: 0.6778 - val_accuracy: 0.5866\n",
      "Epoch 4/400\n",
      "712/712 [==============================] - 0s 217us/sample - loss: 0.6811 - accuracy: 0.5604 - val_loss: 0.6777 - val_accuracy: 0.5866\n",
      "Epoch 5/400\n",
      "712/712 [==============================] - 0s 216us/sample - loss: 0.6877 - accuracy: 0.5604 - val_loss: 0.6781 - val_accuracy: 0.5866\n",
      "Epoch 6/400\n",
      "712/712 [==============================] - 0s 244us/sample - loss: 0.6934 - accuracy: 0.5604 - val_loss: 0.6765 - val_accuracy: 0.5866\n",
      "Epoch 7/400\n",
      "712/712 [==============================] - 0s 203us/sample - loss: 0.6845 - accuracy: 0.5941 - val_loss: 0.6745 - val_accuracy: 0.5866\n",
      "Epoch 8/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6884 - accuracy: 0.5632 - val_loss: 0.6722 - val_accuracy: 0.5866\n",
      "Epoch 9/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6821 - accuracy: 0.5871 - val_loss: 0.6703 - val_accuracy: 0.5866\n",
      "Epoch 10/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6813 - accuracy: 0.5843 - val_loss: 0.6673 - val_accuracy: 0.5866\n",
      "Epoch 11/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6806 - accuracy: 0.5843 - val_loss: 0.6641 - val_accuracy: 0.5866\n",
      "Epoch 12/400\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.6809 - accuracy: 0.6067 - val_loss: 0.6595 - val_accuracy: 0.5866\n",
      "Epoch 13/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6597 - accuracy: 0.6081 - val_loss: 0.6539 - val_accuracy: 0.5866\n",
      "Epoch 14/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.6612 - accuracy: 0.6124 - val_loss: 0.6467 - val_accuracy: 0.5866\n",
      "Epoch 15/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6509 - accuracy: 0.6362 - val_loss: 0.6384 - val_accuracy: 0.5866\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6582 - accuracy: 0.6096 - val_loss: 0.6271 - val_accuracy: 0.5866\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.6353 - accuracy: 0.6433 - val_loss: 0.6117 - val_accuracy: 0.5866\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6288 - accuracy: 0.6306 - val_loss: 0.5947 - val_accuracy: 0.5866\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6262 - accuracy: 0.6531 - val_loss: 0.5758 - val_accuracy: 0.6369\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6159 - accuracy: 0.6390 - val_loss: 0.5600 - val_accuracy: 0.7654\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5836 - accuracy: 0.6854 - val_loss: 0.5438 - val_accuracy: 0.7989\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5620 - accuracy: 0.7219 - val_loss: 0.5288 - val_accuracy: 0.8156\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.5775 - accuracy: 0.7037 - val_loss: 0.5157 - val_accuracy: 0.8101\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.5549 - accuracy: 0.7275 - val_loss: 0.5028 - val_accuracy: 0.8156\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5524 - accuracy: 0.7303 - val_loss: 0.4923 - val_accuracy: 0.8101\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5508 - accuracy: 0.7542 - val_loss: 0.4858 - val_accuracy: 0.8101\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.5245 - accuracy: 0.7753 - val_loss: 0.4785 - val_accuracy: 0.8156\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5243 - accuracy: 0.7556 - val_loss: 0.4720 - val_accuracy: 0.8101\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5285 - accuracy: 0.7725 - val_loss: 0.4652 - val_accuracy: 0.8101\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5049 - accuracy: 0.7767 - val_loss: 0.4610 - val_accuracy: 0.8156\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5207 - accuracy: 0.7823 - val_loss: 0.4578 - val_accuracy: 0.8156\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5049 - accuracy: 0.7935 - val_loss: 0.4554 - val_accuracy: 0.8156\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5145 - accuracy: 0.7683 - val_loss: 0.4513 - val_accuracy: 0.8156\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.4869 - accuracy: 0.8048 - val_loss: 0.4478 - val_accuracy: 0.8156\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4741 - accuracy: 0.8034 - val_loss: 0.4442 - val_accuracy: 0.8156\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.4801 - accuracy: 0.8118 - val_loss: 0.4436 - val_accuracy: 0.8212\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4836 - accuracy: 0.8020 - val_loss: 0.4397 - val_accuracy: 0.8268\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4791 - accuracy: 0.7907 - val_loss: 0.4376 - val_accuracy: 0.8324\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4599 - accuracy: 0.8160 - val_loss: 0.4372 - val_accuracy: 0.8268\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4867 - accuracy: 0.8132 - val_loss: 0.4364 - val_accuracy: 0.8268\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4661 - accuracy: 0.8216 - val_loss: 0.4358 - val_accuracy: 0.8268\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4787 - accuracy: 0.8118 - val_loss: 0.4358 - val_accuracy: 0.8268\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4694 - accuracy: 0.8174 - val_loss: 0.4351 - val_accuracy: 0.8324\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.4691 - accuracy: 0.8048 - val_loss: 0.4342 - val_accuracy: 0.8268\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4495 - accuracy: 0.8174 - val_loss: 0.4361 - val_accuracy: 0.8268\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4677 - accuracy: 0.8020 - val_loss: 0.4346 - val_accuracy: 0.8268\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4754 - accuracy: 0.8188 - val_loss: 0.4312 - val_accuracy: 0.8324\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4662 - accuracy: 0.8090 - val_loss: 0.4309 - val_accuracy: 0.8324\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4538 - accuracy: 0.8188 - val_loss: 0.4300 - val_accuracy: 0.8324\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4821 - accuracy: 0.8076 - val_loss: 0.4303 - val_accuracy: 0.8324\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4644 - accuracy: 0.8188 - val_loss: 0.4298 - val_accuracy: 0.8324\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4560 - accuracy: 0.8258 - val_loss: 0.4291 - val_accuracy: 0.8324\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4508 - accuracy: 0.8343 - val_loss: 0.4288 - val_accuracy: 0.8324\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4599 - accuracy: 0.8104 - val_loss: 0.4283 - val_accuracy: 0.8324\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4362 - accuracy: 0.8244 - val_loss: 0.4275 - val_accuracy: 0.8324\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4304 - accuracy: 0.8315 - val_loss: 0.4263 - val_accuracy: 0.8324\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4821 - accuracy: 0.8244 - val_loss: 0.4257 - val_accuracy: 0.8324\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4577 - accuracy: 0.8174 - val_loss: 0.4259 - val_accuracy: 0.8324\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4457 - accuracy: 0.8118 - val_loss: 0.4255 - val_accuracy: 0.8324\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4439 - accuracy: 0.8216 - val_loss: 0.4254 - val_accuracy: 0.8380\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4614 - accuracy: 0.8090 - val_loss: 0.4243 - val_accuracy: 0.8324\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4602 - accuracy: 0.8287 - val_loss: 0.4242 - val_accuracy: 0.8380\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.4480 - accuracy: 0.8287 - val_loss: 0.4228 - val_accuracy: 0.8324\n",
      "Epoch 64/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4426 - accuracy: 0.8230 - val_loss: 0.4214 - val_accuracy: 0.8380\n",
      "Epoch 65/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4605 - accuracy: 0.8329 - val_loss: 0.4209 - val_accuracy: 0.8324\n",
      "Epoch 66/400\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.4494 - accuracy: 0.8315 - val_loss: 0.4214 - val_accuracy: 0.8380\n",
      "Epoch 67/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.4531 - accuracy: 0.8272 - val_loss: 0.4218 - val_accuracy: 0.8380\n",
      "Epoch 68/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4527 - accuracy: 0.8385 - val_loss: 0.4218 - val_accuracy: 0.8380\n",
      "Epoch 69/400\n",
      "712/712 [==============================] - 0s 222us/sample - loss: 0.4405 - accuracy: 0.8216 - val_loss: 0.4219 - val_accuracy: 0.8380\n",
      "Epoch 70/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4265 - accuracy: 0.8202 - val_loss: 0.4213 - val_accuracy: 0.8324\n",
      "Epoch 71/400\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.4531 - accuracy: 0.8160 - val_loss: 0.4211 - val_accuracy: 0.8380\n",
      "Epoch 72/400\n",
      "712/712 [==============================] - 0s 263us/sample - loss: 0.4431 - accuracy: 0.8188 - val_loss: 0.4223 - val_accuracy: 0.8436\n",
      "Epoch 73/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4419 - accuracy: 0.8258 - val_loss: 0.4218 - val_accuracy: 0.8380\n",
      "Epoch 74/400\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.4271 - accuracy: 0.8301 - val_loss: 0.4216 - val_accuracy: 0.8380\n",
      "Epoch 75/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4233 - accuracy: 0.8413 - val_loss: 0.4214 - val_accuracy: 0.8380\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4211 - accuracy: 0.8385 - val_loss: 0.4218 - val_accuracy: 0.8380\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4412 - accuracy: 0.8216 - val_loss: 0.4231 - val_accuracy: 0.8380\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4509 - accuracy: 0.8174 - val_loss: 0.4225 - val_accuracy: 0.8324\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4374 - accuracy: 0.8258 - val_loss: 0.4228 - val_accuracy: 0.8380\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4579 - accuracy: 0.8090 - val_loss: 0.4242 - val_accuracy: 0.8380\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4456 - accuracy: 0.8230 - val_loss: 0.4251 - val_accuracy: 0.8380\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4191 - accuracy: 0.8329 - val_loss: 0.4249 - val_accuracy: 0.8380\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4470 - accuracy: 0.8244 - val_loss: 0.4255 - val_accuracy: 0.8324\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4370 - accuracy: 0.8315 - val_loss: 0.4254 - val_accuracy: 0.8380\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4404 - accuracy: 0.8216 - val_loss: 0.4262 - val_accuracy: 0.8324\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4159 - accuracy: 0.8258 - val_loss: 0.4262 - val_accuracy: 0.8380\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4137 - accuracy: 0.8272 - val_loss: 0.4267 - val_accuracy: 0.8268\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4359 - accuracy: 0.8287 - val_loss: 0.4265 - val_accuracy: 0.8324\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4258 - accuracy: 0.8287 - val_loss: 0.4263 - val_accuracy: 0.8380\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4357 - accuracy: 0.8315 - val_loss: 0.4269 - val_accuracy: 0.8380\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4294 - accuracy: 0.8399 - val_loss: 0.4271 - val_accuracy: 0.8436\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4215 - accuracy: 0.8413 - val_loss: 0.4266 - val_accuracy: 0.8436\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4360 - accuracy: 0.8132 - val_loss: 0.4266 - val_accuracy: 0.8380\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4425 - accuracy: 0.8469 - val_loss: 0.4267 - val_accuracy: 0.8380\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 225us/sample - loss: 0.4335 - accuracy: 0.8287 - val_loss: 0.4280 - val_accuracy: 0.8268\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4302 - accuracy: 0.8230 - val_loss: 0.4284 - val_accuracy: 0.8380\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 221us/sample - loss: 0.4392 - accuracy: 0.8244 - val_loss: 0.4285 - val_accuracy: 0.8324\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 208us/sample - loss: 0.4181 - accuracy: 0.8287 - val_loss: 0.4277 - val_accuracy: 0.8324\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 227us/sample - loss: 0.4292 - accuracy: 0.8371 - val_loss: 0.4277 - val_accuracy: 0.8324\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 206us/sample - loss: 0.4181 - accuracy: 0.8258 - val_loss: 0.4280 - val_accuracy: 0.8380\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4369 - accuracy: 0.8244 - val_loss: 0.4285 - val_accuracy: 0.8324\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4216 - accuracy: 0.8385 - val_loss: 0.4283 - val_accuracy: 0.8324\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4247 - accuracy: 0.8413 - val_loss: 0.4278 - val_accuracy: 0.8324\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4396 - accuracy: 0.8258 - val_loss: 0.4284 - val_accuracy: 0.8324\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4298 - accuracy: 0.8216 - val_loss: 0.4280 - val_accuracy: 0.8324\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4250 - accuracy: 0.8301 - val_loss: 0.4283 - val_accuracy: 0.8324\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4076 - accuracy: 0.8413 - val_loss: 0.4280 - val_accuracy: 0.8268\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4192 - accuracy: 0.8301 - val_loss: 0.4288 - val_accuracy: 0.8380\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4122 - accuracy: 0.8371 - val_loss: 0.4290 - val_accuracy: 0.8380\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4266 - accuracy: 0.8399 - val_loss: 0.4296 - val_accuracy: 0.8380\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4129 - accuracy: 0.8385 - val_loss: 0.4299 - val_accuracy: 0.8324\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4379 - accuracy: 0.8160 - val_loss: 0.4297 - val_accuracy: 0.8324\n",
      "Epoch 113/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4506 - accuracy: 0.8230 - val_loss: 0.4284 - val_accuracy: 0.8380\n",
      "Epoch 114/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4333 - accuracy: 0.8160 - val_loss: 0.4285 - val_accuracy: 0.8268\n",
      "Epoch 115/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4205 - accuracy: 0.8413 - val_loss: 0.4292 - val_accuracy: 0.8324\n",
      "Epoch 116/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4254 - accuracy: 0.8315 - val_loss: 0.4282 - val_accuracy: 0.8324\n",
      "Epoch 117/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3895 - accuracy: 0.8385 - val_loss: 0.4270 - val_accuracy: 0.8268\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3934 - accuracy: 0.8385 - val_loss: 0.4284 - val_accuracy: 0.8268\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3865 - accuracy: 0.8455 - val_loss: 0.4286 - val_accuracy: 0.8268\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3881 - accuracy: 0.8385 - val_loss: 0.4320 - val_accuracy: 0.8268\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3939 - accuracy: 0.8469 - val_loss: 0.4264 - val_accuracy: 0.8212\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.3892 - accuracy: 0.8413 - val_loss: 0.4333 - val_accuracy: 0.8324\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3895 - accuracy: 0.8413 - val_loss: 0.4298 - val_accuracy: 0.8268\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.3942 - accuracy: 0.8371 - val_loss: 0.4304 - val_accuracy: 0.8324\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3892 - accuracy: 0.8343 - val_loss: 0.4249 - val_accuracy: 0.8212\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3965 - accuracy: 0.8357 - val_loss: 0.4270 - val_accuracy: 0.8212\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3987 - accuracy: 0.8399 - val_loss: 0.4273 - val_accuracy: 0.8268\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3896 - accuracy: 0.8357 - val_loss: 0.4280 - val_accuracy: 0.8268\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4041 - accuracy: 0.8371 - val_loss: 0.4307 - val_accuracy: 0.8212\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.3915 - accuracy: 0.8413 - val_loss: 0.4306 - val_accuracy: 0.8268\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.3933 - accuracy: 0.8357 - val_loss: 0.4319 - val_accuracy: 0.8212\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.3896 - accuracy: 0.8399 - val_loss: 0.4318 - val_accuracy: 0.8268\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.3940 - accuracy: 0.8399 - val_loss: 0.4319 - val_accuracy: 0.8212\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3798 - accuracy: 0.8413 - val_loss: 0.4349 - val_accuracy: 0.8212\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.3902 - accuracy: 0.8315 - val_loss: 0.4343 - val_accuracy: 0.8268\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.3892 - accuracy: 0.8385 - val_loss: 0.4328 - val_accuracy: 0.8268\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3874 - accuracy: 0.8399 - val_loss: 0.4274 - val_accuracy: 0.8324\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3889 - accuracy: 0.8357 - val_loss: 0.4340 - val_accuracy: 0.8324\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.3906 - accuracy: 0.8455 - val_loss: 0.4384 - val_accuracy: 0.8212\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.3813 - accuracy: 0.8427 - val_loss: 0.4344 - val_accuracy: 0.8212\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.3869 - accuracy: 0.8399 - val_loss: 0.4316 - val_accuracy: 0.8268\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.3813 - accuracy: 0.8427 - val_loss: 0.4377 - val_accuracy: 0.8268\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.3923 - accuracy: 0.8357 - val_loss: 0.4309 - val_accuracy: 0.8268\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3770 - accuracy: 0.8469 - val_loss: 0.4352 - val_accuracy: 0.8212\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3875 - accuracy: 0.8413 - val_loss: 0.4405 - val_accuracy: 0.8212\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.3799 - accuracy: 0.8441 - val_loss: 0.4298 - val_accuracy: 0.8212\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.3815 - accuracy: 0.8441 - val_loss: 0.4327 - val_accuracy: 0.8268\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3909 - accuracy: 0.8427 - val_loss: 0.4299 - val_accuracy: 0.8268\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.3833 - accuracy: 0.8371 - val_loss: 0.4321 - val_accuracy: 0.8268\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.3922 - accuracy: 0.8399 - val_loss: 0.4263 - val_accuracy: 0.8268\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.3810 - accuracy: 0.8399 - val_loss: 0.4284 - val_accuracy: 0.8268\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.3844 - accuracy: 0.8371 - val_loss: 0.4333 - val_accuracy: 0.8268\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3862 - accuracy: 0.8483 - val_loss: 0.4426 - val_accuracy: 0.8268\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3774 - accuracy: 0.8413 - val_loss: 0.4385 - val_accuracy: 0.8212\n",
      "Epoch 113/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4709 - accuracy: 0.7935 - val_loss: 0.4338 - val_accuracy: 0.7933\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4570 - accuracy: 0.7893 - val_loss: 0.4599 - val_accuracy: 0.8268\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4678 - accuracy: 0.7907 - val_loss: 0.4574 - val_accuracy: 0.8045\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.4569 - accuracy: 0.7921 - val_loss: 0.4346 - val_accuracy: 0.8156\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4400 - accuracy: 0.8132 - val_loss: 0.4254 - val_accuracy: 0.8268\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4220 - accuracy: 0.8034 - val_loss: 0.4935 - val_accuracy: 0.8324\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.4635 - accuracy: 0.7978 - val_loss: 0.4739 - val_accuracy: 0.8212\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4415 - accuracy: 0.7837 - val_loss: 0.4745 - val_accuracy: 0.8268\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.4422 - accuracy: 0.7935 - val_loss: 0.4346 - val_accuracy: 0.8324\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4433 - accuracy: 0.7851 - val_loss: 0.4090 - val_accuracy: 0.8436\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.4276 - accuracy: 0.8034 - val_loss: 0.4280 - val_accuracy: 0.8268\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4303 - accuracy: 0.7949 - val_loss: 0.4204 - val_accuracy: 0.8380\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4460 - accuracy: 0.7992 - val_loss: 0.4224 - val_accuracy: 0.8324\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4320 - accuracy: 0.7963 - val_loss: 0.4048 - val_accuracy: 0.8380\n",
      "Epoch 363/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4293 - accuracy: 0.8020 - val_loss: 0.4368 - val_accuracy: 0.8324\n",
      "Epoch 364/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4065 - accuracy: 0.8118 - val_loss: 0.4602 - val_accuracy: 0.8268\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.4085 - accuracy: 0.8216 - val_loss: 0.5508 - val_accuracy: 0.8268\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4080 - accuracy: 0.8272 - val_loss: 0.6663 - val_accuracy: 0.8212\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4027 - accuracy: 0.8216 - val_loss: 0.7688 - val_accuracy: 0.8268\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3885 - accuracy: 0.8188 - val_loss: 0.8173 - val_accuracy: 0.8101\n",
      "Epoch 369/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4462 - accuracy: 0.8076 - val_loss: 0.7036 - val_accuracy: 0.7989\n",
      "Epoch 370/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5699 - accuracy: 0.8287 - val_loss: 0.4641 - val_accuracy: 0.7709\n",
      "Epoch 371/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4294 - accuracy: 0.8188 - val_loss: 0.4724 - val_accuracy: 0.8212\n",
      "Epoch 372/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4319 - accuracy: 0.8132 - val_loss: 0.4252 - val_accuracy: 0.8268\n",
      "Epoch 373/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4167 - accuracy: 0.8230 - val_loss: 0.4203 - val_accuracy: 0.8156\n",
      "Epoch 374/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3898 - accuracy: 0.8371 - val_loss: 0.4242 - val_accuracy: 0.8212\n",
      "Epoch 375/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4141 - accuracy: 0.8230 - val_loss: 0.4645 - val_accuracy: 0.7989\n",
      "Epoch 376/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4192 - accuracy: 0.8132 - val_loss: 0.4304 - val_accuracy: 0.8101\n",
      "Epoch 377/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4051 - accuracy: 0.8216 - val_loss: 0.4354 - val_accuracy: 0.8212\n",
      "Epoch 378/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4103 - accuracy: 0.8357 - val_loss: 0.4443 - val_accuracy: 0.8045\n",
      "Epoch 379/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.3982 - accuracy: 0.8329 - val_loss: 0.4666 - val_accuracy: 0.7989\n",
      "Epoch 380/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3997 - accuracy: 0.8146 - val_loss: 0.4396 - val_accuracy: 0.7877\n",
      "Epoch 381/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4122 - accuracy: 0.8104 - val_loss: 0.4424 - val_accuracy: 0.7877\n",
      "Epoch 382/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4059 - accuracy: 0.8132 - val_loss: 0.4885 - val_accuracy: 0.7989\n",
      "Epoch 383/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4082 - accuracy: 0.8287 - val_loss: 0.4511 - val_accuracy: 0.7933\n",
      "Epoch 384/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4287 - accuracy: 0.8188 - val_loss: 0.4151 - val_accuracy: 0.7989\n",
      "Epoch 385/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4119 - accuracy: 0.8230 - val_loss: 0.4279 - val_accuracy: 0.8324\n",
      "Epoch 386/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3892 - accuracy: 0.8301 - val_loss: 0.4552 - val_accuracy: 0.8156\n",
      "Epoch 387/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.3958 - accuracy: 0.8357 - val_loss: 0.4418 - val_accuracy: 0.7933\n",
      "Epoch 388/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3945 - accuracy: 0.8315 - val_loss: 0.4755 - val_accuracy: 0.8156\n",
      "Epoch 389/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.3915 - accuracy: 0.8287 - val_loss: 0.5064 - val_accuracy: 0.8212\n",
      "Epoch 390/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4188 - accuracy: 0.8216 - val_loss: 0.4888 - val_accuracy: 0.8212\n",
      "Epoch 391/400\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.3998 - accuracy: 0.8357 - val_loss: 0.5526 - val_accuracy: 0.8212\n",
      "Epoch 392/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3890 - accuracy: 0.8315 - val_loss: 0.5565 - val_accuracy: 0.8156\n",
      "Epoch 393/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3937 - accuracy: 0.8230 - val_loss: 0.5221 - val_accuracy: 0.8101\n",
      "Epoch 394/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3898 - accuracy: 0.8329 - val_loss: 0.4500 - val_accuracy: 0.8045\n",
      "Epoch 395/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4050 - accuracy: 0.8188 - val_loss: 0.4336 - val_accuracy: 0.8212\n",
      "Epoch 396/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3999 - accuracy: 0.8258 - val_loss: 0.4660 - val_accuracy: 0.8212\n",
      "Epoch 397/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4073 - accuracy: 0.8216 - val_loss: 0.4513 - val_accuracy: 0.8212\n",
      "Epoch 398/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.3970 - accuracy: 0.8258 - val_loss: 0.5101 - val_accuracy: 0.8101\n",
      "Epoch 399/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4168 - accuracy: 0.8258 - val_loss: 0.4626 - val_accuracy: 0.8101\n",
      "Epoch 400/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.3905 - accuracy: 0.8385 - val_loss: 0.4891 - val_accuracy: 0.8101\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/400\n",
      "712/712 [==============================] - 1s 2ms/sample - loss: 0.6255 - accuracy: 0.6039 - val_loss: 0.5514 - val_accuracy: 0.5866\n",
      "Epoch 2/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6019 - accuracy: 0.6924 - val_loss: 0.5150 - val_accuracy: 0.7933\n",
      "Epoch 3/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5380 - accuracy: 0.7584 - val_loss: 0.4977 - val_accuracy: 0.7989\n",
      "Epoch 4/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.5227 - accuracy: 0.7542 - val_loss: 0.4602 - val_accuracy: 0.8045\n",
      "Epoch 5/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4990 - accuracy: 0.7865 - val_loss: 0.4881 - val_accuracy: 0.8045\n",
      "Epoch 6/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4924 - accuracy: 0.7725 - val_loss: 0.4527 - val_accuracy: 0.8045\n",
      "Epoch 7/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4691 - accuracy: 0.7781 - val_loss: 0.4981 - val_accuracy: 0.8380\n",
      "Epoch 8/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4409 - accuracy: 0.8104 - val_loss: 0.4541 - val_accuracy: 0.8324\n",
      "Epoch 9/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4524 - accuracy: 0.8062 - val_loss: 0.4853 - val_accuracy: 0.8324\n",
      "Epoch 10/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4526 - accuracy: 0.7949 - val_loss: 0.4805 - val_accuracy: 0.8436\n",
      "Epoch 11/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4718 - accuracy: 0.7879 - val_loss: 0.4831 - val_accuracy: 0.8380\n",
      "Epoch 12/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4825 - accuracy: 0.7907 - val_loss: 0.4465 - val_accuracy: 0.8212\n",
      "Epoch 13/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4642 - accuracy: 0.7935 - val_loss: 0.4760 - val_accuracy: 0.8212\n",
      "Epoch 14/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4864 - accuracy: 0.7865 - val_loss: 0.4586 - val_accuracy: 0.8212\n",
      "Epoch 15/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4539 - accuracy: 0.7949 - val_loss: 0.4542 - val_accuracy: 0.8324\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.4292 - accuracy: 0.8104 - val_loss: 0.4596 - val_accuracy: 0.8268\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4580 - accuracy: 0.7992 - val_loss: 0.4401 - val_accuracy: 0.8268\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4563 - accuracy: 0.7963 - val_loss: 0.4417 - val_accuracy: 0.8212\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4467 - accuracy: 0.8076 - val_loss: 0.4435 - val_accuracy: 0.8268\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4129 - accuracy: 0.8006 - val_loss: 0.4593 - val_accuracy: 0.8101\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4552 - accuracy: 0.7949 - val_loss: 0.4811 - val_accuracy: 0.8156\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4584 - accuracy: 0.8006 - val_loss: 0.4544 - val_accuracy: 0.8156\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4339 - accuracy: 0.8020 - val_loss: 0.4499 - val_accuracy: 0.8268\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4285 - accuracy: 0.7992 - val_loss: 0.4409 - val_accuracy: 0.8380\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4329 - accuracy: 0.7978 - val_loss: 0.4350 - val_accuracy: 0.8268\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4344 - accuracy: 0.8006 - val_loss: 0.4306 - val_accuracy: 0.8156\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4477 - accuracy: 0.8090 - val_loss: 0.4375 - val_accuracy: 0.8045\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4321 - accuracy: 0.7879 - val_loss: 0.4401 - val_accuracy: 0.8324\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4784 - accuracy: 0.8006 - val_loss: 0.4541 - val_accuracy: 0.8268\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4756 - accuracy: 0.7865 - val_loss: 0.4629 - val_accuracy: 0.8268\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4349 - accuracy: 0.7907 - val_loss: 0.4323 - val_accuracy: 0.8212\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4345 - accuracy: 0.7921 - val_loss: 0.4314 - val_accuracy: 0.8212\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4502 - accuracy: 0.8062 - val_loss: 0.4415 - val_accuracy: 0.8101\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.4248 - accuracy: 0.8006 - val_loss: 0.4351 - val_accuracy: 0.8324\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4212 - accuracy: 0.7935 - val_loss: 0.5203 - val_accuracy: 0.8101\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4533 - accuracy: 0.7907 - val_loss: 0.4809 - val_accuracy: 0.8156\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4429 - accuracy: 0.8104 - val_loss: 0.4310 - val_accuracy: 0.8156\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4245 - accuracy: 0.8048 - val_loss: 0.4464 - val_accuracy: 0.8212\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4417 - accuracy: 0.7963 - val_loss: 0.4267 - val_accuracy: 0.8101\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4545 - accuracy: 0.7837 - val_loss: 0.4644 - val_accuracy: 0.7821\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4235 - accuracy: 0.7879 - val_loss: 0.4339 - val_accuracy: 0.8212\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4458 - accuracy: 0.8076 - val_loss: 0.4469 - val_accuracy: 0.8156\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4215 - accuracy: 0.8034 - val_loss: 0.4166 - val_accuracy: 0.8268\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4260 - accuracy: 0.8034 - val_loss: 0.4767 - val_accuracy: 0.8212\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4421 - accuracy: 0.7893 - val_loss: 0.4356 - val_accuracy: 0.8268\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.4285 - accuracy: 0.7893 - val_loss: 0.4256 - val_accuracy: 0.8324\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4622 - accuracy: 0.7809 - val_loss: 0.4608 - val_accuracy: 0.8101\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4382 - accuracy: 0.7865 - val_loss: 0.4291 - val_accuracy: 0.8212\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4116 - accuracy: 0.8090 - val_loss: 0.4465 - val_accuracy: 0.8156\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4324 - accuracy: 0.7921 - val_loss: 0.4260 - val_accuracy: 0.8212\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4418 - accuracy: 0.7893 - val_loss: 0.4385 - val_accuracy: 0.8156\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4441 - accuracy: 0.7879 - val_loss: 0.4324 - val_accuracy: 0.7821\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4312 - accuracy: 0.7823 - val_loss: 0.4406 - val_accuracy: 0.8268\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4337 - accuracy: 0.7963 - val_loss: 0.4511 - val_accuracy: 0.8268\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4556 - accuracy: 0.8034 - val_loss: 0.4705 - val_accuracy: 0.8212\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4480 - accuracy: 0.7992 - val_loss: 0.4423 - val_accuracy: 0.8268\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4340 - accuracy: 0.8076 - val_loss: 0.4597 - val_accuracy: 0.8101\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 195us/sample - loss: 0.4417 - accuracy: 0.8104 - val_loss: 0.4329 - val_accuracy: 0.8156\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.4337 - accuracy: 0.8132 - val_loss: 0.4574 - val_accuracy: 0.8045\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.4135 - accuracy: 0.8006 - val_loss: 0.4360 - val_accuracy: 0.8101\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.4082 - accuracy: 0.7949 - val_loss: 0.4430 - val_accuracy: 0.8212\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.4237 - accuracy: 0.8020 - val_loss: 0.4353 - val_accuracy: 0.8212\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 284us/sample - loss: 0.4339 - accuracy: 0.7907 - val_loss: 0.4368 - val_accuracy: 0.8212\n",
      "Epoch 64/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4200 - accuracy: 0.7992 - val_loss: 0.4460 - val_accuracy: 0.8156\n",
      "Epoch 65/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.4086 - accuracy: 0.8146 - val_loss: 0.4492 - val_accuracy: 0.8212\n",
      "Epoch 66/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4284 - accuracy: 0.7949 - val_loss: 0.4383 - val_accuracy: 0.8156\n",
      "Epoch 67/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4272 - accuracy: 0.8034 - val_loss: 0.4620 - val_accuracy: 0.8156\n",
      "Epoch 68/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4306 - accuracy: 0.7837 - val_loss: 0.4249 - val_accuracy: 0.8101\n",
      "Epoch 69/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4392 - accuracy: 0.8034 - val_loss: 0.4469 - val_accuracy: 0.8045\n",
      "Epoch 70/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4305 - accuracy: 0.8062 - val_loss: 0.4318 - val_accuracy: 0.8324\n",
      "Epoch 71/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4341 - accuracy: 0.8216 - val_loss: 0.4372 - val_accuracy: 0.8156\n",
      "Epoch 72/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4248 - accuracy: 0.8006 - val_loss: 0.4430 - val_accuracy: 0.8101\n",
      "Epoch 73/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4238 - accuracy: 0.8048 - val_loss: 0.4405 - val_accuracy: 0.8156\n",
      "Epoch 74/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4044 - accuracy: 0.8118 - val_loss: 0.4365 - val_accuracy: 0.8156\n",
      "Epoch 75/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4143 - accuracy: 0.7809 - val_loss: 0.4303 - val_accuracy: 0.8324\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5026 - val_accuracy: 0.8101\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.4310 - accuracy: 0.8132 - val_loss: 0.4313 - val_accuracy: 0.8268\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3939 - accuracy: 0.8034 - val_loss: 0.5125 - val_accuracy: 0.8101\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4619 - accuracy: 0.7907 - val_loss: 0.5178 - val_accuracy: 0.6927\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4417 - accuracy: 0.7865 - val_loss: 0.4588 - val_accuracy: 0.8101\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.4192 - val_accuracy: 0.8212\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4270 - accuracy: 0.7711 - val_loss: 0.4423 - val_accuracy: 0.8101\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4154 - accuracy: 0.7851 - val_loss: 0.4474 - val_accuracy: 0.8212\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4311 - accuracy: 0.7893 - val_loss: 0.4334 - val_accuracy: 0.8268\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4184 - accuracy: 0.7739 - val_loss: 0.4205 - val_accuracy: 0.8212\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4393 - accuracy: 0.8034 - val_loss: 0.4411 - val_accuracy: 0.8101\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4280 - accuracy: 0.7949 - val_loss: 0.4170 - val_accuracy: 0.8380\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 226us/sample - loss: 0.4121 - accuracy: 0.7879 - val_loss: 0.4344 - val_accuracy: 0.8101\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4029 - accuracy: 0.7907 - val_loss: 0.4361 - val_accuracy: 0.8324\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.4136 - accuracy: 0.8006 - val_loss: 0.4265 - val_accuracy: 0.8101\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 225us/sample - loss: 0.4201 - accuracy: 0.7837 - val_loss: 0.4530 - val_accuracy: 0.8156\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 220us/sample - loss: 0.4105 - accuracy: 0.8034 - val_loss: 0.4779 - val_accuracy: 0.8268\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 249us/sample - loss: 0.4418 - accuracy: 0.8174 - val_loss: 0.4329 - val_accuracy: 0.8324\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4147 - accuracy: 0.7921 - val_loss: 0.4487 - val_accuracy: 0.8101\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4047 - accuracy: 0.8146 - val_loss: 0.5288 - val_accuracy: 0.8156\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4199 - accuracy: 0.7963 - val_loss: 0.5264 - val_accuracy: 0.8156\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4265 - accuracy: 0.7921 - val_loss: 0.4517 - val_accuracy: 0.8212\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4255 - accuracy: 0.7851 - val_loss: 0.4440 - val_accuracy: 0.8268\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4129 - accuracy: 0.8132 - val_loss: 0.4405 - val_accuracy: 0.8268\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4157 - accuracy: 0.8048 - val_loss: 0.4626 - val_accuracy: 0.8101\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4155 - accuracy: 0.8188 - val_loss: 0.4401 - val_accuracy: 0.8101\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.3921 - accuracy: 0.8118 - val_loss: 0.4714 - val_accuracy: 0.8156\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4414 - accuracy: 0.7935 - val_loss: 0.4506 - val_accuracy: 0.8268\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4203 - accuracy: 0.7893 - val_loss: 0.4532 - val_accuracy: 0.8101\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4168 - accuracy: 0.7963 - val_loss: 0.4604 - val_accuracy: 0.8212\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4030 - accuracy: 0.7865 - val_loss: 0.4851 - val_accuracy: 0.8156\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4276 - accuracy: 0.7781 - val_loss: 0.4506 - val_accuracy: 0.8212\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4179 - accuracy: 0.7907 - val_loss: 0.4390 - val_accuracy: 0.8156\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4033 - accuracy: 0.8062 - val_loss: 0.4456 - val_accuracy: 0.8212\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3992 - accuracy: 0.8118 - val_loss: 0.4377 - val_accuracy: 0.8268\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4269 - accuracy: 0.8062 - val_loss: 0.4249 - val_accuracy: 0.8156\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4354 - accuracy: 0.7893 - val_loss: 0.4612 - val_accuracy: 0.8045\n",
      "Epoch 113/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4541 - accuracy: 0.7753 - val_loss: 0.4640 - val_accuracy: 0.8101\n",
      "Epoch 114/400\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.4367 - accuracy: 0.7767 - val_loss: 0.4529 - val_accuracy: 0.8045\n",
      "Epoch 115/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.3999 - accuracy: 0.8132 - val_loss: 0.4646 - val_accuracy: 0.8212\n",
      "Epoch 116/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.3971 - accuracy: 0.8104 - val_loss: 0.4362 - val_accuracy: 0.8268\n",
      "Epoch 117/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4051 - accuracy: 0.7978 - val_loss: 0.4632 - val_accuracy: 0.8268\n",
      "Epoch 118/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4376 - accuracy: 0.7893 - val_loss: 0.4498 - val_accuracy: 0.8156\n",
      "Epoch 119/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4167 - accuracy: 0.7837 - val_loss: 0.4529 - val_accuracy: 0.8101\n",
      "Epoch 120/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4160 - accuracy: 0.8062 - val_loss: 0.4466 - val_accuracy: 0.8156\n",
      "Epoch 121/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4164 - accuracy: 0.7963 - val_loss: 0.4328 - val_accuracy: 0.8324\n",
      "Epoch 122/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4088 - accuracy: 0.8132 - val_loss: 0.5141 - val_accuracy: 0.8101\n",
      "Epoch 123/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4158 - accuracy: 0.7963 - val_loss: 0.4800 - val_accuracy: 0.8268\n",
      "Epoch 124/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4084 - accuracy: 0.7949 - val_loss: 0.5718 - val_accuracy: 0.8101\n",
      "Epoch 125/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4391 - accuracy: 0.7978 - val_loss: 0.4478 - val_accuracy: 0.8045\n",
      "Epoch 126/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4190 - accuracy: 0.8118 - val_loss: 0.4307 - val_accuracy: 0.8212\n",
      "Epoch 127/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4145 - accuracy: 0.8104 - val_loss: 0.4297 - val_accuracy: 0.8212\n",
      "Epoch 128/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4226 - accuracy: 0.7823 - val_loss: 0.4191 - val_accuracy: 0.8212\n",
      "Epoch 129/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4261 - accuracy: 0.7739 - val_loss: 0.4407 - val_accuracy: 0.8212\n",
      "Epoch 130/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4115 - accuracy: 0.8174 - val_loss: 0.4530 - val_accuracy: 0.8045\n",
      "Epoch 131/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4317 - accuracy: 0.8160 - val_loss: 0.4534 - val_accuracy: 0.8156\n",
      "Epoch 132/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4132 - accuracy: 0.8104 - val_loss: 0.4445 - val_accuracy: 0.8156\n",
      "Epoch 133/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.3948 - accuracy: 0.8146 - val_loss: 0.4659 - val_accuracy: 0.8380\n",
      "Epoch 134/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4120 - accuracy: 0.8118 - val_loss: 0.4392 - val_accuracy: 0.7989\n",
      "Epoch 135/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.3920 - accuracy: 0.8146 - val_loss: 0.4986 - val_accuracy: 0.8101\n",
      "Epoch 136/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4283 - accuracy: 0.8006 - val_loss: 0.4382 - val_accuracy: 0.8212\n",
      "Epoch 137/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4061 - accuracy: 0.8104 - val_loss: 0.4370 - val_accuracy: 0.8268\n",
      "Epoch 138/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4040 - accuracy: 0.8034 - val_loss: 0.4393 - val_accuracy: 0.8101\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3803 - accuracy: 0.8497 - val_loss: 0.4625 - val_accuracy: 0.8101\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3660 - accuracy: 0.8553 - val_loss: 0.4503 - val_accuracy: 0.8156\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3692 - accuracy: 0.8497 - val_loss: 0.4315 - val_accuracy: 0.8212\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.3765 - accuracy: 0.8511 - val_loss: 0.4416 - val_accuracy: 0.8156\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.3810 - accuracy: 0.8413 - val_loss: 0.4385 - val_accuracy: 0.8101\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3630 - accuracy: 0.8511 - val_loss: 0.4446 - val_accuracy: 0.8101\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3608 - accuracy: 0.8497 - val_loss: 0.4289 - val_accuracy: 0.8045\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.3575 - accuracy: 0.8483 - val_loss: 0.4615 - val_accuracy: 0.8101\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.3582 - accuracy: 0.8638 - val_loss: 0.4577 - val_accuracy: 0.8212\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3723 - accuracy: 0.8553 - val_loss: 0.4589 - val_accuracy: 0.8212\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.3824 - accuracy: 0.8497 - val_loss: 0.4527 - val_accuracy: 0.8268\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.3547 - accuracy: 0.8553 - val_loss: 0.4540 - val_accuracy: 0.8156\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3646 - accuracy: 0.8441 - val_loss: 0.4318 - val_accuracy: 0.8268\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.3629 - accuracy: 0.8525 - val_loss: 0.5250 - val_accuracy: 0.7877\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3772 - accuracy: 0.8525 - val_loss: 0.4592 - val_accuracy: 0.8268\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3755 - accuracy: 0.8511 - val_loss: 0.4306 - val_accuracy: 0.8156\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3732 - accuracy: 0.8525 - val_loss: 0.4421 - val_accuracy: 0.8101\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 383us/sample - loss: 0.3514 - accuracy: 0.8596 - val_loss: 0.4591 - val_accuracy: 0.8212\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 244us/sample - loss: 0.3591 - accuracy: 0.8539 - val_loss: 0.4553 - val_accuracy: 0.8156\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 236us/sample - loss: 0.3527 - accuracy: 0.8652 - val_loss: 0.4819 - val_accuracy: 0.8101\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 208us/sample - loss: 0.3522 - accuracy: 0.8553 - val_loss: 0.4774 - val_accuracy: 0.8156\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3620 - accuracy: 0.8525 - val_loss: 0.4638 - val_accuracy: 0.8045\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.3649 - accuracy: 0.8525 - val_loss: 0.4769 - val_accuracy: 0.8045\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3662 - accuracy: 0.8539 - val_loss: 0.4636 - val_accuracy: 0.8045\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.3598 - accuracy: 0.8567 - val_loss: 0.4878 - val_accuracy: 0.7654\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.3536 - accuracy: 0.8469 - val_loss: 0.4725 - val_accuracy: 0.8156\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.3705 - accuracy: 0.8427 - val_loss: 0.4611 - val_accuracy: 0.8101\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.3869 - accuracy: 0.8497 - val_loss: 0.4504 - val_accuracy: 0.8268\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4010 - accuracy: 0.8413 - val_loss: 0.4479 - val_accuracy: 0.8212\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.3921 - accuracy: 0.8525 - val_loss: 0.4759 - val_accuracy: 0.7709\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4051 - accuracy: 0.8357 - val_loss: 0.5091 - val_accuracy: 0.7933\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4343 - accuracy: 0.8287 - val_loss: 0.4408 - val_accuracy: 0.8268\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.3923 - accuracy: 0.8441 - val_loss: 0.4370 - val_accuracy: 0.8212\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.3844 - accuracy: 0.8455 - val_loss: 0.4334 - val_accuracy: 0.8156\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.3829 - accuracy: 0.8483 - val_loss: 0.4366 - val_accuracy: 0.8212\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.3760 - accuracy: 0.8539 - val_loss: 0.4330 - val_accuracy: 0.8156\n",
      "Epoch 113/400\n",
      "712/712 [==============================] - 0s 214us/sample - loss: 0.3760 - accuracy: 0.8596 - val_loss: 0.4399 - val_accuracy: 0.8045\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4105 - accuracy: 0.8385 - val_loss: 0.4302 - val_accuracy: 0.8212\n",
      "Epoch 392/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4184 - accuracy: 0.8315 - val_loss: 0.4316 - val_accuracy: 0.8212\n",
      "Epoch 393/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4283 - accuracy: 0.8244 - val_loss: 0.4305 - val_accuracy: 0.8212\n",
      "Epoch 394/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4166 - accuracy: 0.8329 - val_loss: 0.4296 - val_accuracy: 0.8212\n",
      "Epoch 395/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4080 - accuracy: 0.8258 - val_loss: 0.4303 - val_accuracy: 0.8268\n",
      "Epoch 396/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4067 - accuracy: 0.8287 - val_loss: 0.4315 - val_accuracy: 0.8212\n",
      "Epoch 397/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4099 - accuracy: 0.8427 - val_loss: 0.4316 - val_accuracy: 0.8212\n",
      "Epoch 398/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4139 - accuracy: 0.8329 - val_loss: 0.4330 - val_accuracy: 0.8268\n",
      "Epoch 399/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4339 - accuracy: 0.8244 - val_loss: 0.4335 - val_accuracy: 0.8268\n",
      "Epoch 400/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4163 - accuracy: 0.8329 - val_loss: 0.4343 - val_accuracy: 0.8212\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/400\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.6681 - accuracy: 0.6194 - val_loss: 0.6705 - val_accuracy: 0.5866\n",
      "Epoch 2/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6629 - accuracy: 0.6222 - val_loss: 0.6669 - val_accuracy: 0.5866\n",
      "Epoch 3/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6565 - accuracy: 0.6292 - val_loss: 0.6615 - val_accuracy: 0.5866\n",
      "Epoch 4/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6557 - accuracy: 0.6236 - val_loss: 0.6576 - val_accuracy: 0.5866\n",
      "Epoch 5/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6598 - accuracy: 0.6208 - val_loss: 0.6543 - val_accuracy: 0.5866\n",
      "Epoch 6/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6531 - accuracy: 0.6250 - val_loss: 0.6492 - val_accuracy: 0.5866\n",
      "Epoch 7/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6474 - accuracy: 0.6222 - val_loss: 0.6429 - val_accuracy: 0.5866\n",
      "Epoch 8/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6547 - accuracy: 0.6152 - val_loss: 0.6383 - val_accuracy: 0.5866\n",
      "Epoch 9/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6429 - accuracy: 0.6222 - val_loss: 0.6320 - val_accuracy: 0.5866\n",
      "Epoch 10/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6466 - accuracy: 0.6264 - val_loss: 0.6285 - val_accuracy: 0.5866\n",
      "Epoch 11/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6415 - accuracy: 0.6236 - val_loss: 0.6238 - val_accuracy: 0.5866\n",
      "Epoch 12/400\n",
      "712/712 [==============================] - 0s 215us/sample - loss: 0.6316 - accuracy: 0.6208 - val_loss: 0.6169 - val_accuracy: 0.5866\n",
      "Epoch 13/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6389 - accuracy: 0.6292 - val_loss: 0.6089 - val_accuracy: 0.5866\n",
      "Epoch 14/400\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6291 - accuracy: 0.6278 - val_loss: 0.6036 - val_accuracy: 0.5866\n",
      "Epoch 15/400\n",
      "712/712 [==============================] - 0s 219us/sample - loss: 0.6405 - accuracy: 0.6194 - val_loss: 0.5994 - val_accuracy: 0.6201\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 219us/sample - loss: 0.6302 - accuracy: 0.6348 - val_loss: 0.5936 - val_accuracy: 0.6536\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 232us/sample - loss: 0.6326 - accuracy: 0.6292 - val_loss: 0.5875 - val_accuracy: 0.6648\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6161 - accuracy: 0.6545 - val_loss: 0.5816 - val_accuracy: 0.6816\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6213 - accuracy: 0.6390 - val_loss: 0.5763 - val_accuracy: 0.7039\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6191 - accuracy: 0.6559 - val_loss: 0.5702 - val_accuracy: 0.7095\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5974 - accuracy: 0.6643 - val_loss: 0.5614 - val_accuracy: 0.6983\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6134 - accuracy: 0.6573 - val_loss: 0.5519 - val_accuracy: 0.7207\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5977 - accuracy: 0.6868 - val_loss: 0.5452 - val_accuracy: 0.7263\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5914 - accuracy: 0.6966 - val_loss: 0.5371 - val_accuracy: 0.7598\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6009 - accuracy: 0.6742 - val_loss: 0.5310 - val_accuracy: 0.7654\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6081 - accuracy: 0.6868 - val_loss: 0.5286 - val_accuracy: 0.8101\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6021 - accuracy: 0.6966 - val_loss: 0.5230 - val_accuracy: 0.7765\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6140 - accuracy: 0.6671 - val_loss: 0.5229 - val_accuracy: 0.7933\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5861 - accuracy: 0.7037 - val_loss: 0.5160 - val_accuracy: 0.7989\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5745 - accuracy: 0.7121 - val_loss: 0.5072 - val_accuracy: 0.7989\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5797 - accuracy: 0.7191 - val_loss: 0.5019 - val_accuracy: 0.7933\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5747 - accuracy: 0.6994 - val_loss: 0.4959 - val_accuracy: 0.7989\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5734 - accuracy: 0.7163 - val_loss: 0.4917 - val_accuracy: 0.7989\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5615 - accuracy: 0.7416 - val_loss: 0.4843 - val_accuracy: 0.8101\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5634 - accuracy: 0.7093 - val_loss: 0.4792 - val_accuracy: 0.8045\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5507 - accuracy: 0.7219 - val_loss: 0.4759 - val_accuracy: 0.8045\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5683 - accuracy: 0.7261 - val_loss: 0.4743 - val_accuracy: 0.8045\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5679 - accuracy: 0.7037 - val_loss: 0.4750 - val_accuracy: 0.8045\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5744 - accuracy: 0.7149 - val_loss: 0.4728 - val_accuracy: 0.8156\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5523 - accuracy: 0.7261 - val_loss: 0.4736 - val_accuracy: 0.7989\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5672 - accuracy: 0.7346 - val_loss: 0.4708 - val_accuracy: 0.8045\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5588 - accuracy: 0.7275 - val_loss: 0.4685 - val_accuracy: 0.8156\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5420 - accuracy: 0.7317 - val_loss: 0.4652 - val_accuracy: 0.7989\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5527 - accuracy: 0.7514 - val_loss: 0.4601 - val_accuracy: 0.8212\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5490 - accuracy: 0.7416 - val_loss: 0.4582 - val_accuracy: 0.8156\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5526 - accuracy: 0.7360 - val_loss: 0.4584 - val_accuracy: 0.8156\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5384 - accuracy: 0.7402 - val_loss: 0.4560 - val_accuracy: 0.8268\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5310 - accuracy: 0.7486 - val_loss: 0.4531 - val_accuracy: 0.8212\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5215 - accuracy: 0.7626 - val_loss: 0.4490 - val_accuracy: 0.8268\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5050 - accuracy: 0.7753 - val_loss: 0.4463 - val_accuracy: 0.8156\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5548 - accuracy: 0.7472 - val_loss: 0.4483 - val_accuracy: 0.8101\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.5286 - accuracy: 0.7430 - val_loss: 0.4483 - val_accuracy: 0.8045\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5250 - accuracy: 0.7683 - val_loss: 0.4467 - val_accuracy: 0.7989\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5212 - accuracy: 0.7767 - val_loss: 0.4456 - val_accuracy: 0.7933\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5060 - accuracy: 0.7697 - val_loss: 0.4425 - val_accuracy: 0.8101\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5461 - accuracy: 0.7472 - val_loss: 0.4407 - val_accuracy: 0.8101\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5409 - accuracy: 0.7542 - val_loss: 0.4421 - val_accuracy: 0.8156\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5344 - accuracy: 0.7402 - val_loss: 0.4422 - val_accuracy: 0.8101\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5106 - accuracy: 0.7683 - val_loss: 0.4397 - val_accuracy: 0.8212\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5091 - accuracy: 0.7767 - val_loss: 0.4383 - val_accuracy: 0.8212\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5176 - accuracy: 0.7584 - val_loss: 0.4380 - val_accuracy: 0.8156\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5218 - accuracy: 0.7444 - val_loss: 0.4390 - val_accuracy: 0.8212\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5232 - accuracy: 0.7795 - val_loss: 0.4394 - val_accuracy: 0.8212\n",
      "Epoch 64/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5279 - accuracy: 0.7612 - val_loss: 0.4381 - val_accuracy: 0.8156\n",
      "Epoch 65/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5059 - accuracy: 0.7781 - val_loss: 0.4383 - val_accuracy: 0.8156\n",
      "Epoch 66/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5021 - accuracy: 0.7612 - val_loss: 0.4348 - val_accuracy: 0.8101\n",
      "Epoch 67/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5343 - accuracy: 0.7514 - val_loss: 0.4338 - val_accuracy: 0.8156\n",
      "Epoch 68/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5035 - accuracy: 0.7669 - val_loss: 0.4348 - val_accuracy: 0.8156\n",
      "Epoch 69/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5124 - accuracy: 0.7570 - val_loss: 0.4338 - val_accuracy: 0.8156\n",
      "Epoch 70/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5093 - accuracy: 0.7654 - val_loss: 0.4337 - val_accuracy: 0.8156\n",
      "Epoch 71/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5020 - accuracy: 0.7795 - val_loss: 0.4334 - val_accuracy: 0.8101\n",
      "Epoch 72/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4965 - accuracy: 0.7837 - val_loss: 0.4342 - val_accuracy: 0.8156\n",
      "Epoch 73/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4952 - accuracy: 0.7725 - val_loss: 0.4309 - val_accuracy: 0.8101\n",
      "Epoch 74/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4917 - accuracy: 0.7795 - val_loss: 0.4289 - val_accuracy: 0.8156\n",
      "Epoch 75/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5048 - accuracy: 0.7809 - val_loss: 0.4295 - val_accuracy: 0.8101\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5054 - accuracy: 0.7725 - val_loss: 0.4301 - val_accuracy: 0.8101\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4765 - accuracy: 0.7949 - val_loss: 0.4300 - val_accuracy: 0.8101\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4937 - accuracy: 0.7823 - val_loss: 0.4293 - val_accuracy: 0.8101\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.5221 - accuracy: 0.7697 - val_loss: 0.4304 - val_accuracy: 0.8101\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4909 - accuracy: 0.7907 - val_loss: 0.4305 - val_accuracy: 0.8045\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4951 - accuracy: 0.7879 - val_loss: 0.4297 - val_accuracy: 0.8101\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.4986 - accuracy: 0.7865 - val_loss: 0.4300 - val_accuracy: 0.8045\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4875 - accuracy: 0.7795 - val_loss: 0.4293 - val_accuracy: 0.8045\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 256us/sample - loss: 0.5051 - accuracy: 0.7725 - val_loss: 0.4309 - val_accuracy: 0.8045\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.4891 - accuracy: 0.7795 - val_loss: 0.4299 - val_accuracy: 0.8045\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4835 - accuracy: 0.7893 - val_loss: 0.4295 - val_accuracy: 0.8101\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4933 - accuracy: 0.7879 - val_loss: 0.4294 - val_accuracy: 0.8101\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4948 - accuracy: 0.7781 - val_loss: 0.4295 - val_accuracy: 0.8101\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4835 - accuracy: 0.8034 - val_loss: 0.4299 - val_accuracy: 0.8101\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4949 - accuracy: 0.7739 - val_loss: 0.4291 - val_accuracy: 0.8156\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4764 - accuracy: 0.7809 - val_loss: 0.4281 - val_accuracy: 0.8156\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5016 - accuracy: 0.7837 - val_loss: 0.4282 - val_accuracy: 0.8156\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4949 - accuracy: 0.7781 - val_loss: 0.4288 - val_accuracy: 0.8156\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4855 - accuracy: 0.7935 - val_loss: 0.4299 - val_accuracy: 0.8156\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4882 - accuracy: 0.7879 - val_loss: 0.4317 - val_accuracy: 0.8045\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4614 - accuracy: 0.8118 - val_loss: 0.4289 - val_accuracy: 0.8101\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4677 - accuracy: 0.7992 - val_loss: 0.4288 - val_accuracy: 0.8045\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4717 - accuracy: 0.7992 - val_loss: 0.4297 - val_accuracy: 0.8045\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4721 - accuracy: 0.8062 - val_loss: 0.4292 - val_accuracy: 0.8045\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4726 - accuracy: 0.8048 - val_loss: 0.4297 - val_accuracy: 0.8045\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4649 - accuracy: 0.7992 - val_loss: 0.4287 - val_accuracy: 0.8045\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4882 - accuracy: 0.7935 - val_loss: 0.4284 - val_accuracy: 0.8101\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4784 - accuracy: 0.7963 - val_loss: 0.4281 - val_accuracy: 0.8101\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4768 - accuracy: 0.7963 - val_loss: 0.4283 - val_accuracy: 0.8101\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4939 - accuracy: 0.7893 - val_loss: 0.4291 - val_accuracy: 0.8045\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4649 - accuracy: 0.8104 - val_loss: 0.4295 - val_accuracy: 0.8101\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4411 - accuracy: 0.8216 - val_loss: 0.4277 - val_accuracy: 0.8156\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4733 - accuracy: 0.7963 - val_loss: 0.4270 - val_accuracy: 0.8156\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4683 - accuracy: 0.8048 - val_loss: 0.4272 - val_accuracy: 0.8156\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4739 - accuracy: 0.7992 - val_loss: 0.4281 - val_accuracy: 0.8156\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 243us/sample - loss: 0.4854 - accuracy: 0.7963 - val_loss: 0.4304 - val_accuracy: 0.8101\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.4641 - accuracy: 0.7893 - val_loss: 0.4283 - val_accuracy: 0.8156\n",
      "Epoch 113/400\n",
      "712/712 [==============================] - 0s 207us/sample - loss: 0.4918 - accuracy: 0.7879 - val_loss: 0.4301 - val_accuracy: 0.8101\n",
      "Epoch 114/400\n",
      "712/712 [==============================] - 0s 223us/sample - loss: 0.4526 - accuracy: 0.8118 - val_loss: 0.4277 - val_accuracy: 0.8156\n",
      "Epoch 115/400\n",
      "712/712 [==============================] - 0s 224us/sample - loss: 0.4585 - accuracy: 0.8160 - val_loss: 0.4282 - val_accuracy: 0.8156\n",
      "Epoch 116/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4924 - accuracy: 0.7935 - val_loss: 0.4285 - val_accuracy: 0.8156\n",
      "Epoch 117/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4734 - accuracy: 0.7935 - val_loss: 0.4288 - val_accuracy: 0.8156\n",
      "Epoch 118/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4685 - accuracy: 0.8006 - val_loss: 0.4286 - val_accuracy: 0.8156\n",
      "Epoch 119/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4735 - accuracy: 0.7963 - val_loss: 0.4298 - val_accuracy: 0.8156\n",
      "Epoch 120/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4686 - accuracy: 0.8076 - val_loss: 0.4288 - val_accuracy: 0.8156\n",
      "Epoch 121/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4560 - accuracy: 0.8104 - val_loss: 0.4294 - val_accuracy: 0.8101\n",
      "Epoch 122/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4653 - accuracy: 0.8020 - val_loss: 0.4276 - val_accuracy: 0.8156\n",
      "Epoch 123/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4691 - accuracy: 0.7963 - val_loss: 0.4302 - val_accuracy: 0.8156\n",
      "Epoch 124/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4735 - accuracy: 0.7963 - val_loss: 0.4307 - val_accuracy: 0.8156\n",
      "Epoch 125/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4281 - val_accuracy: 0.8101\n",
      "Epoch 126/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4876 - accuracy: 0.7907 - val_loss: 0.4288 - val_accuracy: 0.8156\n",
      "Epoch 127/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4758 - accuracy: 0.7978 - val_loss: 0.4309 - val_accuracy: 0.8101\n",
      "Epoch 128/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4700 - accuracy: 0.8076 - val_loss: 0.4294 - val_accuracy: 0.8156\n",
      "Epoch 129/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4773 - accuracy: 0.7921 - val_loss: 0.4275 - val_accuracy: 0.8156\n",
      "Epoch 130/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4715 - accuracy: 0.7879 - val_loss: 0.4277 - val_accuracy: 0.8156\n",
      "Epoch 131/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4685 - accuracy: 0.8076 - val_loss: 0.4277 - val_accuracy: 0.8156\n",
      "Epoch 132/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4403 - accuracy: 0.8258 - val_loss: 0.4270 - val_accuracy: 0.8156\n",
      "Epoch 133/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.4703 - accuracy: 0.8076 - val_loss: 0.4276 - val_accuracy: 0.8101\n",
      "Epoch 134/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4699 - accuracy: 0.8118 - val_loss: 0.4275 - val_accuracy: 0.8156\n",
      "Epoch 135/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4647 - accuracy: 0.8034 - val_loss: 0.4271 - val_accuracy: 0.8156\n",
      "Epoch 136/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4539 - accuracy: 0.8146 - val_loss: 0.4303 - val_accuracy: 0.8101\n",
      "Epoch 137/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4707 - accuracy: 0.7978 - val_loss: 0.4283 - val_accuracy: 0.8156\n",
      "Epoch 138/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4650 - accuracy: 0.8020 - val_loss: 0.4274 - val_accuracy: 0.8156\n",
      "Epoch 139/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4728 - accuracy: 0.7963 - val_loss: 0.4279 - val_accuracy: 0.8156\n",
      "Epoch 140/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4760 - accuracy: 0.8104 - val_loss: 0.4285 - val_accuracy: 0.8156\n",
      "Epoch 141/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4709 - accuracy: 0.8090 - val_loss: 0.4297 - val_accuracy: 0.8156\n",
      "Epoch 142/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4480 - accuracy: 0.8104 - val_loss: 0.4272 - val_accuracy: 0.8156\n",
      "Epoch 143/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4469 - accuracy: 0.8118 - val_loss: 0.4262 - val_accuracy: 0.8212\n",
      "Epoch 144/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4505 - accuracy: 0.8118 - val_loss: 0.4268 - val_accuracy: 0.8156\n",
      "Epoch 145/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4699 - accuracy: 0.8006 - val_loss: 0.4277 - val_accuracy: 0.8156\n",
      "Epoch 146/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4628 - accuracy: 0.8132 - val_loss: 0.4278 - val_accuracy: 0.8156\n",
      "Epoch 147/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4628 - accuracy: 0.8034 - val_loss: 0.4280 - val_accuracy: 0.8156\n",
      "Epoch 148/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4414 - accuracy: 0.8202 - val_loss: 0.4269 - val_accuracy: 0.8156\n",
      "Epoch 149/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4455 - accuracy: 0.8188 - val_loss: 0.4285 - val_accuracy: 0.8156\n",
      "Epoch 150/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4723 - accuracy: 0.7865 - val_loss: 0.4292 - val_accuracy: 0.8156\n",
      "Epoch 151/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4600 - accuracy: 0.8062 - val_loss: 0.4294 - val_accuracy: 0.8156\n",
      "Epoch 152/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4660 - accuracy: 0.8174 - val_loss: 0.4282 - val_accuracy: 0.8156\n",
      "Epoch 153/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4514 - accuracy: 0.8118 - val_loss: 0.4284 - val_accuracy: 0.8156\n",
      "Epoch 154/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4394 - accuracy: 0.7963 - val_loss: 0.4280 - val_accuracy: 0.8156\n",
      "Epoch 155/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4641 - accuracy: 0.7978 - val_loss: 0.4291 - val_accuracy: 0.8156\n",
      "Epoch 156/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4507 - accuracy: 0.8301 - val_loss: 0.4278 - val_accuracy: 0.8156\n",
      "Epoch 157/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4480 - accuracy: 0.8118 - val_loss: 0.4284 - val_accuracy: 0.8156\n",
      "Epoch 158/400\n",
      "712/712 [==============================] - 0s 400us/sample - loss: 0.4514 - accuracy: 0.8104 - val_loss: 0.4285 - val_accuracy: 0.8156\n",
      "Epoch 159/400\n",
      "712/712 [==============================] - 0s 269us/sample - loss: 0.4541 - accuracy: 0.7978 - val_loss: 0.4287 - val_accuracy: 0.8156\n",
      "Epoch 160/400\n",
      "712/712 [==============================] - 0s 244us/sample - loss: 0.4603 - accuracy: 0.7978 - val_loss: 0.4270 - val_accuracy: 0.8156\n",
      "Epoch 161/400\n",
      "712/712 [==============================] - 0s 216us/sample - loss: 0.4466 - accuracy: 0.8160 - val_loss: 0.4262 - val_accuracy: 0.8156\n",
      "Epoch 162/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4541 - accuracy: 0.8132 - val_loss: 0.4267 - val_accuracy: 0.8156\n",
      "Epoch 163/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4493 - accuracy: 0.8188 - val_loss: 0.4274 - val_accuracy: 0.8156\n",
      "Epoch 164/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4444 - accuracy: 0.8160 - val_loss: 0.4270 - val_accuracy: 0.8156\n",
      "Epoch 165/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4518 - accuracy: 0.8160 - val_loss: 0.4283 - val_accuracy: 0.8156\n",
      "Epoch 166/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4618 - accuracy: 0.8020 - val_loss: 0.4291 - val_accuracy: 0.8156\n",
      "Epoch 167/400\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4416 - accuracy: 0.8287 - val_loss: 0.4273 - val_accuracy: 0.8156\n",
      "Epoch 168/400\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.4339 - accuracy: 0.8230 - val_loss: 0.4270 - val_accuracy: 0.8156\n",
      "Epoch 169/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4443 - accuracy: 0.8104 - val_loss: 0.4279 - val_accuracy: 0.8156\n",
      "Epoch 170/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4665 - accuracy: 0.8020 - val_loss: 0.4264 - val_accuracy: 0.8156\n",
      "Epoch 171/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4473 - accuracy: 0.8118 - val_loss: 0.4267 - val_accuracy: 0.8156\n",
      "Epoch 172/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4498 - accuracy: 0.8160 - val_loss: 0.4262 - val_accuracy: 0.8156\n",
      "Epoch 173/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4426 - accuracy: 0.8202 - val_loss: 0.4265 - val_accuracy: 0.8156\n",
      "Epoch 174/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4327 - accuracy: 0.8287 - val_loss: 0.4261 - val_accuracy: 0.8156\n",
      "Epoch 175/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4573 - accuracy: 0.8104 - val_loss: 0.4277 - val_accuracy: 0.8156\n",
      "Epoch 176/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4538 - accuracy: 0.7963 - val_loss: 0.4270 - val_accuracy: 0.8156\n",
      "Epoch 177/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4582 - accuracy: 0.8160 - val_loss: 0.4271 - val_accuracy: 0.8156\n",
      "Epoch 178/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4368 - accuracy: 0.8216 - val_loss: 0.4280 - val_accuracy: 0.8156\n",
      "Epoch 179/400\n",
      " 32/712 [>.............................] - ETA: 0s - loss: 0.4922 - accuracy: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
     ]
    }
   ],
   "source": [
    "tuner.search(train_X, train_Y, epochs=N_EPOCH_SEARCH, validation_data=(dev_X, dev_Y))\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 6,\n",
       " 'dense_units_0': 24,\n",
       " 'dense_activation_0': 'tanh',\n",
       " 'dropout_0': 0.1,\n",
       " 'dense_units_1': 64,\n",
       " 'dense_activation_1': 'relu',\n",
       " 'dropout_1': 0.4,\n",
       " 'dense_units_2': 56,\n",
       " 'dense_activation_2': 'tanh',\n",
       " 'dropout_2': 0.05,\n",
       " 'dense_units_3': 32,\n",
       " 'dense_activation_3': 'tanh',\n",
       " 'dropout_3': 0.4,\n",
       " 'dense_units_4': 16,\n",
       " 'dense_activation_4': 'relu',\n",
       " 'dropout_4': 0.1,\n",
       " 'dense_units_5': 56,\n",
       " 'dense_activation_5': 'relu',\n",
       " 'dropout_5': 0.30000000000000004,\n",
       " 'dense_units_6': 48,\n",
       " 'dense_activation_6': 'tanh',\n",
       " 'dropout_6': 0.30000000000000004,\n",
       " 'learning_rate': 0.008367811950596679}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model\n",
      "712/712 [==============================] - 0s 232us/sample - loss: 0.4344 - accuracy: 0.8315\n",
      "Tuned train accuracy: 0.8314606547355652\n",
      "179/179 [==============================] - 0s 94us/sample - loss: 0.4277 - accuracy: 0.8715\n",
      "Tuned dev accuracy: 0.8715083599090576\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 24)                504       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1600      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 56)                3640      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1824      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 56)                952       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 48)                2736      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 11,833\n",
      "Trainable params: 11,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model\")\n",
    "\n",
    "# Get the best model tuned.\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "_, accuracy = best_model.evaluate(train_X, train_Y)\n",
    "print(f\"Tuned train accuracy: {accuracy}\")\n",
    "\n",
    "_, accuracy = best_model.evaluate(dev_X, dev_Y)\n",
    "print(f\"Tuned dev accuracy: {accuracy}\")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_predictions(model, submission_name):\n",
    "    predictions = model.predict(test_data_X)\n",
    "\n",
    "    predictions = np.round(predictions).astype(np.uint8).reshape((-1))\n",
    "\n",
    "    print(f\"{submission_name}:\\n{predictions}\")\n",
    "    \n",
    "    output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "    output.to_csv(f\"{submission_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0\n",
      " 0 1 0 1 1 0 0 1 0 0 1]\n",
      "dl_tuned_submission:\n",
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0\n",
      " 0 1 1 1 1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "store_predictions(model, \"dl_submission\")\n",
    "store_predictions(best_model, \"dl_tuned_submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
