{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONHASHSEED=0\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONHASHSEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\r\n",
      "  Downloading pip-20.1.1-py2.py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 4.6 MB/s \r\n",
      "\u001b[?25hInstalling collected packages: pip\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 20.1\r\n",
      "    Uninstalling pip-20.1:\r\n",
      "      Successfully uninstalled pip-20.1\r\n",
      "Successfully installed pip-20.1.1\r\n",
      "Collecting keras-tuner\r\n",
      "  Downloading keras-tuner-1.0.1.tar.gz (54 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 54 kB 1.3 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (1.18.1)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.8.7)\r\n",
      "Collecting terminaltables\r\n",
      "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (4.45.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (2.23.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (1.4.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.22.2.post1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (2020.4.5.1)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (2.9)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (1.24.3)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (3.0.4)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->keras-tuner) (0.14.1)\r\n",
      "Building wheels for collected packages: keras-tuner, terminaltables\r\n",
      "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-py3-none-any.whl size=73198 sha256=9a45f31c929d6de4e42caca6051f2492e8f777f1f84c73c0e96cf56fdeb110f0\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/cf/2f/1a1749d3a3650fac3305a8d7f9237b6de7c41068e2f8520ca2\r\n",
      "  Building wheel for terminaltables (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=fec4263c3ed9975c0132c49252ff43e5fd8635cc263a53c40123aa598d7b57b5\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\r\n",
      "Successfully built keras-tuner terminaltables\r\n",
      "Installing collected packages: terminaltables, keras-tuner\r\n",
      "Successfully installed keras-tuner-1.0.1 terminaltables-3.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# To display all the columns from left to right without breaking into next line.\n",
    "pd.set_option(\"display.width\", 1500)\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# notebook\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define seed to reprodicibility of random generation\n",
    "SEED = 42\n",
    "\n",
    "DEV_SPLIT=0.2\n",
    "\n",
    "# MODE = \"DEV\"\n",
    "MODE = \"EVAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as python_random\n",
    "\n",
    "# Make sure Keras produces reproducible results.\n",
    "\n",
    "np.random.seed(SEED)\n",
    "python_random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print(physical_devices)\n",
    "for device in (physical_devices or []):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Read data and extract usable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\", index_col=\"PassengerId\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\", index_col=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n",
      "(891,)\n",
      "(418, 9)\n"
     ]
    }
   ],
   "source": [
    "features = \"Pclass Sex SibSp Parch Fare Embarked Name Cabin Age\".split()\n",
    "\n",
    "X_train_init = train_data[features]\n",
    "Y_train_init = train_data.Survived\n",
    "\n",
    "print(X_train_init.shape)\n",
    "print(Y_train_init.shape)\n",
    "\n",
    "X_test_init = test_data[features]\n",
    "\n",
    "print(X_test_init.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Split into train/dev sets\n",
    "## Needs to be done before pre-processing to avoid test-train contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 9) (712,)\n",
      "(179, 9) (179,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# if MODE == \"DEV\":\n",
    "X_train_unproc, X_dev_unproc, Y_train_unproc, Y_dev_unproc = train_test_split(X_train_init, Y_train_init, test_size=DEV_SPLIT, random_state=SEED)\n",
    "\n",
    "print(X_train_unproc.shape, Y_train_unproc.shape)\n",
    "print(X_dev_unproc.shape, Y_dev_unproc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Data observations\n",
    "*Have NaNs:* Age, Fare (some zeros, nans too), Cabin, Embarked\n",
    "*NOTE:* maybe need to approximate missing values using some other technique, like an additional model?\n",
    "\n",
    "* (+) Pclass:\n",
    "  * 1 - 3 number, 1 being the highest\n",
    "  * Range: 1-3\n",
    "  * Current approach: convert to one-hot.\n",
    "  * Previous approaches:\n",
    "      * normalize by 3.\n",
    "* (+) Name:\n",
    "  * has person's title, which could be used (Mr, Ms, Mrs, etc.)\n",
    "  * From title, can infer marital status?\n",
    "  * Current approach: extract titles, replace infrequent ones with \"Others\", convert them to one-hot, and calculate 'Married' based on title (1 - married (Mr, Mrs), -1 - unmarried (Miss, Master), 0 - unknown (other titles))\n",
    "  * Potential improvements: use more titles for getting 'married'; use 'maiden name' in calculation of 'married'; use 'nickname' somehow?\n",
    "* (+) Sex:\n",
    "  * Either male or female\n",
    "  * male: 65%, female: 35%\n",
    "  * Current approach: convert to one-hot.\n",
    "  * Potential improvements: use 1 and -1 for sexes?\n",
    "* (+) Age:\n",
    "  * has fractions if approximated. Has missing values.\n",
    "  * Range: 0.42-80\n",
    "  * Current approach: fill NaN with average in group-by Pclass-Sex, but create a column that identifies missing values. Also, normalize by 80.\n",
    "  * Potential improvements: have a better approximation of age. Convert to age categories?\n",
    "* (+) SibSp:\n",
    "  * how many siblings or spouses on board.\n",
    "  * Range: 0-8\n",
    "  * Current approach: Add to 'Family'.\n",
    "  * Previous approaches:\n",
    "    * normalize by 8.\n",
    "* (+) Parch:\n",
    "  * How many parents/children. (can be 0 for babies, if with nannies)\n",
    "  * Range: 0-6\n",
    "  * Current approach: Add to 'Family'\n",
    "  * Previous approachesL\n",
    "    * normalize by 6.\n",
    "* Ticket:\n",
    "  * A number with some optional letters (which can have some meaning?).\n",
    "  * Has repetitions (maybe for people travelling together).\n",
    "* (+) Fare:\n",
    "  * can have zeros (what do they mean?). Can have omitted (just one in test).\n",
    "  * Range: 0-512.3292\n",
    "  * Current approach: fill nan with mean, normalize by 512.\n",
    "  * Potential improvements: most fare is <= 30 USD, so maybe use fare categories.\n",
    "* (+) Cabin:\n",
    "  * has a lot of omitted values (78%). Can have multiple values (probably for families?).\n",
    "  * One value is a letter with a number. (both probably have meaning and impact?)\n",
    "  * Current approach: convert to one-hot (based on letter), include a 'nan' column for those that are missing values. Create a column for cabin number, and a column to identify missing numbers.\n",
    "  * Potential improvements: maybe cabin number itself doesn't mean much? Also, maybe need to deal with missing values in a different way? Also, maybe deal with multiple values better?\n",
    "* (+) Embarked:\n",
    "  * Either of 3 letters (with different frequency). Has just a few omitted.\n",
    "  * S - 72/65%, C - 19/24%, Q - 9/11%\n",
    "  * Current approach: convert to one-hot matrix (fill 2 missing with mode)\n",
    "  * Potential improvements: somehow take into the account different distribution of embarkation city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X):\n",
    "    import re\n",
    "    \n",
    "    titles = ['Mr', 'Mrs', 'Miss', 'Master', 'Ms', 'Don', 'Rev', 'Dr', 'Mme', 'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess', 'Jonkheer', 'Dona']\n",
    "    \n",
    "    X = X.copy()\n",
    "    \n",
    "    # === Get X - the features. ===\n",
    "\n",
    "    # == Post-process data ==\n",
    "\n",
    "#     if \"SibSp\" in X:\n",
    "#         X.SibSp = X.SibSp.divide(8)\n",
    "\n",
    "#     if \"Parch\" in X:\n",
    "#         X.Parch = X.Parch.divide(6)\n",
    "        \n",
    "    if \"Parch\" in X and \"SibSp\" in X:\n",
    "        X[\"Family\"] = X.Parch + X.SibSp\n",
    "#         X.Family = X.Family.divide(14)\n",
    "        X = X.drop(columns=\"Parch SibSp\".split())\n",
    "\n",
    "    if \"Fare\" in X:\n",
    "        # Since only a few would miss 'fare' value, it's okay to fill with average.\n",
    "        X.Fare = X.Fare.fillna(X.Fare.mean())\n",
    "        \n",
    "        X.Fare = np.where(X.Fare < 50, 1, 2)\n",
    "        \n",
    "#         X.Fare = X.Fare.divide(512)\n",
    "\n",
    "    if \"Embarked\" in X:\n",
    "        X.Embarked = X.Embarked.fillna(X.Embarked.mode()[0])\n",
    "        X.Embarked = X.Embarked.astype(pd.api.types.CategoricalDtype(categories=\"C Q S\".split()))\n",
    "        X = pd.get_dummies(X, columns=[\"Embarked\"])\n",
    "\n",
    "    if \"Name\" in X:\n",
    "        X[\"Title\"] = X.Name.apply(lambda name: re.search(\", ([\\w ]+).\", name).group(1))\n",
    "\n",
    "        # Try to see if the person is married (1), or not (-1), or unknown (0).\n",
    "        X[\"Married\"] = X.Title.apply(lambda title: 1 if title in \"Mrs Mr\".split() else -1 if title in \"Miss Master\".split() else 0)\n",
    "\n",
    "        # Get dummies for title\n",
    "        \n",
    "        # Include all possible values, even those not present in current dataset.\n",
    "#         X.Title = X.Title.astype(pd.api.types.CategoricalDtype(categories=titles))\n",
    "        \n",
    "        # Titles that are rare are converted to 'Others'\n",
    "        important_titles = ['Mr', 'Mrs', 'Miss', 'Master']\n",
    "        X.Title = X.Title.apply(lambda title: title if title in important_titles else \"Others\")\n",
    "        \n",
    "        X = pd.get_dummies(X, columns=[\"Title\"])\n",
    "        \n",
    "        # We don't need the name itself.\n",
    "        X = X.drop(columns=[\"Name\"])\n",
    "        \n",
    "    if \"Cabin\" in X:\n",
    "        X[\"Cabin_Missing\"] = np.where(X.Cabin.isnull(), 1, 0)\n",
    "        X.Cabin = X.Cabin.fillna(\"-\")\n",
    "        \n",
    "#         X[\"Cabin_Number\"] = X.Cabin.apply(lambda cabin: int(re.search(\"\\w(\\d+)\", cabin).group(1)) if len(cabin) > 1 else 0)\n",
    "#         # Do some sort of normalization.\n",
    "#         X.Cabin_Number = X.Cabin_Number.divide(200)\n",
    "#         X[\"Cabin_Number_Missing\"] = np.where(X.Cabin_Number == 0, 1, 0)\n",
    "        \n",
    "        X.Cabin = X.Cabin.apply(lambda cabin: cabin[:1])\n",
    "        \n",
    "        # Convert to one-hot\n",
    "#         X.Cabin = X.Cabin.astype(pd.api.types.CategoricalDtype(categories=list(\"ABCDEFGT\")))\n",
    "#         X = pd.get_dummies(X, columns=[\"Cabin\"], dummy_na=True)\n",
    "\n",
    "        # Convert to numbers with T beeing the lowest deck and S - the highest (sun deck).\n",
    "        X[\"Deck_Level\"] = X.Cabin.apply(lambda cabin: \"SABCDEFGT\".find(cabin[0]))\n",
    "        X = X.drop(columns=[\"Cabin\"])\n",
    "\n",
    "    if \"Age\" in X:\n",
    "        X[\"Age_Missing\"] = np.where(X.Age.isnull(), 1, 0)\n",
    "\n",
    "        # No need to skip 'nan' for Age when calculating mean, as Pandas does that automatically.\n",
    "        # 'transform' will go through each group, and fill its nan values with its mean value.\n",
    "        # Then, all that will be aggregated back into the column, thus replacing nan values with group's mean.\n",
    "        X[\"Age\"] = X.groupby(\"Pclass Sex\".split())[\"Age\"].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "#         X.Age = X.Age.divide(80)\n",
    "\n",
    "        # Convert age to categories 1 - child, 2 - young, 3 - older, 4 - senile\n",
    "        X.Age = pd.cut(X.Age, bins=[0, 16, 30, 50, 80], labels=False) + 1\n",
    "        \n",
    "    # Needs to be after 'Age', since age is using original Sex column.\n",
    "    if \"Sex\" in X:\n",
    "        X.Sex = X.Sex.astype(pd.api.types.CategoricalDtype(categories=\"male female\".split()))\n",
    "        X = pd.get_dummies(X, columns=[\"Sex\"])\n",
    "\n",
    "    if \"Pclass\" in X:\n",
    "        X = pd.get_dummies(X, columns=[\"Pclass\"])\n",
    "        # Do not normalize small numbers\n",
    "#         X.Pclass = X.Pclass.divide(3)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_clean(X):\n",
    "    import re\n",
    "\n",
    "    important_titles = [\"Mr\", \"Mrs\", \"Miss\", \"Master\"]\n",
    "    \n",
    "    X = X.copy()\n",
    "    \n",
    "    # Remember missing values\n",
    "    for col in \"Age\".split():\n",
    "        X[f\"{col}_Missing\"] = np.where(X[col].isnull(), 1, 0)\n",
    "        \n",
    "    if \"Parch\" in X and \"SibSp\" in X:\n",
    "        X[\"Family\"] = X.Parch + X.SibSp\n",
    "\n",
    "    if \"Fare\" in X:\n",
    "        X.Fare = X.Fare.fillna(X.Fare.mean())\n",
    "        X.Fare = pd.cut(X.Fare, bins=[-1, 15, 30, 50, 70, 100, 600], labels=False) + 1\n",
    "\n",
    "    if \"Embarked\" in X:\n",
    "        X.Embarked = X.Embarked.fillna(X.Embarked.mode()[0])\n",
    "        X.Embarked = X.Embarked.astype(pd.api.types.CategoricalDtype(categories=\"C Q S\".split()))\n",
    "\n",
    "    if \"Name\" in X:\n",
    "        X[\"Title\"] = X.Name.apply(lambda name: re.search(\", ([\\w ]+).\", name).group(1))\n",
    "\n",
    "        X.Title = X.Title.apply(lambda title: title if title in important_titles else \"Others\")\n",
    "\n",
    "#         X[\"Married\"] = X.Title.apply(lambda title: 1 if title in \"Mrs Mr\".split() else -1 if title in \"Miss Master\".split() else 0)\n",
    "        \n",
    "#     if \"Cabin\" in X:   \n",
    "#         X[\"Deck_Level\"] = X.Cabin.fillna(\"-\").apply(lambda cabin: \"SABCDEFGT\".find(cabin[0]))\n",
    "\n",
    "    if \"Age\" in X:\n",
    "        X[\"Age\"] = X.groupby(\"Pclass Sex\".split())[\"Age\"].transform(lambda x: x.fillna(x.mean()))\n",
    "        X.Age = pd.cut(X.Age, bins=[0, 16, 30, 50, 80], labels=False) + 1\n",
    "        \n",
    "    X = X.drop(columns=\"Name Cabin Parch SibSp\".split())\n",
    "        \n",
    "    X = pd.get_dummies(X, columns=\"Sex Embarked Title\".split())\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "             Pclass  Fare  Age  Age_Missing  Family  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Others\n",
      "PassengerId                                                                                                                                                               \n",
      "332               1     2    3            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "734               2     1    2            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "383               3     1    3            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "705               3     1    2            0       1           0         1           0           0           1             0           0         1          0             0\n",
      "814               3     3    1            0       6           1         0           0           0           1             0           1         0          0             0\n",
      "Dev data:\n",
      "             Pclass  Fare  Age  Age_Missing  Family  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Others\n",
      "PassengerId                                                                                                                                                               \n",
      "710               3     2    2            1       2           0         1           1           0           0             1           0         0          0             0\n",
      "440               2     1    3            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "841               3     1    2            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "721               2     3    1            0       1           1         0           0           0           1             0           1         0          0             0\n",
      "40                3     1    1            0       1           1         0           1           0           0             0           1         0          0             0\n",
      "Test data:\n",
      "             Pclass  Fare  Age  Age_Missing  Family  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Others\n",
      "PassengerId                                                                                                                                                               \n",
      "892               3     1    3            0       0           0         1           0           1           0             0           0         1          0             0\n",
      "893               3     1    3            0       1           1         0           0           0           1             0           0         0          1             0\n",
      "894               2     1    4            0       0           0         1           0           1           0             0           0         1          0             0\n",
      "895               3     1    2            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "896               3     1    2            0       2           1         0           0           0           1             0           0         0          1             0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\")\n",
    "X_train = prepare_data_clean(X_train_unproc)\n",
    "Y_train = Y_train_unproc\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"Dev data:\")\n",
    "X_dev = prepare_data_clean(X_dev_unproc)\n",
    "Y_dev = Y_dev_unproc\n",
    "print(X_dev.head())\n",
    "\n",
    "print(\"Test data:\")\n",
    "X_test = prepare_data_clean(X_test_init)\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# DL model using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name=\"tp\"),\n",
    "      keras.metrics.FalsePositives(name=\"fp\"),\n",
    "      keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "      keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "      keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "      keras.metrics.Precision(name=\"precision\"),\n",
    "      keras.metrics.Recall(name=\"recall\"),\n",
    "      keras.metrics.AUC(name=\"auc\"),\n",
    "]\n",
    "\n",
    "def get_model(input_size):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(128, input_shape=(input_size,), activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), kernel_initializer=\"he_uniform\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), kernel_initializer=\"he_uniform\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(20, activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), kernel_initializer=\"he_uniform\"),\n",
    "        Dropout(0.25),\n",
    "        Dense(6, activation=\"tanh\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), kernel_initializer=\"glorot_uniform\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), metrics=METRICS, loss=\"binary_crossentropy\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "died_cnt, survived_cnt = np.bincount(Y_train_init)\n",
    "total_cnt = died_cnt + survived_cnt\n",
    "\n",
    "weight_died = total_cnt / died_cnt / 2\n",
    "weight_survived = total_cnt / survived_cnt / 2\n",
    "\n",
    "class_weights = {0: weight_died, 1: weight_survived}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 4s 6ms/sample - loss: 4.2427 - tp: 43.0000 - fp: 94.0000 - tn: 350.0000 - fn: 225.0000 - accuracy: 0.5520 - precision: 0.3139 - recall: 0.1604 - auc: 0.4788 - val_loss: 3.8703 - val_tp: 37.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 37.0000 - val_accuracy: 0.6927 - val_precision: 0.6727 - val_recall: 0.5000 - val_auc: 0.6613\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 3.7864 - tp: 144.0000 - fp: 206.0000 - tn: 238.0000 - fn: 124.0000 - accuracy: 0.5365 - precision: 0.4114 - recall: 0.5373 - auc: 0.5464 - val_loss: 3.5031 - val_tp: 57.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 17.0000 - val_accuracy: 0.7263 - val_precision: 0.6404 - val_recall: 0.7703 - val_auc: 0.8037\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 3.4381 - tp: 149.0000 - fp: 155.0000 - tn: 289.0000 - fn: 119.0000 - accuracy: 0.6152 - precision: 0.4901 - recall: 0.5560 - auc: 0.6376 - val_loss: 3.1998 - val_tp: 62.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 12.0000 - val_accuracy: 0.7318 - val_precision: 0.6327 - val_recall: 0.8378 - val_auc: 0.8233\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 3.1550 - tp: 161.0000 - fp: 155.0000 - tn: 289.0000 - fn: 107.0000 - accuracy: 0.6320 - precision: 0.5095 - recall: 0.6007 - auc: 0.6799 - val_loss: 2.9368 - val_tp: 49.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7095 - val_precision: 0.6447 - val_recall: 0.6622 - val_auc: 0.8310\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 2.9216 - tp: 142.0000 - fp: 112.0000 - tn: 332.0000 - fn: 126.0000 - accuracy: 0.6657 - precision: 0.5591 - recall: 0.5299 - auc: 0.6860 - val_loss: 2.7074 - val_tp: 60.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 14.0000 - val_accuracy: 0.7430 - val_precision: 0.6522 - val_recall: 0.8108 - val_auc: 0.8352\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 2.6900 - tp: 174.0000 - fp: 136.0000 - tn: 308.0000 - fn: 94.0000 - accuracy: 0.6770 - precision: 0.5613 - recall: 0.6493 - auc: 0.7199 - val_loss: 2.4973 - val_tp: 63.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 11.0000 - val_accuracy: 0.7542 - val_precision: 0.6562 - val_recall: 0.8514 - val_auc: 0.8324\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 2.4600 - tp: 180.0000 - fp: 118.0000 - tn: 326.0000 - fn: 88.0000 - accuracy: 0.7107 - precision: 0.6040 - recall: 0.6716 - auc: 0.7700 - val_loss: 2.3045 - val_tp: 60.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 14.0000 - val_accuracy: 0.7486 - val_precision: 0.6593 - val_recall: 0.8108 - val_auc: 0.8372\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 2.2995 - tp: 186.0000 - fp: 142.0000 - tn: 302.0000 - fn: 82.0000 - accuracy: 0.6854 - precision: 0.5671 - recall: 0.6940 - auc: 0.7591 - val_loss: 2.1314 - val_tp: 58.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 16.0000 - val_accuracy: 0.7430 - val_precision: 0.6591 - val_recall: 0.7838 - val_auc: 0.8555\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 2.1420 - tp: 172.0000 - fp: 92.0000 - tn: 352.0000 - fn: 96.0000 - accuracy: 0.7360 - precision: 0.6515 - recall: 0.6418 - auc: 0.7722 - val_loss: 1.9784 - val_tp: 58.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 16.0000 - val_accuracy: 0.7654 - val_precision: 0.6905 - val_recall: 0.7838 - val_auc: 0.8688\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 1.9771 - tp: 194.0000 - fp: 122.0000 - tn: 322.0000 - fn: 74.0000 - accuracy: 0.7247 - precision: 0.6139 - recall: 0.7239 - auc: 0.7962 - val_loss: 1.8428 - val_tp: 59.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 15.0000 - val_accuracy: 0.7709 - val_precision: 0.6941 - val_recall: 0.7973 - val_auc: 0.8687\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 1.8409 - tp: 195.0000 - fp: 107.0000 - tn: 337.0000 - fn: 73.0000 - accuracy: 0.7472 - precision: 0.6457 - recall: 0.7276 - auc: 0.8087 - val_loss: 1.7246 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8676\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 1.7379 - tp: 191.0000 - fp: 93.0000 - tn: 351.0000 - fn: 77.0000 - accuracy: 0.7612 - precision: 0.6725 - recall: 0.7127 - auc: 0.7975 - val_loss: 1.6178 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8671\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 1.6218 - tp: 205.0000 - fp: 118.0000 - tn: 326.0000 - fn: 63.0000 - accuracy: 0.7458 - precision: 0.6347 - recall: 0.7649 - auc: 0.8137 - val_loss: 1.5186 - val_tp: 55.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 19.0000 - val_accuracy: 0.7654 - val_precision: 0.7051 - val_recall: 0.7432 - val_auc: 0.8662\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 1.5250 - tp: 201.0000 - fp: 89.0000 - tn: 355.0000 - fn: 67.0000 - accuracy: 0.7809 - precision: 0.6931 - recall: 0.7500 - auc: 0.8157 - val_loss: 1.4300 - val_tp: 58.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 16.0000 - val_accuracy: 0.7821 - val_precision: 0.7160 - val_recall: 0.7838 - val_auc: 0.8661\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 1.4449 - tp: 204.0000 - fp: 98.0000 - tn: 346.0000 - fn: 64.0000 - accuracy: 0.7725 - precision: 0.6755 - recall: 0.7612 - auc: 0.8156 - val_loss: 1.3521 - val_tp: 59.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 15.0000 - val_accuracy: 0.7654 - val_precision: 0.6860 - val_recall: 0.7973 - val_auc: 0.8642\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 1.3780 - tp: 194.0000 - fp: 89.0000 - tn: 355.0000 - fn: 74.0000 - accuracy: 0.7711 - precision: 0.6855 - recall: 0.7239 - auc: 0.8032 - val_loss: 1.2767 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8735\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 1.3011 - tp: 189.0000 - fp: 80.0000 - tn: 364.0000 - fn: 79.0000 - accuracy: 0.7767 - precision: 0.7026 - recall: 0.7052 - auc: 0.8149 - val_loss: 1.2097 - val_tp: 54.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 20.0000 - val_accuracy: 0.7821 - val_precision: 0.7397 - val_recall: 0.7297 - val_auc: 0.8791\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 1.2372 - tp: 209.0000 - fp: 95.0000 - tn: 349.0000 - fn: 59.0000 - accuracy: 0.7837 - precision: 0.6875 - recall: 0.7799 - auc: 0.8158 - val_loss: 1.1508 - val_tp: 54.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 20.0000 - val_accuracy: 0.7821 - val_precision: 0.7397 - val_recall: 0.7297 - val_auc: 0.8790\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 1.1665 - tp: 195.0000 - fp: 84.0000 - tn: 360.0000 - fn: 73.0000 - accuracy: 0.7795 - precision: 0.6989 - recall: 0.7276 - auc: 0.8283 - val_loss: 1.0983 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8742\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 1.1220 - tp: 198.0000 - fp: 87.0000 - tn: 357.0000 - fn: 70.0000 - accuracy: 0.7795 - precision: 0.6947 - recall: 0.7388 - auc: 0.8203 - val_loss: 1.0496 - val_tp: 58.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 16.0000 - val_accuracy: 0.7877 - val_precision: 0.7250 - val_recall: 0.7838 - val_auc: 0.8735\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 1.0850 - tp: 196.0000 - fp: 86.0000 - tn: 358.0000 - fn: 72.0000 - accuracy: 0.7781 - precision: 0.6950 - recall: 0.7313 - auc: 0.8117 - val_loss: 1.0062 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8736\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 1.0226 - tp: 206.0000 - fp: 85.0000 - tn: 359.0000 - fn: 62.0000 - accuracy: 0.7935 - precision: 0.7079 - recall: 0.7687 - auc: 0.8278 - val_loss: 0.9643 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8764\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 1.0043 - tp: 194.0000 - fp: 84.0000 - tn: 360.0000 - fn: 74.0000 - accuracy: 0.7781 - precision: 0.6978 - recall: 0.7239 - auc: 0.8137 - val_loss: 0.9312 - val_tp: 58.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 16.0000 - val_accuracy: 0.7821 - val_precision: 0.7160 - val_recall: 0.7838 - val_auc: 0.8727\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.9380 - tp: 204.0000 - fp: 83.0000 - tn: 361.0000 - fn: 64.0000 - accuracy: 0.7935 - precision: 0.7108 - recall: 0.7612 - auc: 0.8439 - val_loss: 0.8936 - val_tp: 54.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 20.0000 - val_accuracy: 0.7821 - val_precision: 0.7397 - val_recall: 0.7297 - val_auc: 0.8784\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.9315 - tp: 196.0000 - fp: 90.0000 - tn: 354.0000 - fn: 72.0000 - accuracy: 0.7725 - precision: 0.6853 - recall: 0.7313 - auc: 0.8210 - val_loss: 0.8651 - val_tp: 58.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 16.0000 - val_accuracy: 0.7765 - val_precision: 0.7073 - val_recall: 0.7838 - val_auc: 0.8694\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.8903 - tp: 202.0000 - fp: 87.0000 - tn: 357.0000 - fn: 66.0000 - accuracy: 0.7851 - precision: 0.6990 - recall: 0.7537 - auc: 0.8303 - val_loss: 0.8367 - val_tp: 57.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 17.0000 - val_accuracy: 0.7877 - val_precision: 0.7308 - val_recall: 0.7703 - val_auc: 0.8769\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.8436 - tp: 209.0000 - fp: 78.0000 - tn: 366.0000 - fn: 59.0000 - accuracy: 0.8076 - precision: 0.7282 - recall: 0.7799 - auc: 0.8462 - val_loss: 0.8089 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8772\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.8323 - tp: 199.0000 - fp: 70.0000 - tn: 374.0000 - fn: 69.0000 - accuracy: 0.8048 - precision: 0.7398 - recall: 0.7425 - auc: 0.8367 - val_loss: 0.7841 - val_tp: 57.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 17.0000 - val_accuracy: 0.7877 - val_precision: 0.7308 - val_recall: 0.7703 - val_auc: 0.8812\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7871 - tp: 211.0000 - fp: 89.0000 - tn: 355.0000 - fn: 57.0000 - accuracy: 0.7949 - precision: 0.7033 - recall: 0.7873 - auc: 0.8565 - val_loss: 0.7603 - val_tp: 56.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 18.0000 - val_accuracy: 0.7933 - val_precision: 0.7467 - val_recall: 0.7568 - val_auc: 0.8841\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.8101 - tp: 191.0000 - fp: 78.0000 - tn: 366.0000 - fn: 77.0000 - accuracy: 0.7823 - precision: 0.7100 - recall: 0.7127 - auc: 0.8210 - val_loss: 0.7515 - val_tp: 65.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 9.0000 - val_accuracy: 0.7877 - val_precision: 0.6915 - val_recall: 0.8784 - val_auc: 0.8719\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.7907 - tp: 196.0000 - fp: 76.0000 - tn: 368.0000 - fn: 72.0000 - accuracy: 0.7921 - precision: 0.7206 - recall: 0.7313 - auc: 0.8270 - val_loss: 0.7301 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8796\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.7496 - tp: 206.0000 - fp: 78.0000 - tn: 366.0000 - fn: 62.0000 - accuracy: 0.8034 - precision: 0.7254 - recall: 0.7687 - auc: 0.8421 - val_loss: 0.7140 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8816\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.7198 - tp: 201.0000 - fp: 68.0000 - tn: 376.0000 - fn: 67.0000 - accuracy: 0.8104 - precision: 0.7472 - recall: 0.7500 - auc: 0.8586 - val_loss: 0.7023 - val_tp: 55.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 19.0000 - val_accuracy: 0.7877 - val_precision: 0.7432 - val_recall: 0.7432 - val_auc: 0.8844\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7177 - tp: 203.0000 - fp: 75.0000 - tn: 369.0000 - fn: 65.0000 - accuracy: 0.8034 - precision: 0.7302 - recall: 0.7575 - auc: 0.8460 - val_loss: 0.6869 - val_tp: 65.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 9.0000 - val_accuracy: 0.7877 - val_precision: 0.6915 - val_recall: 0.8784 - val_auc: 0.8741\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6921 - tp: 210.0000 - fp: 78.0000 - tn: 366.0000 - fn: 58.0000 - accuracy: 0.8090 - precision: 0.7292 - recall: 0.7836 - auc: 0.8521 - val_loss: 0.6744 - val_tp: 55.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 19.0000 - val_accuracy: 0.7933 - val_precision: 0.7534 - val_recall: 0.7432 - val_auc: 0.8875\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 260us/sample - loss: 0.6994 - tp: 208.0000 - fp: 72.0000 - tn: 372.0000 - fn: 60.0000 - accuracy: 0.8146 - precision: 0.7429 - recall: 0.7761 - auc: 0.8433 - val_loss: 0.6654 - val_tp: 56.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 18.0000 - val_accuracy: 0.7933 - val_precision: 0.7467 - val_recall: 0.7568 - val_auc: 0.8822\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6970 - tp: 196.0000 - fp: 78.0000 - tn: 366.0000 - fn: 72.0000 - accuracy: 0.7893 - precision: 0.7153 - recall: 0.7313 - auc: 0.8387 - val_loss: 0.6520 - val_tp: 56.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 18.0000 - val_accuracy: 0.7933 - val_precision: 0.7467 - val_recall: 0.7568 - val_auc: 0.8819\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6859 - tp: 196.0000 - fp: 64.0000 - tn: 380.0000 - fn: 72.0000 - accuracy: 0.8090 - precision: 0.7538 - recall: 0.7313 - auc: 0.8386 - val_loss: 0.6529 - val_tp: 64.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 10.0000 - val_accuracy: 0.7821 - val_precision: 0.6882 - val_recall: 0.8649 - val_auc: 0.8728\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.6695 - tp: 211.0000 - fp: 80.0000 - tn: 364.0000 - fn: 57.0000 - accuracy: 0.8076 - precision: 0.7251 - recall: 0.7873 - auc: 0.8396 - val_loss: 0.6362 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8808\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.6521 - tp: 209.0000 - fp: 75.0000 - tn: 369.0000 - fn: 59.0000 - accuracy: 0.8118 - precision: 0.7359 - recall: 0.7799 - auc: 0.8519 - val_loss: 0.6264 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8808\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.6443 - tp: 198.0000 - fp: 67.0000 - tn: 377.0000 - fn: 70.0000 - accuracy: 0.8076 - precision: 0.7472 - recall: 0.7388 - auc: 0.8543 - val_loss: 0.6182 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8807\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6620 - tp: 208.0000 - fp: 84.0000 - tn: 360.0000 - fn: 60.0000 - accuracy: 0.7978 - precision: 0.7123 - recall: 0.7761 - auc: 0.8331 - val_loss: 0.6142 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8833\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6273 - tp: 203.0000 - fp: 80.0000 - tn: 364.0000 - fn: 65.0000 - accuracy: 0.7963 - precision: 0.7173 - recall: 0.7575 - auc: 0.8551 - val_loss: 0.6047 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8861\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6313 - tp: 204.0000 - fp: 61.0000 - tn: 383.0000 - fn: 64.0000 - accuracy: 0.8244 - precision: 0.7698 - recall: 0.7612 - auc: 0.8508 - val_loss: 0.5973 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8850\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.6199 - tp: 203.0000 - fp: 69.0000 - tn: 375.0000 - fn: 65.0000 - accuracy: 0.8118 - precision: 0.7463 - recall: 0.7575 - auc: 0.8520 - val_loss: 0.5882 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8856\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6377 - tp: 208.0000 - fp: 81.0000 - tn: 363.0000 - fn: 60.0000 - accuracy: 0.8020 - precision: 0.7197 - recall: 0.7761 - auc: 0.8347 - val_loss: 0.5908 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8873\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6216 - tp: 205.0000 - fp: 78.0000 - tn: 366.0000 - fn: 63.0000 - accuracy: 0.8020 - precision: 0.7244 - recall: 0.7649 - auc: 0.8420 - val_loss: 0.5847 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8880\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5971 - tp: 208.0000 - fp: 76.0000 - tn: 368.0000 - fn: 60.0000 - accuracy: 0.8090 - precision: 0.7324 - recall: 0.7761 - auc: 0.8600 - val_loss: 0.5788 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8852\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6291 - tp: 208.0000 - fp: 77.0000 - tn: 367.0000 - fn: 60.0000 - accuracy: 0.8076 - precision: 0.7298 - recall: 0.7761 - auc: 0.8284 - val_loss: 0.5790 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8829\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6048 - tp: 206.0000 - fp: 70.0000 - tn: 374.0000 - fn: 62.0000 - accuracy: 0.8146 - precision: 0.7464 - recall: 0.7687 - auc: 0.8453 - val_loss: 0.5767 - val_tp: 61.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 13.0000 - val_accuracy: 0.7989 - val_precision: 0.7262 - val_recall: 0.8243 - val_auc: 0.8799\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6087 - tp: 204.0000 - fp: 81.0000 - tn: 363.0000 - fn: 64.0000 - accuracy: 0.7963 - precision: 0.7158 - recall: 0.7612 - auc: 0.8419 - val_loss: 0.5719 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8838\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5982 - tp: 203.0000 - fp: 63.0000 - tn: 381.0000 - fn: 65.0000 - accuracy: 0.8202 - precision: 0.7632 - recall: 0.7575 - auc: 0.8443 - val_loss: 0.5685 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8837\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5929 - tp: 207.0000 - fp: 73.0000 - tn: 371.0000 - fn: 61.0000 - accuracy: 0.8118 - precision: 0.7393 - recall: 0.7724 - auc: 0.8468 - val_loss: 0.5660 - val_tp: 58.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 16.0000 - val_accuracy: 0.7877 - val_precision: 0.7250 - val_recall: 0.7838 - val_auc: 0.8809\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5955 - tp: 211.0000 - fp: 79.0000 - tn: 365.0000 - fn: 57.0000 - accuracy: 0.8090 - precision: 0.7276 - recall: 0.7873 - auc: 0.8441 - val_loss: 0.5643 - val_tp: 55.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 19.0000 - val_accuracy: 0.8045 - val_precision: 0.7746 - val_recall: 0.7432 - val_auc: 0.8887\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5849 - tp: 204.0000 - fp: 68.0000 - tn: 376.0000 - fn: 64.0000 - accuracy: 0.8146 - precision: 0.7500 - recall: 0.7612 - auc: 0.8479 - val_loss: 0.5585 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8881\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5794 - tp: 199.0000 - fp: 65.0000 - tn: 379.0000 - fn: 69.0000 - accuracy: 0.8118 - precision: 0.7538 - recall: 0.7425 - auc: 0.8515 - val_loss: 0.5638 - val_tp: 65.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 9.0000 - val_accuracy: 0.7877 - val_precision: 0.6915 - val_recall: 0.8784 - val_auc: 0.8792\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5844 - tp: 214.0000 - fp: 84.0000 - tn: 360.0000 - fn: 54.0000 - accuracy: 0.8062 - precision: 0.7181 - recall: 0.7985 - auc: 0.8477 - val_loss: 0.5529 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8892\n",
      "Epoch 58/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5832 - tp: 204.0000 - fp: 78.0000 - tn: 366.0000 - fn: 64.0000 - accuracy: 0.8006 - precision: 0.7234 - recall: 0.7612 - auc: 0.8444 - val_loss: 0.5510 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8876\n",
      "Epoch 59/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5665 - tp: 208.0000 - fp: 72.0000 - tn: 372.0000 - fn: 60.0000 - accuracy: 0.8146 - precision: 0.7429 - recall: 0.7761 - auc: 0.8559 - val_loss: 0.5498 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8880\n",
      "Epoch 60/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.5786 - tp: 203.0000 - fp: 68.0000 - tn: 376.0000 - fn: 65.0000 - accuracy: 0.8132 - precision: 0.7491 - recall: 0.7575 - auc: 0.8456 - val_loss: 0.5434 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8851\n",
      "Epoch 61/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5670 - tp: 210.0000 - fp: 82.0000 - tn: 362.0000 - fn: 58.0000 - accuracy: 0.8034 - precision: 0.7192 - recall: 0.7836 - auc: 0.8548 - val_loss: 0.5446 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8889\n",
      "Epoch 62/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.5751 - tp: 204.0000 - fp: 63.0000 - tn: 381.0000 - fn: 64.0000 - accuracy: 0.8216 - precision: 0.7640 - recall: 0.7612 - auc: 0.8453 - val_loss: 0.5509 - val_tp: 65.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 9.0000 - val_accuracy: 0.7933 - val_precision: 0.6989 - val_recall: 0.8784 - val_auc: 0.8791\n",
      "Epoch 63/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.5700 - tp: 207.0000 - fp: 70.0000 - tn: 374.0000 - fn: 61.0000 - accuracy: 0.8160 - precision: 0.7473 - recall: 0.7724 - auc: 0.8504 - val_loss: 0.5428 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8848\n",
      "Epoch 64/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5589 - tp: 200.0000 - fp: 62.0000 - tn: 382.0000 - fn: 68.0000 - accuracy: 0.8174 - precision: 0.7634 - recall: 0.7463 - auc: 0.8579 - val_loss: 0.5396 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8846\n",
      "Epoch 65/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5816 - tp: 209.0000 - fp: 73.0000 - tn: 371.0000 - fn: 59.0000 - accuracy: 0.8146 - precision: 0.7411 - recall: 0.7799 - auc: 0.8384 - val_loss: 0.5387 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8883\n",
      "Epoch 66/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5492 - tp: 207.0000 - fp: 59.0000 - tn: 385.0000 - fn: 61.0000 - accuracy: 0.8315 - precision: 0.7782 - recall: 0.7724 - auc: 0.8646 - val_loss: 0.5364 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8858\n",
      "Epoch 67/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.5485 - tp: 206.0000 - fp: 61.0000 - tn: 383.0000 - fn: 62.0000 - accuracy: 0.8272 - precision: 0.7715 - recall: 0.7687 - auc: 0.8595 - val_loss: 0.5315 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8882\n",
      "Epoch 68/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.5647 - tp: 211.0000 - fp: 85.0000 - tn: 359.0000 - fn: 57.0000 - accuracy: 0.8006 - precision: 0.7128 - recall: 0.7873 - auc: 0.8488 - val_loss: 0.5321 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8907\n",
      "Epoch 69/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5643 - tp: 198.0000 - fp: 68.0000 - tn: 376.0000 - fn: 70.0000 - accuracy: 0.8062 - precision: 0.7444 - recall: 0.7388 - auc: 0.8484 - val_loss: 0.5341 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8855\n",
      "Epoch 70/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5492 - tp: 204.0000 - fp: 65.0000 - tn: 379.0000 - fn: 64.0000 - accuracy: 0.8188 - precision: 0.7584 - recall: 0.7612 - auc: 0.8528 - val_loss: 0.5323 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8857\n",
      "Epoch 71/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5389 - tp: 210.0000 - fp: 74.0000 - tn: 370.0000 - fn: 58.0000 - accuracy: 0.8146 - precision: 0.7394 - recall: 0.7836 - auc: 0.8650 - val_loss: 0.5292 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8866\n",
      "Epoch 72/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5603 - tp: 205.0000 - fp: 62.0000 - tn: 382.0000 - fn: 63.0000 - accuracy: 0.8244 - precision: 0.7678 - recall: 0.7649 - auc: 0.8466 - val_loss: 0.5323 - val_tp: 62.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 12.0000 - val_accuracy: 0.7933 - val_precision: 0.7126 - val_recall: 0.8378 - val_auc: 0.8836\n",
      "Epoch 73/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5294 - tp: 212.0000 - fp: 55.0000 - tn: 389.0000 - fn: 56.0000 - accuracy: 0.8441 - precision: 0.7940 - recall: 0.7910 - auc: 0.8662 - val_loss: 0.5297 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8886\n",
      "Epoch 74/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5534 - tp: 208.0000 - fp: 80.0000 - tn: 364.0000 - fn: 60.0000 - accuracy: 0.8034 - precision: 0.7222 - recall: 0.7761 - auc: 0.8511 - val_loss: 0.5305 - val_tp: 54.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 20.0000 - val_accuracy: 0.7989 - val_precision: 0.7714 - val_recall: 0.7297 - val_auc: 0.8876\n",
      "Epoch 75/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5621 - tp: 201.0000 - fp: 58.0000 - tn: 386.0000 - fn: 67.0000 - accuracy: 0.8244 - precision: 0.7761 - recall: 0.7500 - auc: 0.8453 - val_loss: 0.5279 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8820\n",
      "Epoch 76/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5497 - tp: 207.0000 - fp: 74.0000 - tn: 370.0000 - fn: 61.0000 - accuracy: 0.8104 - precision: 0.7367 - recall: 0.7724 - auc: 0.8532 - val_loss: 0.5273 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8838\n",
      "Epoch 77/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5406 - tp: 205.0000 - fp: 70.0000 - tn: 374.0000 - fn: 63.0000 - accuracy: 0.8132 - precision: 0.7455 - recall: 0.7649 - auc: 0.8554 - val_loss: 0.5252 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8866\n",
      "Epoch 78/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5450 - tp: 199.0000 - fp: 59.0000 - tn: 385.0000 - fn: 69.0000 - accuracy: 0.8202 - precision: 0.7713 - recall: 0.7425 - auc: 0.8530 - val_loss: 0.5250 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8862\n",
      "Epoch 79/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5438 - tp: 209.0000 - fp: 78.0000 - tn: 366.0000 - fn: 59.0000 - accuracy: 0.8076 - precision: 0.7282 - recall: 0.7799 - auc: 0.8560 - val_loss: 0.5356 - val_tp: 53.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 21.0000 - val_accuracy: 0.7933 - val_precision: 0.7681 - val_recall: 0.7162 - val_auc: 0.8872\n",
      "Epoch 80/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5520 - tp: 199.0000 - fp: 56.0000 - tn: 388.0000 - fn: 69.0000 - accuracy: 0.8244 - precision: 0.7804 - recall: 0.7425 - auc: 0.8474 - val_loss: 0.5283 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8815\n",
      "Epoch 81/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5389 - tp: 205.0000 - fp: 73.0000 - tn: 371.0000 - fn: 63.0000 - accuracy: 0.8090 - precision: 0.7374 - recall: 0.7649 - auc: 0.8586 - val_loss: 0.5214 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8851\n",
      "Epoch 82/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5526 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8455 - val_loss: 0.5255 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8873\n",
      "Epoch 83/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5282 - tp: 205.0000 - fp: 68.0000 - tn: 376.0000 - fn: 63.0000 - accuracy: 0.8160 - precision: 0.7509 - recall: 0.7649 - auc: 0.8693 - val_loss: 0.5167 - val_tp: 62.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 12.0000 - val_accuracy: 0.7933 - val_precision: 0.7126 - val_recall: 0.8378 - val_auc: 0.8849\n",
      "Epoch 84/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5372 - tp: 205.0000 - fp: 80.0000 - tn: 364.0000 - fn: 63.0000 - accuracy: 0.7992 - precision: 0.7193 - recall: 0.7649 - auc: 0.8600 - val_loss: 0.5171 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8841\n",
      "Epoch 85/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5193 - tp: 208.0000 - fp: 69.0000 - tn: 375.0000 - fn: 60.0000 - accuracy: 0.8188 - precision: 0.7509 - recall: 0.7761 - auc: 0.8712 - val_loss: 0.5142 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8873\n",
      "Epoch 86/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5404 - tp: 203.0000 - fp: 63.0000 - tn: 381.0000 - fn: 65.0000 - accuracy: 0.8202 - precision: 0.7632 - recall: 0.7575 - auc: 0.8572 - val_loss: 0.5166 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8854\n",
      "Epoch 87/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.5383 - tp: 210.0000 - fp: 71.0000 - tn: 373.0000 - fn: 58.0000 - accuracy: 0.8188 - precision: 0.7473 - recall: 0.7836 - auc: 0.8575 - val_loss: 0.5217 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8882\n",
      "Epoch 88/500\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.5406 - tp: 203.0000 - fp: 71.0000 - tn: 373.0000 - fn: 65.0000 - accuracy: 0.8090 - precision: 0.7409 - recall: 0.7575 - auc: 0.8539 - val_loss: 0.5158 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8887\n",
      "Epoch 89/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.5356 - tp: 209.0000 - fp: 79.0000 - tn: 365.0000 - fn: 59.0000 - accuracy: 0.8062 - precision: 0.7257 - recall: 0.7799 - auc: 0.8589 - val_loss: 0.5168 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8876\n",
      "Epoch 90/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.5368 - tp: 202.0000 - fp: 66.0000 - tn: 378.0000 - fn: 66.0000 - accuracy: 0.8146 - precision: 0.7537 - recall: 0.7537 - auc: 0.8586 - val_loss: 0.5215 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8880\n",
      "Epoch 91/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.5269 - tp: 207.0000 - fp: 67.0000 - tn: 377.0000 - fn: 61.0000 - accuracy: 0.8202 - precision: 0.7555 - recall: 0.7724 - auc: 0.8588 - val_loss: 0.5158 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8867\n",
      "Epoch 92/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.5395 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8540 - val_loss: 0.5205 - val_tp: 63.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 11.0000 - val_accuracy: 0.7933 - val_precision: 0.7079 - val_recall: 0.8514 - val_auc: 0.8849\n",
      "Epoch 93/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5321 - tp: 207.0000 - fp: 69.0000 - tn: 375.0000 - fn: 61.0000 - accuracy: 0.8174 - precision: 0.7500 - recall: 0.7724 - auc: 0.8584 - val_loss: 0.5148 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8853\n",
      "Epoch 94/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5357 - tp: 206.0000 - fp: 72.0000 - tn: 372.0000 - fn: 62.0000 - accuracy: 0.8118 - precision: 0.7410 - recall: 0.7687 - auc: 0.8586 - val_loss: 0.5305 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8913\n",
      "Epoch 95/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5484 - tp: 203.0000 - fp: 69.0000 - tn: 375.0000 - fn: 65.0000 - accuracy: 0.8118 - precision: 0.7463 - recall: 0.7575 - auc: 0.8508 - val_loss: 0.5172 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8857\n",
      "Epoch 96/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5303 - tp: 205.0000 - fp: 55.0000 - tn: 389.0000 - fn: 63.0000 - accuracy: 0.8343 - precision: 0.7885 - recall: 0.7649 - auc: 0.8577 - val_loss: 0.5200 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8830\n",
      "Epoch 97/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.5319 - tp: 200.0000 - fp: 65.0000 - tn: 379.0000 - fn: 68.0000 - accuracy: 0.8132 - precision: 0.7547 - recall: 0.7463 - auc: 0.8536 - val_loss: 0.5133 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8871\n",
      "Epoch 98/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5171 - tp: 213.0000 - fp: 67.0000 - tn: 377.0000 - fn: 55.0000 - accuracy: 0.8287 - precision: 0.7607 - recall: 0.7948 - auc: 0.8707 - val_loss: 0.5279 - val_tp: 52.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 22.0000 - val_accuracy: 0.8045 - val_precision: 0.8000 - val_recall: 0.7027 - val_auc: 0.8885\n",
      "Epoch 99/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5345 - tp: 199.0000 - fp: 61.0000 - tn: 383.0000 - fn: 69.0000 - accuracy: 0.8174 - precision: 0.7654 - recall: 0.7425 - auc: 0.8578 - val_loss: 0.5129 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8873\n",
      "Epoch 100/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5425 - tp: 206.0000 - fp: 81.0000 - tn: 363.0000 - fn: 62.0000 - accuracy: 0.7992 - precision: 0.7178 - recall: 0.7687 - auc: 0.8484 - val_loss: 0.5114 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8880\n",
      "Epoch 101/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5210 - tp: 201.0000 - fp: 49.0000 - tn: 395.0000 - fn: 67.0000 - accuracy: 0.8371 - precision: 0.8040 - recall: 0.7500 - auc: 0.8691 - val_loss: 0.5133 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8854\n",
      "Epoch 102/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5294 - tp: 202.0000 - fp: 60.0000 - tn: 384.0000 - fn: 66.0000 - accuracy: 0.8230 - precision: 0.7710 - recall: 0.7537 - auc: 0.8577 - val_loss: 0.5121 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8860\n",
      "Epoch 103/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5164 - tp: 205.0000 - fp: 60.0000 - tn: 384.0000 - fn: 63.0000 - accuracy: 0.8272 - precision: 0.7736 - recall: 0.7649 - auc: 0.8679 - val_loss: 0.5111 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8889\n",
      "Epoch 104/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5306 - tp: 207.0000 - fp: 63.0000 - tn: 381.0000 - fn: 61.0000 - accuracy: 0.8258 - precision: 0.7667 - recall: 0.7724 - auc: 0.8537 - val_loss: 0.5111 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8917\n",
      "Epoch 105/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.5232 - tp: 208.0000 - fp: 58.0000 - tn: 386.0000 - fn: 60.0000 - accuracy: 0.8343 - precision: 0.7820 - recall: 0.7761 - auc: 0.8662 - val_loss: 0.5151 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8900\n",
      "Epoch 106/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5292 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8610 - val_loss: 0.5171 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8892\n",
      "Epoch 107/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5096 - tp: 200.0000 - fp: 51.0000 - tn: 393.0000 - fn: 68.0000 - accuracy: 0.8329 - precision: 0.7968 - recall: 0.7463 - auc: 0.8681 - val_loss: 0.5127 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8835\n",
      "Epoch 108/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5143 - tp: 205.0000 - fp: 61.0000 - tn: 383.0000 - fn: 63.0000 - accuracy: 0.8258 - precision: 0.7707 - recall: 0.7649 - auc: 0.8690 - val_loss: 0.5105 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8860\n",
      "Epoch 109/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5161 - tp: 206.0000 - fp: 61.0000 - tn: 383.0000 - fn: 62.0000 - accuracy: 0.8272 - precision: 0.7715 - recall: 0.7687 - auc: 0.8649 - val_loss: 0.5131 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8920\n",
      "Epoch 110/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5332 - tp: 202.0000 - fp: 67.0000 - tn: 377.0000 - fn: 66.0000 - accuracy: 0.8132 - precision: 0.7509 - recall: 0.7537 - auc: 0.8443 - val_loss: 0.5104 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8924\n",
      "Epoch 111/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5318 - tp: 206.0000 - fp: 72.0000 - tn: 372.0000 - fn: 62.0000 - accuracy: 0.8118 - precision: 0.7410 - recall: 0.7687 - auc: 0.8603 - val_loss: 0.5060 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8907\n",
      "Epoch 112/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5125 - tp: 201.0000 - fp: 62.0000 - tn: 382.0000 - fn: 67.0000 - accuracy: 0.8188 - precision: 0.7643 - recall: 0.7500 - auc: 0.8711 - val_loss: 0.5116 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8893\n",
      "Epoch 113/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5230 - tp: 200.0000 - fp: 54.0000 - tn: 390.0000 - fn: 68.0000 - accuracy: 0.8287 - precision: 0.7874 - recall: 0.7463 - auc: 0.8585 - val_loss: 0.5128 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8853\n",
      "Epoch 114/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5290 - tp: 200.0000 - fp: 61.0000 - tn: 383.0000 - fn: 68.0000 - accuracy: 0.8188 - precision: 0.7663 - recall: 0.7463 - auc: 0.8621 - val_loss: 0.5073 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8862\n",
      "Epoch 115/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5221 - tp: 207.0000 - fp: 64.0000 - tn: 380.0000 - fn: 61.0000 - accuracy: 0.8244 - precision: 0.7638 - recall: 0.7724 - auc: 0.8648 - val_loss: 0.5127 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8897\n",
      "Epoch 116/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5274 - tp: 199.0000 - fp: 55.0000 - tn: 389.0000 - fn: 69.0000 - accuracy: 0.8258 - precision: 0.7835 - recall: 0.7425 - auc: 0.8597 - val_loss: 0.5031 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8907\n",
      "Epoch 117/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5209 - tp: 204.0000 - fp: 60.0000 - tn: 384.0000 - fn: 64.0000 - accuracy: 0.8258 - precision: 0.7727 - recall: 0.7612 - auc: 0.8627 - val_loss: 0.5054 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8913\n",
      "Epoch 118/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5081 - tp: 200.0000 - fp: 46.0000 - tn: 398.0000 - fn: 68.0000 - accuracy: 0.8399 - precision: 0.8130 - recall: 0.7463 - auc: 0.8713 - val_loss: 0.5133 - val_tp: 62.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 12.0000 - val_accuracy: 0.7933 - val_precision: 0.7126 - val_recall: 0.8378 - val_auc: 0.8837\n",
      "Epoch 119/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5117 - tp: 215.0000 - fp: 79.0000 - tn: 365.0000 - fn: 53.0000 - accuracy: 0.8146 - precision: 0.7313 - recall: 0.8022 - auc: 0.8678 - val_loss: 0.5139 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8871\n",
      "Epoch 120/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5244 - tp: 204.0000 - fp: 72.0000 - tn: 372.0000 - fn: 64.0000 - accuracy: 0.8090 - precision: 0.7391 - recall: 0.7612 - auc: 0.8612 - val_loss: 0.5054 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8913\n",
      "Epoch 121/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5329 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8510 - val_loss: 0.5046 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8908\n",
      "Epoch 122/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5236 - tp: 197.0000 - fp: 53.0000 - tn: 391.0000 - fn: 71.0000 - accuracy: 0.8258 - precision: 0.7880 - recall: 0.7351 - auc: 0.8566 - val_loss: 0.5101 - val_tp: 65.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 9.0000 - val_accuracy: 0.7933 - val_precision: 0.6989 - val_recall: 0.8784 - val_auc: 0.8858\n",
      "Epoch 123/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5279 - tp: 215.0000 - fp: 72.0000 - tn: 372.0000 - fn: 53.0000 - accuracy: 0.8244 - precision: 0.7491 - recall: 0.8022 - auc: 0.8561 - val_loss: 0.5039 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8923\n",
      "Epoch 124/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5172 - tp: 202.0000 - fp: 59.0000 - tn: 385.0000 - fn: 66.0000 - accuracy: 0.8244 - precision: 0.7739 - recall: 0.7537 - auc: 0.8637 - val_loss: 0.5088 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8915\n",
      "Epoch 125/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5204 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8638 - val_loss: 0.4986 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8914\n",
      "Epoch 126/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5335 - tp: 191.0000 - fp: 45.0000 - tn: 399.0000 - fn: 77.0000 - accuracy: 0.8287 - precision: 0.8093 - recall: 0.7127 - auc: 0.8532 - val_loss: 0.5080 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8853\n",
      "Epoch 127/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5235 - tp: 198.0000 - fp: 57.0000 - tn: 387.0000 - fn: 70.0000 - accuracy: 0.8216 - precision: 0.7765 - recall: 0.7388 - auc: 0.8551 - val_loss: 0.5047 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8860\n",
      "Epoch 128/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5091 - tp: 209.0000 - fp: 65.0000 - tn: 379.0000 - fn: 59.0000 - accuracy: 0.8258 - precision: 0.7628 - recall: 0.7799 - auc: 0.8698 - val_loss: 0.5047 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8882\n",
      "Epoch 129/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5081 - tp: 211.0000 - fp: 72.0000 - tn: 372.0000 - fn: 57.0000 - accuracy: 0.8188 - precision: 0.7456 - recall: 0.7873 - auc: 0.8723 - val_loss: 0.5094 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8918\n",
      "Epoch 130/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5160 - tp: 198.0000 - fp: 65.0000 - tn: 379.0000 - fn: 70.0000 - accuracy: 0.8104 - precision: 0.7529 - recall: 0.7388 - auc: 0.8639 - val_loss: 0.4984 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8923\n",
      "Epoch 131/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5062 - tp: 203.0000 - fp: 44.0000 - tn: 400.0000 - fn: 65.0000 - accuracy: 0.8469 - precision: 0.8219 - recall: 0.7575 - auc: 0.8702 - val_loss: 0.5076 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8870\n",
      "Epoch 132/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5107 - tp: 203.0000 - fp: 63.0000 - tn: 381.0000 - fn: 65.0000 - accuracy: 0.8202 - precision: 0.7632 - recall: 0.7575 - auc: 0.8681 - val_loss: 0.5032 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8916\n",
      "Epoch 133/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5135 - tp: 209.0000 - fp: 66.0000 - tn: 378.0000 - fn: 59.0000 - accuracy: 0.8244 - precision: 0.7600 - recall: 0.7799 - auc: 0.8694 - val_loss: 0.5021 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8927\n",
      "Epoch 134/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5193 - tp: 200.0000 - fp: 54.0000 - tn: 390.0000 - fn: 68.0000 - accuracy: 0.8287 - precision: 0.7874 - recall: 0.7463 - auc: 0.8652 - val_loss: 0.5055 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8885\n",
      "Epoch 135/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5188 - tp: 200.0000 - fp: 53.0000 - tn: 391.0000 - fn: 68.0000 - accuracy: 0.8301 - precision: 0.7905 - recall: 0.7463 - auc: 0.8603 - val_loss: 0.4982 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8918\n",
      "Epoch 136/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5233 - tp: 206.0000 - fp: 66.0000 - tn: 378.0000 - fn: 62.0000 - accuracy: 0.8202 - precision: 0.7574 - recall: 0.7687 - auc: 0.8565 - val_loss: 0.5041 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8926\n",
      "Epoch 137/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5049 - tp: 213.0000 - fp: 71.0000 - tn: 373.0000 - fn: 55.0000 - accuracy: 0.8230 - precision: 0.7500 - recall: 0.7948 - auc: 0.8692 - val_loss: 0.5015 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8937\n",
      "Epoch 138/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5165 - tp: 200.0000 - fp: 50.0000 - tn: 394.0000 - fn: 68.0000 - accuracy: 0.8343 - precision: 0.8000 - recall: 0.7463 - auc: 0.8623 - val_loss: 0.5019 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8903\n",
      "Epoch 139/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5021 - tp: 208.0000 - fp: 75.0000 - tn: 369.0000 - fn: 60.0000 - accuracy: 0.8104 - precision: 0.7350 - recall: 0.7761 - auc: 0.8745 - val_loss: 0.5037 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8876\n",
      "Epoch 140/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5285 - tp: 193.0000 - fp: 57.0000 - tn: 387.0000 - fn: 75.0000 - accuracy: 0.8146 - precision: 0.7720 - recall: 0.7201 - auc: 0.8536 - val_loss: 0.4992 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8942\n",
      "Epoch 141/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5105 - tp: 205.0000 - fp: 56.0000 - tn: 388.0000 - fn: 63.0000 - accuracy: 0.8329 - precision: 0.7854 - recall: 0.7649 - auc: 0.8666 - val_loss: 0.4935 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8946\n",
      "Epoch 142/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5248 - tp: 206.0000 - fp: 66.0000 - tn: 378.0000 - fn: 62.0000 - accuracy: 0.8202 - precision: 0.7574 - recall: 0.7687 - auc: 0.8611 - val_loss: 0.4967 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8932\n",
      "Epoch 143/500\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.5173 - tp: 194.0000 - fp: 46.0000 - tn: 398.0000 - fn: 74.0000 - accuracy: 0.8315 - precision: 0.8083 - recall: 0.7239 - auc: 0.8646 - val_loss: 0.5005 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8889\n",
      "Epoch 144/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5155 - tp: 205.0000 - fp: 68.0000 - tn: 376.0000 - fn: 63.0000 - accuracy: 0.8160 - precision: 0.7509 - recall: 0.7649 - auc: 0.8659 - val_loss: 0.5175 - val_tp: 63.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 11.0000 - val_accuracy: 0.7821 - val_precision: 0.6923 - val_recall: 0.8514 - val_auc: 0.8851\n",
      "Epoch 145/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5115 - tp: 207.0000 - fp: 66.0000 - tn: 378.0000 - fn: 61.0000 - accuracy: 0.8216 - precision: 0.7582 - recall: 0.7724 - auc: 0.8680 - val_loss: 0.5034 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8911\n",
      "Epoch 146/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5192 - tp: 205.0000 - fp: 67.0000 - tn: 377.0000 - fn: 63.0000 - accuracy: 0.8174 - precision: 0.7537 - recall: 0.7649 - auc: 0.8589 - val_loss: 0.4985 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8880\n",
      "Epoch 147/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5198 - tp: 197.0000 - fp: 45.0000 - tn: 399.0000 - fn: 71.0000 - accuracy: 0.8371 - precision: 0.8140 - recall: 0.7351 - auc: 0.8555 - val_loss: 0.5027 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8854\n",
      "Epoch 148/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5042 - tp: 203.0000 - fp: 76.0000 - tn: 368.0000 - fn: 65.0000 - accuracy: 0.8020 - precision: 0.7276 - recall: 0.7575 - auc: 0.8716 - val_loss: 0.5007 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8925\n",
      "Epoch 149/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5018 - tp: 206.0000 - fp: 54.0000 - tn: 390.0000 - fn: 62.0000 - accuracy: 0.8371 - precision: 0.7923 - recall: 0.7687 - auc: 0.8739 - val_loss: 0.5157 - val_tp: 65.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 9.0000 - val_accuracy: 0.7933 - val_precision: 0.6989 - val_recall: 0.8784 - val_auc: 0.8842\n",
      "Epoch 150/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5239 - tp: 201.0000 - fp: 73.0000 - tn: 371.0000 - fn: 67.0000 - accuracy: 0.8034 - precision: 0.7336 - recall: 0.7500 - auc: 0.8566 - val_loss: 0.5031 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8878\n",
      "Epoch 151/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5115 - tp: 206.0000 - fp: 64.0000 - tn: 380.0000 - fn: 62.0000 - accuracy: 0.8230 - precision: 0.7630 - recall: 0.7687 - auc: 0.8671 - val_loss: 0.5021 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8872\n",
      "Epoch 152/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4942 - tp: 205.0000 - fp: 57.0000 - tn: 387.0000 - fn: 63.0000 - accuracy: 0.8315 - precision: 0.7824 - recall: 0.7649 - auc: 0.8807 - val_loss: 0.4995 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8862\n",
      "Epoch 153/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.5026 - tp: 197.0000 - fp: 56.0000 - tn: 388.0000 - fn: 71.0000 - accuracy: 0.8216 - precision: 0.7787 - recall: 0.7351 - auc: 0.8701 - val_loss: 0.5018 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8902\n",
      "Epoch 154/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.5021 - tp: 205.0000 - fp: 61.0000 - tn: 383.0000 - fn: 63.0000 - accuracy: 0.8258 - precision: 0.7707 - recall: 0.7649 - auc: 0.8685 - val_loss: 0.5028 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8862\n",
      "Epoch 155/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5092 - tp: 197.0000 - fp: 58.0000 - tn: 386.0000 - fn: 71.0000 - accuracy: 0.8188 - precision: 0.7725 - recall: 0.7351 - auc: 0.8644 - val_loss: 0.5069 - val_tp: 54.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 20.0000 - val_accuracy: 0.8212 - val_precision: 0.8182 - val_recall: 0.7297 - val_auc: 0.8910\n",
      "Epoch 156/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4959 - tp: 200.0000 - fp: 43.0000 - tn: 401.0000 - fn: 68.0000 - accuracy: 0.8441 - precision: 0.8230 - recall: 0.7463 - auc: 0.8755 - val_loss: 0.5041 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8862\n",
      "Epoch 157/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5144 - tp: 206.0000 - fp: 63.0000 - tn: 381.0000 - fn: 62.0000 - accuracy: 0.8244 - precision: 0.7658 - recall: 0.7687 - auc: 0.8635 - val_loss: 0.5007 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8900\n",
      "Epoch 158/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5130 - tp: 201.0000 - fp: 59.0000 - tn: 385.0000 - fn: 67.0000 - accuracy: 0.8230 - precision: 0.7731 - recall: 0.7500 - auc: 0.8610 - val_loss: 0.4942 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8929\n",
      "Epoch 159/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5233 - tp: 199.0000 - fp: 69.0000 - tn: 375.0000 - fn: 69.0000 - accuracy: 0.8062 - precision: 0.7425 - recall: 0.7425 - auc: 0.8573 - val_loss: 0.4995 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8901\n",
      "Epoch 160/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4998 - tp: 209.0000 - fp: 63.0000 - tn: 381.0000 - fn: 59.0000 - accuracy: 0.8287 - precision: 0.7684 - recall: 0.7799 - auc: 0.8724 - val_loss: 0.4967 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8938\n",
      "Epoch 161/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5081 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8603 - val_loss: 0.4906 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8896\n",
      "Epoch 162/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5073 - tp: 199.0000 - fp: 62.0000 - tn: 382.0000 - fn: 69.0000 - accuracy: 0.8160 - precision: 0.7625 - recall: 0.7425 - auc: 0.8688 - val_loss: 0.4949 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8889\n",
      "Epoch 163/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5035 - tp: 203.0000 - fp: 59.0000 - tn: 385.0000 - fn: 65.0000 - accuracy: 0.8258 - precision: 0.7748 - recall: 0.7575 - auc: 0.8664 - val_loss: 0.4955 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8872\n",
      "Epoch 164/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5157 - tp: 208.0000 - fp: 84.0000 - tn: 360.0000 - fn: 60.0000 - accuracy: 0.7978 - precision: 0.7123 - recall: 0.7761 - auc: 0.8632 - val_loss: 0.4974 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8916\n",
      "Epoch 165/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5031 - tp: 201.0000 - fp: 59.0000 - tn: 385.0000 - fn: 67.0000 - accuracy: 0.8230 - precision: 0.7731 - recall: 0.7500 - auc: 0.8706 - val_loss: 0.5006 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8907\n",
      "Epoch 166/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5126 - tp: 203.0000 - fp: 58.0000 - tn: 386.0000 - fn: 65.0000 - accuracy: 0.8272 - precision: 0.7778 - recall: 0.7575 - auc: 0.8649 - val_loss: 0.4990 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8871\n",
      "Epoch 167/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4909 - tp: 210.0000 - fp: 62.0000 - tn: 382.0000 - fn: 58.0000 - accuracy: 0.8315 - precision: 0.7721 - recall: 0.7836 - auc: 0.8774 - val_loss: 0.5025 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8923\n",
      "Epoch 168/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5132 - tp: 204.0000 - fp: 60.0000 - tn: 384.0000 - fn: 64.0000 - accuracy: 0.8258 - precision: 0.7727 - recall: 0.7612 - auc: 0.8601 - val_loss: 0.4940 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8936\n",
      "Epoch 169/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5160 - tp: 201.0000 - fp: 63.0000 - tn: 381.0000 - fn: 67.0000 - accuracy: 0.8174 - precision: 0.7614 - recall: 0.7500 - auc: 0.8636 - val_loss: 0.4976 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8952\n",
      "Epoch 170/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5048 - tp: 196.0000 - fp: 57.0000 - tn: 387.0000 - fn: 72.0000 - accuracy: 0.8188 - precision: 0.7747 - recall: 0.7313 - auc: 0.8689 - val_loss: 0.4970 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8895\n",
      "Epoch 171/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.4974 - tp: 201.0000 - fp: 50.0000 - tn: 394.0000 - fn: 67.0000 - accuracy: 0.8357 - precision: 0.8008 - recall: 0.7500 - auc: 0.8700 - val_loss: 0.4995 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8936\n",
      "Epoch 172/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5007 - tp: 201.0000 - fp: 68.0000 - tn: 376.0000 - fn: 67.0000 - accuracy: 0.8104 - precision: 0.7472 - recall: 0.7500 - auc: 0.8751 - val_loss: 0.4939 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8886\n",
      "Epoch 173/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5096 - tp: 204.0000 - fp: 59.0000 - tn: 385.0000 - fn: 64.0000 - accuracy: 0.8272 - precision: 0.7757 - recall: 0.7612 - auc: 0.8653 - val_loss: 0.4929 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8927\n",
      "Epoch 174/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5119 - tp: 206.0000 - fp: 69.0000 - tn: 375.0000 - fn: 62.0000 - accuracy: 0.8160 - precision: 0.7491 - recall: 0.7687 - auc: 0.8657 - val_loss: 0.4946 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8930\n",
      "Epoch 175/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5038 - tp: 201.0000 - fp: 51.0000 - tn: 393.0000 - fn: 67.0000 - accuracy: 0.8343 - precision: 0.7976 - recall: 0.7500 - auc: 0.8703 - val_loss: 0.4928 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8919\n",
      "Epoch 176/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5145 - tp: 202.0000 - fp: 62.0000 - tn: 382.0000 - fn: 66.0000 - accuracy: 0.8202 - precision: 0.7652 - recall: 0.7537 - auc: 0.8614 - val_loss: 0.4924 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8909\n",
      "Epoch 177/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5093 - tp: 205.0000 - fp: 55.0000 - tn: 389.0000 - fn: 63.0000 - accuracy: 0.8343 - precision: 0.7885 - recall: 0.7649 - auc: 0.8639 - val_loss: 0.4912 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8943\n",
      "Epoch 178/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5098 - tp: 201.0000 - fp: 56.0000 - tn: 388.0000 - fn: 67.0000 - accuracy: 0.8272 - precision: 0.7821 - recall: 0.7500 - auc: 0.8573 - val_loss: 0.4962 - val_tp: 61.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 13.0000 - val_accuracy: 0.8156 - val_precision: 0.7531 - val_recall: 0.8243 - val_auc: 0.8896\n",
      "Epoch 179/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5088 - tp: 205.0000 - fp: 64.0000 - tn: 380.0000 - fn: 63.0000 - accuracy: 0.8216 - precision: 0.7621 - recall: 0.7649 - auc: 0.8648 - val_loss: 0.4972 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8894\n",
      "Epoch 180/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.5219 - tp: 206.0000 - fp: 79.0000 - tn: 365.0000 - fn: 62.0000 - accuracy: 0.8020 - precision: 0.7228 - recall: 0.7687 - auc: 0.8518 - val_loss: 0.4936 - val_tp: 63.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 11.0000 - val_accuracy: 0.7877 - val_precision: 0.7000 - val_recall: 0.8514 - val_auc: 0.8907\n",
      "Epoch 181/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5157 - tp: 205.0000 - fp: 69.0000 - tn: 375.0000 - fn: 63.0000 - accuracy: 0.8146 - precision: 0.7482 - recall: 0.7649 - auc: 0.8591 - val_loss: 0.4898 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8921\n",
      "Epoch 182/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4980 - tp: 210.0000 - fp: 67.0000 - tn: 377.0000 - fn: 58.0000 - accuracy: 0.8244 - precision: 0.7581 - recall: 0.7836 - auc: 0.8729 - val_loss: 0.4914 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8923\n",
      "Epoch 183/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5055 - tp: 200.0000 - fp: 48.0000 - tn: 396.0000 - fn: 68.0000 - accuracy: 0.8371 - precision: 0.8065 - recall: 0.7463 - auc: 0.8654 - val_loss: 0.4934 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8914\n",
      "Epoch 184/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4970 - tp: 200.0000 - fp: 53.0000 - tn: 391.0000 - fn: 68.0000 - accuracy: 0.8301 - precision: 0.7905 - recall: 0.7463 - auc: 0.8732 - val_loss: 0.4855 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8957\n",
      "Epoch 185/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4970 - tp: 208.0000 - fp: 54.0000 - tn: 390.0000 - fn: 60.0000 - accuracy: 0.8399 - precision: 0.7939 - recall: 0.7761 - auc: 0.8733 - val_loss: 0.4896 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8929\n",
      "Epoch 186/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5008 - tp: 196.0000 - fp: 61.0000 - tn: 383.0000 - fn: 72.0000 - accuracy: 0.8132 - precision: 0.7626 - recall: 0.7313 - auc: 0.8703 - val_loss: 0.4911 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8891\n",
      "Epoch 187/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4992 - tp: 208.0000 - fp: 63.0000 - tn: 381.0000 - fn: 60.0000 - accuracy: 0.8272 - precision: 0.7675 - recall: 0.7761 - auc: 0.8707 - val_loss: 0.4891 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8948\n",
      "Epoch 188/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5020 - tp: 201.0000 - fp: 51.0000 - tn: 393.0000 - fn: 67.0000 - accuracy: 0.8343 - precision: 0.7976 - recall: 0.7500 - auc: 0.8675 - val_loss: 0.4925 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8944\n",
      "Epoch 189/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4876 - tp: 208.0000 - fp: 60.0000 - tn: 384.0000 - fn: 60.0000 - accuracy: 0.8315 - precision: 0.7761 - recall: 0.7761 - auc: 0.8802 - val_loss: 0.4852 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8931\n",
      "Epoch 190/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.5088 - tp: 209.0000 - fp: 66.0000 - tn: 378.0000 - fn: 59.0000 - accuracy: 0.8244 - precision: 0.7600 - recall: 0.7799 - auc: 0.8635 - val_loss: 0.4903 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8920\n",
      "Epoch 191/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5040 - tp: 199.0000 - fp: 52.0000 - tn: 392.0000 - fn: 69.0000 - accuracy: 0.8301 - precision: 0.7928 - recall: 0.7425 - auc: 0.8652 - val_loss: 0.4971 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8930\n",
      "Epoch 192/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5012 - tp: 202.0000 - fp: 65.0000 - tn: 379.0000 - fn: 66.0000 - accuracy: 0.8160 - precision: 0.7566 - recall: 0.7537 - auc: 0.8717 - val_loss: 0.4912 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8927\n",
      "Epoch 193/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5042 - tp: 202.0000 - fp: 60.0000 - tn: 384.0000 - fn: 66.0000 - accuracy: 0.8230 - precision: 0.7710 - recall: 0.7537 - auc: 0.8642 - val_loss: 0.4961 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8895\n",
      "Epoch 194/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5208 - tp: 197.0000 - fp: 61.0000 - tn: 383.0000 - fn: 71.0000 - accuracy: 0.8146 - precision: 0.7636 - recall: 0.7351 - auc: 0.8568 - val_loss: 0.4914 - val_tp: 62.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 12.0000 - val_accuracy: 0.7933 - val_precision: 0.7126 - val_recall: 0.8378 - val_auc: 0.8898\n",
      "Epoch 195/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5131 - tp: 202.0000 - fp: 54.0000 - tn: 390.0000 - fn: 66.0000 - accuracy: 0.8315 - precision: 0.7891 - recall: 0.7537 - auc: 0.8579 - val_loss: 0.4876 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8921\n",
      "Epoch 196/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5021 - tp: 205.0000 - fp: 59.0000 - tn: 385.0000 - fn: 63.0000 - accuracy: 0.8287 - precision: 0.7765 - recall: 0.7649 - auc: 0.8740 - val_loss: 0.4904 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8956\n",
      "Epoch 197/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4925 - tp: 204.0000 - fp: 52.0000 - tn: 392.0000 - fn: 64.0000 - accuracy: 0.8371 - precision: 0.7969 - recall: 0.7612 - auc: 0.8723 - val_loss: 0.4955 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8920\n",
      "Epoch 198/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5093 - tp: 196.0000 - fp: 54.0000 - tn: 390.0000 - fn: 72.0000 - accuracy: 0.8230 - precision: 0.7840 - recall: 0.7313 - auc: 0.8632 - val_loss: 0.4918 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8911\n",
      "Epoch 199/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5129 - tp: 202.0000 - fp: 61.0000 - tn: 383.0000 - fn: 66.0000 - accuracy: 0.8216 - precision: 0.7681 - recall: 0.7537 - auc: 0.8551 - val_loss: 0.4876 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8954\n",
      "Epoch 200/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5019 - tp: 205.0000 - fp: 61.0000 - tn: 383.0000 - fn: 63.0000 - accuracy: 0.8258 - precision: 0.7707 - recall: 0.7649 - auc: 0.8657 - val_loss: 0.4923 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8952\n",
      "Epoch 201/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5005 - tp: 193.0000 - fp: 36.0000 - tn: 408.0000 - fn: 75.0000 - accuracy: 0.8441 - precision: 0.8428 - recall: 0.7201 - auc: 0.8637 - val_loss: 0.5046 - val_tp: 63.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 11.0000 - val_accuracy: 0.7933 - val_precision: 0.7079 - val_recall: 0.8514 - val_auc: 0.8891\n",
      "Epoch 202/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5077 - tp: 199.0000 - fp: 71.0000 - tn: 373.0000 - fn: 69.0000 - accuracy: 0.8034 - precision: 0.7370 - recall: 0.7425 - auc: 0.8692 - val_loss: 0.4929 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8909\n",
      "Epoch 203/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5159 - tp: 205.0000 - fp: 62.0000 - tn: 382.0000 - fn: 63.0000 - accuracy: 0.8244 - precision: 0.7678 - recall: 0.7649 - auc: 0.8556 - val_loss: 0.4997 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8936\n",
      "Epoch 204/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5020 - tp: 201.0000 - fp: 48.0000 - tn: 396.0000 - fn: 67.0000 - accuracy: 0.8385 - precision: 0.8072 - recall: 0.7500 - auc: 0.8697 - val_loss: 0.4862 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8926\n",
      "Epoch 205/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5085 - tp: 209.0000 - fp: 71.0000 - tn: 373.0000 - fn: 59.0000 - accuracy: 0.8174 - precision: 0.7464 - recall: 0.7799 - auc: 0.8584 - val_loss: 0.4912 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8943\n",
      "Epoch 206/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4896 - tp: 203.0000 - fp: 48.0000 - tn: 396.0000 - fn: 65.0000 - accuracy: 0.8413 - precision: 0.8088 - recall: 0.7575 - auc: 0.8725 - val_loss: 0.4957 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8923\n",
      "Epoch 207/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4844 - tp: 209.0000 - fp: 61.0000 - tn: 383.0000 - fn: 59.0000 - accuracy: 0.8315 - precision: 0.7741 - recall: 0.7799 - auc: 0.8841 - val_loss: 0.4948 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8929\n",
      "Epoch 208/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5083 - tp: 200.0000 - fp: 58.0000 - tn: 386.0000 - fn: 68.0000 - accuracy: 0.8230 - precision: 0.7752 - recall: 0.7463 - auc: 0.8645 - val_loss: 0.4896 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8954\n",
      "Epoch 209/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5030 - tp: 198.0000 - fp: 49.0000 - tn: 395.0000 - fn: 70.0000 - accuracy: 0.8329 - precision: 0.8016 - recall: 0.7388 - auc: 0.8640 - val_loss: 0.4913 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8923\n",
      "Epoch 210/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4892 - tp: 203.0000 - fp: 50.0000 - tn: 394.0000 - fn: 65.0000 - accuracy: 0.8385 - precision: 0.8024 - recall: 0.7575 - auc: 0.8774 - val_loss: 0.4840 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8950\n",
      "Epoch 211/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5087 - tp: 203.0000 - fp: 57.0000 - tn: 387.0000 - fn: 65.0000 - accuracy: 0.8287 - precision: 0.7808 - recall: 0.7575 - auc: 0.8573 - val_loss: 0.4866 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8918\n",
      "Epoch 212/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.4997 - tp: 207.0000 - fp: 66.0000 - tn: 378.0000 - fn: 61.0000 - accuracy: 0.8216 - precision: 0.7582 - recall: 0.7724 - auc: 0.8683 - val_loss: 0.4856 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8952\n",
      "Epoch 213/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.5045 - tp: 199.0000 - fp: 51.0000 - tn: 393.0000 - fn: 69.0000 - accuracy: 0.8315 - precision: 0.7960 - recall: 0.7425 - auc: 0.8670 - val_loss: 0.4886 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8952\n",
      "Epoch 214/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4977 - tp: 204.0000 - fp: 67.0000 - tn: 377.0000 - fn: 64.0000 - accuracy: 0.8160 - precision: 0.7528 - recall: 0.7612 - auc: 0.8690 - val_loss: 0.4915 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8929\n",
      "Epoch 215/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5051 - tp: 199.0000 - fp: 55.0000 - tn: 389.0000 - fn: 69.0000 - accuracy: 0.8258 - precision: 0.7835 - recall: 0.7425 - auc: 0.8601 - val_loss: 0.4904 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8924\n",
      "Epoch 216/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.5085 - tp: 194.0000 - fp: 49.0000 - tn: 395.0000 - fn: 74.0000 - accuracy: 0.8272 - precision: 0.7984 - recall: 0.7239 - auc: 0.8705 - val_loss: 0.4896 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8974\n",
      "Epoch 217/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4950 - tp: 204.0000 - fp: 64.0000 - tn: 380.0000 - fn: 64.0000 - accuracy: 0.8202 - precision: 0.7612 - recall: 0.7612 - auc: 0.8724 - val_loss: 0.4894 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8929\n",
      "Epoch 218/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4947 - tp: 207.0000 - fp: 62.0000 - tn: 382.0000 - fn: 61.0000 - accuracy: 0.8272 - precision: 0.7695 - recall: 0.7724 - auc: 0.8734 - val_loss: 0.4958 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8960\n",
      "Epoch 219/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.5111 - tp: 199.0000 - fp: 57.0000 - tn: 387.0000 - fn: 69.0000 - accuracy: 0.8230 - precision: 0.7773 - recall: 0.7425 - auc: 0.8514 - val_loss: 0.4862 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8947\n",
      "Epoch 220/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4977 - tp: 197.0000 - fp: 47.0000 - tn: 397.0000 - fn: 71.0000 - accuracy: 0.8343 - precision: 0.8074 - recall: 0.7351 - auc: 0.8658 - val_loss: 0.4892 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8947\n",
      "Epoch 221/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.5074 - tp: 196.0000 - fp: 61.0000 - tn: 383.0000 - fn: 72.0000 - accuracy: 0.8132 - precision: 0.7626 - recall: 0.7313 - auc: 0.8613 - val_loss: 0.4916 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8898\n",
      "Epoch 222/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5090 - tp: 199.0000 - fp: 58.0000 - tn: 386.0000 - fn: 69.0000 - accuracy: 0.8216 - precision: 0.7743 - recall: 0.7425 - auc: 0.8599 - val_loss: 0.4940 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8929\n",
      "Epoch 223/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5054 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8679 - val_loss: 0.4927 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8894\n",
      "Epoch 224/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5066 - tp: 202.0000 - fp: 44.0000 - tn: 400.0000 - fn: 66.0000 - accuracy: 0.8455 - precision: 0.8211 - recall: 0.7537 - auc: 0.8565 - val_loss: 0.4958 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8885\n",
      "Epoch 225/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5045 - tp: 199.0000 - fp: 46.0000 - tn: 398.0000 - fn: 69.0000 - accuracy: 0.8385 - precision: 0.8122 - recall: 0.7425 - auc: 0.8639 - val_loss: 0.4937 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8939\n",
      "Epoch 226/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5031 - tp: 200.0000 - fp: 52.0000 - tn: 392.0000 - fn: 68.0000 - accuracy: 0.8315 - precision: 0.7937 - recall: 0.7463 - auc: 0.8639 - val_loss: 0.4864 - val_tp: 61.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 13.0000 - val_accuracy: 0.8156 - val_precision: 0.7531 - val_recall: 0.8243 - val_auc: 0.8982\n",
      "Epoch 227/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4906 - tp: 208.0000 - fp: 58.0000 - tn: 386.0000 - fn: 60.0000 - accuracy: 0.8343 - precision: 0.7820 - recall: 0.7761 - auc: 0.8731 - val_loss: 0.4952 - val_tp: 62.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 12.0000 - val_accuracy: 0.7933 - val_precision: 0.7126 - val_recall: 0.8378 - val_auc: 0.8894\n",
      "Epoch 228/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5156 - tp: 204.0000 - fp: 58.0000 - tn: 386.0000 - fn: 64.0000 - accuracy: 0.8287 - precision: 0.7786 - recall: 0.7612 - auc: 0.8530 - val_loss: 0.4861 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8954\n",
      "Epoch 229/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5033 - tp: 196.0000 - fp: 51.0000 - tn: 393.0000 - fn: 72.0000 - accuracy: 0.8272 - precision: 0.7935 - recall: 0.7313 - auc: 0.8717 - val_loss: 0.4928 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8905\n",
      "Epoch 230/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5018 - tp: 201.0000 - fp: 54.0000 - tn: 390.0000 - fn: 67.0000 - accuracy: 0.8301 - precision: 0.7882 - recall: 0.7500 - auc: 0.8664 - val_loss: 0.4870 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8972\n",
      "Epoch 231/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5097 - tp: 205.0000 - fp: 55.0000 - tn: 389.0000 - fn: 63.0000 - accuracy: 0.8343 - precision: 0.7885 - recall: 0.7649 - auc: 0.8604 - val_loss: 0.4892 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8953\n",
      "Epoch 232/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4975 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8681 - val_loss: 0.4917 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8978\n",
      "Epoch 233/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4999 - tp: 200.0000 - fp: 52.0000 - tn: 392.0000 - fn: 68.0000 - accuracy: 0.8315 - precision: 0.7937 - recall: 0.7463 - auc: 0.8661 - val_loss: 0.4851 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8938\n",
      "Epoch 234/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4964 - tp: 194.0000 - fp: 42.0000 - tn: 402.0000 - fn: 74.0000 - accuracy: 0.8371 - precision: 0.8220 - recall: 0.7239 - auc: 0.8665 - val_loss: 0.4898 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8951\n",
      "Epoch 235/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4955 - tp: 207.0000 - fp: 59.0000 - tn: 385.0000 - fn: 61.0000 - accuracy: 0.8315 - precision: 0.7782 - recall: 0.7724 - auc: 0.8736 - val_loss: 0.4883 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8930\n",
      "Epoch 236/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5059 - tp: 201.0000 - fp: 48.0000 - tn: 396.0000 - fn: 67.0000 - accuracy: 0.8385 - precision: 0.8072 - recall: 0.7500 - auc: 0.8590 - val_loss: 0.4883 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8967\n",
      "Epoch 237/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4972 - tp: 201.0000 - fp: 57.0000 - tn: 387.0000 - fn: 67.0000 - accuracy: 0.8258 - precision: 0.7791 - recall: 0.7500 - auc: 0.8741 - val_loss: 0.4848 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8986\n",
      "Epoch 238/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5000 - tp: 193.0000 - fp: 40.0000 - tn: 404.0000 - fn: 75.0000 - accuracy: 0.8385 - precision: 0.8283 - recall: 0.7201 - auc: 0.8635 - val_loss: 0.4864 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8965\n",
      "Epoch 239/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4907 - tp: 207.0000 - fp: 55.0000 - tn: 389.0000 - fn: 61.0000 - accuracy: 0.8371 - precision: 0.7901 - recall: 0.7724 - auc: 0.8738 - val_loss: 0.4884 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8905\n",
      "Epoch 240/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5061 - tp: 193.0000 - fp: 58.0000 - tn: 386.0000 - fn: 75.0000 - accuracy: 0.8132 - precision: 0.7689 - recall: 0.7201 - auc: 0.8646 - val_loss: 0.4927 - val_tp: 63.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 11.0000 - val_accuracy: 0.8156 - val_precision: 0.7412 - val_recall: 0.8514 - val_auc: 0.8938\n",
      "Epoch 241/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4927 - tp: 203.0000 - fp: 45.0000 - tn: 399.0000 - fn: 65.0000 - accuracy: 0.8455 - precision: 0.8185 - recall: 0.7575 - auc: 0.8688 - val_loss: 0.4909 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8963\n",
      "Epoch 242/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4961 - tp: 199.0000 - fp: 49.0000 - tn: 395.0000 - fn: 69.0000 - accuracy: 0.8343 - precision: 0.8024 - recall: 0.7425 - auc: 0.8708 - val_loss: 0.4898 - val_tp: 61.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 13.0000 - val_accuracy: 0.7989 - val_precision: 0.7262 - val_recall: 0.8243 - val_auc: 0.8915\n",
      "Epoch 243/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5106 - tp: 211.0000 - fp: 75.0000 - tn: 369.0000 - fn: 57.0000 - accuracy: 0.8146 - precision: 0.7378 - recall: 0.7873 - auc: 0.8583 - val_loss: 0.4871 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8960\n",
      "Epoch 244/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5023 - tp: 197.0000 - fp: 50.0000 - tn: 394.0000 - fn: 71.0000 - accuracy: 0.8301 - precision: 0.7976 - recall: 0.7351 - auc: 0.8634 - val_loss: 0.4958 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8932\n",
      "Epoch 245/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4905 - tp: 200.0000 - fp: 55.0000 - tn: 389.0000 - fn: 68.0000 - accuracy: 0.8272 - precision: 0.7843 - recall: 0.7463 - auc: 0.8703 - val_loss: 0.4887 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8971\n",
      "Epoch 246/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4849 - tp: 206.0000 - fp: 50.0000 - tn: 394.0000 - fn: 62.0000 - accuracy: 0.8427 - precision: 0.8047 - recall: 0.7687 - auc: 0.8776 - val_loss: 0.4851 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8957\n",
      "Epoch 247/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5045 - tp: 203.0000 - fp: 55.0000 - tn: 389.0000 - fn: 65.0000 - accuracy: 0.8315 - precision: 0.7868 - recall: 0.7575 - auc: 0.8638 - val_loss: 0.4891 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8929\n",
      "Epoch 248/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5118 - tp: 198.0000 - fp: 52.0000 - tn: 392.0000 - fn: 70.0000 - accuracy: 0.8287 - precision: 0.7920 - recall: 0.7388 - auc: 0.8560 - val_loss: 0.4905 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8962\n",
      "Epoch 249/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4919 - tp: 201.0000 - fp: 55.0000 - tn: 389.0000 - fn: 67.0000 - accuracy: 0.8287 - precision: 0.7852 - recall: 0.7500 - auc: 0.8749 - val_loss: 0.4883 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8950\n",
      "Epoch 250/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4949 - tp: 196.0000 - fp: 44.0000 - tn: 400.0000 - fn: 72.0000 - accuracy: 0.8371 - precision: 0.8167 - recall: 0.7313 - auc: 0.8730 - val_loss: 0.4905 - val_tp: 62.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 12.0000 - val_accuracy: 0.8156 - val_precision: 0.7470 - val_recall: 0.8378 - val_auc: 0.8945\n",
      "Epoch 251/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4931 - tp: 207.0000 - fp: 55.0000 - tn: 389.0000 - fn: 61.0000 - accuracy: 0.8371 - precision: 0.7901 - recall: 0.7724 - auc: 0.8715 - val_loss: 0.4912 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8918\n",
      "Epoch 252/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5133 - tp: 204.0000 - fp: 59.0000 - tn: 385.0000 - fn: 64.0000 - accuracy: 0.8272 - precision: 0.7757 - recall: 0.7612 - auc: 0.8578 - val_loss: 0.4932 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8941\n",
      "Epoch 253/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5021 - tp: 201.0000 - fp: 45.0000 - tn: 399.0000 - fn: 67.0000 - accuracy: 0.8427 - precision: 0.8171 - recall: 0.7500 - auc: 0.8638 - val_loss: 0.4873 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8955\n",
      "Epoch 254/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4895 - tp: 208.0000 - fp: 63.0000 - tn: 381.0000 - fn: 60.0000 - accuracy: 0.8272 - precision: 0.7675 - recall: 0.7761 - auc: 0.8731 - val_loss: 0.4852 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8999\n",
      "Epoch 255/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4908 - tp: 206.0000 - fp: 60.0000 - tn: 384.0000 - fn: 62.0000 - accuracy: 0.8287 - precision: 0.7744 - recall: 0.7687 - auc: 0.8706 - val_loss: 0.4875 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8968\n",
      "Epoch 256/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4968 - tp: 202.0000 - fp: 46.0000 - tn: 398.0000 - fn: 66.0000 - accuracy: 0.8427 - precision: 0.8145 - recall: 0.7537 - auc: 0.8661 - val_loss: 0.4846 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8974\n",
      "Epoch 257/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4826 - tp: 201.0000 - fp: 44.0000 - tn: 400.0000 - fn: 67.0000 - accuracy: 0.8441 - precision: 0.8204 - recall: 0.7500 - auc: 0.8829 - val_loss: 0.4964 - val_tp: 63.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 11.0000 - val_accuracy: 0.8045 - val_precision: 0.7241 - val_recall: 0.8514 - val_auc: 0.8914\n",
      "Epoch 258/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4894 - tp: 209.0000 - fp: 60.0000 - tn: 384.0000 - fn: 59.0000 - accuracy: 0.8329 - precision: 0.7770 - recall: 0.7799 - auc: 0.8736 - val_loss: 0.4884 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8972\n",
      "Epoch 259/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5072 - tp: 204.0000 - fp: 62.0000 - tn: 382.0000 - fn: 64.0000 - accuracy: 0.8230 - precision: 0.7669 - recall: 0.7612 - auc: 0.8596 - val_loss: 0.4898 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8948\n",
      "Epoch 260/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4994 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8615 - val_loss: 0.4867 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8955\n",
      "Epoch 261/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4857 - tp: 194.0000 - fp: 47.0000 - tn: 397.0000 - fn: 74.0000 - accuracy: 0.8301 - precision: 0.8050 - recall: 0.7239 - auc: 0.8768 - val_loss: 0.4902 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8937\n",
      "Epoch 262/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4990 - tp: 201.0000 - fp: 62.0000 - tn: 382.0000 - fn: 67.0000 - accuracy: 0.8188 - precision: 0.7643 - recall: 0.7500 - auc: 0.8722 - val_loss: 0.4796 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8995\n",
      "Epoch 263/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4999 - tp: 200.0000 - fp: 50.0000 - tn: 394.0000 - fn: 68.0000 - accuracy: 0.8343 - precision: 0.8000 - recall: 0.7463 - auc: 0.8575 - val_loss: 0.4857 - val_tp: 62.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 12.0000 - val_accuracy: 0.8380 - val_precision: 0.7848 - val_recall: 0.8378 - val_auc: 0.8953\n",
      "Epoch 264/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.4996 - tp: 201.0000 - fp: 45.0000 - tn: 399.0000 - fn: 67.0000 - accuracy: 0.8427 - precision: 0.8171 - recall: 0.7500 - auc: 0.8660 - val_loss: 0.4858 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8927\n",
      "Epoch 265/500\n",
      "712/712 [==============================] - 0s 193us/sample - loss: 0.4978 - tp: 203.0000 - fp: 53.0000 - tn: 391.0000 - fn: 65.0000 - accuracy: 0.8343 - precision: 0.7930 - recall: 0.7575 - auc: 0.8685 - val_loss: 0.4787 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.9023\n",
      "Epoch 266/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.5029 - tp: 198.0000 - fp: 51.0000 - tn: 393.0000 - fn: 70.0000 - accuracy: 0.8301 - precision: 0.7952 - recall: 0.7388 - auc: 0.8642 - val_loss: 0.4878 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8913\n",
      "Epoch 267/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4832 - tp: 198.0000 - fp: 50.0000 - tn: 394.0000 - fn: 70.0000 - accuracy: 0.8315 - precision: 0.7984 - recall: 0.7388 - auc: 0.8763 - val_loss: 0.4925 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8900\n",
      "Epoch 268/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4983 - tp: 200.0000 - fp: 60.0000 - tn: 384.0000 - fn: 68.0000 - accuracy: 0.8202 - precision: 0.7692 - recall: 0.7463 - auc: 0.8689 - val_loss: 0.4912 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8898\n",
      "Epoch 269/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4994 - tp: 199.0000 - fp: 54.0000 - tn: 390.0000 - fn: 69.0000 - accuracy: 0.8272 - precision: 0.7866 - recall: 0.7425 - auc: 0.8684 - val_loss: 0.4837 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8990\n",
      "Epoch 270/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4841 - tp: 210.0000 - fp: 51.0000 - tn: 393.0000 - fn: 58.0000 - accuracy: 0.8469 - precision: 0.8046 - recall: 0.7836 - auc: 0.8801 - val_loss: 0.4811 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8933\n",
      "Epoch 271/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4935 - tp: 206.0000 - fp: 52.0000 - tn: 392.0000 - fn: 62.0000 - accuracy: 0.8399 - precision: 0.7984 - recall: 0.7687 - auc: 0.8663 - val_loss: 0.4897 - val_tp: 62.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 12.0000 - val_accuracy: 0.8324 - val_precision: 0.7750 - val_recall: 0.8378 - val_auc: 0.8931\n",
      "Epoch 272/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.4872 - tp: 203.0000 - fp: 58.0000 - tn: 386.0000 - fn: 65.0000 - accuracy: 0.8272 - precision: 0.7778 - recall: 0.7575 - auc: 0.8696 - val_loss: 0.4836 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8963\n",
      "Epoch 273/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4918 - tp: 201.0000 - fp: 50.0000 - tn: 394.0000 - fn: 67.0000 - accuracy: 0.8357 - precision: 0.8008 - recall: 0.7500 - auc: 0.8702 - val_loss: 0.4863 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8937\n",
      "Epoch 274/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4931 - tp: 202.0000 - fp: 66.0000 - tn: 378.0000 - fn: 66.0000 - accuracy: 0.8146 - precision: 0.7537 - recall: 0.7537 - auc: 0.8690 - val_loss: 0.4787 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8951\n",
      "Epoch 275/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.4922 - tp: 207.0000 - fp: 53.0000 - tn: 391.0000 - fn: 61.0000 - accuracy: 0.8399 - precision: 0.7962 - recall: 0.7724 - auc: 0.8686 - val_loss: 0.4834 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8959\n",
      "Epoch 276/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4877 - tp: 203.0000 - fp: 66.0000 - tn: 378.0000 - fn: 65.0000 - accuracy: 0.8160 - precision: 0.7546 - recall: 0.7575 - auc: 0.8757 - val_loss: 0.4803 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8921\n",
      "Epoch 277/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4988 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8659 - val_loss: 0.4862 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8941\n",
      "Epoch 278/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4872 - tp: 199.0000 - fp: 50.0000 - tn: 394.0000 - fn: 69.0000 - accuracy: 0.8329 - precision: 0.7992 - recall: 0.7425 - auc: 0.8727 - val_loss: 0.4879 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8935\n",
      "Epoch 279/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4986 - tp: 200.0000 - fp: 69.0000 - tn: 375.0000 - fn: 68.0000 - accuracy: 0.8076 - precision: 0.7435 - recall: 0.7463 - auc: 0.8593 - val_loss: 0.4885 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8941\n",
      "Epoch 280/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4925 - tp: 198.0000 - fp: 48.0000 - tn: 396.0000 - fn: 70.0000 - accuracy: 0.8343 - precision: 0.8049 - recall: 0.7388 - auc: 0.8662 - val_loss: 0.4897 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8938\n",
      "Epoch 281/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5032 - tp: 207.0000 - fp: 70.0000 - tn: 374.0000 - fn: 61.0000 - accuracy: 0.8160 - precision: 0.7473 - recall: 0.7724 - auc: 0.8615 - val_loss: 0.4985 - val_tp: 55.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 19.0000 - val_accuracy: 0.8324 - val_precision: 0.8333 - val_recall: 0.7432 - val_auc: 0.8974\n",
      "Epoch 282/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5075 - tp: 203.0000 - fp: 50.0000 - tn: 394.0000 - fn: 65.0000 - accuracy: 0.8385 - precision: 0.8024 - recall: 0.7575 - auc: 0.8574 - val_loss: 0.4827 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8963\n",
      "Epoch 283/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5014 - tp: 203.0000 - fp: 48.0000 - tn: 396.0000 - fn: 65.0000 - accuracy: 0.8413 - precision: 0.8088 - recall: 0.7575 - auc: 0.8541 - val_loss: 0.4827 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8950\n",
      "Epoch 284/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4991 - tp: 202.0000 - fp: 58.0000 - tn: 386.0000 - fn: 66.0000 - accuracy: 0.8258 - precision: 0.7769 - recall: 0.7537 - auc: 0.8600 - val_loss: 0.4890 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8926\n",
      "Epoch 285/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5106 - tp: 202.0000 - fp: 61.0000 - tn: 383.0000 - fn: 66.0000 - accuracy: 0.8216 - precision: 0.7681 - recall: 0.7537 - auc: 0.8607 - val_loss: 0.4930 - val_tp: 54.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 20.0000 - val_accuracy: 0.8156 - val_precision: 0.8060 - val_recall: 0.7297 - val_auc: 0.8923\n",
      "Epoch 286/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4939 - tp: 203.0000 - fp: 61.0000 - tn: 383.0000 - fn: 65.0000 - accuracy: 0.8230 - precision: 0.7689 - recall: 0.7575 - auc: 0.8704 - val_loss: 0.4840 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8959\n",
      "Epoch 287/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4999 - tp: 204.0000 - fp: 54.0000 - tn: 390.0000 - fn: 64.0000 - accuracy: 0.8343 - precision: 0.7907 - recall: 0.7612 - auc: 0.8663 - val_loss: 0.4862 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8949\n",
      "Epoch 288/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4915 - tp: 199.0000 - fp: 51.0000 - tn: 393.0000 - fn: 69.0000 - accuracy: 0.8315 - precision: 0.7960 - recall: 0.7425 - auc: 0.8728 - val_loss: 0.4877 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8949\n",
      "Epoch 289/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4962 - tp: 196.0000 - fp: 50.0000 - tn: 394.0000 - fn: 72.0000 - accuracy: 0.8287 - precision: 0.7967 - recall: 0.7313 - auc: 0.8720 - val_loss: 0.4973 - val_tp: 63.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 11.0000 - val_accuracy: 0.8045 - val_precision: 0.7241 - val_recall: 0.8514 - val_auc: 0.8924\n",
      "Epoch 290/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4773 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8790 - val_loss: 0.4852 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8925\n",
      "Epoch 291/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4810 - tp: 209.0000 - fp: 53.0000 - tn: 391.0000 - fn: 59.0000 - accuracy: 0.8427 - precision: 0.7977 - recall: 0.7799 - auc: 0.8764 - val_loss: 0.4847 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8913\n",
      "Epoch 292/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5001 - tp: 199.0000 - fp: 54.0000 - tn: 390.0000 - fn: 69.0000 - accuracy: 0.8272 - precision: 0.7866 - recall: 0.7425 - auc: 0.8614 - val_loss: 0.4785 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8959\n",
      "Epoch 293/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4944 - tp: 199.0000 - fp: 55.0000 - tn: 389.0000 - fn: 69.0000 - accuracy: 0.8258 - precision: 0.7835 - recall: 0.7425 - auc: 0.8690 - val_loss: 0.4818 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8958\n",
      "Epoch 294/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4967 - tp: 206.0000 - fp: 52.0000 - tn: 392.0000 - fn: 62.0000 - accuracy: 0.8399 - precision: 0.7984 - recall: 0.7687 - auc: 0.8611 - val_loss: 0.4840 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8946\n",
      "Epoch 295/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4974 - tp: 204.0000 - fp: 56.0000 - tn: 388.0000 - fn: 64.0000 - accuracy: 0.8315 - precision: 0.7846 - recall: 0.7612 - auc: 0.8635 - val_loss: 0.4908 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8941\n",
      "Epoch 296/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4924 - tp: 206.0000 - fp: 56.0000 - tn: 388.0000 - fn: 62.0000 - accuracy: 0.8343 - precision: 0.7863 - recall: 0.7687 - auc: 0.8696 - val_loss: 0.4903 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8907\n",
      "Epoch 297/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4891 - tp: 198.0000 - fp: 48.0000 - tn: 396.0000 - fn: 70.0000 - accuracy: 0.8343 - precision: 0.8049 - recall: 0.7388 - auc: 0.8735 - val_loss: 0.4874 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8909\n",
      "Epoch 298/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4849 - tp: 210.0000 - fp: 70.0000 - tn: 374.0000 - fn: 58.0000 - accuracy: 0.8202 - precision: 0.7500 - recall: 0.7836 - auc: 0.8742 - val_loss: 0.4853 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8952\n",
      "Epoch 299/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4983 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8639 - val_loss: 0.4821 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8955\n",
      "Epoch 300/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4940 - tp: 196.0000 - fp: 43.0000 - tn: 401.0000 - fn: 72.0000 - accuracy: 0.8385 - precision: 0.8201 - recall: 0.7313 - auc: 0.8647 - val_loss: 0.4930 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8916\n",
      "Epoch 301/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4965 - tp: 203.0000 - fp: 60.0000 - tn: 384.0000 - fn: 65.0000 - accuracy: 0.8244 - precision: 0.7719 - recall: 0.7575 - auc: 0.8705 - val_loss: 0.4854 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8949\n",
      "Epoch 302/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4870 - tp: 202.0000 - fp: 40.0000 - tn: 404.0000 - fn: 66.0000 - accuracy: 0.8511 - precision: 0.8347 - recall: 0.7537 - auc: 0.8767 - val_loss: 0.4892 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8898\n",
      "Epoch 303/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4812 - tp: 198.0000 - fp: 51.0000 - tn: 393.0000 - fn: 70.0000 - accuracy: 0.8301 - precision: 0.7952 - recall: 0.7388 - auc: 0.8824 - val_loss: 0.4810 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8927\n",
      "Epoch 304/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4925 - tp: 200.0000 - fp: 55.0000 - tn: 389.0000 - fn: 68.0000 - accuracy: 0.8272 - precision: 0.7843 - recall: 0.7463 - auc: 0.8731 - val_loss: 0.4864 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8939\n",
      "Epoch 305/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4882 - tp: 204.0000 - fp: 48.0000 - tn: 396.0000 - fn: 64.0000 - accuracy: 0.8427 - precision: 0.8095 - recall: 0.7612 - auc: 0.8681 - val_loss: 0.4837 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8955\n",
      "Epoch 306/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4932 - tp: 202.0000 - fp: 55.0000 - tn: 389.0000 - fn: 66.0000 - accuracy: 0.8301 - precision: 0.7860 - recall: 0.7537 - auc: 0.8757 - val_loss: 0.4847 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8918\n",
      "Epoch 307/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4955 - tp: 196.0000 - fp: 45.0000 - tn: 399.0000 - fn: 72.0000 - accuracy: 0.8357 - precision: 0.8133 - recall: 0.7313 - auc: 0.8687 - val_loss: 0.4959 - val_tp: 63.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 11.0000 - val_accuracy: 0.8045 - val_precision: 0.7241 - val_recall: 0.8514 - val_auc: 0.8888\n",
      "Epoch 308/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4941 - tp: 207.0000 - fp: 60.0000 - tn: 384.0000 - fn: 61.0000 - accuracy: 0.8301 - precision: 0.7753 - recall: 0.7724 - auc: 0.8609 - val_loss: 0.4863 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8952\n",
      "Epoch 309/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.4881 - tp: 204.0000 - fp: 60.0000 - tn: 384.0000 - fn: 64.0000 - accuracy: 0.8258 - precision: 0.7727 - recall: 0.7612 - auc: 0.8796 - val_loss: 0.4913 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8959\n",
      "Epoch 310/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5013 - tp: 192.0000 - fp: 41.0000 - tn: 403.0000 - fn: 76.0000 - accuracy: 0.8357 - precision: 0.8240 - recall: 0.7164 - auc: 0.8655 - val_loss: 0.4839 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8921\n",
      "Epoch 311/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4837 - tp: 215.0000 - fp: 66.0000 - tn: 378.0000 - fn: 53.0000 - accuracy: 0.8329 - precision: 0.7651 - recall: 0.8022 - auc: 0.8741 - val_loss: 0.4861 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8924\n",
      "Epoch 312/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4988 - tp: 198.0000 - fp: 49.0000 - tn: 395.0000 - fn: 70.0000 - accuracy: 0.8329 - precision: 0.8016 - recall: 0.7388 - auc: 0.8658 - val_loss: 0.4861 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8945\n",
      "Epoch 313/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5026 - tp: 198.0000 - fp: 46.0000 - tn: 398.0000 - fn: 70.0000 - accuracy: 0.8371 - precision: 0.8115 - recall: 0.7388 - auc: 0.8535 - val_loss: 0.4907 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8894\n",
      "Epoch 314/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4919 - tp: 201.0000 - fp: 46.0000 - tn: 398.0000 - fn: 67.0000 - accuracy: 0.8413 - precision: 0.8138 - recall: 0.7500 - auc: 0.8651 - val_loss: 0.4854 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8935\n",
      "Epoch 315/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4967 - tp: 200.0000 - fp: 63.0000 - tn: 381.0000 - fn: 68.0000 - accuracy: 0.8160 - precision: 0.7605 - recall: 0.7463 - auc: 0.8652 - val_loss: 0.4969 - val_tp: 55.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 19.0000 - val_accuracy: 0.8324 - val_precision: 0.8333 - val_recall: 0.7432 - val_auc: 0.8963\n",
      "Epoch 316/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5107 - tp: 192.0000 - fp: 53.0000 - tn: 391.0000 - fn: 76.0000 - accuracy: 0.8188 - precision: 0.7837 - recall: 0.7164 - auc: 0.8555 - val_loss: 0.4805 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8947\n",
      "Epoch 317/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4865 - tp: 200.0000 - fp: 51.0000 - tn: 393.0000 - fn: 68.0000 - accuracy: 0.8329 - precision: 0.7968 - recall: 0.7463 - auc: 0.8764 - val_loss: 0.4817 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8938\n",
      "Epoch 318/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5058 - tp: 203.0000 - fp: 59.0000 - tn: 385.0000 - fn: 65.0000 - accuracy: 0.8258 - precision: 0.7748 - recall: 0.7575 - auc: 0.8552 - val_loss: 0.4843 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8941\n",
      "Epoch 319/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5064 - tp: 189.0000 - fp: 45.0000 - tn: 399.0000 - fn: 79.0000 - accuracy: 0.8258 - precision: 0.8077 - recall: 0.7052 - auc: 0.8683 - val_loss: 0.4828 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8941\n",
      "Epoch 320/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4897 - tp: 207.0000 - fp: 65.0000 - tn: 379.0000 - fn: 61.0000 - accuracy: 0.8230 - precision: 0.7610 - recall: 0.7724 - auc: 0.8691 - val_loss: 0.4756 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8972\n",
      "Epoch 321/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4830 - tp: 202.0000 - fp: 61.0000 - tn: 383.0000 - fn: 66.0000 - accuracy: 0.8216 - precision: 0.7681 - recall: 0.7537 - auc: 0.8741 - val_loss: 0.4838 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8965\n",
      "Epoch 322/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4884 - tp: 196.0000 - fp: 46.0000 - tn: 398.0000 - fn: 72.0000 - accuracy: 0.8343 - precision: 0.8099 - recall: 0.7313 - auc: 0.8675 - val_loss: 0.4876 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8940\n",
      "Epoch 323/500\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.4826 - tp: 209.0000 - fp: 63.0000 - tn: 381.0000 - fn: 59.0000 - accuracy: 0.8287 - precision: 0.7684 - recall: 0.7799 - auc: 0.8772 - val_loss: 0.4842 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8932\n",
      "Epoch 324/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4948 - tp: 201.0000 - fp: 56.0000 - tn: 388.0000 - fn: 67.0000 - accuracy: 0.8272 - precision: 0.7821 - recall: 0.7500 - auc: 0.8669 - val_loss: 0.4843 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8957\n",
      "Epoch 325/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4956 - tp: 204.0000 - fp: 58.0000 - tn: 386.0000 - fn: 64.0000 - accuracy: 0.8287 - precision: 0.7786 - recall: 0.7612 - auc: 0.8699 - val_loss: 0.4841 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8947\n",
      "Epoch 326/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4838 - tp: 201.0000 - fp: 49.0000 - tn: 395.0000 - fn: 67.0000 - accuracy: 0.8371 - precision: 0.8040 - recall: 0.7500 - auc: 0.8712 - val_loss: 0.4822 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8963\n",
      "Epoch 327/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4852 - tp: 204.0000 - fp: 47.0000 - tn: 397.0000 - fn: 64.0000 - accuracy: 0.8441 - precision: 0.8127 - recall: 0.7612 - auc: 0.8709 - val_loss: 0.4822 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8942\n",
      "Epoch 328/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4846 - tp: 207.0000 - fp: 51.0000 - tn: 393.0000 - fn: 61.0000 - accuracy: 0.8427 - precision: 0.8023 - recall: 0.7724 - auc: 0.8758 - val_loss: 0.4776 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8950\n",
      "Epoch 329/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5075 - tp: 197.0000 - fp: 48.0000 - tn: 396.0000 - fn: 71.0000 - accuracy: 0.8329 - precision: 0.8041 - recall: 0.7351 - auc: 0.8560 - val_loss: 0.4760 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8977\n",
      "Epoch 330/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4772 - tp: 208.0000 - fp: 57.0000 - tn: 387.0000 - fn: 60.0000 - accuracy: 0.8357 - precision: 0.7849 - recall: 0.7761 - auc: 0.8769 - val_loss: 0.4796 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8964\n",
      "Epoch 331/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4983 - tp: 202.0000 - fp: 57.0000 - tn: 387.0000 - fn: 66.0000 - accuracy: 0.8272 - precision: 0.7799 - recall: 0.7537 - auc: 0.8586 - val_loss: 0.4829 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8941\n",
      "Epoch 332/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4938 - tp: 207.0000 - fp: 58.0000 - tn: 386.0000 - fn: 61.0000 - accuracy: 0.8329 - precision: 0.7811 - recall: 0.7724 - auc: 0.8670 - val_loss: 0.4924 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8949\n",
      "Epoch 333/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5010 - tp: 198.0000 - fp: 51.0000 - tn: 393.0000 - fn: 70.0000 - accuracy: 0.8301 - precision: 0.7952 - recall: 0.7388 - auc: 0.8583 - val_loss: 0.4821 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8977\n",
      "Epoch 334/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4816 - tp: 200.0000 - fp: 52.0000 - tn: 392.0000 - fn: 68.0000 - accuracy: 0.8315 - precision: 0.7937 - recall: 0.7463 - auc: 0.8781 - val_loss: 0.4789 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8931\n",
      "Epoch 335/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4919 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8621 - val_loss: 0.4851 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8917\n",
      "Epoch 336/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4913 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8688 - val_loss: 0.4785 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8963\n",
      "Epoch 337/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4934 - tp: 206.0000 - fp: 58.0000 - tn: 386.0000 - fn: 62.0000 - accuracy: 0.8315 - precision: 0.7803 - recall: 0.7687 - auc: 0.8639 - val_loss: 0.4774 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8957\n",
      "Epoch 338/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4818 - tp: 205.0000 - fp: 53.0000 - tn: 391.0000 - fn: 63.0000 - accuracy: 0.8371 - precision: 0.7946 - recall: 0.7649 - auc: 0.8711 - val_loss: 0.4836 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8947\n",
      "Epoch 339/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4932 - tp: 200.0000 - fp: 53.0000 - tn: 391.0000 - fn: 68.0000 - accuracy: 0.8301 - precision: 0.7905 - recall: 0.7463 - auc: 0.8706 - val_loss: 0.4775 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8997\n",
      "Epoch 340/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5103 - tp: 191.0000 - fp: 49.0000 - tn: 395.0000 - fn: 77.0000 - accuracy: 0.8230 - precision: 0.7958 - recall: 0.7127 - auc: 0.8514 - val_loss: 0.4765 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8960\n",
      "Epoch 341/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4909 - tp: 201.0000 - fp: 43.0000 - tn: 401.0000 - fn: 67.0000 - accuracy: 0.8455 - precision: 0.8238 - recall: 0.7500 - auc: 0.8659 - val_loss: 0.4921 - val_tp: 66.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 8.0000 - val_accuracy: 0.7989 - val_precision: 0.7021 - val_recall: 0.8919 - val_auc: 0.8922\n",
      "Epoch 342/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4963 - tp: 191.0000 - fp: 52.0000 - tn: 392.0000 - fn: 77.0000 - accuracy: 0.8188 - precision: 0.7860 - recall: 0.7127 - auc: 0.8655 - val_loss: 0.4815 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8957\n",
      "Epoch 343/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4904 - tp: 205.0000 - fp: 63.0000 - tn: 381.0000 - fn: 63.0000 - accuracy: 0.8230 - precision: 0.7649 - recall: 0.7649 - auc: 0.8701 - val_loss: 0.4833 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8945\n",
      "Epoch 344/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4821 - tp: 196.0000 - fp: 46.0000 - tn: 398.0000 - fn: 72.0000 - accuracy: 0.8343 - precision: 0.8099 - recall: 0.7313 - auc: 0.8771 - val_loss: 0.4903 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8925\n",
      "Epoch 345/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4903 - tp: 202.0000 - fp: 50.0000 - tn: 394.0000 - fn: 66.0000 - accuracy: 0.8371 - precision: 0.8016 - recall: 0.7537 - auc: 0.8629 - val_loss: 0.4768 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8969\n",
      "Epoch 346/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4932 - tp: 197.0000 - fp: 43.0000 - tn: 401.0000 - fn: 71.0000 - accuracy: 0.8399 - precision: 0.8208 - recall: 0.7351 - auc: 0.8749 - val_loss: 0.4879 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8920\n",
      "Epoch 347/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4906 - tp: 202.0000 - fp: 49.0000 - tn: 395.0000 - fn: 66.0000 - accuracy: 0.8385 - precision: 0.8048 - recall: 0.7537 - auc: 0.8605 - val_loss: 0.4861 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8965\n",
      "Epoch 348/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4983 - tp: 204.0000 - fp: 59.0000 - tn: 385.0000 - fn: 64.0000 - accuracy: 0.8272 - precision: 0.7757 - recall: 0.7612 - auc: 0.8661 - val_loss: 0.4760 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8975\n",
      "Epoch 349/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4844 - tp: 193.0000 - fp: 38.0000 - tn: 406.0000 - fn: 75.0000 - accuracy: 0.8413 - precision: 0.8355 - recall: 0.7201 - auc: 0.8838 - val_loss: 0.4819 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8907\n",
      "Epoch 350/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4962 - tp: 200.0000 - fp: 49.0000 - tn: 395.0000 - fn: 68.0000 - accuracy: 0.8357 - precision: 0.8032 - recall: 0.7463 - auc: 0.8656 - val_loss: 0.4756 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8970\n",
      "Epoch 351/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4868 - tp: 199.0000 - fp: 47.0000 - tn: 397.0000 - fn: 69.0000 - accuracy: 0.8371 - precision: 0.8089 - recall: 0.7425 - auc: 0.8752 - val_loss: 0.4755 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8931\n",
      "Epoch 352/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4863 - tp: 208.0000 - fp: 72.0000 - tn: 372.0000 - fn: 60.0000 - accuracy: 0.8146 - precision: 0.7429 - recall: 0.7761 - auc: 0.8704 - val_loss: 0.4830 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8922\n",
      "Epoch 353/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5029 - tp: 201.0000 - fp: 63.0000 - tn: 381.0000 - fn: 67.0000 - accuracy: 0.8174 - precision: 0.7614 - recall: 0.7500 - auc: 0.8664 - val_loss: 0.4830 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8952\n",
      "Epoch 354/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4778 - tp: 205.0000 - fp: 55.0000 - tn: 389.0000 - fn: 63.0000 - accuracy: 0.8343 - precision: 0.7885 - recall: 0.7649 - auc: 0.8818 - val_loss: 0.4836 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8923\n",
      "Epoch 355/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5019 - tp: 201.0000 - fp: 52.0000 - tn: 392.0000 - fn: 67.0000 - accuracy: 0.8329 - precision: 0.7945 - recall: 0.7500 - auc: 0.8598 - val_loss: 0.4905 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8910\n",
      "Epoch 356/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4823 - tp: 200.0000 - fp: 63.0000 - tn: 381.0000 - fn: 68.0000 - accuracy: 0.8160 - precision: 0.7605 - recall: 0.7463 - auc: 0.8763 - val_loss: 0.4826 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8943\n",
      "Epoch 357/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4777 - tp: 204.0000 - fp: 49.0000 - tn: 395.0000 - fn: 64.0000 - accuracy: 0.8413 - precision: 0.8063 - recall: 0.7612 - auc: 0.8738 - val_loss: 0.4820 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8940\n",
      "Epoch 358/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4937 - tp: 198.0000 - fp: 45.0000 - tn: 399.0000 - fn: 70.0000 - accuracy: 0.8385 - precision: 0.8148 - recall: 0.7388 - auc: 0.8719 - val_loss: 0.5069 - val_tp: 67.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 7.0000 - val_accuracy: 0.7989 - val_precision: 0.6979 - val_recall: 0.9054 - val_auc: 0.8909\n",
      "Epoch 359/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4865 - tp: 199.0000 - fp: 49.0000 - tn: 395.0000 - fn: 69.0000 - accuracy: 0.8343 - precision: 0.8024 - recall: 0.7425 - auc: 0.8695 - val_loss: 0.4838 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8940\n",
      "Epoch 360/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4904 - tp: 207.0000 - fp: 61.0000 - tn: 383.0000 - fn: 61.0000 - accuracy: 0.8287 - precision: 0.7724 - recall: 0.7724 - auc: 0.8746 - val_loss: 0.4735 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8956\n",
      "Epoch 361/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4968 - tp: 201.0000 - fp: 49.0000 - tn: 395.0000 - fn: 67.0000 - accuracy: 0.8371 - precision: 0.8040 - recall: 0.7500 - auc: 0.8647 - val_loss: 0.4765 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.9008\n",
      "Epoch 362/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5013 - tp: 196.0000 - fp: 50.0000 - tn: 394.0000 - fn: 72.0000 - accuracy: 0.8287 - precision: 0.7967 - recall: 0.7313 - auc: 0.8560 - val_loss: 0.4782 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8926\n",
      "Epoch 363/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4918 - tp: 193.0000 - fp: 57.0000 - tn: 387.0000 - fn: 75.0000 - accuracy: 0.8146 - precision: 0.7720 - recall: 0.7201 - auc: 0.8673 - val_loss: 0.4825 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8935\n",
      "Epoch 364/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4877 - tp: 197.0000 - fp: 48.0000 - tn: 396.0000 - fn: 71.0000 - accuracy: 0.8329 - precision: 0.8041 - recall: 0.7351 - auc: 0.8705 - val_loss: 0.4888 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8912\n",
      "Epoch 365/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4870 - tp: 203.0000 - fp: 55.0000 - tn: 389.0000 - fn: 65.0000 - accuracy: 0.8315 - precision: 0.7868 - recall: 0.7575 - auc: 0.8671 - val_loss: 0.4863 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8898\n",
      "Epoch 366/500\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.4871 - tp: 200.0000 - fp: 45.0000 - tn: 399.0000 - fn: 68.0000 - accuracy: 0.8413 - precision: 0.8163 - recall: 0.7463 - auc: 0.8659 - val_loss: 0.4887 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8963\n",
      "Epoch 367/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4761 - tp: 206.0000 - fp: 56.0000 - tn: 388.0000 - fn: 62.0000 - accuracy: 0.8343 - precision: 0.7863 - recall: 0.7687 - auc: 0.8751 - val_loss: 0.4834 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8946\n",
      "Epoch 368/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4937 - tp: 200.0000 - fp: 46.0000 - tn: 398.0000 - fn: 68.0000 - accuracy: 0.8399 - precision: 0.8130 - recall: 0.7463 - auc: 0.8654 - val_loss: 0.4898 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8916\n",
      "Epoch 369/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.4889 - tp: 198.0000 - fp: 52.0000 - tn: 392.0000 - fn: 70.0000 - accuracy: 0.8287 - precision: 0.7920 - recall: 0.7388 - auc: 0.8691 - val_loss: 0.4794 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8924\n",
      "Epoch 370/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4907 - tp: 209.0000 - fp: 64.0000 - tn: 380.0000 - fn: 59.0000 - accuracy: 0.8272 - precision: 0.7656 - recall: 0.7799 - auc: 0.8641 - val_loss: 0.4823 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8946\n",
      "Epoch 371/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4929 - tp: 199.0000 - fp: 45.0000 - tn: 399.0000 - fn: 69.0000 - accuracy: 0.8399 - precision: 0.8156 - recall: 0.7425 - auc: 0.8688 - val_loss: 0.4998 - val_tp: 63.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 11.0000 - val_accuracy: 0.7989 - val_precision: 0.7159 - val_recall: 0.8514 - val_auc: 0.8912\n",
      "Epoch 372/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5024 - tp: 206.0000 - fp: 65.0000 - tn: 379.0000 - fn: 62.0000 - accuracy: 0.8216 - precision: 0.7601 - recall: 0.7687 - auc: 0.8735 - val_loss: 0.4782 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8921\n",
      "Epoch 373/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4835 - tp: 202.0000 - fp: 51.0000 - tn: 393.0000 - fn: 66.0000 - accuracy: 0.8357 - precision: 0.7984 - recall: 0.7537 - auc: 0.8702 - val_loss: 0.4869 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8914\n",
      "Epoch 374/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5014 - tp: 201.0000 - fp: 56.0000 - tn: 388.0000 - fn: 67.0000 - accuracy: 0.8272 - precision: 0.7821 - recall: 0.7500 - auc: 0.8575 - val_loss: 0.4854 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8985\n",
      "Epoch 375/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4938 - tp: 194.0000 - fp: 42.0000 - tn: 402.0000 - fn: 74.0000 - accuracy: 0.8371 - precision: 0.8220 - recall: 0.7239 - auc: 0.8668 - val_loss: 0.4825 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8954\n",
      "Epoch 376/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4790 - tp: 207.0000 - fp: 53.0000 - tn: 391.0000 - fn: 61.0000 - accuracy: 0.8399 - precision: 0.7962 - recall: 0.7724 - auc: 0.8738 - val_loss: 0.4837 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8961\n",
      "Epoch 377/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5016 - tp: 194.0000 - fp: 43.0000 - tn: 401.0000 - fn: 74.0000 - accuracy: 0.8357 - precision: 0.8186 - recall: 0.7239 - auc: 0.8617 - val_loss: 0.4957 - val_tp: 55.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 19.0000 - val_accuracy: 0.8324 - val_precision: 0.8333 - val_recall: 0.7432 - val_auc: 0.8963\n",
      "Epoch 378/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4984 - tp: 199.0000 - fp: 67.0000 - tn: 377.0000 - fn: 69.0000 - accuracy: 0.8090 - precision: 0.7481 - recall: 0.7425 - auc: 0.8674 - val_loss: 0.4779 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8956\n",
      "Epoch 379/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4901 - tp: 207.0000 - fp: 57.0000 - tn: 387.0000 - fn: 61.0000 - accuracy: 0.8343 - precision: 0.7841 - recall: 0.7724 - auc: 0.8706 - val_loss: 0.4738 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8959\n",
      "Epoch 380/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4781 - tp: 200.0000 - fp: 42.0000 - tn: 402.0000 - fn: 68.0000 - accuracy: 0.8455 - precision: 0.8264 - recall: 0.7463 - auc: 0.8784 - val_loss: 0.4900 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8948\n",
      "Epoch 381/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.5005 - tp: 193.0000 - fp: 49.0000 - tn: 395.0000 - fn: 75.0000 - accuracy: 0.8258 - precision: 0.7975 - recall: 0.7201 - auc: 0.8658 - val_loss: 0.4937 - val_tp: 63.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 11.0000 - val_accuracy: 0.8045 - val_precision: 0.7241 - val_recall: 0.8514 - val_auc: 0.8912\n",
      "Epoch 382/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.5011 - tp: 205.0000 - fp: 61.0000 - tn: 383.0000 - fn: 63.0000 - accuracy: 0.8258 - precision: 0.7707 - recall: 0.7649 - auc: 0.8627 - val_loss: 0.4825 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8949\n",
      "Epoch 383/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5092 - tp: 203.0000 - fp: 56.0000 - tn: 388.0000 - fn: 65.0000 - accuracy: 0.8301 - precision: 0.7838 - recall: 0.7575 - auc: 0.8552 - val_loss: 0.4817 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8949\n",
      "Epoch 384/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4916 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8666 - val_loss: 0.4881 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8893\n",
      "Epoch 385/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4940 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8668 - val_loss: 0.4827 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8958\n",
      "Epoch 386/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.4726 - tp: 198.0000 - fp: 53.0000 - tn: 391.0000 - fn: 70.0000 - accuracy: 0.8272 - precision: 0.7888 - recall: 0.7388 - auc: 0.8745 - val_loss: 0.4883 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8916\n",
      "Epoch 387/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4682 - tp: 208.0000 - fp: 58.0000 - tn: 386.0000 - fn: 60.0000 - accuracy: 0.8343 - precision: 0.7820 - recall: 0.7761 - auc: 0.8855 - val_loss: 0.4924 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8927\n",
      "Epoch 388/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4720 - tp: 206.0000 - fp: 45.0000 - tn: 399.0000 - fn: 62.0000 - accuracy: 0.8497 - precision: 0.8207 - recall: 0.7687 - auc: 0.8869 - val_loss: 0.4797 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8945\n",
      "Epoch 389/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4899 - tp: 192.0000 - fp: 51.0000 - tn: 393.0000 - fn: 76.0000 - accuracy: 0.8216 - precision: 0.7901 - recall: 0.7164 - auc: 0.8634 - val_loss: 0.4751 - val_tp: 58.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 16.0000 - val_accuracy: 0.7877 - val_precision: 0.7250 - val_recall: 0.7838 - val_auc: 0.8950\n",
      "Epoch 390/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4843 - tp: 199.0000 - fp: 52.0000 - tn: 392.0000 - fn: 69.0000 - accuracy: 0.8301 - precision: 0.7928 - recall: 0.7425 - auc: 0.8693 - val_loss: 0.4848 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8913\n",
      "Epoch 391/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4814 - tp: 203.0000 - fp: 52.0000 - tn: 392.0000 - fn: 65.0000 - accuracy: 0.8357 - precision: 0.7961 - recall: 0.7575 - auc: 0.8751 - val_loss: 0.4825 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8976\n",
      "Epoch 392/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4838 - tp: 201.0000 - fp: 54.0000 - tn: 390.0000 - fn: 67.0000 - accuracy: 0.8301 - precision: 0.7882 - recall: 0.7500 - auc: 0.8771 - val_loss: 0.4741 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8960\n",
      "Epoch 393/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4932 - tp: 198.0000 - fp: 55.0000 - tn: 389.0000 - fn: 70.0000 - accuracy: 0.8244 - precision: 0.7826 - recall: 0.7388 - auc: 0.8656 - val_loss: 0.4753 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8961\n",
      "Epoch 394/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4821 - tp: 209.0000 - fp: 58.0000 - tn: 386.0000 - fn: 59.0000 - accuracy: 0.8357 - precision: 0.7828 - recall: 0.7799 - auc: 0.8746 - val_loss: 0.4841 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8916\n",
      "Epoch 395/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4918 - tp: 201.0000 - fp: 43.0000 - tn: 401.0000 - fn: 67.0000 - accuracy: 0.8455 - precision: 0.8238 - recall: 0.7500 - auc: 0.8710 - val_loss: 0.4804 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8967\n",
      "Epoch 396/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4946 - tp: 200.0000 - fp: 46.0000 - tn: 398.0000 - fn: 68.0000 - accuracy: 0.8399 - precision: 0.8130 - recall: 0.7463 - auc: 0.8654 - val_loss: 0.4781 - val_tp: 55.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 19.0000 - val_accuracy: 0.8101 - val_precision: 0.7857 - val_recall: 0.7432 - val_auc: 0.8951\n",
      "Epoch 397/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4815 - tp: 203.0000 - fp: 59.0000 - tn: 385.0000 - fn: 65.0000 - accuracy: 0.8258 - precision: 0.7748 - recall: 0.7575 - auc: 0.8688 - val_loss: 0.4788 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8956\n",
      "Epoch 398/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4773 - tp: 199.0000 - fp: 49.0000 - tn: 395.0000 - fn: 69.0000 - accuracy: 0.8343 - precision: 0.8024 - recall: 0.7425 - auc: 0.8765 - val_loss: 0.4725 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8967\n",
      "Epoch 399/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4888 - tp: 195.0000 - fp: 43.0000 - tn: 401.0000 - fn: 73.0000 - accuracy: 0.8371 - precision: 0.8193 - recall: 0.7276 - auc: 0.8676 - val_loss: 0.4820 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8920\n",
      "Epoch 400/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5004 - tp: 200.0000 - fp: 63.0000 - tn: 381.0000 - fn: 68.0000 - accuracy: 0.8160 - precision: 0.7605 - recall: 0.7463 - auc: 0.8635 - val_loss: 0.4850 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8930\n",
      "Epoch 401/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4924 - tp: 195.0000 - fp: 53.0000 - tn: 391.0000 - fn: 73.0000 - accuracy: 0.8230 - precision: 0.7863 - recall: 0.7276 - auc: 0.8669 - val_loss: 0.4845 - val_tp: 58.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 16.0000 - val_accuracy: 0.7877 - val_precision: 0.7250 - val_recall: 0.7838 - val_auc: 0.8914\n",
      "Epoch 402/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4772 - tp: 203.0000 - fp: 52.0000 - tn: 392.0000 - fn: 65.0000 - accuracy: 0.8357 - precision: 0.7961 - recall: 0.7575 - auc: 0.8794 - val_loss: 0.4825 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8943\n",
      "Epoch 403/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4884 - tp: 196.0000 - fp: 42.0000 - tn: 402.0000 - fn: 72.0000 - accuracy: 0.8399 - precision: 0.8235 - recall: 0.7313 - auc: 0.8667 - val_loss: 0.4955 - val_tp: 63.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 11.0000 - val_accuracy: 0.8156 - val_precision: 0.7412 - val_recall: 0.8514 - val_auc: 0.8934\n",
      "Epoch 404/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5060 - tp: 204.0000 - fp: 58.0000 - tn: 386.0000 - fn: 64.0000 - accuracy: 0.8287 - precision: 0.7786 - recall: 0.7612 - auc: 0.8599 - val_loss: 0.4752 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8933\n",
      "Epoch 405/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4958 - tp: 200.0000 - fp: 51.0000 - tn: 393.0000 - fn: 68.0000 - accuracy: 0.8329 - precision: 0.7968 - recall: 0.7463 - auc: 0.8597 - val_loss: 0.4830 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8940\n",
      "Epoch 406/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4897 - tp: 205.0000 - fp: 60.0000 - tn: 384.0000 - fn: 63.0000 - accuracy: 0.8272 - precision: 0.7736 - recall: 0.7649 - auc: 0.8686 - val_loss: 0.4952 - val_tp: 54.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 20.0000 - val_accuracy: 0.8212 - val_precision: 0.8182 - val_recall: 0.7297 - val_auc: 0.8936\n",
      "Epoch 407/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4893 - tp: 198.0000 - fp: 47.0000 - tn: 397.0000 - fn: 70.0000 - accuracy: 0.8357 - precision: 0.8082 - recall: 0.7388 - auc: 0.8689 - val_loss: 0.4857 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8894\n",
      "Epoch 408/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4818 - tp: 195.0000 - fp: 52.0000 - tn: 392.0000 - fn: 73.0000 - accuracy: 0.8244 - precision: 0.7895 - recall: 0.7276 - auc: 0.8802 - val_loss: 0.4829 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8955\n",
      "Epoch 409/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4787 - tp: 202.0000 - fp: 48.0000 - tn: 396.0000 - fn: 66.0000 - accuracy: 0.8399 - precision: 0.8080 - recall: 0.7537 - auc: 0.8744 - val_loss: 0.4715 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8952\n",
      "Epoch 410/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4897 - tp: 197.0000 - fp: 46.0000 - tn: 398.0000 - fn: 71.0000 - accuracy: 0.8357 - precision: 0.8107 - recall: 0.7351 - auc: 0.8702 - val_loss: 0.4826 - val_tp: 63.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 11.0000 - val_accuracy: 0.8101 - val_precision: 0.7326 - val_recall: 0.8514 - val_auc: 0.8954\n",
      "Epoch 411/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4963 - tp: 213.0000 - fp: 70.0000 - tn: 374.0000 - fn: 55.0000 - accuracy: 0.8244 - precision: 0.7527 - recall: 0.7948 - auc: 0.8686 - val_loss: 0.4737 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8974\n",
      "Epoch 412/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5009 - tp: 207.0000 - fp: 68.0000 - tn: 376.0000 - fn: 61.0000 - accuracy: 0.8188 - precision: 0.7527 - recall: 0.7724 - auc: 0.8598 - val_loss: 0.4823 - val_tp: 54.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 20.0000 - val_accuracy: 0.8268 - val_precision: 0.8308 - val_recall: 0.7297 - val_auc: 0.8995\n",
      "Epoch 413/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5002 - tp: 193.0000 - fp: 45.0000 - tn: 399.0000 - fn: 75.0000 - accuracy: 0.8315 - precision: 0.8109 - recall: 0.7201 - auc: 0.8646 - val_loss: 0.4841 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8951\n",
      "Epoch 414/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4866 - tp: 194.0000 - fp: 45.0000 - tn: 399.0000 - fn: 74.0000 - accuracy: 0.8329 - precision: 0.8117 - recall: 0.7239 - auc: 0.8716 - val_loss: 0.4960 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8898\n",
      "Epoch 415/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5018 - tp: 199.0000 - fp: 60.0000 - tn: 384.0000 - fn: 69.0000 - accuracy: 0.8188 - precision: 0.7683 - recall: 0.7425 - auc: 0.8585 - val_loss: 0.4780 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8967\n",
      "Epoch 416/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4811 - tp: 198.0000 - fp: 49.0000 - tn: 395.0000 - fn: 70.0000 - accuracy: 0.8329 - precision: 0.8016 - recall: 0.7388 - auc: 0.8781 - val_loss: 0.4802 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8939\n",
      "Epoch 417/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4906 - tp: 201.0000 - fp: 50.0000 - tn: 394.0000 - fn: 67.0000 - accuracy: 0.8357 - precision: 0.8008 - recall: 0.7500 - auc: 0.8708 - val_loss: 0.4851 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8909\n",
      "Epoch 418/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4850 - tp: 196.0000 - fp: 46.0000 - tn: 398.0000 - fn: 72.0000 - accuracy: 0.8343 - precision: 0.8099 - recall: 0.7313 - auc: 0.8735 - val_loss: 0.4777 - val_tp: 62.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 12.0000 - val_accuracy: 0.8045 - val_precision: 0.7294 - val_recall: 0.8378 - val_auc: 0.8938\n",
      "Epoch 419/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4992 - tp: 196.0000 - fp: 55.0000 - tn: 389.0000 - fn: 72.0000 - accuracy: 0.8216 - precision: 0.7809 - recall: 0.7313 - auc: 0.8647 - val_loss: 0.4785 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8933\n",
      "Epoch 420/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4827 - tp: 204.0000 - fp: 54.0000 - tn: 390.0000 - fn: 64.0000 - accuracy: 0.8343 - precision: 0.7907 - recall: 0.7612 - auc: 0.8685 - val_loss: 0.4922 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8952\n",
      "Epoch 421/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4857 - tp: 198.0000 - fp: 58.0000 - tn: 386.0000 - fn: 70.0000 - accuracy: 0.8202 - precision: 0.7734 - recall: 0.7388 - auc: 0.8685 - val_loss: 0.4803 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8943\n",
      "Epoch 422/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5079 - tp: 202.0000 - fp: 57.0000 - tn: 387.0000 - fn: 66.0000 - accuracy: 0.8272 - precision: 0.7799 - recall: 0.7537 - auc: 0.8565 - val_loss: 0.4838 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8896\n",
      "Epoch 423/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4899 - tp: 193.0000 - fp: 41.0000 - tn: 403.0000 - fn: 75.0000 - accuracy: 0.8371 - precision: 0.8248 - recall: 0.7201 - auc: 0.8723 - val_loss: 0.4908 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8889\n",
      "Epoch 424/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4853 - tp: 209.0000 - fp: 64.0000 - tn: 380.0000 - fn: 59.0000 - accuracy: 0.8272 - precision: 0.7656 - recall: 0.7799 - auc: 0.8702 - val_loss: 0.4754 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8948\n",
      "Epoch 425/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4761 - tp: 207.0000 - fp: 52.0000 - tn: 392.0000 - fn: 61.0000 - accuracy: 0.8413 - precision: 0.7992 - recall: 0.7724 - auc: 0.8828 - val_loss: 0.4740 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8943\n",
      "Epoch 426/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4825 - tp: 196.0000 - fp: 45.0000 - tn: 399.0000 - fn: 72.0000 - accuracy: 0.8357 - precision: 0.8133 - recall: 0.7313 - auc: 0.8689 - val_loss: 0.4882 - val_tp: 63.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 11.0000 - val_accuracy: 0.8101 - val_precision: 0.7326 - val_recall: 0.8514 - val_auc: 0.8945\n",
      "Epoch 427/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5012 - tp: 207.0000 - fp: 73.0000 - tn: 371.0000 - fn: 61.0000 - accuracy: 0.8118 - precision: 0.7393 - recall: 0.7724 - auc: 0.8616 - val_loss: 0.4735 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8959\n",
      "Epoch 428/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4810 - tp: 206.0000 - fp: 52.0000 - tn: 392.0000 - fn: 62.0000 - accuracy: 0.8399 - precision: 0.7984 - recall: 0.7687 - auc: 0.8752 - val_loss: 0.4735 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8967\n",
      "Epoch 429/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4900 - tp: 207.0000 - fp: 61.0000 - tn: 383.0000 - fn: 61.0000 - accuracy: 0.8287 - precision: 0.7724 - recall: 0.7724 - auc: 0.8675 - val_loss: 0.4698 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8953\n",
      "Epoch 430/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4782 - tp: 199.0000 - fp: 47.0000 - tn: 397.0000 - fn: 69.0000 - accuracy: 0.8371 - precision: 0.8089 - recall: 0.7425 - auc: 0.8725 - val_loss: 0.4810 - val_tp: 63.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 11.0000 - val_accuracy: 0.8156 - val_precision: 0.7412 - val_recall: 0.8514 - val_auc: 0.8952\n",
      "Epoch 431/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4765 - tp: 200.0000 - fp: 54.0000 - tn: 390.0000 - fn: 68.0000 - accuracy: 0.8287 - precision: 0.7874 - recall: 0.7463 - auc: 0.8733 - val_loss: 0.4748 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8983\n",
      "Epoch 432/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4766 - tp: 199.0000 - fp: 57.0000 - tn: 387.0000 - fn: 69.0000 - accuracy: 0.8230 - precision: 0.7773 - recall: 0.7425 - auc: 0.8766 - val_loss: 0.4706 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8971\n",
      "Epoch 433/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4843 - tp: 204.0000 - fp: 60.0000 - tn: 384.0000 - fn: 64.0000 - accuracy: 0.8258 - precision: 0.7727 - recall: 0.7612 - auc: 0.8723 - val_loss: 0.4691 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8950\n",
      "Epoch 434/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4769 - tp: 197.0000 - fp: 47.0000 - tn: 397.0000 - fn: 71.0000 - accuracy: 0.8343 - precision: 0.8074 - recall: 0.7351 - auc: 0.8780 - val_loss: 0.4718 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.9014\n",
      "Epoch 435/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4707 - tp: 202.0000 - fp: 60.0000 - tn: 384.0000 - fn: 66.0000 - accuracy: 0.8230 - precision: 0.7710 - recall: 0.7537 - auc: 0.8895 - val_loss: 0.4674 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8968\n",
      "Epoch 436/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4963 - tp: 196.0000 - fp: 52.0000 - tn: 392.0000 - fn: 72.0000 - accuracy: 0.8258 - precision: 0.7903 - recall: 0.7313 - auc: 0.8684 - val_loss: 0.4730 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8974\n",
      "Epoch 437/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4898 - tp: 200.0000 - fp: 53.0000 - tn: 391.0000 - fn: 68.0000 - accuracy: 0.8301 - precision: 0.7905 - recall: 0.7463 - auc: 0.8653 - val_loss: 0.4803 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8931\n",
      "Epoch 438/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4954 - tp: 195.0000 - fp: 54.0000 - tn: 390.0000 - fn: 73.0000 - accuracy: 0.8216 - precision: 0.7831 - recall: 0.7276 - auc: 0.8647 - val_loss: 0.4776 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8963\n",
      "Epoch 439/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4852 - tp: 203.0000 - fp: 58.0000 - tn: 386.0000 - fn: 65.0000 - accuracy: 0.8272 - precision: 0.7778 - recall: 0.7575 - auc: 0.8747 - val_loss: 0.4711 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8975\n",
      "Epoch 440/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4729 - tp: 208.0000 - fp: 53.0000 - tn: 391.0000 - fn: 60.0000 - accuracy: 0.8413 - precision: 0.7969 - recall: 0.7761 - auc: 0.8777 - val_loss: 0.4902 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8940\n",
      "Epoch 441/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4840 - tp: 195.0000 - fp: 45.0000 - tn: 399.0000 - fn: 73.0000 - accuracy: 0.8343 - precision: 0.8125 - recall: 0.7276 - auc: 0.8706 - val_loss: 0.4779 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8963\n",
      "Epoch 442/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4743 - tp: 202.0000 - fp: 51.0000 - tn: 393.0000 - fn: 66.0000 - accuracy: 0.8357 - precision: 0.7984 - recall: 0.7537 - auc: 0.8766 - val_loss: 0.4744 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8958\n",
      "Epoch 443/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4906 - tp: 199.0000 - fp: 50.0000 - tn: 394.0000 - fn: 69.0000 - accuracy: 0.8329 - precision: 0.7992 - recall: 0.7425 - auc: 0.8637 - val_loss: 0.4754 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8976\n",
      "Epoch 444/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4921 - tp: 201.0000 - fp: 55.0000 - tn: 389.0000 - fn: 67.0000 - accuracy: 0.8287 - precision: 0.7852 - recall: 0.7500 - auc: 0.8655 - val_loss: 0.4763 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8959\n",
      "Epoch 445/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4855 - tp: 200.0000 - fp: 53.0000 - tn: 391.0000 - fn: 68.0000 - accuracy: 0.8301 - precision: 0.7905 - recall: 0.7463 - auc: 0.8643 - val_loss: 0.4762 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8956\n",
      "Epoch 446/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4776 - tp: 198.0000 - fp: 52.0000 - tn: 392.0000 - fn: 70.0000 - accuracy: 0.8287 - precision: 0.7920 - recall: 0.7388 - auc: 0.8765 - val_loss: 0.4706 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8978\n",
      "Epoch 447/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4904 - tp: 196.0000 - fp: 52.0000 - tn: 392.0000 - fn: 72.0000 - accuracy: 0.8258 - precision: 0.7903 - recall: 0.7313 - auc: 0.8665 - val_loss: 0.4749 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8976\n",
      "Epoch 448/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4857 - tp: 204.0000 - fp: 54.0000 - tn: 390.0000 - fn: 64.0000 - accuracy: 0.8343 - precision: 0.7907 - recall: 0.7612 - auc: 0.8731 - val_loss: 0.4723 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8959\n",
      "Epoch 449/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4899 - tp: 198.0000 - fp: 51.0000 - tn: 393.0000 - fn: 70.0000 - accuracy: 0.8301 - precision: 0.7952 - recall: 0.7388 - auc: 0.8651 - val_loss: 0.4730 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8981\n",
      "Epoch 450/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4905 - tp: 213.0000 - fp: 56.0000 - tn: 388.0000 - fn: 55.0000 - accuracy: 0.8441 - precision: 0.7918 - recall: 0.7948 - auc: 0.8695 - val_loss: 0.4747 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8961\n",
      "Epoch 451/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4783 - tp: 195.0000 - fp: 49.0000 - tn: 395.0000 - fn: 73.0000 - accuracy: 0.8287 - precision: 0.7992 - recall: 0.7276 - auc: 0.8764 - val_loss: 0.4753 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8973\n",
      "Epoch 452/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4963 - tp: 201.0000 - fp: 52.0000 - tn: 392.0000 - fn: 67.0000 - accuracy: 0.8329 - precision: 0.7945 - recall: 0.7500 - auc: 0.8645 - val_loss: 0.4739 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8979\n",
      "Epoch 453/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4797 - tp: 202.0000 - fp: 45.0000 - tn: 399.0000 - fn: 66.0000 - accuracy: 0.8441 - precision: 0.8178 - recall: 0.7537 - auc: 0.8723 - val_loss: 0.4739 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8967\n",
      "Epoch 454/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4879 - tp: 194.0000 - fp: 51.0000 - tn: 393.0000 - fn: 74.0000 - accuracy: 0.8244 - precision: 0.7918 - recall: 0.7239 - auc: 0.8673 - val_loss: 0.4690 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8998\n",
      "Epoch 455/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4770 - tp: 207.0000 - fp: 57.0000 - tn: 387.0000 - fn: 61.0000 - accuracy: 0.8343 - precision: 0.7841 - recall: 0.7724 - auc: 0.8772 - val_loss: 0.4757 - val_tp: 55.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 19.0000 - val_accuracy: 0.8101 - val_precision: 0.7857 - val_recall: 0.7432 - val_auc: 0.8963\n",
      "Epoch 456/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4941 - tp: 197.0000 - fp: 50.0000 - tn: 394.0000 - fn: 71.0000 - accuracy: 0.8301 - precision: 0.7976 - recall: 0.7351 - auc: 0.8673 - val_loss: 0.4704 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8983\n",
      "Epoch 457/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4723 - tp: 198.0000 - fp: 51.0000 - tn: 393.0000 - fn: 70.0000 - accuracy: 0.8301 - precision: 0.7952 - recall: 0.7388 - auc: 0.8826 - val_loss: 0.4759 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8937\n",
      "Epoch 458/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4836 - tp: 197.0000 - fp: 50.0000 - tn: 394.0000 - fn: 71.0000 - accuracy: 0.8301 - precision: 0.7976 - recall: 0.7351 - auc: 0.8664 - val_loss: 0.4771 - val_tp: 65.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 9.0000 - val_accuracy: 0.8045 - val_precision: 0.7143 - val_recall: 0.8784 - val_auc: 0.8965\n",
      "Epoch 459/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4908 - tp: 201.0000 - fp: 58.0000 - tn: 386.0000 - fn: 67.0000 - accuracy: 0.8244 - precision: 0.7761 - recall: 0.7500 - auc: 0.8683 - val_loss: 0.4781 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8927\n",
      "Epoch 460/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4878 - tp: 198.0000 - fp: 45.0000 - tn: 399.0000 - fn: 70.0000 - accuracy: 0.8385 - precision: 0.8148 - recall: 0.7388 - auc: 0.8706 - val_loss: 0.4785 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8920\n",
      "Epoch 461/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4777 - tp: 203.0000 - fp: 59.0000 - tn: 385.0000 - fn: 65.0000 - accuracy: 0.8258 - precision: 0.7748 - recall: 0.7575 - auc: 0.8748 - val_loss: 0.4711 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8957\n",
      "Epoch 462/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4737 - tp: 200.0000 - fp: 53.0000 - tn: 391.0000 - fn: 68.0000 - accuracy: 0.8301 - precision: 0.7905 - recall: 0.7463 - auc: 0.8790 - val_loss: 0.4718 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8947\n",
      "Epoch 463/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4913 - tp: 193.0000 - fp: 61.0000 - tn: 383.0000 - fn: 75.0000 - accuracy: 0.8090 - precision: 0.7598 - recall: 0.7201 - auc: 0.8734 - val_loss: 0.4767 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8951\n",
      "Epoch 464/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4857 - tp: 203.0000 - fp: 60.0000 - tn: 384.0000 - fn: 65.0000 - accuracy: 0.8244 - precision: 0.7719 - recall: 0.7575 - auc: 0.8674 - val_loss: 0.4777 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8968\n",
      "Epoch 465/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4865 - tp: 199.0000 - fp: 45.0000 - tn: 399.0000 - fn: 69.0000 - accuracy: 0.8399 - precision: 0.8156 - recall: 0.7425 - auc: 0.8691 - val_loss: 0.4721 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8934\n",
      "Epoch 466/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4715 - tp: 199.0000 - fp: 47.0000 - tn: 397.0000 - fn: 69.0000 - accuracy: 0.8371 - precision: 0.8089 - recall: 0.7425 - auc: 0.8754 - val_loss: 0.4803 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8942\n",
      "Epoch 467/500\n",
      "712/712 [==============================] - 0s 193us/sample - loss: 0.4875 - tp: 209.0000 - fp: 61.0000 - tn: 383.0000 - fn: 59.0000 - accuracy: 0.8315 - precision: 0.7741 - recall: 0.7799 - auc: 0.8734 - val_loss: 0.4716 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8963\n",
      "Epoch 468/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4747 - tp: 203.0000 - fp: 52.0000 - tn: 392.0000 - fn: 65.0000 - accuracy: 0.8357 - precision: 0.7961 - recall: 0.7575 - auc: 0.8794 - val_loss: 0.4720 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8972\n",
      "Epoch 469/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4840 - tp: 204.0000 - fp: 72.0000 - tn: 372.0000 - fn: 64.0000 - accuracy: 0.8090 - precision: 0.7391 - recall: 0.7612 - auc: 0.8756 - val_loss: 0.4759 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8934\n",
      "Epoch 470/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4745 - tp: 204.0000 - fp: 62.0000 - tn: 382.0000 - fn: 64.0000 - accuracy: 0.8230 - precision: 0.7669 - recall: 0.7612 - auc: 0.8786 - val_loss: 0.4699 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8941\n",
      "Epoch 471/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4805 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8748 - val_loss: 0.4769 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8986\n",
      "Epoch 472/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.4841 - tp: 202.0000 - fp: 55.0000 - tn: 389.0000 - fn: 66.0000 - accuracy: 0.8301 - precision: 0.7860 - recall: 0.7537 - auc: 0.8714 - val_loss: 0.4835 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8933\n",
      "Epoch 473/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4944 - tp: 202.0000 - fp: 61.0000 - tn: 383.0000 - fn: 66.0000 - accuracy: 0.8216 - precision: 0.7681 - recall: 0.7537 - auc: 0.8667 - val_loss: 0.4803 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8948\n",
      "Epoch 474/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4731 - tp: 199.0000 - fp: 36.0000 - tn: 408.0000 - fn: 69.0000 - accuracy: 0.8525 - precision: 0.8468 - recall: 0.7425 - auc: 0.8789 - val_loss: 0.4800 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8970\n",
      "Epoch 475/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4878 - tp: 196.0000 - fp: 54.0000 - tn: 390.0000 - fn: 72.0000 - accuracy: 0.8230 - precision: 0.7840 - recall: 0.7313 - auc: 0.8687 - val_loss: 0.4809 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8939\n",
      "Epoch 476/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4797 - tp: 198.0000 - fp: 45.0000 - tn: 399.0000 - fn: 70.0000 - accuracy: 0.8385 - precision: 0.8148 - recall: 0.7388 - auc: 0.8758 - val_loss: 0.4790 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8944\n",
      "Epoch 477/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4826 - tp: 203.0000 - fp: 60.0000 - tn: 384.0000 - fn: 65.0000 - accuracy: 0.8244 - precision: 0.7719 - recall: 0.7575 - auc: 0.8744 - val_loss: 0.4784 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.9001\n",
      "Epoch 478/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4768 - tp: 201.0000 - fp: 49.0000 - tn: 395.0000 - fn: 67.0000 - accuracy: 0.8371 - precision: 0.8040 - recall: 0.7500 - auc: 0.8748 - val_loss: 0.4711 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8974\n",
      "Epoch 479/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4877 - tp: 196.0000 - fp: 46.0000 - tn: 398.0000 - fn: 72.0000 - accuracy: 0.8343 - precision: 0.8099 - recall: 0.7313 - auc: 0.8708 - val_loss: 0.4703 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8996\n",
      "Epoch 480/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.4871 - tp: 199.0000 - fp: 56.0000 - tn: 388.0000 - fn: 69.0000 - accuracy: 0.8244 - precision: 0.7804 - recall: 0.7425 - auc: 0.8668 - val_loss: 0.4674 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.9023\n",
      "Epoch 481/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.4883 - tp: 192.0000 - fp: 53.0000 - tn: 391.0000 - fn: 76.0000 - accuracy: 0.8188 - precision: 0.7837 - recall: 0.7164 - auc: 0.8694 - val_loss: 0.4727 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8977\n",
      "Epoch 482/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4804 - tp: 198.0000 - fp: 36.0000 - tn: 408.0000 - fn: 70.0000 - accuracy: 0.8511 - precision: 0.8462 - recall: 0.7388 - auc: 0.8679 - val_loss: 0.4782 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8950\n",
      "Epoch 483/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4773 - tp: 194.0000 - fp: 41.0000 - tn: 403.0000 - fn: 74.0000 - accuracy: 0.8385 - precision: 0.8255 - recall: 0.7239 - auc: 0.8755 - val_loss: 0.4829 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8936\n",
      "Epoch 484/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4864 - tp: 203.0000 - fp: 54.0000 - tn: 390.0000 - fn: 65.0000 - accuracy: 0.8329 - precision: 0.7899 - recall: 0.7575 - auc: 0.8732 - val_loss: 0.4853 - val_tp: 54.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 20.0000 - val_accuracy: 0.8212 - val_precision: 0.8182 - val_recall: 0.7297 - val_auc: 0.8947\n",
      "Epoch 485/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4892 - tp: 199.0000 - fp: 56.0000 - tn: 388.0000 - fn: 69.0000 - accuracy: 0.8244 - precision: 0.7804 - recall: 0.7425 - auc: 0.8668 - val_loss: 0.4783 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8979\n",
      "Epoch 486/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4788 - tp: 198.0000 - fp: 36.0000 - tn: 408.0000 - fn: 70.0000 - accuracy: 0.8511 - precision: 0.8462 - recall: 0.7388 - auc: 0.8692 - val_loss: 0.4769 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8974\n",
      "Epoch 487/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4839 - tp: 202.0000 - fp: 56.0000 - tn: 388.0000 - fn: 66.0000 - accuracy: 0.8287 - precision: 0.7829 - recall: 0.7537 - auc: 0.8817 - val_loss: 0.4805 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8928\n",
      "Epoch 488/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4893 - tp: 206.0000 - fp: 61.0000 - tn: 383.0000 - fn: 62.0000 - accuracy: 0.8272 - precision: 0.7715 - recall: 0.7687 - auc: 0.8626 - val_loss: 0.4728 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8966\n",
      "Epoch 489/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4825 - tp: 201.0000 - fp: 48.0000 - tn: 396.0000 - fn: 67.0000 - accuracy: 0.8385 - precision: 0.8072 - recall: 0.7500 - auc: 0.8699 - val_loss: 0.4760 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8977\n",
      "Epoch 490/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4877 - tp: 189.0000 - fp: 37.0000 - tn: 407.0000 - fn: 79.0000 - accuracy: 0.8371 - precision: 0.8363 - recall: 0.7052 - auc: 0.8712 - val_loss: 0.4878 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8944\n",
      "Epoch 491/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4819 - tp: 198.0000 - fp: 42.0000 - tn: 402.0000 - fn: 70.0000 - accuracy: 0.8427 - precision: 0.8250 - recall: 0.7388 - auc: 0.8729 - val_loss: 0.4741 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8955\n",
      "Epoch 492/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4799 - tp: 207.0000 - fp: 62.0000 - tn: 382.0000 - fn: 61.0000 - accuracy: 0.8272 - precision: 0.7695 - recall: 0.7724 - auc: 0.8740 - val_loss: 0.4690 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8976\n",
      "Epoch 493/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4806 - tp: 206.0000 - fp: 61.0000 - tn: 383.0000 - fn: 62.0000 - accuracy: 0.8272 - precision: 0.7715 - recall: 0.7687 - auc: 0.8715 - val_loss: 0.4703 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8962\n",
      "Epoch 494/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4910 - tp: 199.0000 - fp: 51.0000 - tn: 393.0000 - fn: 69.0000 - accuracy: 0.8315 - precision: 0.7960 - recall: 0.7425 - auc: 0.8682 - val_loss: 0.4730 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8926\n",
      "Epoch 495/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4742 - tp: 196.0000 - fp: 39.0000 - tn: 405.0000 - fn: 72.0000 - accuracy: 0.8441 - precision: 0.8340 - recall: 0.7313 - auc: 0.8769 - val_loss: 0.4827 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8948\n",
      "Epoch 496/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4828 - tp: 202.0000 - fp: 53.0000 - tn: 391.0000 - fn: 66.0000 - accuracy: 0.8329 - precision: 0.7922 - recall: 0.7537 - auc: 0.8675 - val_loss: 0.4738 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8959\n",
      "Epoch 497/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4749 - tp: 200.0000 - fp: 52.0000 - tn: 392.0000 - fn: 68.0000 - accuracy: 0.8315 - precision: 0.7937 - recall: 0.7463 - auc: 0.8805 - val_loss: 0.4777 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8941\n",
      "Epoch 498/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4731 - tp: 202.0000 - fp: 52.0000 - tn: 392.0000 - fn: 66.0000 - accuracy: 0.8343 - precision: 0.7953 - recall: 0.7537 - auc: 0.8739 - val_loss: 0.4751 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8985\n",
      "Epoch 499/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4979 - tp: 194.0000 - fp: 51.0000 - tn: 393.0000 - fn: 74.0000 - accuracy: 0.8244 - precision: 0.7918 - recall: 0.7239 - auc: 0.8610 - val_loss: 0.4779 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8952\n",
      "Epoch 500/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4835 - tp: 205.0000 - fp: 56.0000 - tn: 388.0000 - fn: 63.0000 - accuracy: 0.8329 - precision: 0.7854 - recall: 0.7649 - auc: 0.8709 - val_loss: 0.4760 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8956\n"
     ]
    }
   ],
   "source": [
    "# Create a new model each time before running training (otherwise new trainings would just be on already trained model)\n",
    "model = get_model(X_train.shape[1])\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=500, batch_size=32, validation_data=(X_dev, Y_dev), class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Results of the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.plot(history.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'tp', 'fp', 'tn', 'fn', 'accuracy', 'precision', 'recall', 'auc', 'val_loss', 'val_tp', 'val_fp', 'val_tn', 'val_fn', 'val_accuracy', 'val_precision', 'val_recall', 'val_auc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(evaluation_result, label):\n",
    "    # TP FP\n",
    "    # FN TN\n",
    "    matrix = np.round(np.array([[evaluation_result[1], evaluation_result[2]], [evaluation_result[4], evaluation_result[3]]]))\n",
    "    \n",
    "    plt.figure(figsize=(4,3))\n",
    "    \n",
    "    ax = sns.heatmap(data=matrix, annot=True, fmt=\".0f\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.invert_xaxis()\n",
    "    \n",
    "    plt.xlabel(\"True\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.title(f\"Confusion matrix for {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train evaluation:\n",
      "712/712 - 1s - loss: 0.4433 - tp: 202.0000 - fp: 44.0000 - tn: 400.0000 - fn: 66.0000 - accuracy: 0.8455 - precision: 0.8211 - recall: 0.7537 - auc: 0.8808\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train evaluation:\")\n",
    "evaluation_train = model.evaluate(X_train, Y_train, verbose=2)\n",
    "draw_confusion_matrix(evaluation_train, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev evaluation:\n",
      "179/179 - 0s - loss: 0.4803 - tp: 56.0000 - fp: 15.0000 - tn: 90.0000 - fn: 18.0000 - accuracy: 0.8156 - precision: 0.7887 - recall: 0.7568 - auc: 0.8956\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Dev evaluation:\")\n",
    "evaluation_dev = model.evaluate(X_dev, Y_dev, verbose=2)\n",
    "draw_confusion_matrix(evaluation_dev, \"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Predict with DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_predictions(model, submission_name):\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    predictions = np.round(predictions).astype(np.uint8).reshape((-1))\n",
    "\n",
    "    print(f\"{submission_name}:\\n{predictions}\")\n",
    "    \n",
    "    output = pd.DataFrame({\"Survived\": predictions}, index=test_data.index)\n",
    "    output.to_csv(f\"{submission_name}.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "store_predictions(model, \"dl_submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Tune hyperparameters for the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt\n",
    "\n",
    "# https://www.sicara.ai/blog/hyperparameter-tuning-keras-tuner\n",
    "# https://www.curiousily.com/posts/hackers-guide-to-hyperparameter-tuning/\n",
    "\n",
    "class TitanicHyperModel(kt.HyperModel):\n",
    "    def __init__(self, input_size):\n",
    "        self.input_shape = (input_size, )\n",
    "\n",
    "    def build(self, hp):\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import Dense, Dropout, InputLayer\n",
    "        from tensorflow.keras.regularizers import L1L2\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(input_shape=self.input_shape))\n",
    "        \n",
    "        for layer_n in range(hp.Int(\"num_layers\", min_value=2, max_value=7, step=1, default=3)):\n",
    "            units = hp.Int(\n",
    "                f\"dense_units_{layer_n}\",\n",
    "                min_value=8,\n",
    "                max_value=64,\n",
    "                step=8,\n",
    "                default=64\n",
    "            )\n",
    "            activation = hp.Choice(\n",
    "                f\"dense_activation_{layer_n}\",\n",
    "                values=[\"relu\", \"tanh\"],\n",
    "                default=\"relu\"\n",
    "            )\n",
    "            regularizer_l1 = hp.Choice(\n",
    "                f\"l1_{layer_n}\",\n",
    "                values=[0.01, 0.001, 1e-4, 1e-5, 0.0],\n",
    "                default=1e-2\n",
    "            )\n",
    "            regularizer_l2 = hp.Choice(\n",
    "                f\"l2_{layer_n}\",\n",
    "                values=[0.1, 0.01, 0.001],\n",
    "                default=1e-2\n",
    "            )\n",
    "            initializer = \"he_uniform\" if activation == \"relu\" else \"glorot_uniform\"\n",
    "\n",
    "            model.add(Dense(\n",
    "                units=units,\n",
    "                activation=activation,\n",
    "                kernel_regularizer=L1L2(l1=regularizer_l1, l2=regularizer_l2),\n",
    "                bias_regularizer=L1L2(l1=regularizer_l1, l2=regularizer_l2),\n",
    "                kernel_initializer=initializer\n",
    "            ))\n",
    "            \n",
    "            droupout_rate = hp.Float(\n",
    "                f\"dropout_{layer_n}\",\n",
    "                min_value=0.15,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            )\n",
    "            \n",
    "            model.add(Dropout(rate=droupout_rate))\n",
    "        \n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "        \n",
    "        learning_rate = hp.Choice(\n",
    "            \"learning_rate\",\n",
    "            values=[1e-2, 1e-3],#, 5e-4, 1e-4],\n",
    "            default=1e-3\n",
    "        )\n",
    "        \n",
    "        optimizer = hp.Choice(\n",
    "            \"optimizer\",\n",
    "            values=[\"adam\", \"RMSprop\"],\n",
    "            default=\"adam\"\n",
    "        )\n",
    "        optimizer_type = {\n",
    "            \"adam\": keras.optimizers.Adam,\n",
    "            \"RMSprop\": keras.optimizers.RMSprop,\n",
    "            \"SGD\": keras.optimizers.SGD\n",
    "        }\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer_type[optimizer](learning_rate=learning_rate),\n",
    "            metrics=METRICS,\n",
    "            loss=\"binary_crossentropy\",\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "hypermodel = TitanicHyperModel(input_size=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTuner(kt.Tuner):\n",
    "    def run_trial(self, trial, X_train, Y_train, validation_data):\n",
    "        hp = trial.hyperparameters\n",
    "        \n",
    "        batch_size = hp.Int(\"batch_size\", 16, 128, step=16, default=32)\n",
    "        epoch_number = hp.Int(\"epoch_number\", 400, 700, step=100, default=500)\n",
    "        \n",
    "        model = self.hypermodel.build(hp)\n",
    "        \n",
    "        history = model.fit(X_train, Y_train, epochs=epoch_number, batch_size=batch_size, validation_data=validation_data, class_weight=class_weights)\n",
    "        \n",
    "        self.oracle.update_trial(trial.trial_id, {\"val_accuracy\": history.history[\"val_accuracy\"][-1]})\n",
    "        self.save_model(trial.trial_id, model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dev mode\n",
    "\n",
    "if MODE == \"DEV\":\n",
    "    MAX_TRIALS = 20\n",
    "else:\n",
    "    MAX_TRIALS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ATTEMPT = ATTEMPT + 1\n",
    "except NameError:\n",
    "    ATTEMPT = 0\n",
    "\n",
    "hp = kt.HyperParameters()\n",
    "if MODE == \"DEV\":\n",
    "    hp.Fixed(\"epoch_number\", 50)\n",
    "# else:\n",
    "#     hp.Fixed(\"epoch_number\", 500)\n",
    "\n",
    "# Seems like 32 always comes to be the best option...\n",
    "hp.Fixed(\"batch_size\", 32)\n",
    "\n",
    "tuner = MyTuner(\n",
    "    oracle=kt.oracles.RandomSearch(\n",
    "        objective=\"val_accuracy\",\n",
    "        seed=SEED,\n",
    "        hyperparameters=hp,\n",
    "        tune_new_entries=True,\n",
    "        max_trials=MAX_TRIALS),\n",
    "    hypermodel=hypermodel,\n",
    "    directory=f\"my_search_{ATTEMPT}\",\n",
    "    project_name=\"titanic\"\n",
    ")\n",
    "\n",
    "# tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 4s 6ms/sample - loss: 1.3829 - tp: 169.0000 - fp: 137.0000 - tn: 307.0000 - fn: 99.0000 - accuracy: 0.6685 - precision: 0.5523 - recall: 0.6306 - auc: 0.7077 - val_loss: 0.9195 - val_tp: 61.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 13.0000 - val_accuracy: 0.7486 - val_precision: 0.6559 - val_recall: 0.8243 - val_auc: 0.8671\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 209us/sample - loss: 0.8558 - tp: 195.0000 - fp: 104.0000 - tn: 340.0000 - fn: 73.0000 - accuracy: 0.7514 - precision: 0.6522 - recall: 0.7276 - auc: 0.8152 - val_loss: 0.8045 - val_tp: 38.0000 - val_fp: 5.0000 - val_tn: 100.0000 - val_fn: 36.0000 - val_accuracy: 0.7709 - val_precision: 0.8837 - val_recall: 0.5135 - val_auc: 0.8706\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 224us/sample - loss: 0.7469 - tp: 188.0000 - fp: 89.0000 - tn: 355.0000 - fn: 80.0000 - accuracy: 0.7626 - precision: 0.6787 - recall: 0.7015 - auc: 0.8040 - val_loss: 0.6577 - val_tp: 61.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 13.0000 - val_accuracy: 0.7542 - val_precision: 0.6630 - val_recall: 0.8243 - val_auc: 0.8572\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.6819 - tp: 200.0000 - fp: 108.0000 - tn: 336.0000 - fn: 68.0000 - accuracy: 0.7528 - precision: 0.6494 - recall: 0.7463 - auc: 0.8128 - val_loss: 0.6753 - val_tp: 39.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 35.0000 - val_accuracy: 0.7709 - val_precision: 0.8667 - val_recall: 0.5270 - val_auc: 0.8809\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.6491 - tp: 194.0000 - fp: 103.0000 - tn: 341.0000 - fn: 74.0000 - accuracy: 0.7514 - precision: 0.6532 - recall: 0.7239 - auc: 0.8087 - val_loss: 0.6438 - val_tp: 70.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 4.0000 - val_accuracy: 0.7709 - val_precision: 0.6542 - val_recall: 0.9459 - val_auc: 0.8636\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 199us/sample - loss: 0.6145 - tp: 207.0000 - fp: 102.0000 - tn: 342.0000 - fn: 61.0000 - accuracy: 0.7711 - precision: 0.6699 - recall: 0.7724 - auc: 0.8300 - val_loss: 0.5846 - val_tp: 53.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 21.0000 - val_accuracy: 0.7709 - val_precision: 0.7260 - val_recall: 0.7162 - val_auc: 0.8786\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 205us/sample - loss: 0.6162 - tp: 201.0000 - fp: 109.0000 - tn: 335.0000 - fn: 67.0000 - accuracy: 0.7528 - precision: 0.6484 - recall: 0.7500 - auc: 0.8236 - val_loss: 0.6224 - val_tp: 70.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 4.0000 - val_accuracy: 0.7709 - val_precision: 0.6542 - val_recall: 0.9459 - val_auc: 0.8644\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 200us/sample - loss: 0.6099 - tp: 206.0000 - fp: 104.0000 - tn: 340.0000 - fn: 62.0000 - accuracy: 0.7669 - precision: 0.6645 - recall: 0.7687 - auc: 0.8318 - val_loss: 0.5938 - val_tp: 51.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 23.0000 - val_accuracy: 0.7877 - val_precision: 0.7727 - val_recall: 0.6892 - val_auc: 0.8749\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.6249 - tp: 208.0000 - fp: 102.0000 - tn: 342.0000 - fn: 60.0000 - accuracy: 0.7725 - precision: 0.6710 - recall: 0.7761 - auc: 0.8146 - val_loss: 0.5900 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8686\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6081 - tp: 203.0000 - fp: 94.0000 - tn: 350.0000 - fn: 65.0000 - accuracy: 0.7767 - precision: 0.6835 - recall: 0.7575 - auc: 0.8199 - val_loss: 0.5551 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8774\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6078 - tp: 201.0000 - fp: 103.0000 - tn: 341.0000 - fn: 67.0000 - accuracy: 0.7612 - precision: 0.6612 - recall: 0.7500 - auc: 0.8195 - val_loss: 0.5668 - val_tp: 59.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 15.0000 - val_accuracy: 0.7765 - val_precision: 0.7024 - val_recall: 0.7973 - val_auc: 0.8764\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6044 - tp: 196.0000 - fp: 96.0000 - tn: 348.0000 - fn: 72.0000 - accuracy: 0.7640 - precision: 0.6712 - recall: 0.7313 - auc: 0.8231 - val_loss: 0.6313 - val_tp: 70.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 4.0000 - val_accuracy: 0.7709 - val_precision: 0.6542 - val_recall: 0.9459 - val_auc: 0.8604\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6059 - tp: 199.0000 - fp: 89.0000 - tn: 355.0000 - fn: 69.0000 - accuracy: 0.7781 - precision: 0.6910 - recall: 0.7425 - auc: 0.8278 - val_loss: 0.6372 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8654\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5986 - tp: 203.0000 - fp: 95.0000 - tn: 349.0000 - fn: 65.0000 - accuracy: 0.7753 - precision: 0.6812 - recall: 0.7575 - auc: 0.8326 - val_loss: 0.5493 - val_tp: 55.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 19.0000 - val_accuracy: 0.7486 - val_precision: 0.6790 - val_recall: 0.7432 - val_auc: 0.8780\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.6197 - tp: 198.0000 - fp: 89.0000 - tn: 355.0000 - fn: 70.0000 - accuracy: 0.7767 - precision: 0.6899 - recall: 0.7388 - auc: 0.8125 - val_loss: 0.5648 - val_tp: 52.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 22.0000 - val_accuracy: 0.7765 - val_precision: 0.7429 - val_recall: 0.7027 - val_auc: 0.8796\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5958 - tp: 199.0000 - fp: 96.0000 - tn: 348.0000 - fn: 69.0000 - accuracy: 0.7683 - precision: 0.6746 - recall: 0.7425 - auc: 0.8305 - val_loss: 0.6607 - val_tp: 46.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 28.0000 - val_accuracy: 0.8045 - val_precision: 0.8679 - val_recall: 0.6216 - val_auc: 0.8856\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.5884 - tp: 200.0000 - fp: 80.0000 - tn: 364.0000 - fn: 68.0000 - accuracy: 0.7921 - precision: 0.7143 - recall: 0.7463 - auc: 0.8417 - val_loss: 0.5524 - val_tp: 56.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 18.0000 - val_accuracy: 0.7654 - val_precision: 0.7000 - val_recall: 0.7568 - val_auc: 0.8741\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6001 - tp: 206.0000 - fp: 101.0000 - tn: 343.0000 - fn: 62.0000 - accuracy: 0.7711 - precision: 0.6710 - recall: 0.7687 - auc: 0.8295 - val_loss: 0.5726 - val_tp: 55.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 19.0000 - val_accuracy: 0.7933 - val_precision: 0.7534 - val_recall: 0.7432 - val_auc: 0.8803\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.5854 - tp: 205.0000 - fp: 89.0000 - tn: 355.0000 - fn: 63.0000 - accuracy: 0.7865 - precision: 0.6973 - recall: 0.7649 - auc: 0.8371 - val_loss: 0.6299 - val_tp: 69.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 5.0000 - val_accuracy: 0.7709 - val_precision: 0.6571 - val_recall: 0.9324 - val_auc: 0.8663\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6015 - tp: 201.0000 - fp: 100.0000 - tn: 344.0000 - fn: 67.0000 - accuracy: 0.7654 - precision: 0.6678 - recall: 0.7500 - auc: 0.8264 - val_loss: 0.6581 - val_tp: 38.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 36.0000 - val_accuracy: 0.7654 - val_precision: 0.8636 - val_recall: 0.5135 - val_auc: 0.8802\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5893 - tp: 203.0000 - fp: 81.0000 - tn: 363.0000 - fn: 65.0000 - accuracy: 0.7949 - precision: 0.7148 - recall: 0.7575 - auc: 0.8324 - val_loss: 0.5678 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8712\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5957 - tp: 200.0000 - fp: 99.0000 - tn: 345.0000 - fn: 68.0000 - accuracy: 0.7654 - precision: 0.6689 - recall: 0.7463 - auc: 0.8246 - val_loss: 0.5878 - val_tp: 61.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 13.0000 - val_accuracy: 0.7542 - val_precision: 0.6630 - val_recall: 0.8243 - val_auc: 0.8683\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5978 - tp: 206.0000 - fp: 97.0000 - tn: 347.0000 - fn: 62.0000 - accuracy: 0.7767 - precision: 0.6799 - recall: 0.7687 - auc: 0.8304 - val_loss: 0.5583 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8726\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5861 - tp: 200.0000 - fp: 90.0000 - tn: 354.0000 - fn: 68.0000 - accuracy: 0.7781 - precision: 0.6897 - recall: 0.7463 - auc: 0.8362 - val_loss: 0.5945 - val_tp: 52.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 22.0000 - val_accuracy: 0.7989 - val_precision: 0.7879 - val_recall: 0.7027 - val_auc: 0.8805\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.6094 - tp: 199.0000 - fp: 97.0000 - tn: 347.0000 - fn: 69.0000 - accuracy: 0.7669 - precision: 0.6723 - recall: 0.7425 - auc: 0.8232 - val_loss: 0.5626 - val_tp: 54.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 20.0000 - val_accuracy: 0.7933 - val_precision: 0.7606 - val_recall: 0.7297 - val_auc: 0.8775\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5758 - tp: 200.0000 - fp: 87.0000 - tn: 357.0000 - fn: 68.0000 - accuracy: 0.7823 - precision: 0.6969 - recall: 0.7463 - auc: 0.8395 - val_loss: 0.5428 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8726\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6028 - tp: 195.0000 - fp: 93.0000 - tn: 351.0000 - fn: 73.0000 - accuracy: 0.7669 - precision: 0.6771 - recall: 0.7276 - auc: 0.8267 - val_loss: 0.5612 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8749\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 201us/sample - loss: 0.6000 - tp: 199.0000 - fp: 93.0000 - tn: 351.0000 - fn: 69.0000 - accuracy: 0.7725 - precision: 0.6815 - recall: 0.7425 - auc: 0.8232 - val_loss: 0.5949 - val_tp: 64.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 10.0000 - val_accuracy: 0.7374 - val_precision: 0.6337 - val_recall: 0.8649 - val_auc: 0.8692\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5992 - tp: 207.0000 - fp: 98.0000 - tn: 346.0000 - fn: 61.0000 - accuracy: 0.7767 - precision: 0.6787 - recall: 0.7724 - auc: 0.8273 - val_loss: 0.6488 - val_tp: 37.0000 - val_fp: 5.0000 - val_tn: 100.0000 - val_fn: 37.0000 - val_accuracy: 0.7654 - val_precision: 0.8810 - val_recall: 0.5000 - val_auc: 0.8813\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.5863 - tp: 199.0000 - fp: 82.0000 - tn: 362.0000 - fn: 69.0000 - accuracy: 0.7879 - precision: 0.7082 - recall: 0.7425 - auc: 0.8295 - val_loss: 0.6238 - val_tp: 70.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 4.0000 - val_accuracy: 0.7765 - val_precision: 0.6604 - val_recall: 0.9459 - val_auc: 0.8548\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6309 - tp: 197.0000 - fp: 106.0000 - tn: 338.0000 - fn: 71.0000 - accuracy: 0.7514 - precision: 0.6502 - recall: 0.7351 - auc: 0.8148 - val_loss: 0.6312 - val_tp: 69.0000 - val_fp: 38.0000 - val_tn: 67.0000 - val_fn: 5.0000 - val_accuracy: 0.7598 - val_precision: 0.6449 - val_recall: 0.9324 - val_auc: 0.8696\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5958 - tp: 199.0000 - fp: 94.0000 - tn: 350.0000 - fn: 69.0000 - accuracy: 0.7711 - precision: 0.6792 - recall: 0.7425 - auc: 0.8301 - val_loss: 0.5702 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8762\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5834 - tp: 208.0000 - fp: 89.0000 - tn: 355.0000 - fn: 60.0000 - accuracy: 0.7907 - precision: 0.7003 - recall: 0.7761 - auc: 0.8423 - val_loss: 0.5564 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8808\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5839 - tp: 196.0000 - fp: 78.0000 - tn: 366.0000 - fn: 72.0000 - accuracy: 0.7893 - precision: 0.7153 - recall: 0.7313 - auc: 0.8392 - val_loss: 0.5510 - val_tp: 60.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 14.0000 - val_accuracy: 0.7709 - val_precision: 0.6897 - val_recall: 0.8108 - val_auc: 0.8756\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6103 - tp: 195.0000 - fp: 97.0000 - tn: 347.0000 - fn: 73.0000 - accuracy: 0.7612 - precision: 0.6678 - recall: 0.7276 - auc: 0.8181 - val_loss: 0.5843 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8684\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5981 - tp: 204.0000 - fp: 100.0000 - tn: 344.0000 - fn: 64.0000 - accuracy: 0.7697 - precision: 0.6711 - recall: 0.7612 - auc: 0.8235 - val_loss: 0.5677 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8737\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5686 - tp: 205.0000 - fp: 87.0000 - tn: 357.0000 - fn: 63.0000 - accuracy: 0.7893 - precision: 0.7021 - recall: 0.7649 - auc: 0.8471 - val_loss: 0.5647 - val_tp: 53.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 21.0000 - val_accuracy: 0.7933 - val_precision: 0.7681 - val_recall: 0.7162 - val_auc: 0.8824\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.5980 - tp: 203.0000 - fp: 95.0000 - tn: 349.0000 - fn: 65.0000 - accuracy: 0.7753 - precision: 0.6812 - recall: 0.7575 - auc: 0.8322 - val_loss: 0.6503 - val_tp: 40.0000 - val_fp: 5.0000 - val_tn: 100.0000 - val_fn: 34.0000 - val_accuracy: 0.7821 - val_precision: 0.8889 - val_recall: 0.5405 - val_auc: 0.8805\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6086 - tp: 201.0000 - fp: 101.0000 - tn: 343.0000 - fn: 67.0000 - accuracy: 0.7640 - precision: 0.6656 - recall: 0.7500 - auc: 0.8226 - val_loss: 0.5480 - val_tp: 54.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 20.0000 - val_accuracy: 0.7877 - val_precision: 0.7500 - val_recall: 0.7297 - val_auc: 0.8867\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5972 - tp: 202.0000 - fp: 91.0000 - tn: 353.0000 - fn: 66.0000 - accuracy: 0.7795 - precision: 0.6894 - recall: 0.7537 - auc: 0.8300 - val_loss: 0.5975 - val_tp: 63.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 11.0000 - val_accuracy: 0.7542 - val_precision: 0.6562 - val_recall: 0.8514 - val_auc: 0.8719\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5934 - tp: 208.0000 - fp: 90.0000 - tn: 354.0000 - fn: 60.0000 - accuracy: 0.7893 - precision: 0.6980 - recall: 0.7761 - auc: 0.8313 - val_loss: 0.5840 - val_tp: 48.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 26.0000 - val_accuracy: 0.7877 - val_precision: 0.8000 - val_recall: 0.6486 - val_auc: 0.8814\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.6143 - tp: 196.0000 - fp: 112.0000 - tn: 332.0000 - fn: 72.0000 - accuracy: 0.7416 - precision: 0.6364 - recall: 0.7313 - auc: 0.8137 - val_loss: 0.6011 - val_tp: 49.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 25.0000 - val_accuracy: 0.7989 - val_precision: 0.8167 - val_recall: 0.6622 - val_auc: 0.8842\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6046 - tp: 202.0000 - fp: 88.0000 - tn: 356.0000 - fn: 66.0000 - accuracy: 0.7837 - precision: 0.6966 - recall: 0.7537 - auc: 0.8183 - val_loss: 0.6647 - val_tp: 40.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 34.0000 - val_accuracy: 0.7709 - val_precision: 0.8511 - val_recall: 0.5405 - val_auc: 0.8834\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6120 - tp: 196.0000 - fp: 73.0000 - tn: 371.0000 - fn: 72.0000 - accuracy: 0.7963 - precision: 0.7286 - recall: 0.7313 - auc: 0.8171 - val_loss: 0.5585 - val_tp: 52.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 22.0000 - val_accuracy: 0.7709 - val_precision: 0.7324 - val_recall: 0.7027 - val_auc: 0.8708\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6194 - tp: 197.0000 - fp: 91.0000 - tn: 353.0000 - fn: 71.0000 - accuracy: 0.7725 - precision: 0.6840 - recall: 0.7351 - auc: 0.8166 - val_loss: 0.6133 - val_tp: 69.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 5.0000 - val_accuracy: 0.7709 - val_precision: 0.6571 - val_recall: 0.9324 - val_auc: 0.8722\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5867 - tp: 209.0000 - fp: 101.0000 - tn: 343.0000 - fn: 59.0000 - accuracy: 0.7753 - precision: 0.6742 - recall: 0.7799 - auc: 0.8373 - val_loss: 0.5694 - val_tp: 61.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 13.0000 - val_accuracy: 0.7542 - val_precision: 0.6630 - val_recall: 0.8243 - val_auc: 0.8704\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6002 - tp: 209.0000 - fp: 101.0000 - tn: 343.0000 - fn: 59.0000 - accuracy: 0.7753 - precision: 0.6742 - recall: 0.7799 - auc: 0.8204 - val_loss: 0.7165 - val_tp: 71.0000 - val_fp: 48.0000 - val_tn: 57.0000 - val_fn: 3.0000 - val_accuracy: 0.7151 - val_precision: 0.5966 - val_recall: 0.9595 - val_auc: 0.8649\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6090 - tp: 198.0000 - fp: 96.0000 - tn: 348.0000 - fn: 70.0000 - accuracy: 0.7669 - precision: 0.6735 - recall: 0.7388 - auc: 0.8158 - val_loss: 0.5761 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8721\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6113 - tp: 201.0000 - fp: 94.0000 - tn: 350.0000 - fn: 67.0000 - accuracy: 0.7739 - precision: 0.6814 - recall: 0.7500 - auc: 0.8213 - val_loss: 0.5432 - val_tp: 57.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 17.0000 - val_accuracy: 0.7877 - val_precision: 0.7308 - val_recall: 0.7703 - val_auc: 0.8777\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6030 - tp: 208.0000 - fp: 88.0000 - tn: 356.0000 - fn: 60.0000 - accuracy: 0.7921 - precision: 0.7027 - recall: 0.7761 - auc: 0.8341 - val_loss: 0.6120 - val_tp: 70.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 4.0000 - val_accuracy: 0.7765 - val_precision: 0.6604 - val_recall: 0.9459 - val_auc: 0.8682\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6088 - tp: 196.0000 - fp: 94.0000 - tn: 350.0000 - fn: 72.0000 - accuracy: 0.7669 - precision: 0.6759 - recall: 0.7313 - auc: 0.8205 - val_loss: 0.5581 - val_tp: 56.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 18.0000 - val_accuracy: 0.7933 - val_precision: 0.7467 - val_recall: 0.7568 - val_auc: 0.8804\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6175 - tp: 201.0000 - fp: 106.0000 - tn: 338.0000 - fn: 67.0000 - accuracy: 0.7570 - precision: 0.6547 - recall: 0.7500 - auc: 0.8189 - val_loss: 0.5348 - val_tp: 58.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 16.0000 - val_accuracy: 0.7486 - val_precision: 0.6667 - val_recall: 0.7838 - val_auc: 0.8760\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6133 - tp: 200.0000 - fp: 93.0000 - tn: 351.0000 - fn: 68.0000 - accuracy: 0.7739 - precision: 0.6826 - recall: 0.7463 - auc: 0.8157 - val_loss: 0.6553 - val_tp: 70.0000 - val_fp: 47.0000 - val_tn: 58.0000 - val_fn: 4.0000 - val_accuracy: 0.7151 - val_precision: 0.5983 - val_recall: 0.9459 - val_auc: 0.8584\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.6198 - tp: 199.0000 - fp: 96.0000 - tn: 348.0000 - fn: 69.0000 - accuracy: 0.7683 - precision: 0.6746 - recall: 0.7425 - auc: 0.8128 - val_loss: 0.5899 - val_tp: 65.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 9.0000 - val_accuracy: 0.7542 - val_precision: 0.6500 - val_recall: 0.8784 - val_auc: 0.8667\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5889 - tp: 203.0000 - fp: 96.0000 - tn: 348.0000 - fn: 65.0000 - accuracy: 0.7739 - precision: 0.6789 - recall: 0.7575 - auc: 0.8339 - val_loss: 0.5618 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8722\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5877 - tp: 200.0000 - fp: 91.0000 - tn: 353.0000 - fn: 68.0000 - accuracy: 0.7767 - precision: 0.6873 - recall: 0.7463 - auc: 0.8350 - val_loss: 1.0867 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8368\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6205 - tp: 203.0000 - fp: 109.0000 - tn: 335.0000 - fn: 65.0000 - accuracy: 0.7556 - precision: 0.6506 - recall: 0.7575 - auc: 0.8041 - val_loss: 0.5540 - val_tp: 64.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 10.0000 - val_accuracy: 0.7542 - val_precision: 0.6531 - val_recall: 0.8649 - val_auc: 0.8714\n",
      "Epoch 58/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.6093 - tp: 208.0000 - fp: 92.0000 - tn: 352.0000 - fn: 60.0000 - accuracy: 0.7865 - precision: 0.6933 - recall: 0.7761 - auc: 0.8235 - val_loss: 0.5680 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8704\n",
      "Epoch 59/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6055 - tp: 199.0000 - fp: 101.0000 - tn: 343.0000 - fn: 69.0000 - accuracy: 0.7612 - precision: 0.6633 - recall: 0.7425 - auc: 0.8247 - val_loss: 0.5757 - val_tp: 64.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 10.0000 - val_accuracy: 0.7598 - val_precision: 0.6598 - val_recall: 0.8649 - val_auc: 0.8731\n",
      "Epoch 60/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6370 - tp: 199.0000 - fp: 102.0000 - tn: 342.0000 - fn: 69.0000 - accuracy: 0.7598 - precision: 0.6611 - recall: 0.7425 - auc: 0.8037 - val_loss: 0.7178 - val_tp: 70.0000 - val_fp: 47.0000 - val_tn: 58.0000 - val_fn: 4.0000 - val_accuracy: 0.7151 - val_precision: 0.5983 - val_recall: 0.9459 - val_auc: 0.8563\n",
      "Epoch 61/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6124 - tp: 202.0000 - fp: 99.0000 - tn: 345.0000 - fn: 66.0000 - accuracy: 0.7683 - precision: 0.6711 - recall: 0.7537 - auc: 0.8203 - val_loss: 0.5629 - val_tp: 62.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 12.0000 - val_accuracy: 0.7765 - val_precision: 0.6889 - val_recall: 0.8378 - val_auc: 0.8730\n",
      "Epoch 62/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6026 - tp: 211.0000 - fp: 92.0000 - tn: 352.0000 - fn: 57.0000 - accuracy: 0.7907 - precision: 0.6964 - recall: 0.7873 - auc: 0.8215 - val_loss: 0.6250 - val_tp: 48.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 26.0000 - val_accuracy: 0.7821 - val_precision: 0.7869 - val_recall: 0.6486 - val_auc: 0.8811\n",
      "Epoch 63/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5982 - tp: 197.0000 - fp: 91.0000 - tn: 353.0000 - fn: 71.0000 - accuracy: 0.7725 - precision: 0.6840 - recall: 0.7351 - auc: 0.8245 - val_loss: 0.5896 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8811\n",
      "Epoch 64/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6272 - tp: 203.0000 - fp: 96.0000 - tn: 348.0000 - fn: 65.0000 - accuracy: 0.7739 - precision: 0.6789 - recall: 0.7575 - auc: 0.8147 - val_loss: 0.6019 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8660\n",
      "Epoch 65/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6076 - tp: 202.0000 - fp: 110.0000 - tn: 334.0000 - fn: 66.0000 - accuracy: 0.7528 - precision: 0.6474 - recall: 0.7537 - auc: 0.8227 - val_loss: 0.5375 - val_tp: 56.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 18.0000 - val_accuracy: 0.7654 - val_precision: 0.7000 - val_recall: 0.7568 - val_auc: 0.8769\n",
      "Epoch 66/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6076 - tp: 202.0000 - fp: 96.0000 - tn: 348.0000 - fn: 66.0000 - accuracy: 0.7725 - precision: 0.6779 - recall: 0.7537 - auc: 0.8223 - val_loss: 0.6138 - val_tp: 49.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 25.0000 - val_accuracy: 0.8045 - val_precision: 0.8305 - val_recall: 0.6622 - val_auc: 0.8817\n",
      "Epoch 67/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5927 - tp: 201.0000 - fp: 87.0000 - tn: 357.0000 - fn: 67.0000 - accuracy: 0.7837 - precision: 0.6979 - recall: 0.7500 - auc: 0.8344 - val_loss: 0.6438 - val_tp: 70.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 4.0000 - val_accuracy: 0.7709 - val_precision: 0.6542 - val_recall: 0.9459 - val_auc: 0.8636\n",
      "Epoch 68/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5991 - tp: 203.0000 - fp: 104.0000 - tn: 340.0000 - fn: 65.0000 - accuracy: 0.7626 - precision: 0.6612 - recall: 0.7575 - auc: 0.8299 - val_loss: 0.5537 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8723\n",
      "Epoch 69/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5945 - tp: 199.0000 - fp: 89.0000 - tn: 355.0000 - fn: 69.0000 - accuracy: 0.7781 - precision: 0.6910 - recall: 0.7425 - auc: 0.8363 - val_loss: 0.5516 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8770\n",
      "Epoch 70/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6124 - tp: 201.0000 - fp: 108.0000 - tn: 336.0000 - fn: 67.0000 - accuracy: 0.7542 - precision: 0.6505 - recall: 0.7500 - auc: 0.8192 - val_loss: 0.5517 - val_tp: 53.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 21.0000 - val_accuracy: 0.7654 - val_precision: 0.7162 - val_recall: 0.7162 - val_auc: 0.8718\n",
      "Epoch 71/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6182 - tp: 201.0000 - fp: 101.0000 - tn: 343.0000 - fn: 67.0000 - accuracy: 0.7640 - precision: 0.6656 - recall: 0.7500 - auc: 0.8132 - val_loss: 0.5569 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8696\n",
      "Epoch 72/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6035 - tp: 203.0000 - fp: 91.0000 - tn: 353.0000 - fn: 65.0000 - accuracy: 0.7809 - precision: 0.6905 - recall: 0.7575 - auc: 0.8296 - val_loss: 0.5648 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8780\n",
      "Epoch 73/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5998 - tp: 200.0000 - fp: 90.0000 - tn: 354.0000 - fn: 68.0000 - accuracy: 0.7781 - precision: 0.6897 - recall: 0.7463 - auc: 0.8301 - val_loss: 0.6159 - val_tp: 49.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 25.0000 - val_accuracy: 0.7877 - val_precision: 0.7903 - val_recall: 0.6622 - val_auc: 0.8815\n",
      "Epoch 74/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6052 - tp: 190.0000 - fp: 83.0000 - tn: 361.0000 - fn: 78.0000 - accuracy: 0.7739 - precision: 0.6960 - recall: 0.7090 - auc: 0.8190 - val_loss: 0.5660 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8737\n",
      "Epoch 75/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6438 - tp: 200.0000 - fp: 100.0000 - tn: 344.0000 - fn: 68.0000 - accuracy: 0.7640 - precision: 0.6667 - recall: 0.7463 - auc: 0.8031 - val_loss: 0.5728 - val_tp: 51.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 23.0000 - val_accuracy: 0.7765 - val_precision: 0.7500 - val_recall: 0.6892 - val_auc: 0.8763\n",
      "Epoch 76/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5914 - tp: 204.0000 - fp: 87.0000 - tn: 357.0000 - fn: 64.0000 - accuracy: 0.7879 - precision: 0.7010 - recall: 0.7612 - auc: 0.8289 - val_loss: 0.5782 - val_tp: 66.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 8.0000 - val_accuracy: 0.7654 - val_precision: 0.6600 - val_recall: 0.8919 - val_auc: 0.8661\n",
      "Epoch 77/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6123 - tp: 195.0000 - fp: 97.0000 - tn: 347.0000 - fn: 73.0000 - accuracy: 0.7612 - precision: 0.6678 - recall: 0.7276 - auc: 0.8187 - val_loss: 0.5637 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8755\n",
      "Epoch 78/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6120 - tp: 195.0000 - fp: 92.0000 - tn: 352.0000 - fn: 73.0000 - accuracy: 0.7683 - precision: 0.6794 - recall: 0.7276 - auc: 0.8204 - val_loss: 0.5671 - val_tp: 62.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 12.0000 - val_accuracy: 0.7542 - val_precision: 0.6596 - val_recall: 0.8378 - val_auc: 0.8711\n",
      "Epoch 79/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5870 - tp: 205.0000 - fp: 103.0000 - tn: 341.0000 - fn: 63.0000 - accuracy: 0.7669 - precision: 0.6656 - recall: 0.7649 - auc: 0.8346 - val_loss: 0.6019 - val_tp: 51.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 23.0000 - val_accuracy: 0.7877 - val_precision: 0.7727 - val_recall: 0.6892 - val_auc: 0.8742\n",
      "Epoch 80/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6052 - tp: 200.0000 - fp: 93.0000 - tn: 351.0000 - fn: 68.0000 - accuracy: 0.7739 - precision: 0.6826 - recall: 0.7463 - auc: 0.8189 - val_loss: 0.5520 - val_tp: 51.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 23.0000 - val_accuracy: 0.7654 - val_precision: 0.7286 - val_recall: 0.6892 - val_auc: 0.8741\n",
      "Epoch 81/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6099 - tp: 203.0000 - fp: 100.0000 - tn: 344.0000 - fn: 65.0000 - accuracy: 0.7683 - precision: 0.6700 - recall: 0.7575 - auc: 0.8181 - val_loss: 0.5542 - val_tp: 54.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 20.0000 - val_accuracy: 0.7933 - val_precision: 0.7606 - val_recall: 0.7297 - val_auc: 0.8765\n",
      "Epoch 82/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6038 - tp: 201.0000 - fp: 87.0000 - tn: 357.0000 - fn: 67.0000 - accuracy: 0.7837 - precision: 0.6979 - recall: 0.7500 - auc: 0.8188 - val_loss: 0.6693 - val_tp: 72.0000 - val_fp: 58.0000 - val_tn: 47.0000 - val_fn: 2.0000 - val_accuracy: 0.6648 - val_precision: 0.5538 - val_recall: 0.9730 - val_auc: 0.8681\n",
      "Epoch 83/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6107 - tp: 198.0000 - fp: 97.0000 - tn: 347.0000 - fn: 70.0000 - accuracy: 0.7654 - precision: 0.6712 - recall: 0.7388 - auc: 0.8153 - val_loss: 0.5486 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8725\n",
      "Epoch 84/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6066 - tp: 196.0000 - fp: 96.0000 - tn: 348.0000 - fn: 72.0000 - accuracy: 0.7640 - precision: 0.6712 - recall: 0.7313 - auc: 0.8185 - val_loss: 0.5408 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8748\n",
      "Epoch 85/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5767 - tp: 203.0000 - fp: 84.0000 - tn: 360.0000 - fn: 65.0000 - accuracy: 0.7907 - precision: 0.7073 - recall: 0.7575 - auc: 0.8355 - val_loss: 0.5594 - val_tp: 54.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 20.0000 - val_accuracy: 0.7709 - val_precision: 0.7200 - val_recall: 0.7297 - val_auc: 0.8757\n",
      "Epoch 86/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6057 - tp: 203.0000 - fp: 93.0000 - tn: 351.0000 - fn: 65.0000 - accuracy: 0.7781 - precision: 0.6858 - recall: 0.7575 - auc: 0.8213 - val_loss: 0.6195 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8692\n",
      "Epoch 87/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6130 - tp: 205.0000 - fp: 102.0000 - tn: 342.0000 - fn: 63.0000 - accuracy: 0.7683 - precision: 0.6678 - recall: 0.7649 - auc: 0.8128 - val_loss: 0.5614 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8743\n",
      "Epoch 88/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5872 - tp: 206.0000 - fp: 89.0000 - tn: 355.0000 - fn: 62.0000 - accuracy: 0.7879 - precision: 0.6983 - recall: 0.7687 - auc: 0.8385 - val_loss: 0.5879 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8761\n",
      "Epoch 89/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6004 - tp: 206.0000 - fp: 102.0000 - tn: 342.0000 - fn: 62.0000 - accuracy: 0.7697 - precision: 0.6688 - recall: 0.7687 - auc: 0.8270 - val_loss: 0.6157 - val_tp: 66.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 8.0000 - val_accuracy: 0.7486 - val_precision: 0.6408 - val_recall: 0.8919 - val_auc: 0.8719\n",
      "Epoch 90/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6257 - tp: 198.0000 - fp: 94.0000 - tn: 350.0000 - fn: 70.0000 - accuracy: 0.7697 - precision: 0.6781 - recall: 0.7388 - auc: 0.8150 - val_loss: 0.5680 - val_tp: 53.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 21.0000 - val_accuracy: 0.7933 - val_precision: 0.7681 - val_recall: 0.7162 - val_auc: 0.8797\n",
      "Epoch 91/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5972 - tp: 204.0000 - fp: 84.0000 - tn: 360.0000 - fn: 64.0000 - accuracy: 0.7921 - precision: 0.7083 - recall: 0.7612 - auc: 0.8310 - val_loss: 0.5802 - val_tp: 66.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 8.0000 - val_accuracy: 0.7654 - val_precision: 0.6600 - val_recall: 0.8919 - val_auc: 0.8728\n",
      "Epoch 92/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6126 - tp: 198.0000 - fp: 99.0000 - tn: 345.0000 - fn: 70.0000 - accuracy: 0.7626 - precision: 0.6667 - recall: 0.7388 - auc: 0.8181 - val_loss: 0.5544 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8762\n",
      "Epoch 93/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5874 - tp: 199.0000 - fp: 84.0000 - tn: 360.0000 - fn: 69.0000 - accuracy: 0.7851 - precision: 0.7032 - recall: 0.7425 - auc: 0.8296 - val_loss: 0.5704 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8773\n",
      "Epoch 94/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6189 - tp: 202.0000 - fp: 79.0000 - tn: 365.0000 - fn: 66.0000 - accuracy: 0.7963 - precision: 0.7189 - recall: 0.7537 - auc: 0.8165 - val_loss: 0.5742 - val_tp: 61.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 13.0000 - val_accuracy: 0.7709 - val_precision: 0.6854 - val_recall: 0.8243 - val_auc: 0.8758\n",
      "Epoch 95/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.6085 - tp: 197.0000 - fp: 90.0000 - tn: 354.0000 - fn: 71.0000 - accuracy: 0.7739 - precision: 0.6864 - recall: 0.7351 - auc: 0.8224 - val_loss: 0.6318 - val_tp: 66.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 8.0000 - val_accuracy: 0.7486 - val_precision: 0.6408 - val_recall: 0.8919 - val_auc: 0.8629\n",
      "Epoch 96/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5992 - tp: 201.0000 - fp: 88.0000 - tn: 356.0000 - fn: 67.0000 - accuracy: 0.7823 - precision: 0.6955 - recall: 0.7500 - auc: 0.8287 - val_loss: 0.6196 - val_tp: 69.0000 - val_fp: 38.0000 - val_tn: 67.0000 - val_fn: 5.0000 - val_accuracy: 0.7598 - val_precision: 0.6449 - val_recall: 0.9324 - val_auc: 0.8663\n",
      "Epoch 97/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6150 - tp: 202.0000 - fp: 95.0000 - tn: 349.0000 - fn: 66.0000 - accuracy: 0.7739 - precision: 0.6801 - recall: 0.7537 - auc: 0.8193 - val_loss: 0.7680 - val_tp: 74.0000 - val_fp: 89.0000 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5028 - val_precision: 0.4540 - val_recall: 1.0000 - val_auc: 0.8546\n",
      "Epoch 98/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.6211 - tp: 211.0000 - fp: 112.0000 - tn: 332.0000 - fn: 57.0000 - accuracy: 0.7626 - precision: 0.6533 - recall: 0.7873 - auc: 0.8129 - val_loss: 0.5845 - val_tp: 50.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 24.0000 - val_accuracy: 0.7821 - val_precision: 0.7692 - val_recall: 0.6757 - val_auc: 0.8789\n",
      "Epoch 99/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5793 - tp: 191.0000 - fp: 89.0000 - tn: 355.0000 - fn: 77.0000 - accuracy: 0.7669 - precision: 0.6821 - recall: 0.7127 - auc: 0.8349 - val_loss: 0.8340 - val_tp: 72.0000 - val_fp: 64.0000 - val_tn: 41.0000 - val_fn: 2.0000 - val_accuracy: 0.6313 - val_precision: 0.5294 - val_recall: 0.9730 - val_auc: 0.8533\n",
      "Epoch 100/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6151 - tp: 204.0000 - fp: 97.0000 - tn: 347.0000 - fn: 64.0000 - accuracy: 0.7739 - precision: 0.6777 - recall: 0.7612 - auc: 0.8175 - val_loss: 0.5557 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8777\n",
      "Epoch 101/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5984 - tp: 200.0000 - fp: 101.0000 - tn: 343.0000 - fn: 68.0000 - accuracy: 0.7626 - precision: 0.6645 - recall: 0.7463 - auc: 0.8239 - val_loss: 0.5875 - val_tp: 41.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 33.0000 - val_accuracy: 0.7430 - val_precision: 0.7593 - val_recall: 0.5541 - val_auc: 0.8704\n",
      "Epoch 102/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6074 - tp: 202.0000 - fp: 97.0000 - tn: 347.0000 - fn: 66.0000 - accuracy: 0.7711 - precision: 0.6756 - recall: 0.7537 - auc: 0.8236 - val_loss: 0.5544 - val_tp: 63.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 11.0000 - val_accuracy: 0.7542 - val_precision: 0.6562 - val_recall: 0.8514 - val_auc: 0.8733\n",
      "Epoch 103/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6162 - tp: 206.0000 - fp: 112.0000 - tn: 332.0000 - fn: 62.0000 - accuracy: 0.7556 - precision: 0.6478 - recall: 0.7687 - auc: 0.8075 - val_loss: 0.5894 - val_tp: 70.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 4.0000 - val_accuracy: 0.7765 - val_precision: 0.6604 - val_recall: 0.9459 - val_auc: 0.8684\n",
      "Epoch 104/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6048 - tp: 198.0000 - fp: 95.0000 - tn: 349.0000 - fn: 70.0000 - accuracy: 0.7683 - precision: 0.6758 - recall: 0.7388 - auc: 0.8222 - val_loss: 0.8203 - val_tp: 74.0000 - val_fp: 103.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4246 - val_precision: 0.4181 - val_recall: 1.0000 - val_auc: 0.8550\n",
      "Epoch 105/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6080 - tp: 198.0000 - fp: 104.0000 - tn: 340.0000 - fn: 70.0000 - accuracy: 0.7556 - precision: 0.6556 - recall: 0.7388 - auc: 0.8201 - val_loss: 0.5618 - val_tp: 62.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 12.0000 - val_accuracy: 0.7486 - val_precision: 0.6526 - val_recall: 0.8378 - val_auc: 0.8696\n",
      "Epoch 106/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5784 - tp: 203.0000 - fp: 88.0000 - tn: 356.0000 - fn: 65.0000 - accuracy: 0.7851 - precision: 0.6976 - recall: 0.7575 - auc: 0.8399 - val_loss: 0.5499 - val_tp: 58.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 16.0000 - val_accuracy: 0.7598 - val_precision: 0.6824 - val_recall: 0.7838 - val_auc: 0.8705\n",
      "Epoch 107/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5908 - tp: 203.0000 - fp: 88.0000 - tn: 356.0000 - fn: 65.0000 - accuracy: 0.7851 - precision: 0.6976 - recall: 0.7575 - auc: 0.8326 - val_loss: 0.6621 - val_tp: 70.0000 - val_fp: 41.0000 - val_tn: 64.0000 - val_fn: 4.0000 - val_accuracy: 0.7486 - val_precision: 0.6306 - val_recall: 0.9459 - val_auc: 0.8634\n",
      "Epoch 108/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6050 - tp: 204.0000 - fp: 97.0000 - tn: 347.0000 - fn: 64.0000 - accuracy: 0.7739 - precision: 0.6777 - recall: 0.7612 - auc: 0.8240 - val_loss: 0.5793 - val_tp: 61.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 13.0000 - val_accuracy: 0.7542 - val_precision: 0.6630 - val_recall: 0.8243 - val_auc: 0.8760\n",
      "Epoch 109/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6218 - tp: 199.0000 - fp: 91.0000 - tn: 353.0000 - fn: 69.0000 - accuracy: 0.7753 - precision: 0.6862 - recall: 0.7425 - auc: 0.8110 - val_loss: 0.6160 - val_tp: 70.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 4.0000 - val_accuracy: 0.7709 - val_precision: 0.6542 - val_recall: 0.9459 - val_auc: 0.8690\n",
      "Epoch 110/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5999 - tp: 201.0000 - fp: 104.0000 - tn: 340.0000 - fn: 67.0000 - accuracy: 0.7598 - precision: 0.6590 - recall: 0.7500 - auc: 0.8238 - val_loss: 0.7964 - val_tp: 74.0000 - val_fp: 102.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4302 - val_precision: 0.4205 - val_recall: 1.0000 - val_auc: 0.8528\n",
      "Epoch 111/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6151 - tp: 204.0000 - fp: 109.0000 - tn: 335.0000 - fn: 64.0000 - accuracy: 0.7570 - precision: 0.6518 - recall: 0.7612 - auc: 0.8126 - val_loss: 0.5486 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8790\n",
      "Epoch 112/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6103 - tp: 200.0000 - fp: 88.0000 - tn: 356.0000 - fn: 68.0000 - accuracy: 0.7809 - precision: 0.6944 - recall: 0.7463 - auc: 0.8189 - val_loss: 0.5637 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8812\n",
      "Epoch 113/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6108 - tp: 206.0000 - fp: 95.0000 - tn: 349.0000 - fn: 62.0000 - accuracy: 0.7795 - precision: 0.6844 - recall: 0.7687 - auc: 0.8229 - val_loss: 0.5935 - val_tp: 52.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 22.0000 - val_accuracy: 0.8045 - val_precision: 0.8000 - val_recall: 0.7027 - val_auc: 0.8858\n",
      "Epoch 114/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5824 - tp: 201.0000 - fp: 88.0000 - tn: 356.0000 - fn: 67.0000 - accuracy: 0.7823 - precision: 0.6955 - recall: 0.7500 - auc: 0.8369 - val_loss: 0.5946 - val_tp: 69.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 5.0000 - val_accuracy: 0.7765 - val_precision: 0.6635 - val_recall: 0.9324 - val_auc: 0.8723\n",
      "Epoch 115/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5851 - tp: 202.0000 - fp: 103.0000 - tn: 341.0000 - fn: 66.0000 - accuracy: 0.7626 - precision: 0.6623 - recall: 0.7537 - auc: 0.8362 - val_loss: 0.6704 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 27.0000 - val_accuracy: 0.7933 - val_precision: 0.8246 - val_recall: 0.6351 - val_auc: 0.8871\n",
      "Epoch 116/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6214 - tp: 201.0000 - fp: 98.0000 - tn: 346.0000 - fn: 67.0000 - accuracy: 0.7683 - precision: 0.6722 - recall: 0.7500 - auc: 0.8149 - val_loss: 0.6298 - val_tp: 49.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 25.0000 - val_accuracy: 0.7989 - val_precision: 0.8167 - val_recall: 0.6622 - val_auc: 0.8862\n",
      "Epoch 117/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6047 - tp: 197.0000 - fp: 92.0000 - tn: 352.0000 - fn: 71.0000 - accuracy: 0.7711 - precision: 0.6817 - recall: 0.7351 - auc: 0.8191 - val_loss: 0.5653 - val_tp: 54.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 20.0000 - val_accuracy: 0.7877 - val_precision: 0.7500 - val_recall: 0.7297 - val_auc: 0.8783\n",
      "Epoch 118/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6099 - tp: 203.0000 - fp: 84.0000 - tn: 360.0000 - fn: 65.0000 - accuracy: 0.7907 - precision: 0.7073 - recall: 0.7575 - auc: 0.8261 - val_loss: 1.1094 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8422\n",
      "Epoch 119/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6412 - tp: 203.0000 - fp: 101.0000 - tn: 343.0000 - fn: 65.0000 - accuracy: 0.7669 - precision: 0.6678 - recall: 0.7575 - auc: 0.8030 - val_loss: 0.5536 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8768\n",
      "Epoch 120/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5854 - tp: 202.0000 - fp: 87.0000 - tn: 357.0000 - fn: 66.0000 - accuracy: 0.7851 - precision: 0.6990 - recall: 0.7537 - auc: 0.8342 - val_loss: 0.5971 - val_tp: 49.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 25.0000 - val_accuracy: 0.7765 - val_precision: 0.7656 - val_recall: 0.6622 - val_auc: 0.8759\n",
      "Epoch 121/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6089 - tp: 201.0000 - fp: 100.0000 - tn: 344.0000 - fn: 67.0000 - accuracy: 0.7654 - precision: 0.6678 - recall: 0.7500 - auc: 0.8241 - val_loss: 0.5729 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8732\n",
      "Epoch 122/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5936 - tp: 198.0000 - fp: 88.0000 - tn: 356.0000 - fn: 70.0000 - accuracy: 0.7781 - precision: 0.6923 - recall: 0.7388 - auc: 0.8317 - val_loss: 0.6651 - val_tp: 70.0000 - val_fp: 42.0000 - val_tn: 63.0000 - val_fn: 4.0000 - val_accuracy: 0.7430 - val_precision: 0.6250 - val_recall: 0.9459 - val_auc: 0.8658\n",
      "Epoch 123/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6230 - tp: 198.0000 - fp: 93.0000 - tn: 351.0000 - fn: 70.0000 - accuracy: 0.7711 - precision: 0.6804 - recall: 0.7388 - auc: 0.8091 - val_loss: 0.7887 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 55.0000 - val_accuracy: 0.6927 - val_precision: 1.0000 - val_recall: 0.2568 - val_auc: 0.8871\n",
      "Epoch 124/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6380 - tp: 191.0000 - fp: 99.0000 - tn: 345.0000 - fn: 77.0000 - accuracy: 0.7528 - precision: 0.6586 - recall: 0.7127 - auc: 0.7920 - val_loss: 0.6194 - val_tp: 42.0000 - val_fp: 5.0000 - val_tn: 100.0000 - val_fn: 32.0000 - val_accuracy: 0.7933 - val_precision: 0.8936 - val_recall: 0.5676 - val_auc: 0.8808\n",
      "Epoch 125/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5902 - tp: 202.0000 - fp: 76.0000 - tn: 368.0000 - fn: 66.0000 - accuracy: 0.8006 - precision: 0.7266 - recall: 0.7537 - auc: 0.8345 - val_loss: 0.6220 - val_tp: 48.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 26.0000 - val_accuracy: 0.7933 - val_precision: 0.8136 - val_recall: 0.6486 - val_auc: 0.8771\n",
      "Epoch 126/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6125 - tp: 202.0000 - fp: 101.0000 - tn: 343.0000 - fn: 66.0000 - accuracy: 0.7654 - precision: 0.6667 - recall: 0.7537 - auc: 0.8132 - val_loss: 0.6088 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8671\n",
      "Epoch 127/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5885 - tp: 207.0000 - fp: 86.0000 - tn: 358.0000 - fn: 61.0000 - accuracy: 0.7935 - precision: 0.7065 - recall: 0.7724 - auc: 0.8387 - val_loss: 0.7171 - val_tp: 41.0000 - val_fp: 4.0000 - val_tn: 101.0000 - val_fn: 33.0000 - val_accuracy: 0.7933 - val_precision: 0.9111 - val_recall: 0.5541 - val_auc: 0.8879\n",
      "Epoch 128/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6047 - tp: 194.0000 - fp: 89.0000 - tn: 355.0000 - fn: 74.0000 - accuracy: 0.7711 - precision: 0.6855 - recall: 0.7239 - auc: 0.8280 - val_loss: 0.6253 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8655\n",
      "Epoch 129/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6119 - tp: 209.0000 - fp: 96.0000 - tn: 348.0000 - fn: 59.0000 - accuracy: 0.7823 - precision: 0.6852 - recall: 0.7799 - auc: 0.8212 - val_loss: 0.5500 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8838\n",
      "Epoch 130/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6077 - tp: 199.0000 - fp: 100.0000 - tn: 344.0000 - fn: 69.0000 - accuracy: 0.7626 - precision: 0.6656 - recall: 0.7425 - auc: 0.8187 - val_loss: 0.5912 - val_tp: 53.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 21.0000 - val_accuracy: 0.8045 - val_precision: 0.7910 - val_recall: 0.7162 - val_auc: 0.8816\n",
      "Epoch 131/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6049 - tp: 202.0000 - fp: 94.0000 - tn: 350.0000 - fn: 66.0000 - accuracy: 0.7753 - precision: 0.6824 - recall: 0.7537 - auc: 0.8230 - val_loss: 0.6184 - val_tp: 66.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 8.0000 - val_accuracy: 0.7486 - val_precision: 0.6408 - val_recall: 0.8919 - val_auc: 0.8671\n",
      "Epoch 132/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6100 - tp: 201.0000 - fp: 101.0000 - tn: 343.0000 - fn: 67.0000 - accuracy: 0.7640 - precision: 0.6656 - recall: 0.7500 - auc: 0.8172 - val_loss: 0.5515 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8719\n",
      "Epoch 133/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6008 - tp: 202.0000 - fp: 105.0000 - tn: 339.0000 - fn: 66.0000 - accuracy: 0.7598 - precision: 0.6580 - recall: 0.7537 - auc: 0.8241 - val_loss: 0.6979 - val_tp: 39.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 35.0000 - val_accuracy: 0.7654 - val_precision: 0.8478 - val_recall: 0.5270 - val_auc: 0.8823\n",
      "Epoch 134/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6128 - tp: 198.0000 - fp: 81.0000 - tn: 363.0000 - fn: 70.0000 - accuracy: 0.7879 - precision: 0.7097 - recall: 0.7388 - auc: 0.8195 - val_loss: 0.5899 - val_tp: 64.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 10.0000 - val_accuracy: 0.7374 - val_precision: 0.6337 - val_recall: 0.8649 - val_auc: 0.8719\n",
      "Epoch 135/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6003 - tp: 203.0000 - fp: 94.0000 - tn: 350.0000 - fn: 65.0000 - accuracy: 0.7767 - precision: 0.6835 - recall: 0.7575 - auc: 0.8281 - val_loss: 0.7191 - val_tp: 74.0000 - val_fp: 81.0000 - val_tn: 24.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5475 - val_precision: 0.4774 - val_recall: 1.0000 - val_auc: 0.8636\n",
      "Epoch 136/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6215 - tp: 201.0000 - fp: 96.0000 - tn: 348.0000 - fn: 67.0000 - accuracy: 0.7711 - precision: 0.6768 - recall: 0.7500 - auc: 0.8225 - val_loss: 0.5927 - val_tp: 69.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 5.0000 - val_accuracy: 0.7709 - val_precision: 0.6571 - val_recall: 0.9324 - val_auc: 0.8704\n",
      "Epoch 137/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5832 - tp: 203.0000 - fp: 100.0000 - tn: 344.0000 - fn: 65.0000 - accuracy: 0.7683 - precision: 0.6700 - recall: 0.7575 - auc: 0.8329 - val_loss: 0.5878 - val_tp: 48.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 26.0000 - val_accuracy: 0.7654 - val_precision: 0.7500 - val_recall: 0.6486 - val_auc: 0.8746\n",
      "Epoch 138/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.5998 - tp: 198.0000 - fp: 91.0000 - tn: 353.0000 - fn: 70.0000 - accuracy: 0.7739 - precision: 0.6851 - recall: 0.7388 - auc: 0.8238 - val_loss: 0.6660 - val_tp: 36.0000 - val_fp: 4.0000 - val_tn: 101.0000 - val_fn: 38.0000 - val_accuracy: 0.7654 - val_precision: 0.9000 - val_recall: 0.4865 - val_auc: 0.8761\n",
      "Epoch 139/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6145 - tp: 199.0000 - fp: 100.0000 - tn: 344.0000 - fn: 69.0000 - accuracy: 0.7626 - precision: 0.6656 - recall: 0.7425 - auc: 0.8184 - val_loss: 0.7014 - val_tp: 41.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 33.0000 - val_accuracy: 0.7821 - val_precision: 0.8723 - val_recall: 0.5541 - val_auc: 0.8876\n",
      "Epoch 140/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6081 - tp: 197.0000 - fp: 89.0000 - tn: 355.0000 - fn: 71.0000 - accuracy: 0.7753 - precision: 0.6888 - recall: 0.7351 - auc: 0.8266 - val_loss: 0.6413 - val_tp: 47.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 27.0000 - val_accuracy: 0.7821 - val_precision: 0.7966 - val_recall: 0.6351 - val_auc: 0.8841\n",
      "Epoch 141/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5903 - tp: 204.0000 - fp: 84.0000 - tn: 360.0000 - fn: 64.0000 - accuracy: 0.7921 - precision: 0.7083 - recall: 0.7612 - auc: 0.8346 - val_loss: 0.5503 - val_tp: 54.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 20.0000 - val_accuracy: 0.7821 - val_precision: 0.7397 - val_recall: 0.7297 - val_auc: 0.8762\n",
      "Epoch 142/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6239 - tp: 200.0000 - fp: 108.0000 - tn: 336.0000 - fn: 68.0000 - accuracy: 0.7528 - precision: 0.6494 - recall: 0.7463 - auc: 0.8136 - val_loss: 0.5826 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8800\n",
      "Epoch 143/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6058 - tp: 195.0000 - fp: 92.0000 - tn: 352.0000 - fn: 73.0000 - accuracy: 0.7683 - precision: 0.6794 - recall: 0.7276 - auc: 0.8169 - val_loss: 0.5902 - val_tp: 66.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 8.0000 - val_accuracy: 0.7654 - val_precision: 0.6600 - val_recall: 0.8919 - val_auc: 0.8729\n",
      "Epoch 144/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6127 - tp: 206.0000 - fp: 93.0000 - tn: 351.0000 - fn: 62.0000 - accuracy: 0.7823 - precision: 0.6890 - recall: 0.7687 - auc: 0.8164 - val_loss: 0.6573 - val_tp: 50.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 24.0000 - val_accuracy: 0.7933 - val_precision: 0.7937 - val_recall: 0.6757 - val_auc: 0.8819\n",
      "Epoch 145/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6208 - tp: 194.0000 - fp: 91.0000 - tn: 353.0000 - fn: 74.0000 - accuracy: 0.7683 - precision: 0.6807 - recall: 0.7239 - auc: 0.8103 - val_loss: 0.5929 - val_tp: 52.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 22.0000 - val_accuracy: 0.8045 - val_precision: 0.8000 - val_recall: 0.7027 - val_auc: 0.8792\n",
      "Epoch 146/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6042 - tp: 191.0000 - fp: 92.0000 - tn: 352.0000 - fn: 77.0000 - accuracy: 0.7626 - precision: 0.6749 - recall: 0.7127 - auc: 0.8228 - val_loss: 0.6306 - val_tp: 47.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 27.0000 - val_accuracy: 0.7989 - val_precision: 0.8393 - val_recall: 0.6351 - val_auc: 0.8771\n",
      "Epoch 147/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5949 - tp: 195.0000 - fp: 82.0000 - tn: 362.0000 - fn: 73.0000 - accuracy: 0.7823 - precision: 0.7040 - recall: 0.7276 - auc: 0.8298 - val_loss: 0.5529 - val_tp: 58.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 16.0000 - val_accuracy: 0.7877 - val_precision: 0.7250 - val_recall: 0.7838 - val_auc: 0.8718\n",
      "Epoch 148/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5944 - tp: 202.0000 - fp: 96.0000 - tn: 348.0000 - fn: 66.0000 - accuracy: 0.7725 - precision: 0.6779 - recall: 0.7537 - auc: 0.8308 - val_loss: 0.6771 - val_tp: 70.0000 - val_fp: 42.0000 - val_tn: 63.0000 - val_fn: 4.0000 - val_accuracy: 0.7430 - val_precision: 0.6250 - val_recall: 0.9459 - val_auc: 0.8667\n",
      "Epoch 149/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6108 - tp: 204.0000 - fp: 103.0000 - tn: 341.0000 - fn: 64.0000 - accuracy: 0.7654 - precision: 0.6645 - recall: 0.7612 - auc: 0.8116 - val_loss: 0.7759 - val_tp: 74.0000 - val_fp: 101.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4358 - val_precision: 0.4229 - val_recall: 1.0000 - val_auc: 0.8569\n",
      "Epoch 150/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6162 - tp: 197.0000 - fp: 103.0000 - tn: 341.0000 - fn: 71.0000 - accuracy: 0.7556 - precision: 0.6567 - recall: 0.7351 - auc: 0.8089 - val_loss: 0.6189 - val_tp: 46.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 28.0000 - val_accuracy: 0.7765 - val_precision: 0.7931 - val_recall: 0.6216 - val_auc: 0.8734\n",
      "Epoch 151/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6032 - tp: 200.0000 - fp: 93.0000 - tn: 351.0000 - fn: 68.0000 - accuracy: 0.7739 - precision: 0.6826 - recall: 0.7463 - auc: 0.8208 - val_loss: 0.6696 - val_tp: 71.0000 - val_fp: 56.0000 - val_tn: 49.0000 - val_fn: 3.0000 - val_accuracy: 0.6704 - val_precision: 0.5591 - val_recall: 0.9595 - val_auc: 0.8703\n",
      "Epoch 152/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6109 - tp: 203.0000 - fp: 101.0000 - tn: 343.0000 - fn: 65.0000 - accuracy: 0.7669 - precision: 0.6678 - recall: 0.7575 - auc: 0.8215 - val_loss: 0.6177 - val_tp: 49.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 25.0000 - val_accuracy: 0.7821 - val_precision: 0.7778 - val_recall: 0.6622 - val_auc: 0.8685\n",
      "Epoch 153/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5963 - tp: 206.0000 - fp: 97.0000 - tn: 347.0000 - fn: 62.0000 - accuracy: 0.7767 - precision: 0.6799 - recall: 0.7687 - auc: 0.8326 - val_loss: 0.5384 - val_tp: 55.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 19.0000 - val_accuracy: 0.7654 - val_precision: 0.7051 - val_recall: 0.7432 - val_auc: 0.8753\n",
      "Epoch 154/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6034 - tp: 209.0000 - fp: 89.0000 - tn: 355.0000 - fn: 59.0000 - accuracy: 0.7921 - precision: 0.7013 - recall: 0.7799 - auc: 0.8302 - val_loss: 0.6029 - val_tp: 49.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 25.0000 - val_accuracy: 0.7877 - val_precision: 0.7903 - val_recall: 0.6622 - val_auc: 0.8826\n",
      "Epoch 155/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5929 - tp: 199.0000 - fp: 88.0000 - tn: 356.0000 - fn: 69.0000 - accuracy: 0.7795 - precision: 0.6934 - recall: 0.7425 - auc: 0.8348 - val_loss: 0.7636 - val_tp: 30.0000 - val_fp: 1.0000 - val_tn: 104.0000 - val_fn: 44.0000 - val_accuracy: 0.7486 - val_precision: 0.9677 - val_recall: 0.4054 - val_auc: 0.8839\n",
      "Epoch 156/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6063 - tp: 197.0000 - fp: 87.0000 - tn: 357.0000 - fn: 71.0000 - accuracy: 0.7781 - precision: 0.6937 - recall: 0.7351 - auc: 0.8197 - val_loss: 0.5974 - val_tp: 69.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 5.0000 - val_accuracy: 0.7709 - val_precision: 0.6571 - val_recall: 0.9324 - val_auc: 0.8662\n",
      "Epoch 157/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5908 - tp: 204.0000 - fp: 98.0000 - tn: 346.0000 - fn: 64.0000 - accuracy: 0.7725 - precision: 0.6755 - recall: 0.7612 - auc: 0.8364 - val_loss: 0.5635 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8635\n",
      "Epoch 158/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6102 - tp: 205.0000 - fp: 98.0000 - tn: 346.0000 - fn: 63.0000 - accuracy: 0.7739 - precision: 0.6766 - recall: 0.7649 - auc: 0.8228 - val_loss: 0.5705 - val_tp: 66.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 8.0000 - val_accuracy: 0.7765 - val_precision: 0.6735 - val_recall: 0.8919 - val_auc: 0.8635\n",
      "Epoch 159/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5859 - tp: 203.0000 - fp: 95.0000 - tn: 349.0000 - fn: 65.0000 - accuracy: 0.7753 - precision: 0.6812 - recall: 0.7575 - auc: 0.8342 - val_loss: 0.5699 - val_tp: 60.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 14.0000 - val_accuracy: 0.7486 - val_precision: 0.6593 - val_recall: 0.8108 - val_auc: 0.8719\n",
      "Epoch 160/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6135 - tp: 202.0000 - fp: 102.0000 - tn: 342.0000 - fn: 66.0000 - accuracy: 0.7640 - precision: 0.6645 - recall: 0.7537 - auc: 0.8106 - val_loss: 0.6810 - val_tp: 70.0000 - val_fp: 44.0000 - val_tn: 61.0000 - val_fn: 4.0000 - val_accuracy: 0.7318 - val_precision: 0.6140 - val_recall: 0.9459 - val_auc: 0.8523\n",
      "Epoch 161/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6032 - tp: 200.0000 - fp: 102.0000 - tn: 342.0000 - fn: 68.0000 - accuracy: 0.7612 - precision: 0.6623 - recall: 0.7463 - auc: 0.8237 - val_loss: 0.6117 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8594\n",
      "Epoch 162/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6100 - tp: 199.0000 - fp: 99.0000 - tn: 345.0000 - fn: 69.0000 - accuracy: 0.7640 - precision: 0.6678 - recall: 0.7425 - auc: 0.8218 - val_loss: 0.6840 - val_tp: 34.0000 - val_fp: 2.0000 - val_tn: 103.0000 - val_fn: 40.0000 - val_accuracy: 0.7654 - val_precision: 0.9444 - val_recall: 0.4595 - val_auc: 0.8837\n",
      "Epoch 163/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6167 - tp: 193.0000 - fp: 89.0000 - tn: 355.0000 - fn: 75.0000 - accuracy: 0.7697 - precision: 0.6844 - recall: 0.7201 - auc: 0.8139 - val_loss: 0.6318 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8675\n",
      "Epoch 164/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6164 - tp: 209.0000 - fp: 107.0000 - tn: 337.0000 - fn: 59.0000 - accuracy: 0.7669 - precision: 0.6614 - recall: 0.7799 - auc: 0.8147 - val_loss: 0.6223 - val_tp: 41.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 33.0000 - val_accuracy: 0.7709 - val_precision: 0.8367 - val_recall: 0.5541 - val_auc: 0.8773\n",
      "Epoch 165/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6005 - tp: 195.0000 - fp: 76.0000 - tn: 368.0000 - fn: 73.0000 - accuracy: 0.7907 - precision: 0.7196 - recall: 0.7276 - auc: 0.8296 - val_loss: 0.5630 - val_tp: 63.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 11.0000 - val_accuracy: 0.7821 - val_precision: 0.6923 - val_recall: 0.8514 - val_auc: 0.8692\n",
      "Epoch 166/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6079 - tp: 202.0000 - fp: 97.0000 - tn: 347.0000 - fn: 66.0000 - accuracy: 0.7711 - precision: 0.6756 - recall: 0.7537 - auc: 0.8154 - val_loss: 0.5521 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8728\n",
      "Epoch 167/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5823 - tp: 200.0000 - fp: 90.0000 - tn: 354.0000 - fn: 68.0000 - accuracy: 0.7781 - precision: 0.6897 - recall: 0.7463 - auc: 0.8359 - val_loss: 0.5650 - val_tp: 59.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 15.0000 - val_accuracy: 0.7709 - val_precision: 0.6941 - val_recall: 0.7973 - val_auc: 0.8773\n",
      "Epoch 168/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5917 - tp: 201.0000 - fp: 104.0000 - tn: 340.0000 - fn: 67.0000 - accuracy: 0.7598 - precision: 0.6590 - recall: 0.7500 - auc: 0.8270 - val_loss: 0.6585 - val_tp: 47.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 27.0000 - val_accuracy: 0.7821 - val_precision: 0.7966 - val_recall: 0.6351 - val_auc: 0.8777\n",
      "Epoch 169/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5909 - tp: 197.0000 - fp: 82.0000 - tn: 362.0000 - fn: 71.0000 - accuracy: 0.7851 - precision: 0.7061 - recall: 0.7351 - auc: 0.8350 - val_loss: 0.5491 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8772\n",
      "Epoch 170/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6097 - tp: 207.0000 - fp: 98.0000 - tn: 346.0000 - fn: 61.0000 - accuracy: 0.7767 - precision: 0.6787 - recall: 0.7724 - auc: 0.8189 - val_loss: 0.5957 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8631\n",
      "Epoch 171/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5882 - tp: 206.0000 - fp: 95.0000 - tn: 349.0000 - fn: 62.0000 - accuracy: 0.7795 - precision: 0.6844 - recall: 0.7687 - auc: 0.8369 - val_loss: 0.5924 - val_tp: 52.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 22.0000 - val_accuracy: 0.7598 - val_precision: 0.7123 - val_recall: 0.7027 - val_auc: 0.8680\n",
      "Epoch 172/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6179 - tp: 201.0000 - fp: 109.0000 - tn: 335.0000 - fn: 67.0000 - accuracy: 0.7528 - precision: 0.6484 - recall: 0.7500 - auc: 0.8106 - val_loss: 0.7534 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 46.0000 - val_accuracy: 0.7430 - val_precision: 1.0000 - val_recall: 0.3784 - val_auc: 0.8830\n",
      "Epoch 173/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6184 - tp: 195.0000 - fp: 92.0000 - tn: 352.0000 - fn: 73.0000 - accuracy: 0.7683 - precision: 0.6794 - recall: 0.7276 - auc: 0.8176 - val_loss: 0.5429 - val_tp: 55.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 19.0000 - val_accuracy: 0.7654 - val_precision: 0.7051 - val_recall: 0.7432 - val_auc: 0.8707\n",
      "Epoch 174/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5959 - tp: 205.0000 - fp: 106.0000 - tn: 338.0000 - fn: 63.0000 - accuracy: 0.7626 - precision: 0.6592 - recall: 0.7649 - auc: 0.8349 - val_loss: 0.6593 - val_tp: 39.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 35.0000 - val_accuracy: 0.7709 - val_precision: 0.8667 - val_recall: 0.5270 - val_auc: 0.8837\n",
      "Epoch 175/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6097 - tp: 195.0000 - fp: 90.0000 - tn: 354.0000 - fn: 73.0000 - accuracy: 0.7711 - precision: 0.6842 - recall: 0.7276 - auc: 0.8168 - val_loss: 0.6150 - val_tp: 69.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 5.0000 - val_accuracy: 0.7709 - val_precision: 0.6571 - val_recall: 0.9324 - val_auc: 0.8683\n",
      "Epoch 176/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5946 - tp: 203.0000 - fp: 87.0000 - tn: 357.0000 - fn: 65.0000 - accuracy: 0.7865 - precision: 0.7000 - recall: 0.7575 - auc: 0.8359 - val_loss: 0.6465 - val_tp: 70.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 4.0000 - val_accuracy: 0.7709 - val_precision: 0.6542 - val_recall: 0.9459 - val_auc: 0.8728\n",
      "Epoch 177/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6294 - tp: 207.0000 - fp: 104.0000 - tn: 340.0000 - fn: 61.0000 - accuracy: 0.7683 - precision: 0.6656 - recall: 0.7724 - auc: 0.8111 - val_loss: 0.5687 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8827\n",
      "Epoch 178/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6228 - tp: 199.0000 - fp: 94.0000 - tn: 350.0000 - fn: 69.0000 - accuracy: 0.7711 - precision: 0.6792 - recall: 0.7425 - auc: 0.8132 - val_loss: 0.5650 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8796\n",
      "Epoch 179/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5886 - tp: 198.0000 - fp: 87.0000 - tn: 357.0000 - fn: 70.0000 - accuracy: 0.7795 - precision: 0.6947 - recall: 0.7388 - auc: 0.8309 - val_loss: 0.6043 - val_tp: 69.0000 - val_fp: 38.0000 - val_tn: 67.0000 - val_fn: 5.0000 - val_accuracy: 0.7598 - val_precision: 0.6449 - val_recall: 0.9324 - val_auc: 0.8656\n",
      "Epoch 180/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5956 - tp: 206.0000 - fp: 103.0000 - tn: 341.0000 - fn: 62.0000 - accuracy: 0.7683 - precision: 0.6667 - recall: 0.7687 - auc: 0.8257 - val_loss: 0.5366 - val_tp: 58.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 16.0000 - val_accuracy: 0.7542 - val_precision: 0.6744 - val_recall: 0.7838 - val_auc: 0.8777\n",
      "Epoch 181/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6050 - tp: 206.0000 - fp: 93.0000 - tn: 351.0000 - fn: 62.0000 - accuracy: 0.7823 - precision: 0.6890 - recall: 0.7687 - auc: 0.8277 - val_loss: 0.5525 - val_tp: 53.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 21.0000 - val_accuracy: 0.7709 - val_precision: 0.7260 - val_recall: 0.7162 - val_auc: 0.8756\n",
      "Epoch 182/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6113 - tp: 202.0000 - fp: 88.0000 - tn: 356.0000 - fn: 66.0000 - accuracy: 0.7837 - precision: 0.6966 - recall: 0.7537 - auc: 0.8232 - val_loss: 0.5602 - val_tp: 61.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 13.0000 - val_accuracy: 0.7654 - val_precision: 0.6778 - val_recall: 0.8243 - val_auc: 0.8727\n",
      "Epoch 183/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5854 - tp: 207.0000 - fp: 90.0000 - tn: 354.0000 - fn: 61.0000 - accuracy: 0.7879 - precision: 0.6970 - recall: 0.7724 - auc: 0.8381 - val_loss: 0.5464 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8864\n",
      "Epoch 184/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.5858 - tp: 206.0000 - fp: 92.0000 - tn: 352.0000 - fn: 62.0000 - accuracy: 0.7837 - precision: 0.6913 - recall: 0.7687 - auc: 0.8416 - val_loss: 0.5627 - val_tp: 53.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 21.0000 - val_accuracy: 0.7654 - val_precision: 0.7162 - val_recall: 0.7162 - val_auc: 0.8775\n",
      "Epoch 185/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6177 - tp: 205.0000 - fp: 98.0000 - tn: 346.0000 - fn: 63.0000 - accuracy: 0.7739 - precision: 0.6766 - recall: 0.7649 - auc: 0.8145 - val_loss: 0.5742 - val_tp: 53.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 21.0000 - val_accuracy: 0.7709 - val_precision: 0.7260 - val_recall: 0.7162 - val_auc: 0.8744\n",
      "Epoch 186/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6083 - tp: 203.0000 - fp: 91.0000 - tn: 353.0000 - fn: 65.0000 - accuracy: 0.7809 - precision: 0.6905 - recall: 0.7575 - auc: 0.8229 - val_loss: 0.7497 - val_tp: 36.0000 - val_fp: 4.0000 - val_tn: 101.0000 - val_fn: 38.0000 - val_accuracy: 0.7654 - val_precision: 0.9000 - val_recall: 0.4865 - val_auc: 0.8878\n",
      "Epoch 187/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6197 - tp: 190.0000 - fp: 90.0000 - tn: 354.0000 - fn: 78.0000 - accuracy: 0.7640 - precision: 0.6786 - recall: 0.7090 - auc: 0.8183 - val_loss: 0.5678 - val_tp: 53.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 21.0000 - val_accuracy: 0.7933 - val_precision: 0.7681 - val_recall: 0.7162 - val_auc: 0.8792\n",
      "Epoch 188/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6103 - tp: 191.0000 - fp: 104.0000 - tn: 340.0000 - fn: 77.0000 - accuracy: 0.7458 - precision: 0.6475 - recall: 0.7127 - auc: 0.8171 - val_loss: 0.8395 - val_tp: 74.0000 - val_fp: 103.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4246 - val_precision: 0.4181 - val_recall: 1.0000 - val_auc: 0.8551\n",
      "Epoch 189/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6077 - tp: 198.0000 - fp: 100.0000 - tn: 344.0000 - fn: 70.0000 - accuracy: 0.7612 - precision: 0.6644 - recall: 0.7388 - auc: 0.8131 - val_loss: 0.5483 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8718\n",
      "Epoch 190/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6452 - tp: 193.0000 - fp: 96.0000 - tn: 348.0000 - fn: 75.0000 - accuracy: 0.7598 - precision: 0.6678 - recall: 0.7201 - auc: 0.7948 - val_loss: 0.5617 - val_tp: 58.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 16.0000 - val_accuracy: 0.7542 - val_precision: 0.6744 - val_recall: 0.7838 - val_auc: 0.8792\n",
      "Epoch 191/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6205 - tp: 194.0000 - fp: 102.0000 - tn: 342.0000 - fn: 74.0000 - accuracy: 0.7528 - precision: 0.6554 - recall: 0.7239 - auc: 0.8103 - val_loss: 0.5682 - val_tp: 64.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 10.0000 - val_accuracy: 0.7709 - val_precision: 0.6737 - val_recall: 0.8649 - val_auc: 0.8745\n",
      "Epoch 192/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.5811 - tp: 201.0000 - fp: 89.0000 - tn: 355.0000 - fn: 67.0000 - accuracy: 0.7809 - precision: 0.6931 - recall: 0.7500 - auc: 0.8377 - val_loss: 0.5705 - val_tp: 58.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 16.0000 - val_accuracy: 0.7709 - val_precision: 0.6988 - val_recall: 0.7838 - val_auc: 0.8732\n",
      "Epoch 193/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6238 - tp: 198.0000 - fp: 92.0000 - tn: 352.0000 - fn: 70.0000 - accuracy: 0.7725 - precision: 0.6828 - recall: 0.7388 - auc: 0.8222 - val_loss: 0.5582 - val_tp: 55.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 19.0000 - val_accuracy: 0.7933 - val_precision: 0.7534 - val_recall: 0.7432 - val_auc: 0.8835\n",
      "Epoch 194/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6036 - tp: 200.0000 - fp: 88.0000 - tn: 356.0000 - fn: 68.0000 - accuracy: 0.7809 - precision: 0.6944 - recall: 0.7463 - auc: 0.8251 - val_loss: 0.5807 - val_tp: 53.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 21.0000 - val_accuracy: 0.8045 - val_precision: 0.7910 - val_recall: 0.7162 - val_auc: 0.8839\n",
      "Epoch 195/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5918 - tp: 210.0000 - fp: 92.0000 - tn: 352.0000 - fn: 58.0000 - accuracy: 0.7893 - precision: 0.6954 - recall: 0.7836 - auc: 0.8337 - val_loss: 0.6755 - val_tp: 33.0000 - val_fp: 3.0000 - val_tn: 102.0000 - val_fn: 41.0000 - val_accuracy: 0.7542 - val_precision: 0.9167 - val_recall: 0.4459 - val_auc: 0.8761\n",
      "Epoch 196/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6288 - tp: 193.0000 - fp: 85.0000 - tn: 359.0000 - fn: 75.0000 - accuracy: 0.7753 - precision: 0.6942 - recall: 0.7201 - auc: 0.8008 - val_loss: 0.6279 - val_tp: 48.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 26.0000 - val_accuracy: 0.7989 - val_precision: 0.8276 - val_recall: 0.6486 - val_auc: 0.8858\n",
      "Epoch 197/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5959 - tp: 197.0000 - fp: 82.0000 - tn: 362.0000 - fn: 71.0000 - accuracy: 0.7851 - precision: 0.7061 - recall: 0.7351 - auc: 0.8316 - val_loss: 0.5679 - val_tp: 63.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 11.0000 - val_accuracy: 0.7486 - val_precision: 0.6495 - val_recall: 0.8514 - val_auc: 0.8712\n",
      "Epoch 198/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5864 - tp: 196.0000 - fp: 90.0000 - tn: 354.0000 - fn: 72.0000 - accuracy: 0.7725 - precision: 0.6853 - recall: 0.7313 - auc: 0.8338 - val_loss: 0.5483 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8774\n",
      "Epoch 199/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5994 - tp: 202.0000 - fp: 96.0000 - tn: 348.0000 - fn: 66.0000 - accuracy: 0.7725 - precision: 0.6779 - recall: 0.7537 - auc: 0.8297 - val_loss: 0.5895 - val_tp: 57.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 17.0000 - val_accuracy: 0.7709 - val_precision: 0.7037 - val_recall: 0.7703 - val_auc: 0.8667\n",
      "Epoch 200/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6033 - tp: 201.0000 - fp: 86.0000 - tn: 358.0000 - fn: 67.0000 - accuracy: 0.7851 - precision: 0.7003 - recall: 0.7500 - auc: 0.8283 - val_loss: 0.6515 - val_tp: 41.0000 - val_fp: 5.0000 - val_tn: 100.0000 - val_fn: 33.0000 - val_accuracy: 0.7877 - val_precision: 0.8913 - val_recall: 0.5541 - val_auc: 0.8827\n",
      "Epoch 201/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6069 - tp: 190.0000 - fp: 84.0000 - tn: 360.0000 - fn: 78.0000 - accuracy: 0.7725 - precision: 0.6934 - recall: 0.7090 - auc: 0.8210 - val_loss: 0.5618 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8813\n",
      "Epoch 202/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6051 - tp: 196.0000 - fp: 93.0000 - tn: 351.0000 - fn: 72.0000 - accuracy: 0.7683 - precision: 0.6782 - recall: 0.7313 - auc: 0.8166 - val_loss: 0.5550 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8723\n",
      "Epoch 203/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6045 - tp: 198.0000 - fp: 91.0000 - tn: 353.0000 - fn: 70.0000 - accuracy: 0.7739 - precision: 0.6851 - recall: 0.7388 - auc: 0.8214 - val_loss: 0.5620 - val_tp: 58.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 16.0000 - val_accuracy: 0.7765 - val_precision: 0.7073 - val_recall: 0.7838 - val_auc: 0.8798\n",
      "Epoch 204/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6054 - tp: 199.0000 - fp: 91.0000 - tn: 353.0000 - fn: 69.0000 - accuracy: 0.7753 - precision: 0.6862 - recall: 0.7425 - auc: 0.8176 - val_loss: 0.8189 - val_tp: 74.0000 - val_fp: 99.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4469 - val_precision: 0.4277 - val_recall: 1.0000 - val_auc: 0.8544\n",
      "Epoch 205/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6192 - tp: 194.0000 - fp: 90.0000 - tn: 354.0000 - fn: 74.0000 - accuracy: 0.7697 - precision: 0.6831 - recall: 0.7239 - auc: 0.8237 - val_loss: 0.7615 - val_tp: 74.0000 - val_fp: 102.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4302 - val_precision: 0.4205 - val_recall: 1.0000 - val_auc: 0.8637\n",
      "Epoch 206/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6035 - tp: 214.0000 - fp: 100.0000 - tn: 344.0000 - fn: 54.0000 - accuracy: 0.7837 - precision: 0.6815 - recall: 0.7985 - auc: 0.8219 - val_loss: 0.5759 - val_tp: 53.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 21.0000 - val_accuracy: 0.8045 - val_precision: 0.7910 - val_recall: 0.7162 - val_auc: 0.8834\n",
      "Epoch 207/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6119 - tp: 199.0000 - fp: 91.0000 - tn: 353.0000 - fn: 69.0000 - accuracy: 0.7753 - precision: 0.6862 - recall: 0.7425 - auc: 0.8202 - val_loss: 0.5539 - val_tp: 60.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 14.0000 - val_accuracy: 0.7654 - val_precision: 0.6818 - val_recall: 0.8108 - val_auc: 0.8697\n",
      "Epoch 208/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5975 - tp: 200.0000 - fp: 89.0000 - tn: 355.0000 - fn: 68.0000 - accuracy: 0.7795 - precision: 0.6920 - recall: 0.7463 - auc: 0.8239 - val_loss: 0.6801 - val_tp: 40.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 34.0000 - val_accuracy: 0.7765 - val_precision: 0.8696 - val_recall: 0.5405 - val_auc: 0.8827\n",
      "Epoch 209/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6022 - tp: 193.0000 - fp: 85.0000 - tn: 359.0000 - fn: 75.0000 - accuracy: 0.7753 - precision: 0.6942 - recall: 0.7201 - auc: 0.8241 - val_loss: 0.5535 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8734\n",
      "Epoch 210/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6160 - tp: 200.0000 - fp: 92.0000 - tn: 352.0000 - fn: 68.0000 - accuracy: 0.7753 - precision: 0.6849 - recall: 0.7463 - auc: 0.8125 - val_loss: 0.5749 - val_tp: 64.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 10.0000 - val_accuracy: 0.7542 - val_precision: 0.6531 - val_recall: 0.8649 - val_auc: 0.8800\n",
      "Epoch 211/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6007 - tp: 200.0000 - fp: 85.0000 - tn: 359.0000 - fn: 68.0000 - accuracy: 0.7851 - precision: 0.7018 - recall: 0.7463 - auc: 0.8257 - val_loss: 0.6149 - val_tp: 64.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 10.0000 - val_accuracy: 0.7374 - val_precision: 0.6337 - val_recall: 0.8649 - val_auc: 0.8712\n",
      "Epoch 212/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5874 - tp: 200.0000 - fp: 89.0000 - tn: 355.0000 - fn: 68.0000 - accuracy: 0.7795 - precision: 0.6920 - recall: 0.7463 - auc: 0.8361 - val_loss: 0.5531 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8808\n",
      "Epoch 213/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6055 - tp: 203.0000 - fp: 90.0000 - tn: 354.0000 - fn: 65.0000 - accuracy: 0.7823 - precision: 0.6928 - recall: 0.7575 - auc: 0.8285 - val_loss: 0.9104 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8505\n",
      "Epoch 214/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6317 - tp: 203.0000 - fp: 107.0000 - tn: 337.0000 - fn: 65.0000 - accuracy: 0.7584 - precision: 0.6548 - recall: 0.7575 - auc: 0.8113 - val_loss: 0.6030 - val_tp: 49.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 25.0000 - val_accuracy: 0.7821 - val_precision: 0.7778 - val_recall: 0.6622 - val_auc: 0.8816\n",
      "Epoch 215/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6066 - tp: 198.0000 - fp: 87.0000 - tn: 357.0000 - fn: 70.0000 - accuracy: 0.7795 - precision: 0.6947 - recall: 0.7388 - auc: 0.8153 - val_loss: 0.5742 - val_tp: 58.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 16.0000 - val_accuracy: 0.7765 - val_precision: 0.7073 - val_recall: 0.7838 - val_auc: 0.8774\n",
      "Epoch 216/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6265 - tp: 197.0000 - fp: 96.0000 - tn: 348.0000 - fn: 71.0000 - accuracy: 0.7654 - precision: 0.6724 - recall: 0.7351 - auc: 0.8064 - val_loss: 0.6996 - val_tp: 38.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 36.0000 - val_accuracy: 0.7598 - val_precision: 0.8444 - val_recall: 0.5135 - val_auc: 0.8806\n",
      "Epoch 217/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5915 - tp: 200.0000 - fp: 86.0000 - tn: 358.0000 - fn: 68.0000 - accuracy: 0.7837 - precision: 0.6993 - recall: 0.7463 - auc: 0.8306 - val_loss: 0.5708 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8787\n",
      "Epoch 218/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6079 - tp: 197.0000 - fp: 97.0000 - tn: 347.0000 - fn: 71.0000 - accuracy: 0.7640 - precision: 0.6701 - recall: 0.7351 - auc: 0.8170 - val_loss: 0.5568 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8768\n",
      "Epoch 219/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6080 - tp: 204.0000 - fp: 99.0000 - tn: 345.0000 - fn: 64.0000 - accuracy: 0.7711 - precision: 0.6733 - recall: 0.7612 - auc: 0.8206 - val_loss: 0.5936 - val_tp: 51.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 23.0000 - val_accuracy: 0.7933 - val_precision: 0.7846 - val_recall: 0.6892 - val_auc: 0.8766\n",
      "Epoch 220/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6051 - tp: 193.0000 - fp: 93.0000 - tn: 351.0000 - fn: 75.0000 - accuracy: 0.7640 - precision: 0.6748 - recall: 0.7201 - auc: 0.8201 - val_loss: 0.5603 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8753\n",
      "Epoch 221/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5961 - tp: 203.0000 - fp: 90.0000 - tn: 354.0000 - fn: 65.0000 - accuracy: 0.7823 - precision: 0.6928 - recall: 0.7575 - auc: 0.8260 - val_loss: 0.5803 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8665\n",
      "Epoch 222/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6051 - tp: 205.0000 - fp: 95.0000 - tn: 349.0000 - fn: 63.0000 - accuracy: 0.7781 - precision: 0.6833 - recall: 0.7649 - auc: 0.8188 - val_loss: 1.0540 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 61.0000 - val_accuracy: 0.6592 - val_precision: 1.0000 - val_recall: 0.1757 - val_auc: 0.8805\n",
      "Epoch 223/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6030 - tp: 196.0000 - fp: 87.0000 - tn: 357.0000 - fn: 72.0000 - accuracy: 0.7767 - precision: 0.6926 - recall: 0.7313 - auc: 0.8239 - val_loss: 0.5483 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8791\n",
      "Epoch 224/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6162 - tp: 200.0000 - fp: 103.0000 - tn: 341.0000 - fn: 68.0000 - accuracy: 0.7598 - precision: 0.6601 - recall: 0.7463 - auc: 0.8078 - val_loss: 0.8361 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8526\n",
      "Epoch 225/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5939 - tp: 208.0000 - fp: 94.0000 - tn: 350.0000 - fn: 60.0000 - accuracy: 0.7837 - precision: 0.6887 - recall: 0.7761 - auc: 0.8293 - val_loss: 0.5468 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8785\n",
      "Epoch 226/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5945 - tp: 209.0000 - fp: 94.0000 - tn: 350.0000 - fn: 59.0000 - accuracy: 0.7851 - precision: 0.6898 - recall: 0.7799 - auc: 0.8360 - val_loss: 0.5476 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8719\n",
      "Epoch 227/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5868 - tp: 205.0000 - fp: 85.0000 - tn: 359.0000 - fn: 63.0000 - accuracy: 0.7921 - precision: 0.7069 - recall: 0.7649 - auc: 0.8386 - val_loss: 0.5571 - val_tp: 64.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 10.0000 - val_accuracy: 0.7542 - val_precision: 0.6531 - val_recall: 0.8649 - val_auc: 0.8665\n",
      "Epoch 228/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6168 - tp: 205.0000 - fp: 97.0000 - tn: 347.0000 - fn: 63.0000 - accuracy: 0.7753 - precision: 0.6788 - recall: 0.7649 - auc: 0.8154 - val_loss: 0.5855 - val_tp: 50.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 24.0000 - val_accuracy: 0.7877 - val_precision: 0.7812 - val_recall: 0.6757 - val_auc: 0.8790\n",
      "Epoch 229/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5832 - tp: 198.0000 - fp: 86.0000 - tn: 358.0000 - fn: 70.0000 - accuracy: 0.7809 - precision: 0.6972 - recall: 0.7388 - auc: 0.8385 - val_loss: 0.6067 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8648\n",
      "Epoch 230/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6070 - tp: 202.0000 - fp: 95.0000 - tn: 349.0000 - fn: 66.0000 - accuracy: 0.7739 - precision: 0.6801 - recall: 0.7537 - auc: 0.8218 - val_loss: 0.6803 - val_tp: 34.0000 - val_fp: 4.0000 - val_tn: 101.0000 - val_fn: 40.0000 - val_accuracy: 0.7542 - val_precision: 0.8947 - val_recall: 0.4595 - val_auc: 0.8849\n",
      "Epoch 231/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6069 - tp: 199.0000 - fp: 92.0000 - tn: 352.0000 - fn: 69.0000 - accuracy: 0.7739 - precision: 0.6838 - recall: 0.7425 - auc: 0.8258 - val_loss: 0.5929 - val_tp: 66.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 8.0000 - val_accuracy: 0.7486 - val_precision: 0.6408 - val_recall: 0.8919 - val_auc: 0.8683\n",
      "Epoch 232/500\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6002 - tp: 206.0000 - fp: 103.0000 - tn: 341.0000 - fn: 62.0000 - accuracy: 0.7683 - precision: 0.6667 - recall: 0.7687 - auc: 0.8254 - val_loss: 0.8250 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 57.0000 - val_accuracy: 0.6816 - val_precision: 1.0000 - val_recall: 0.2297 - val_auc: 0.8873\n",
      "Epoch 233/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6095 - tp: 199.0000 - fp: 91.0000 - tn: 353.0000 - fn: 69.0000 - accuracy: 0.7753 - precision: 0.6862 - recall: 0.7425 - auc: 0.8174 - val_loss: 0.5551 - val_tp: 53.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 21.0000 - val_accuracy: 0.7933 - val_precision: 0.7681 - val_recall: 0.7162 - val_auc: 0.8784\n",
      "Epoch 234/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5991 - tp: 205.0000 - fp: 94.0000 - tn: 350.0000 - fn: 63.0000 - accuracy: 0.7795 - precision: 0.6856 - recall: 0.7649 - auc: 0.8267 - val_loss: 0.6592 - val_tp: 42.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 32.0000 - val_accuracy: 0.7765 - val_precision: 0.8400 - val_recall: 0.5676 - val_auc: 0.8845\n",
      "Epoch 235/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6012 - tp: 199.0000 - fp: 92.0000 - tn: 352.0000 - fn: 69.0000 - accuracy: 0.7739 - precision: 0.6838 - recall: 0.7425 - auc: 0.8233 - val_loss: 0.5745 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8725\n",
      "Epoch 236/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5982 - tp: 201.0000 - fp: 94.0000 - tn: 350.0000 - fn: 67.0000 - accuracy: 0.7739 - precision: 0.6814 - recall: 0.7500 - auc: 0.8215 - val_loss: 0.5652 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8787\n",
      "Epoch 237/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6018 - tp: 200.0000 - fp: 90.0000 - tn: 354.0000 - fn: 68.0000 - accuracy: 0.7781 - precision: 0.6897 - recall: 0.7463 - auc: 0.8278 - val_loss: 0.6856 - val_tp: 44.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 30.0000 - val_accuracy: 0.7765 - val_precision: 0.8148 - val_recall: 0.5946 - val_auc: 0.8862\n",
      "Epoch 238/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6040 - tp: 204.0000 - fp: 89.0000 - tn: 355.0000 - fn: 64.0000 - accuracy: 0.7851 - precision: 0.6962 - recall: 0.7612 - auc: 0.8250 - val_loss: 0.6772 - val_tp: 72.0000 - val_fp: 56.0000 - val_tn: 49.0000 - val_fn: 2.0000 - val_accuracy: 0.6760 - val_precision: 0.5625 - val_recall: 0.9730 - val_auc: 0.8606\n",
      "Epoch 239/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5943 - tp: 203.0000 - fp: 90.0000 - tn: 354.0000 - fn: 65.0000 - accuracy: 0.7823 - precision: 0.6928 - recall: 0.7575 - auc: 0.8292 - val_loss: 0.7072 - val_tp: 33.0000 - val_fp: 2.0000 - val_tn: 103.0000 - val_fn: 41.0000 - val_accuracy: 0.7598 - val_precision: 0.9429 - val_recall: 0.4459 - val_auc: 0.8764\n",
      "Epoch 240/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6221 - tp: 189.0000 - fp: 88.0000 - tn: 356.0000 - fn: 79.0000 - accuracy: 0.7654 - precision: 0.6823 - recall: 0.7052 - auc: 0.8071 - val_loss: 0.6709 - val_tp: 38.0000 - val_fp: 5.0000 - val_tn: 100.0000 - val_fn: 36.0000 - val_accuracy: 0.7709 - val_precision: 0.8837 - val_recall: 0.5135 - val_auc: 0.8855\n",
      "Epoch 241/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6314 - tp: 183.0000 - fp: 89.0000 - tn: 355.0000 - fn: 85.0000 - accuracy: 0.7556 - precision: 0.6728 - recall: 0.6828 - auc: 0.7978 - val_loss: 0.5531 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8835\n",
      "Epoch 242/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6164 - tp: 201.0000 - fp: 95.0000 - tn: 349.0000 - fn: 67.0000 - accuracy: 0.7725 - precision: 0.6791 - recall: 0.7500 - auc: 0.8130 - val_loss: 0.5779 - val_tp: 64.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 10.0000 - val_accuracy: 0.7654 - val_precision: 0.6667 - val_recall: 0.8649 - val_auc: 0.8719\n",
      "Epoch 243/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5955 - tp: 196.0000 - fp: 79.0000 - tn: 365.0000 - fn: 72.0000 - accuracy: 0.7879 - precision: 0.7127 - recall: 0.7313 - auc: 0.8317 - val_loss: 0.6757 - val_tp: 70.0000 - val_fp: 47.0000 - val_tn: 58.0000 - val_fn: 4.0000 - val_accuracy: 0.7151 - val_precision: 0.5983 - val_recall: 0.9459 - val_auc: 0.8542\n",
      "Epoch 244/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6033 - tp: 206.0000 - fp: 99.0000 - tn: 345.0000 - fn: 62.0000 - accuracy: 0.7739 - precision: 0.6754 - recall: 0.7687 - auc: 0.8192 - val_loss: 0.6370 - val_tp: 70.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 4.0000 - val_accuracy: 0.7709 - val_precision: 0.6542 - val_recall: 0.9459 - val_auc: 0.8647\n",
      "Epoch 245/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5988 - tp: 203.0000 - fp: 95.0000 - tn: 349.0000 - fn: 65.0000 - accuracy: 0.7753 - precision: 0.6812 - recall: 0.7575 - auc: 0.8308 - val_loss: 0.5519 - val_tp: 64.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 10.0000 - val_accuracy: 0.7598 - val_precision: 0.6598 - val_recall: 0.8649 - val_auc: 0.8680\n",
      "Epoch 246/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6038 - tp: 202.0000 - fp: 94.0000 - tn: 350.0000 - fn: 66.0000 - accuracy: 0.7753 - precision: 0.6824 - recall: 0.7537 - auc: 0.8188 - val_loss: 0.5618 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8747\n",
      "Epoch 247/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5948 - tp: 202.0000 - fp: 90.0000 - tn: 354.0000 - fn: 66.0000 - accuracy: 0.7809 - precision: 0.6918 - recall: 0.7537 - auc: 0.8291 - val_loss: 0.5753 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8743\n",
      "Epoch 248/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5948 - tp: 207.0000 - fp: 110.0000 - tn: 334.0000 - fn: 61.0000 - accuracy: 0.7598 - precision: 0.6530 - recall: 0.7724 - auc: 0.8281 - val_loss: 0.6382 - val_tp: 44.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 30.0000 - val_accuracy: 0.7989 - val_precision: 0.8800 - val_recall: 0.5946 - val_auc: 0.8860\n",
      "Epoch 249/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6182 - tp: 200.0000 - fp: 94.0000 - tn: 350.0000 - fn: 68.0000 - accuracy: 0.7725 - precision: 0.6803 - recall: 0.7463 - auc: 0.8056 - val_loss: 0.5817 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8681\n",
      "Epoch 250/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6169 - tp: 202.0000 - fp: 97.0000 - tn: 347.0000 - fn: 66.0000 - accuracy: 0.7711 - precision: 0.6756 - recall: 0.7537 - auc: 0.8082 - val_loss: 0.5467 - val_tp: 63.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 11.0000 - val_accuracy: 0.7542 - val_precision: 0.6562 - val_recall: 0.8514 - val_auc: 0.8699\n",
      "Epoch 251/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5885 - tp: 207.0000 - fp: 91.0000 - tn: 353.0000 - fn: 61.0000 - accuracy: 0.7865 - precision: 0.6946 - recall: 0.7724 - auc: 0.8324 - val_loss: 0.6075 - val_tp: 50.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 24.0000 - val_accuracy: 0.7933 - val_precision: 0.7937 - val_recall: 0.6757 - val_auc: 0.8748\n",
      "Epoch 252/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6077 - tp: 197.0000 - fp: 93.0000 - tn: 351.0000 - fn: 71.0000 - accuracy: 0.7697 - precision: 0.6793 - recall: 0.7351 - auc: 0.8174 - val_loss: 0.5731 - val_tp: 65.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 9.0000 - val_accuracy: 0.7542 - val_precision: 0.6500 - val_recall: 0.8784 - val_auc: 0.8713\n",
      "Epoch 253/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6155 - tp: 202.0000 - fp: 104.0000 - tn: 340.0000 - fn: 66.0000 - accuracy: 0.7612 - precision: 0.6601 - recall: 0.7537 - auc: 0.8142 - val_loss: 0.5896 - val_tp: 52.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 22.0000 - val_accuracy: 0.7933 - val_precision: 0.7761 - val_recall: 0.7027 - val_auc: 0.8788\n",
      "Epoch 254/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5949 - tp: 198.0000 - fp: 97.0000 - tn: 347.0000 - fn: 70.0000 - accuracy: 0.7654 - precision: 0.6712 - recall: 0.7388 - auc: 0.8265 - val_loss: 0.5622 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8781\n",
      "Epoch 255/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5992 - tp: 203.0000 - fp: 90.0000 - tn: 354.0000 - fn: 65.0000 - accuracy: 0.7823 - precision: 0.6928 - recall: 0.7575 - auc: 0.8269 - val_loss: 0.5532 - val_tp: 58.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 16.0000 - val_accuracy: 0.7654 - val_precision: 0.6905 - val_recall: 0.7838 - val_auc: 0.8736\n",
      "Epoch 256/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6126 - tp: 204.0000 - fp: 82.0000 - tn: 362.0000 - fn: 64.0000 - accuracy: 0.7949 - precision: 0.7133 - recall: 0.7612 - auc: 0.8202 - val_loss: 0.7021 - val_tp: 74.0000 - val_fp: 87.0000 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5140 - val_precision: 0.4596 - val_recall: 1.0000 - val_auc: 0.8634\n",
      "Epoch 257/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6125 - tp: 205.0000 - fp: 114.0000 - tn: 330.0000 - fn: 63.0000 - accuracy: 0.7514 - precision: 0.6426 - recall: 0.7649 - auc: 0.8166 - val_loss: 0.5501 - val_tp: 55.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 19.0000 - val_accuracy: 0.7654 - val_precision: 0.7051 - val_recall: 0.7432 - val_auc: 0.8757\n",
      "Epoch 258/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5750 - tp: 203.0000 - fp: 89.0000 - tn: 355.0000 - fn: 65.0000 - accuracy: 0.7837 - precision: 0.6952 - recall: 0.7575 - auc: 0.8387 - val_loss: 0.8144 - val_tp: 74.0000 - val_fp: 98.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4525 - val_precision: 0.4302 - val_recall: 1.0000 - val_auc: 0.8501\n",
      "Epoch 259/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6102 - tp: 209.0000 - fp: 109.0000 - tn: 335.0000 - fn: 59.0000 - accuracy: 0.7640 - precision: 0.6572 - recall: 0.7799 - auc: 0.8223 - val_loss: 0.6009 - val_tp: 52.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 22.0000 - val_accuracy: 0.7989 - val_precision: 0.7879 - val_recall: 0.7027 - val_auc: 0.8840\n",
      "Epoch 260/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6152 - tp: 200.0000 - fp: 87.0000 - tn: 357.0000 - fn: 68.0000 - accuracy: 0.7823 - precision: 0.6969 - recall: 0.7463 - auc: 0.8163 - val_loss: 0.6011 - val_tp: 50.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 24.0000 - val_accuracy: 0.7877 - val_precision: 0.7812 - val_recall: 0.6757 - val_auc: 0.8815\n",
      "Epoch 261/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5936 - tp: 195.0000 - fp: 86.0000 - tn: 358.0000 - fn: 73.0000 - accuracy: 0.7767 - precision: 0.6940 - recall: 0.7276 - auc: 0.8282 - val_loss: 0.7649 - val_tp: 74.0000 - val_fp: 96.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4637 - val_precision: 0.4353 - val_recall: 1.0000 - val_auc: 0.8654\n",
      "Epoch 262/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.6080 - tp: 198.0000 - fp: 100.0000 - tn: 344.0000 - fn: 70.0000 - accuracy: 0.7612 - precision: 0.6644 - recall: 0.7388 - auc: 0.8210 - val_loss: 0.6755 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8702\n",
      "Epoch 263/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6089 - tp: 207.0000 - fp: 92.0000 - tn: 352.0000 - fn: 61.0000 - accuracy: 0.7851 - precision: 0.6923 - recall: 0.7724 - auc: 0.8233 - val_loss: 0.5423 - val_tp: 59.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 15.0000 - val_accuracy: 0.7709 - val_precision: 0.6941 - val_recall: 0.7973 - val_auc: 0.8774\n",
      "Epoch 264/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5770 - tp: 203.0000 - fp: 95.0000 - tn: 349.0000 - fn: 65.0000 - accuracy: 0.7753 - precision: 0.6812 - recall: 0.7575 - auc: 0.8416 - val_loss: 0.5744 - val_tp: 61.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 13.0000 - val_accuracy: 0.7765 - val_precision: 0.6932 - val_recall: 0.8243 - val_auc: 0.8735\n",
      "Epoch 265/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6157 - tp: 201.0000 - fp: 88.0000 - tn: 356.0000 - fn: 67.0000 - accuracy: 0.7823 - precision: 0.6955 - recall: 0.7500 - auc: 0.8153 - val_loss: 0.6550 - val_tp: 40.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 34.0000 - val_accuracy: 0.7654 - val_precision: 0.8333 - val_recall: 0.5405 - val_auc: 0.8789\n",
      "Epoch 266/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5945 - tp: 200.0000 - fp: 85.0000 - tn: 359.0000 - fn: 68.0000 - accuracy: 0.7851 - precision: 0.7018 - recall: 0.7463 - auc: 0.8275 - val_loss: 0.6710 - val_tp: 48.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 26.0000 - val_accuracy: 0.8101 - val_precision: 0.8571 - val_recall: 0.6486 - val_auc: 0.8847\n",
      "Epoch 267/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5952 - tp: 199.0000 - fp: 83.0000 - tn: 361.0000 - fn: 69.0000 - accuracy: 0.7865 - precision: 0.7057 - recall: 0.7425 - auc: 0.8333 - val_loss: 0.5968 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8715\n",
      "Epoch 268/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6109 - tp: 205.0000 - fp: 105.0000 - tn: 339.0000 - fn: 63.0000 - accuracy: 0.7640 - precision: 0.6613 - recall: 0.7649 - auc: 0.8161 - val_loss: 0.5540 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8814\n",
      "Epoch 269/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6027 - tp: 200.0000 - fp: 95.0000 - tn: 349.0000 - fn: 68.0000 - accuracy: 0.7711 - precision: 0.6780 - recall: 0.7463 - auc: 0.8257 - val_loss: 0.6043 - val_tp: 70.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 4.0000 - val_accuracy: 0.7709 - val_precision: 0.6542 - val_recall: 0.9459 - val_auc: 0.8653\n",
      "Epoch 270/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5949 - tp: 202.0000 - fp: 99.0000 - tn: 345.0000 - fn: 66.0000 - accuracy: 0.7683 - precision: 0.6711 - recall: 0.7537 - auc: 0.8231 - val_loss: 0.5514 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8797\n",
      "Epoch 271/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6241 - tp: 197.0000 - fp: 105.0000 - tn: 339.0000 - fn: 71.0000 - accuracy: 0.7528 - precision: 0.6523 - recall: 0.7351 - auc: 0.8048 - val_loss: 0.5487 - val_tp: 52.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 22.0000 - val_accuracy: 0.7709 - val_precision: 0.7324 - val_recall: 0.7027 - val_auc: 0.8740\n",
      "Epoch 272/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5787 - tp: 200.0000 - fp: 84.0000 - tn: 360.0000 - fn: 68.0000 - accuracy: 0.7865 - precision: 0.7042 - recall: 0.7463 - auc: 0.8420 - val_loss: 0.5490 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8725\n",
      "Epoch 273/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6199 - tp: 205.0000 - fp: 101.0000 - tn: 343.0000 - fn: 63.0000 - accuracy: 0.7697 - precision: 0.6699 - recall: 0.7649 - auc: 0.8204 - val_loss: 0.5489 - val_tp: 64.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 10.0000 - val_accuracy: 0.7821 - val_precision: 0.6882 - val_recall: 0.8649 - val_auc: 0.8761\n",
      "Epoch 274/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5923 - tp: 204.0000 - fp: 94.0000 - tn: 350.0000 - fn: 64.0000 - accuracy: 0.7781 - precision: 0.6846 - recall: 0.7612 - auc: 0.8288 - val_loss: 0.5688 - val_tp: 54.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 20.0000 - val_accuracy: 0.7877 - val_precision: 0.7500 - val_recall: 0.7297 - val_auc: 0.8791\n",
      "Epoch 275/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6235 - tp: 203.0000 - fp: 95.0000 - tn: 349.0000 - fn: 65.0000 - accuracy: 0.7753 - precision: 0.6812 - recall: 0.7575 - auc: 0.8105 - val_loss: 0.5521 - val_tp: 59.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 15.0000 - val_accuracy: 0.7709 - val_precision: 0.6941 - val_recall: 0.7973 - val_auc: 0.8749\n",
      "Epoch 276/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6032 - tp: 200.0000 - fp: 94.0000 - tn: 350.0000 - fn: 68.0000 - accuracy: 0.7725 - precision: 0.6803 - recall: 0.7463 - auc: 0.8267 - val_loss: 0.5980 - val_tp: 65.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 9.0000 - val_accuracy: 0.7542 - val_precision: 0.6500 - val_recall: 0.8784 - val_auc: 0.8673\n",
      "Epoch 277/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5767 - tp: 200.0000 - fp: 93.0000 - tn: 351.0000 - fn: 68.0000 - accuracy: 0.7739 - precision: 0.6826 - recall: 0.7463 - auc: 0.8406 - val_loss: 0.5957 - val_tp: 52.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 22.0000 - val_accuracy: 0.7989 - val_precision: 0.7879 - val_recall: 0.7027 - val_auc: 0.8804\n",
      "Epoch 278/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5691 - tp: 206.0000 - fp: 83.0000 - tn: 361.0000 - fn: 62.0000 - accuracy: 0.7963 - precision: 0.7128 - recall: 0.7687 - auc: 0.8466 - val_loss: 0.6506 - val_tp: 48.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 26.0000 - val_accuracy: 0.7821 - val_precision: 0.7869 - val_recall: 0.6486 - val_auc: 0.8842\n",
      "Epoch 279/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5942 - tp: 195.0000 - fp: 90.0000 - tn: 354.0000 - fn: 73.0000 - accuracy: 0.7711 - precision: 0.6842 - recall: 0.7276 - auc: 0.8301 - val_loss: 0.5627 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8790\n",
      "Epoch 280/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5987 - tp: 203.0000 - fp: 93.0000 - tn: 351.0000 - fn: 65.0000 - accuracy: 0.7781 - precision: 0.6858 - recall: 0.7575 - auc: 0.8249 - val_loss: 0.6618 - val_tp: 70.0000 - val_fp: 40.0000 - val_tn: 65.0000 - val_fn: 4.0000 - val_accuracy: 0.7542 - val_precision: 0.6364 - val_recall: 0.9459 - val_auc: 0.8671\n",
      "Epoch 281/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5939 - tp: 204.0000 - fp: 97.0000 - tn: 347.0000 - fn: 64.0000 - accuracy: 0.7739 - precision: 0.6777 - recall: 0.7612 - auc: 0.8322 - val_loss: 0.5473 - val_tp: 60.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 14.0000 - val_accuracy: 0.7709 - val_precision: 0.6897 - val_recall: 0.8108 - val_auc: 0.8742\n",
      "Epoch 282/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5965 - tp: 196.0000 - fp: 90.0000 - tn: 354.0000 - fn: 72.0000 - accuracy: 0.7725 - precision: 0.6853 - recall: 0.7313 - auc: 0.8257 - val_loss: 0.5883 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8686\n",
      "Epoch 283/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5889 - tp: 211.0000 - fp: 110.0000 - tn: 334.0000 - fn: 57.0000 - accuracy: 0.7654 - precision: 0.6573 - recall: 0.7873 - auc: 0.8330 - val_loss: 0.6521 - val_tp: 36.0000 - val_fp: 5.0000 - val_tn: 100.0000 - val_fn: 38.0000 - val_accuracy: 0.7598 - val_precision: 0.8780 - val_recall: 0.4865 - val_auc: 0.8701\n",
      "Epoch 284/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5956 - tp: 195.0000 - fp: 89.0000 - tn: 355.0000 - fn: 73.0000 - accuracy: 0.7725 - precision: 0.6866 - recall: 0.7276 - auc: 0.8282 - val_loss: 0.6272 - val_tp: 45.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 29.0000 - val_accuracy: 0.8045 - val_precision: 0.8824 - val_recall: 0.6081 - val_auc: 0.8846\n",
      "Epoch 285/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6105 - tp: 198.0000 - fp: 90.0000 - tn: 354.0000 - fn: 70.0000 - accuracy: 0.7753 - precision: 0.6875 - recall: 0.7388 - auc: 0.8242 - val_loss: 0.6663 - val_tp: 70.0000 - val_fp: 41.0000 - val_tn: 64.0000 - val_fn: 4.0000 - val_accuracy: 0.7486 - val_precision: 0.6306 - val_recall: 0.9459 - val_auc: 0.8665\n",
      "Epoch 286/500\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.5958 - tp: 206.0000 - fp: 98.0000 - tn: 346.0000 - fn: 62.0000 - accuracy: 0.7753 - precision: 0.6776 - recall: 0.7687 - auc: 0.8337 - val_loss: 0.5658 - val_tp: 64.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 10.0000 - val_accuracy: 0.7598 - val_precision: 0.6598 - val_recall: 0.8649 - val_auc: 0.8725\n",
      "Epoch 287/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6021 - tp: 200.0000 - fp: 90.0000 - tn: 354.0000 - fn: 68.0000 - accuracy: 0.7781 - precision: 0.6897 - recall: 0.7463 - auc: 0.8250 - val_loss: 0.5581 - val_tp: 54.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 20.0000 - val_accuracy: 0.7877 - val_precision: 0.7500 - val_recall: 0.7297 - val_auc: 0.8739\n",
      "Epoch 288/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5968 - tp: 203.0000 - fp: 78.0000 - tn: 366.0000 - fn: 65.0000 - accuracy: 0.7992 - precision: 0.7224 - recall: 0.7575 - auc: 0.8284 - val_loss: 0.5600 - val_tp: 60.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 14.0000 - val_accuracy: 0.7654 - val_precision: 0.6818 - val_recall: 0.8108 - val_auc: 0.8737\n",
      "Epoch 289/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6058 - tp: 201.0000 - fp: 89.0000 - tn: 355.0000 - fn: 67.0000 - accuracy: 0.7809 - precision: 0.6931 - recall: 0.7500 - auc: 0.8198 - val_loss: 0.5825 - val_tp: 53.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 21.0000 - val_accuracy: 0.7933 - val_precision: 0.7681 - val_recall: 0.7162 - val_auc: 0.8829\n",
      "Epoch 290/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5840 - tp: 201.0000 - fp: 85.0000 - tn: 359.0000 - fn: 67.0000 - accuracy: 0.7865 - precision: 0.7028 - recall: 0.7500 - auc: 0.8432 - val_loss: 0.6779 - val_tp: 72.0000 - val_fp: 54.0000 - val_tn: 51.0000 - val_fn: 2.0000 - val_accuracy: 0.6872 - val_precision: 0.5714 - val_recall: 0.9730 - val_auc: 0.8666\n",
      "Epoch 291/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6068 - tp: 200.0000 - fp: 91.0000 - tn: 353.0000 - fn: 68.0000 - accuracy: 0.7767 - precision: 0.6873 - recall: 0.7463 - auc: 0.8126 - val_loss: 0.6863 - val_tp: 39.0000 - val_fp: 4.0000 - val_tn: 101.0000 - val_fn: 35.0000 - val_accuracy: 0.7821 - val_precision: 0.9070 - val_recall: 0.5270 - val_auc: 0.8868\n",
      "Epoch 292/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5930 - tp: 195.0000 - fp: 88.0000 - tn: 356.0000 - fn: 73.0000 - accuracy: 0.7739 - precision: 0.6890 - recall: 0.7276 - auc: 0.8358 - val_loss: 0.5616 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8799\n",
      "Epoch 293/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5961 - tp: 207.0000 - fp: 100.0000 - tn: 344.0000 - fn: 61.0000 - accuracy: 0.7739 - precision: 0.6743 - recall: 0.7724 - auc: 0.8268 - val_loss: 0.5507 - val_tp: 59.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 15.0000 - val_accuracy: 0.7765 - val_precision: 0.7024 - val_recall: 0.7973 - val_auc: 0.8696\n",
      "Epoch 294/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5978 - tp: 198.0000 - fp: 90.0000 - tn: 354.0000 - fn: 70.0000 - accuracy: 0.7753 - precision: 0.6875 - recall: 0.7388 - auc: 0.8248 - val_loss: 0.5545 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8744\n",
      "Epoch 295/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5974 - tp: 200.0000 - fp: 88.0000 - tn: 356.0000 - fn: 68.0000 - accuracy: 0.7809 - precision: 0.6944 - recall: 0.7463 - auc: 0.8324 - val_loss: 0.5827 - val_tp: 64.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 10.0000 - val_accuracy: 0.7374 - val_precision: 0.6337 - val_recall: 0.8649 - val_auc: 0.8632\n",
      "Epoch 296/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6028 - tp: 206.0000 - fp: 98.0000 - tn: 346.0000 - fn: 62.0000 - accuracy: 0.7753 - precision: 0.6776 - recall: 0.7687 - auc: 0.8262 - val_loss: 0.6833 - val_tp: 36.0000 - val_fp: 5.0000 - val_tn: 100.0000 - val_fn: 38.0000 - val_accuracy: 0.7598 - val_precision: 0.8780 - val_recall: 0.4865 - val_auc: 0.8826\n",
      "Epoch 297/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6010 - tp: 196.0000 - fp: 92.0000 - tn: 352.0000 - fn: 72.0000 - accuracy: 0.7697 - precision: 0.6806 - recall: 0.7313 - auc: 0.8215 - val_loss: 0.5457 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8721\n",
      "Epoch 298/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6098 - tp: 203.0000 - fp: 101.0000 - tn: 343.0000 - fn: 65.0000 - accuracy: 0.7669 - precision: 0.6678 - recall: 0.7575 - auc: 0.8177 - val_loss: 0.6222 - val_tp: 49.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 25.0000 - val_accuracy: 0.8101 - val_precision: 0.8448 - val_recall: 0.6622 - val_auc: 0.8863\n",
      "Epoch 299/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6161 - tp: 199.0000 - fp: 97.0000 - tn: 347.0000 - fn: 69.0000 - accuracy: 0.7669 - precision: 0.6723 - recall: 0.7425 - auc: 0.8137 - val_loss: 0.5535 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8712\n",
      "Epoch 300/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6075 - tp: 197.0000 - fp: 100.0000 - tn: 344.0000 - fn: 71.0000 - accuracy: 0.7598 - precision: 0.6633 - recall: 0.7351 - auc: 0.8163 - val_loss: 0.5752 - val_tp: 49.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 25.0000 - val_accuracy: 0.7709 - val_precision: 0.7538 - val_recall: 0.6622 - val_auc: 0.8752\n",
      "Epoch 301/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5999 - tp: 203.0000 - fp: 88.0000 - tn: 356.0000 - fn: 65.0000 - accuracy: 0.7851 - precision: 0.6976 - recall: 0.7575 - auc: 0.8252 - val_loss: 0.5762 - val_tp: 58.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 16.0000 - val_accuracy: 0.7598 - val_precision: 0.6824 - val_recall: 0.7838 - val_auc: 0.8754\n",
      "Epoch 302/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5995 - tp: 205.0000 - fp: 93.0000 - tn: 351.0000 - fn: 63.0000 - accuracy: 0.7809 - precision: 0.6879 - recall: 0.7649 - auc: 0.8334 - val_loss: 0.5972 - val_tp: 49.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 25.0000 - val_accuracy: 0.7877 - val_precision: 0.7903 - val_recall: 0.6622 - val_auc: 0.8836\n",
      "Epoch 303/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5861 - tp: 205.0000 - fp: 89.0000 - tn: 355.0000 - fn: 63.0000 - accuracy: 0.7865 - precision: 0.6973 - recall: 0.7649 - auc: 0.8343 - val_loss: 0.5516 - val_tp: 58.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 16.0000 - val_accuracy: 0.7654 - val_precision: 0.6905 - val_recall: 0.7838 - val_auc: 0.8720\n",
      "Epoch 304/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6112 - tp: 201.0000 - fp: 92.0000 - tn: 352.0000 - fn: 67.0000 - accuracy: 0.7767 - precision: 0.6860 - recall: 0.7500 - auc: 0.8152 - val_loss: 0.7445 - val_tp: 25.0000 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 49.0000 - val_accuracy: 0.7263 - val_precision: 1.0000 - val_recall: 0.3378 - val_auc: 0.8851\n",
      "Epoch 305/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5822 - tp: 196.0000 - fp: 94.0000 - tn: 350.0000 - fn: 72.0000 - accuracy: 0.7669 - precision: 0.6759 - recall: 0.7313 - auc: 0.8367 - val_loss: 0.5846 - val_tp: 51.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 23.0000 - val_accuracy: 0.7877 - val_precision: 0.7727 - val_recall: 0.6892 - val_auc: 0.8734\n",
      "Epoch 306/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6116 - tp: 203.0000 - fp: 96.0000 - tn: 348.0000 - fn: 65.0000 - accuracy: 0.7739 - precision: 0.6789 - recall: 0.7575 - auc: 0.8163 - val_loss: 0.6662 - val_tp: 70.0000 - val_fp: 41.0000 - val_tn: 64.0000 - val_fn: 4.0000 - val_accuracy: 0.7486 - val_precision: 0.6306 - val_recall: 0.9459 - val_auc: 0.8566\n",
      "Epoch 307/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6224 - tp: 202.0000 - fp: 97.0000 - tn: 347.0000 - fn: 66.0000 - accuracy: 0.7711 - precision: 0.6756 - recall: 0.7537 - auc: 0.8096 - val_loss: 0.6128 - val_tp: 69.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 5.0000 - val_accuracy: 0.7765 - val_precision: 0.6635 - val_recall: 0.9324 - val_auc: 0.8668\n",
      "Epoch 308/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6101 - tp: 203.0000 - fp: 95.0000 - tn: 349.0000 - fn: 65.0000 - accuracy: 0.7753 - precision: 0.6812 - recall: 0.7575 - auc: 0.8192 - val_loss: 0.5455 - val_tp: 56.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 18.0000 - val_accuracy: 0.7654 - val_precision: 0.7000 - val_recall: 0.7568 - val_auc: 0.8695\n",
      "Epoch 309/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6215 - tp: 195.0000 - fp: 94.0000 - tn: 350.0000 - fn: 73.0000 - accuracy: 0.7654 - precision: 0.6747 - recall: 0.7276 - auc: 0.8102 - val_loss: 0.5906 - val_tp: 49.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 25.0000 - val_accuracy: 0.7598 - val_precision: 0.7313 - val_recall: 0.6622 - val_auc: 0.8718\n",
      "Epoch 310/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6094 - tp: 202.0000 - fp: 88.0000 - tn: 356.0000 - fn: 66.0000 - accuracy: 0.7837 - precision: 0.6966 - recall: 0.7537 - auc: 0.8149 - val_loss: 0.6242 - val_tp: 70.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 4.0000 - val_accuracy: 0.7709 - val_precision: 0.6542 - val_recall: 0.9459 - val_auc: 0.8616\n",
      "Epoch 311/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6120 - tp: 203.0000 - fp: 96.0000 - tn: 348.0000 - fn: 65.0000 - accuracy: 0.7739 - precision: 0.6789 - recall: 0.7575 - auc: 0.8196 - val_loss: 0.5653 - val_tp: 54.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 20.0000 - val_accuracy: 0.7654 - val_precision: 0.7105 - val_recall: 0.7297 - val_auc: 0.8793\n",
      "Epoch 312/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5961 - tp: 204.0000 - fp: 92.0000 - tn: 352.0000 - fn: 64.0000 - accuracy: 0.7809 - precision: 0.6892 - recall: 0.7612 - auc: 0.8252 - val_loss: 0.5728 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8760\n",
      "Epoch 313/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6152 - tp: 199.0000 - fp: 94.0000 - tn: 350.0000 - fn: 69.0000 - accuracy: 0.7711 - precision: 0.6792 - recall: 0.7425 - auc: 0.8146 - val_loss: 0.5926 - val_tp: 51.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 23.0000 - val_accuracy: 0.7933 - val_precision: 0.7846 - val_recall: 0.6892 - val_auc: 0.8775\n",
      "Epoch 314/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6054 - tp: 197.0000 - fp: 94.0000 - tn: 350.0000 - fn: 71.0000 - accuracy: 0.7683 - precision: 0.6770 - recall: 0.7351 - auc: 0.8207 - val_loss: 0.5627 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8784\n",
      "Epoch 315/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5990 - tp: 201.0000 - fp: 93.0000 - tn: 351.0000 - fn: 67.0000 - accuracy: 0.7753 - precision: 0.6837 - recall: 0.7500 - auc: 0.8268 - val_loss: 0.5457 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8778\n",
      "Epoch 316/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6170 - tp: 201.0000 - fp: 95.0000 - tn: 349.0000 - fn: 67.0000 - accuracy: 0.7725 - precision: 0.6791 - recall: 0.7500 - auc: 0.8161 - val_loss: 0.5753 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8692\n",
      "Epoch 317/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6023 - tp: 199.0000 - fp: 92.0000 - tn: 352.0000 - fn: 69.0000 - accuracy: 0.7739 - precision: 0.6838 - recall: 0.7425 - auc: 0.8222 - val_loss: 0.5589 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8792\n",
      "Epoch 318/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6022 - tp: 203.0000 - fp: 98.0000 - tn: 346.0000 - fn: 65.0000 - accuracy: 0.7711 - precision: 0.6744 - recall: 0.7575 - auc: 0.8243 - val_loss: 0.7078 - val_tp: 28.0000 - val_fp: 2.0000 - val_tn: 103.0000 - val_fn: 46.0000 - val_accuracy: 0.7318 - val_precision: 0.9333 - val_recall: 0.3784 - val_auc: 0.8785\n",
      "Epoch 319/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5977 - tp: 191.0000 - fp: 82.0000 - tn: 362.0000 - fn: 77.0000 - accuracy: 0.7767 - precision: 0.6996 - recall: 0.7127 - auc: 0.8222 - val_loss: 0.5521 - val_tp: 53.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 21.0000 - val_accuracy: 0.7709 - val_precision: 0.7260 - val_recall: 0.7162 - val_auc: 0.8698\n",
      "Epoch 320/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5897 - tp: 203.0000 - fp: 87.0000 - tn: 357.0000 - fn: 65.0000 - accuracy: 0.7865 - precision: 0.7000 - recall: 0.7575 - auc: 0.8380 - val_loss: 0.6318 - val_tp: 48.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 26.0000 - val_accuracy: 0.7877 - val_precision: 0.8000 - val_recall: 0.6486 - val_auc: 0.8830\n",
      "Epoch 321/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.6125 - tp: 195.0000 - fp: 102.0000 - tn: 342.0000 - fn: 73.0000 - accuracy: 0.7542 - precision: 0.6566 - recall: 0.7276 - auc: 0.8131 - val_loss: 0.5605 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8815\n",
      "Epoch 322/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5916 - tp: 205.0000 - fp: 92.0000 - tn: 352.0000 - fn: 63.0000 - accuracy: 0.7823 - precision: 0.6902 - recall: 0.7649 - auc: 0.8325 - val_loss: 0.5587 - val_tp: 56.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 18.0000 - val_accuracy: 0.7877 - val_precision: 0.7368 - val_recall: 0.7568 - val_auc: 0.8788\n",
      "Epoch 323/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6161 - tp: 196.0000 - fp: 110.0000 - tn: 334.0000 - fn: 72.0000 - accuracy: 0.7444 - precision: 0.6405 - recall: 0.7313 - auc: 0.8126 - val_loss: 0.5490 - val_tp: 62.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 12.0000 - val_accuracy: 0.7598 - val_precision: 0.6667 - val_recall: 0.8378 - val_auc: 0.8761\n",
      "Epoch 324/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6067 - tp: 196.0000 - fp: 92.0000 - tn: 352.0000 - fn: 72.0000 - accuracy: 0.7697 - precision: 0.6806 - recall: 0.7313 - auc: 0.8181 - val_loss: 0.5730 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8805\n",
      "Epoch 325/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5738 - tp: 206.0000 - fp: 81.0000 - tn: 363.0000 - fn: 62.0000 - accuracy: 0.7992 - precision: 0.7178 - recall: 0.7687 - auc: 0.8466 - val_loss: 0.6359 - val_tp: 43.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 31.0000 - val_accuracy: 0.7654 - val_precision: 0.7963 - val_recall: 0.5811 - val_auc: 0.8804\n",
      "Epoch 326/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6202 - tp: 194.0000 - fp: 86.0000 - tn: 358.0000 - fn: 74.0000 - accuracy: 0.7753 - precision: 0.6929 - recall: 0.7239 - auc: 0.8185 - val_loss: 0.6084 - val_tp: 49.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 25.0000 - val_accuracy: 0.7933 - val_precision: 0.8033 - val_recall: 0.6622 - val_auc: 0.8819\n",
      "Epoch 327/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6054 - tp: 195.0000 - fp: 86.0000 - tn: 358.0000 - fn: 73.0000 - accuracy: 0.7767 - precision: 0.6940 - recall: 0.7276 - auc: 0.8203 - val_loss: 0.6101 - val_tp: 48.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 26.0000 - val_accuracy: 0.7877 - val_precision: 0.8000 - val_recall: 0.6486 - val_auc: 0.8832\n",
      "Epoch 328/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5964 - tp: 204.0000 - fp: 87.0000 - tn: 357.0000 - fn: 64.0000 - accuracy: 0.7879 - precision: 0.7010 - recall: 0.7612 - auc: 0.8259 - val_loss: 0.5550 - val_tp: 58.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 16.0000 - val_accuracy: 0.7709 - val_precision: 0.6988 - val_recall: 0.7838 - val_auc: 0.8790\n",
      "Epoch 329/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6027 - tp: 195.0000 - fp: 88.0000 - tn: 356.0000 - fn: 73.0000 - accuracy: 0.7739 - precision: 0.6890 - recall: 0.7276 - auc: 0.8285 - val_loss: 0.6419 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8692\n",
      "Epoch 330/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6156 - tp: 209.0000 - fp: 106.0000 - tn: 338.0000 - fn: 59.0000 - accuracy: 0.7683 - precision: 0.6635 - recall: 0.7799 - auc: 0.8112 - val_loss: 0.5990 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8717\n",
      "Epoch 331/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6009 - tp: 194.0000 - fp: 86.0000 - tn: 358.0000 - fn: 74.0000 - accuracy: 0.7753 - precision: 0.6929 - recall: 0.7239 - auc: 0.8220 - val_loss: 0.5486 - val_tp: 55.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 19.0000 - val_accuracy: 0.7598 - val_precision: 0.6962 - val_recall: 0.7432 - val_auc: 0.8746\n",
      "Epoch 332/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5850 - tp: 209.0000 - fp: 90.0000 - tn: 354.0000 - fn: 59.0000 - accuracy: 0.7907 - precision: 0.6990 - recall: 0.7799 - auc: 0.8375 - val_loss: 0.5683 - val_tp: 55.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 19.0000 - val_accuracy: 0.7654 - val_precision: 0.7051 - val_recall: 0.7432 - val_auc: 0.8696\n",
      "Epoch 333/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6141 - tp: 200.0000 - fp: 95.0000 - tn: 349.0000 - fn: 68.0000 - accuracy: 0.7711 - precision: 0.6780 - recall: 0.7463 - auc: 0.8222 - val_loss: 0.6685 - val_tp: 70.0000 - val_fp: 40.0000 - val_tn: 65.0000 - val_fn: 4.0000 - val_accuracy: 0.7542 - val_precision: 0.6364 - val_recall: 0.9459 - val_auc: 0.8588\n",
      "Epoch 334/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6230 - tp: 204.0000 - fp: 95.0000 - tn: 349.0000 - fn: 64.0000 - accuracy: 0.7767 - precision: 0.6823 - recall: 0.7612 - auc: 0.8083 - val_loss: 0.5665 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8766\n",
      "Epoch 335/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5990 - tp: 200.0000 - fp: 80.0000 - tn: 364.0000 - fn: 68.0000 - accuracy: 0.7921 - precision: 0.7143 - recall: 0.7463 - auc: 0.8251 - val_loss: 0.6117 - val_tp: 68.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 6.0000 - val_accuracy: 0.7654 - val_precision: 0.6538 - val_recall: 0.9189 - val_auc: 0.8689\n",
      "Epoch 336/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6294 - tp: 202.0000 - fp: 88.0000 - tn: 356.0000 - fn: 66.0000 - accuracy: 0.7837 - precision: 0.6966 - recall: 0.7537 - auc: 0.8066 - val_loss: 0.5823 - val_tp: 51.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 23.0000 - val_accuracy: 0.7821 - val_precision: 0.7612 - val_recall: 0.6892 - val_auc: 0.8678\n",
      "Epoch 337/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.5999 - tp: 202.0000 - fp: 93.0000 - tn: 351.0000 - fn: 66.0000 - accuracy: 0.7767 - precision: 0.6847 - recall: 0.7537 - auc: 0.8266 - val_loss: 0.5766 - val_tp: 53.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 21.0000 - val_accuracy: 0.7709 - val_precision: 0.7260 - val_recall: 0.7162 - val_auc: 0.8683\n",
      "Epoch 338/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6101 - tp: 196.0000 - fp: 97.0000 - tn: 347.0000 - fn: 72.0000 - accuracy: 0.7626 - precision: 0.6689 - recall: 0.7313 - auc: 0.8163 - val_loss: 0.5470 - val_tp: 56.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 18.0000 - val_accuracy: 0.7765 - val_precision: 0.7179 - val_recall: 0.7568 - val_auc: 0.8791\n",
      "Epoch 339/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5961 - tp: 202.0000 - fp: 91.0000 - tn: 353.0000 - fn: 66.0000 - accuracy: 0.7795 - precision: 0.6894 - recall: 0.7537 - auc: 0.8256 - val_loss: 0.8104 - val_tp: 31.0000 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 43.0000 - val_accuracy: 0.7598 - val_precision: 1.0000 - val_recall: 0.4189 - val_auc: 0.8870\n",
      "Epoch 340/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6059 - tp: 200.0000 - fp: 89.0000 - tn: 355.0000 - fn: 68.0000 - accuracy: 0.7795 - precision: 0.6920 - recall: 0.7463 - auc: 0.8331 - val_loss: 0.5472 - val_tp: 58.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 16.0000 - val_accuracy: 0.7821 - val_precision: 0.7160 - val_recall: 0.7838 - val_auc: 0.8767\n",
      "Epoch 341/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6023 - tp: 203.0000 - fp: 96.0000 - tn: 348.0000 - fn: 65.0000 - accuracy: 0.7739 - precision: 0.6789 - recall: 0.7575 - auc: 0.8207 - val_loss: 0.5436 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8743\n",
      "Epoch 342/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6110 - tp: 206.0000 - fp: 88.0000 - tn: 356.0000 - fn: 62.0000 - accuracy: 0.7893 - precision: 0.7007 - recall: 0.7687 - auc: 0.8263 - val_loss: 0.6218 - val_tp: 43.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 31.0000 - val_accuracy: 0.7765 - val_precision: 0.8269 - val_recall: 0.5811 - val_auc: 0.8841\n",
      "Epoch 343/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5943 - tp: 205.0000 - fp: 84.0000 - tn: 360.0000 - fn: 63.0000 - accuracy: 0.7935 - precision: 0.7093 - recall: 0.7649 - auc: 0.8307 - val_loss: 0.5650 - val_tp: 51.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 23.0000 - val_accuracy: 0.7821 - val_precision: 0.7612 - val_recall: 0.6892 - val_auc: 0.8838\n",
      "Epoch 344/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.5861 - tp: 205.0000 - fp: 100.0000 - tn: 344.0000 - fn: 63.0000 - accuracy: 0.7711 - precision: 0.6721 - recall: 0.7649 - auc: 0.8346 - val_loss: 0.5654 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8794\n",
      "Epoch 345/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6405 - tp: 204.0000 - fp: 113.0000 - tn: 331.0000 - fn: 64.0000 - accuracy: 0.7514 - precision: 0.6435 - recall: 0.7612 - auc: 0.8023 - val_loss: 0.5443 - val_tp: 56.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 18.0000 - val_accuracy: 0.7933 - val_precision: 0.7467 - val_recall: 0.7568 - val_auc: 0.8804\n",
      "Epoch 346/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5948 - tp: 199.0000 - fp: 86.0000 - tn: 358.0000 - fn: 69.0000 - accuracy: 0.7823 - precision: 0.6982 - recall: 0.7425 - auc: 0.8334 - val_loss: 0.5548 - val_tp: 54.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 20.0000 - val_accuracy: 0.7821 - val_precision: 0.7397 - val_recall: 0.7297 - val_auc: 0.8816\n",
      "Epoch 347/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5859 - tp: 203.0000 - fp: 86.0000 - tn: 358.0000 - fn: 65.0000 - accuracy: 0.7879 - precision: 0.7024 - recall: 0.7575 - auc: 0.8418 - val_loss: 0.6428 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8685\n",
      "Epoch 348/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6099 - tp: 207.0000 - fp: 104.0000 - tn: 340.0000 - fn: 61.0000 - accuracy: 0.7683 - precision: 0.6656 - recall: 0.7724 - auc: 0.8230 - val_loss: 0.6614 - val_tp: 33.0000 - val_fp: 1.0000 - val_tn: 104.0000 - val_fn: 41.0000 - val_accuracy: 0.7654 - val_precision: 0.9706 - val_recall: 0.4459 - val_auc: 0.8845\n",
      "Epoch 349/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6220 - tp: 192.0000 - fp: 99.0000 - tn: 345.0000 - fn: 76.0000 - accuracy: 0.7542 - precision: 0.6598 - recall: 0.7164 - auc: 0.8097 - val_loss: 0.6003 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8747\n",
      "Epoch 350/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6281 - tp: 198.0000 - fp: 98.0000 - tn: 346.0000 - fn: 70.0000 - accuracy: 0.7640 - precision: 0.6689 - recall: 0.7388 - auc: 0.8080 - val_loss: 0.5965 - val_tp: 49.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 25.0000 - val_accuracy: 0.7765 - val_precision: 0.7656 - val_recall: 0.6622 - val_auc: 0.8785\n",
      "Epoch 351/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5927 - tp: 199.0000 - fp: 89.0000 - tn: 355.0000 - fn: 69.0000 - accuracy: 0.7781 - precision: 0.6910 - recall: 0.7425 - auc: 0.8322 - val_loss: 0.5672 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8732\n",
      "Epoch 352/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6193 - tp: 195.0000 - fp: 89.0000 - tn: 355.0000 - fn: 73.0000 - accuracy: 0.7725 - precision: 0.6866 - recall: 0.7276 - auc: 0.8131 - val_loss: 0.6088 - val_tp: 43.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 31.0000 - val_accuracy: 0.7654 - val_precision: 0.7963 - val_recall: 0.5811 - val_auc: 0.8768\n",
      "Epoch 353/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6041 - tp: 204.0000 - fp: 96.0000 - tn: 348.0000 - fn: 64.0000 - accuracy: 0.7753 - precision: 0.6800 - recall: 0.7612 - auc: 0.8218 - val_loss: 0.6611 - val_tp: 39.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 35.0000 - val_accuracy: 0.7709 - val_precision: 0.8667 - val_recall: 0.5270 - val_auc: 0.8799\n",
      "Epoch 354/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5999 - tp: 199.0000 - fp: 85.0000 - tn: 359.0000 - fn: 69.0000 - accuracy: 0.7837 - precision: 0.7007 - recall: 0.7425 - auc: 0.8289 - val_loss: 0.5599 - val_tp: 54.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 20.0000 - val_accuracy: 0.7877 - val_precision: 0.7500 - val_recall: 0.7297 - val_auc: 0.8727\n",
      "Epoch 355/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6099 - tp: 205.0000 - fp: 96.0000 - tn: 348.0000 - fn: 63.0000 - accuracy: 0.7767 - precision: 0.6811 - recall: 0.7649 - auc: 0.8205 - val_loss: 0.6205 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 26.0000 - val_accuracy: 0.8045 - val_precision: 0.8421 - val_recall: 0.6486 - val_auc: 0.8856\n",
      "Epoch 356/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6007 - tp: 203.0000 - fp: 96.0000 - tn: 348.0000 - fn: 65.0000 - accuracy: 0.7739 - precision: 0.6789 - recall: 0.7575 - auc: 0.8263 - val_loss: 0.5875 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8730\n",
      "Epoch 357/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6187 - tp: 204.0000 - fp: 96.0000 - tn: 348.0000 - fn: 64.0000 - accuracy: 0.7753 - precision: 0.6800 - recall: 0.7612 - auc: 0.8144 - val_loss: 0.5728 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8826\n",
      "Epoch 358/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6120 - tp: 200.0000 - fp: 89.0000 - tn: 355.0000 - fn: 68.0000 - accuracy: 0.7795 - precision: 0.6920 - recall: 0.7463 - auc: 0.8219 - val_loss: 0.5693 - val_tp: 53.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 21.0000 - val_accuracy: 0.7933 - val_precision: 0.7681 - val_recall: 0.7162 - val_auc: 0.8817\n",
      "Epoch 359/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6070 - tp: 193.0000 - fp: 82.0000 - tn: 362.0000 - fn: 75.0000 - accuracy: 0.7795 - precision: 0.7018 - recall: 0.7201 - auc: 0.8227 - val_loss: 0.5658 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8786\n",
      "Epoch 360/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5815 - tp: 205.0000 - fp: 83.0000 - tn: 361.0000 - fn: 63.0000 - accuracy: 0.7949 - precision: 0.7118 - recall: 0.7649 - auc: 0.8421 - val_loss: 0.6407 - val_tp: 49.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 25.0000 - val_accuracy: 0.7933 - val_precision: 0.8033 - val_recall: 0.6622 - val_auc: 0.8849\n",
      "Epoch 361/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6109 - tp: 193.0000 - fp: 85.0000 - tn: 359.0000 - fn: 75.0000 - accuracy: 0.7753 - precision: 0.6942 - recall: 0.7201 - auc: 0.8154 - val_loss: 0.6539 - val_tp: 40.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 34.0000 - val_accuracy: 0.7709 - val_precision: 0.8511 - val_recall: 0.5405 - val_auc: 0.8810\n",
      "Epoch 362/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6296 - tp: 185.0000 - fp: 95.0000 - tn: 349.0000 - fn: 83.0000 - accuracy: 0.7500 - precision: 0.6607 - recall: 0.6903 - auc: 0.8090 - val_loss: 0.5716 - val_tp: 52.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 22.0000 - val_accuracy: 0.7877 - val_precision: 0.7647 - val_recall: 0.7027 - val_auc: 0.8818\n",
      "Epoch 363/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6061 - tp: 209.0000 - fp: 82.0000 - tn: 362.0000 - fn: 59.0000 - accuracy: 0.8020 - precision: 0.7182 - recall: 0.7799 - auc: 0.8228 - val_loss: 0.5761 - val_tp: 50.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 24.0000 - val_accuracy: 0.7765 - val_precision: 0.7576 - val_recall: 0.6757 - val_auc: 0.8788\n",
      "Epoch 364/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6172 - tp: 202.0000 - fp: 94.0000 - tn: 350.0000 - fn: 66.0000 - accuracy: 0.7753 - precision: 0.6824 - recall: 0.7537 - auc: 0.8118 - val_loss: 0.7749 - val_tp: 74.0000 - val_fp: 102.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4302 - val_precision: 0.4205 - val_recall: 1.0000 - val_auc: 0.8578\n",
      "Epoch 365/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6086 - tp: 208.0000 - fp: 99.0000 - tn: 345.0000 - fn: 60.0000 - accuracy: 0.7767 - precision: 0.6775 - recall: 0.7761 - auc: 0.8254 - val_loss: 0.5697 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8772\n",
      "Epoch 366/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6038 - tp: 199.0000 - fp: 85.0000 - tn: 359.0000 - fn: 69.0000 - accuracy: 0.7837 - precision: 0.7007 - recall: 0.7425 - auc: 0.8196 - val_loss: 0.6698 - val_tp: 70.0000 - val_fp: 42.0000 - val_tn: 63.0000 - val_fn: 4.0000 - val_accuracy: 0.7430 - val_precision: 0.6250 - val_recall: 0.9459 - val_auc: 0.8585\n",
      "Epoch 367/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6116 - tp: 208.0000 - fp: 102.0000 - tn: 342.0000 - fn: 60.0000 - accuracy: 0.7725 - precision: 0.6710 - recall: 0.7761 - auc: 0.8217 - val_loss: 0.9620 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 59.0000 - val_accuracy: 0.6704 - val_precision: 1.0000 - val_recall: 0.2027 - val_auc: 0.8820\n",
      "Epoch 368/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6063 - tp: 200.0000 - fp: 78.0000 - tn: 366.0000 - fn: 68.0000 - accuracy: 0.7949 - precision: 0.7194 - recall: 0.7463 - auc: 0.8243 - val_loss: 0.5854 - val_tp: 51.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 23.0000 - val_accuracy: 0.7989 - val_precision: 0.7969 - val_recall: 0.6892 - val_auc: 0.8829\n",
      "Epoch 369/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5885 - tp: 208.0000 - fp: 89.0000 - tn: 355.0000 - fn: 60.0000 - accuracy: 0.7907 - precision: 0.7003 - recall: 0.7761 - auc: 0.8381 - val_loss: 0.5840 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8804\n",
      "Epoch 370/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5867 - tp: 207.0000 - fp: 95.0000 - tn: 349.0000 - fn: 61.0000 - accuracy: 0.7809 - precision: 0.6854 - recall: 0.7724 - auc: 0.8342 - val_loss: 0.6996 - val_tp: 37.0000 - val_fp: 5.0000 - val_tn: 100.0000 - val_fn: 37.0000 - val_accuracy: 0.7654 - val_precision: 0.8810 - val_recall: 0.5000 - val_auc: 0.8900\n",
      "Epoch 371/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5874 - tp: 199.0000 - fp: 75.0000 - tn: 369.0000 - fn: 69.0000 - accuracy: 0.7978 - precision: 0.7263 - recall: 0.7425 - auc: 0.8392 - val_loss: 0.6454 - val_tp: 70.0000 - val_fp: 41.0000 - val_tn: 64.0000 - val_fn: 4.0000 - val_accuracy: 0.7486 - val_precision: 0.6306 - val_recall: 0.9459 - val_auc: 0.8618\n",
      "Epoch 372/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5946 - tp: 209.0000 - fp: 96.0000 - tn: 348.0000 - fn: 59.0000 - accuracy: 0.7823 - precision: 0.6852 - recall: 0.7799 - auc: 0.8281 - val_loss: 0.5723 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8796\n",
      "Epoch 373/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5880 - tp: 208.0000 - fp: 98.0000 - tn: 346.0000 - fn: 60.0000 - accuracy: 0.7781 - precision: 0.6797 - recall: 0.7761 - auc: 0.8378 - val_loss: 0.6571 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8594\n",
      "Epoch 374/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6143 - tp: 196.0000 - fp: 97.0000 - tn: 347.0000 - fn: 72.0000 - accuracy: 0.7626 - precision: 0.6689 - recall: 0.7313 - auc: 0.8236 - val_loss: 0.5718 - val_tp: 54.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 20.0000 - val_accuracy: 0.7709 - val_precision: 0.7200 - val_recall: 0.7297 - val_auc: 0.8714\n",
      "Epoch 375/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5811 - tp: 197.0000 - fp: 88.0000 - tn: 356.0000 - fn: 71.0000 - accuracy: 0.7767 - precision: 0.6912 - recall: 0.7351 - auc: 0.8346 - val_loss: 0.6036 - val_tp: 70.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 4.0000 - val_accuracy: 0.7709 - val_precision: 0.6542 - val_recall: 0.9459 - val_auc: 0.8718\n",
      "Epoch 376/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6063 - tp: 204.0000 - fp: 96.0000 - tn: 348.0000 - fn: 64.0000 - accuracy: 0.7753 - precision: 0.6800 - recall: 0.7612 - auc: 0.8210 - val_loss: 0.5799 - val_tp: 63.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 11.0000 - val_accuracy: 0.7542 - val_precision: 0.6562 - val_recall: 0.8514 - val_auc: 0.8754\n",
      "Epoch 377/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6062 - tp: 204.0000 - fp: 102.0000 - tn: 342.0000 - fn: 64.0000 - accuracy: 0.7669 - precision: 0.6667 - recall: 0.7612 - auc: 0.8198 - val_loss: 0.6903 - val_tp: 72.0000 - val_fp: 55.0000 - val_tn: 50.0000 - val_fn: 2.0000 - val_accuracy: 0.6816 - val_precision: 0.5669 - val_recall: 0.9730 - val_auc: 0.8605\n",
      "Epoch 378/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6118 - tp: 199.0000 - fp: 106.0000 - tn: 338.0000 - fn: 69.0000 - accuracy: 0.7542 - precision: 0.6525 - recall: 0.7425 - auc: 0.8142 - val_loss: 0.5758 - val_tp: 66.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 8.0000 - val_accuracy: 0.7654 - val_precision: 0.6600 - val_recall: 0.8919 - val_auc: 0.8639\n",
      "Epoch 379/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6054 - tp: 200.0000 - fp: 94.0000 - tn: 350.0000 - fn: 68.0000 - accuracy: 0.7725 - precision: 0.6803 - recall: 0.7463 - auc: 0.8243 - val_loss: 0.5465 - val_tp: 60.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 14.0000 - val_accuracy: 0.7542 - val_precision: 0.6667 - val_recall: 0.8108 - val_auc: 0.8751\n",
      "Epoch 380/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.5942 - tp: 196.0000 - fp: 79.0000 - tn: 365.0000 - fn: 72.0000 - accuracy: 0.7879 - precision: 0.7127 - recall: 0.7313 - auc: 0.8236 - val_loss: 0.5403 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8786\n",
      "Epoch 381/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5737 - tp: 197.0000 - fp: 86.0000 - tn: 358.0000 - fn: 71.0000 - accuracy: 0.7795 - precision: 0.6961 - recall: 0.7351 - auc: 0.8472 - val_loss: 0.6776 - val_tp: 70.0000 - val_fp: 42.0000 - val_tn: 63.0000 - val_fn: 4.0000 - val_accuracy: 0.7430 - val_precision: 0.6250 - val_recall: 0.9459 - val_auc: 0.8609\n",
      "Epoch 382/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6209 - tp: 197.0000 - fp: 102.0000 - tn: 342.0000 - fn: 71.0000 - accuracy: 0.7570 - precision: 0.6589 - recall: 0.7351 - auc: 0.8154 - val_loss: 0.5568 - val_tp: 63.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 11.0000 - val_accuracy: 0.7430 - val_precision: 0.6429 - val_recall: 0.8514 - val_auc: 0.8730\n",
      "Epoch 383/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6118 - tp: 210.0000 - fp: 114.0000 - tn: 330.0000 - fn: 58.0000 - accuracy: 0.7584 - precision: 0.6481 - recall: 0.7836 - auc: 0.8151 - val_loss: 0.5743 - val_tp: 66.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 8.0000 - val_accuracy: 0.7654 - val_precision: 0.6600 - val_recall: 0.8919 - val_auc: 0.8609\n",
      "Epoch 384/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5956 - tp: 200.0000 - fp: 88.0000 - tn: 356.0000 - fn: 68.0000 - accuracy: 0.7809 - precision: 0.6944 - recall: 0.7463 - auc: 0.8235 - val_loss: 0.5963 - val_tp: 69.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 5.0000 - val_accuracy: 0.7709 - val_precision: 0.6571 - val_recall: 0.9324 - val_auc: 0.8637\n",
      "Epoch 385/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6093 - tp: 203.0000 - fp: 107.0000 - tn: 337.0000 - fn: 65.0000 - accuracy: 0.7584 - precision: 0.6548 - recall: 0.7575 - auc: 0.8158 - val_loss: 0.5495 - val_tp: 56.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 18.0000 - val_accuracy: 0.7486 - val_precision: 0.6747 - val_recall: 0.7568 - val_auc: 0.8701\n",
      "Epoch 386/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6010 - tp: 199.0000 - fp: 91.0000 - tn: 353.0000 - fn: 69.0000 - accuracy: 0.7753 - precision: 0.6862 - recall: 0.7425 - auc: 0.8204 - val_loss: 0.5932 - val_tp: 69.0000 - val_fp: 38.0000 - val_tn: 67.0000 - val_fn: 5.0000 - val_accuracy: 0.7598 - val_precision: 0.6449 - val_recall: 0.9324 - val_auc: 0.8664\n",
      "Epoch 387/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.6348 - tp: 203.0000 - fp: 95.0000 - tn: 349.0000 - fn: 65.0000 - accuracy: 0.7753 - precision: 0.6812 - recall: 0.7575 - auc: 0.8025 - val_loss: 0.5590 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8703\n",
      "Epoch 388/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5797 - tp: 210.0000 - fp: 78.0000 - tn: 366.0000 - fn: 58.0000 - accuracy: 0.8090 - precision: 0.7292 - recall: 0.7836 - auc: 0.8422 - val_loss: 0.6427 - val_tp: 38.0000 - val_fp: 3.0000 - val_tn: 102.0000 - val_fn: 36.0000 - val_accuracy: 0.7821 - val_precision: 0.9268 - val_recall: 0.5135 - val_auc: 0.8831\n",
      "Epoch 389/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6183 - tp: 201.0000 - fp: 95.0000 - tn: 349.0000 - fn: 67.0000 - accuracy: 0.7725 - precision: 0.6791 - recall: 0.7500 - auc: 0.8151 - val_loss: 0.5420 - val_tp: 63.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 11.0000 - val_accuracy: 0.7654 - val_precision: 0.6702 - val_recall: 0.8514 - val_auc: 0.8646\n",
      "Epoch 390/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5985 - tp: 205.0000 - fp: 96.0000 - tn: 348.0000 - fn: 63.0000 - accuracy: 0.7767 - precision: 0.6811 - recall: 0.7649 - auc: 0.8303 - val_loss: 0.6235 - val_tp: 48.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 26.0000 - val_accuracy: 0.7821 - val_precision: 0.7869 - val_recall: 0.6486 - val_auc: 0.8814\n",
      "Epoch 391/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6133 - tp: 195.0000 - fp: 85.0000 - tn: 359.0000 - fn: 73.0000 - accuracy: 0.7781 - precision: 0.6964 - recall: 0.7276 - auc: 0.8173 - val_loss: 0.5520 - val_tp: 62.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 12.0000 - val_accuracy: 0.7542 - val_precision: 0.6596 - val_recall: 0.8378 - val_auc: 0.8741\n",
      "Epoch 392/500\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6127 - tp: 200.0000 - fp: 96.0000 - tn: 348.0000 - fn: 68.0000 - accuracy: 0.7697 - precision: 0.6757 - recall: 0.7463 - auc: 0.8179 - val_loss: 0.6307 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8747\n",
      "Epoch 393/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6042 - tp: 200.0000 - fp: 104.0000 - tn: 340.0000 - fn: 68.0000 - accuracy: 0.7584 - precision: 0.6579 - recall: 0.7463 - auc: 0.8216 - val_loss: 0.5933 - val_tp: 69.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 5.0000 - val_accuracy: 0.7709 - val_precision: 0.6571 - val_recall: 0.9324 - val_auc: 0.8722\n",
      "Epoch 394/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5943 - tp: 200.0000 - fp: 90.0000 - tn: 354.0000 - fn: 68.0000 - accuracy: 0.7781 - precision: 0.6897 - recall: 0.7463 - auc: 0.8258 - val_loss: 0.5775 - val_tp: 63.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 11.0000 - val_accuracy: 0.7486 - val_precision: 0.6495 - val_recall: 0.8514 - val_auc: 0.8690\n",
      "Epoch 395/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5884 - tp: 205.0000 - fp: 87.0000 - tn: 357.0000 - fn: 63.0000 - accuracy: 0.7893 - precision: 0.7021 - recall: 0.7649 - auc: 0.8381 - val_loss: 0.5388 - val_tp: 59.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 15.0000 - val_accuracy: 0.7709 - val_precision: 0.6941 - val_recall: 0.7973 - val_auc: 0.8830\n",
      "Epoch 396/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5983 - tp: 203.0000 - fp: 94.0000 - tn: 350.0000 - fn: 65.0000 - accuracy: 0.7767 - precision: 0.6835 - recall: 0.7575 - auc: 0.8281 - val_loss: 0.5463 - val_tp: 54.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 20.0000 - val_accuracy: 0.7709 - val_precision: 0.7200 - val_recall: 0.7297 - val_auc: 0.8783\n",
      "Epoch 397/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5892 - tp: 200.0000 - fp: 86.0000 - tn: 358.0000 - fn: 68.0000 - accuracy: 0.7837 - precision: 0.6993 - recall: 0.7463 - auc: 0.8405 - val_loss: 0.7359 - val_tp: 74.0000 - val_fp: 96.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4637 - val_precision: 0.4353 - val_recall: 1.0000 - val_auc: 0.8569\n",
      "Epoch 398/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6013 - tp: 204.0000 - fp: 105.0000 - tn: 339.0000 - fn: 64.0000 - accuracy: 0.7626 - precision: 0.6602 - recall: 0.7612 - auc: 0.8225 - val_loss: 0.5741 - val_tp: 53.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 21.0000 - val_accuracy: 0.8045 - val_precision: 0.7910 - val_recall: 0.7162 - val_auc: 0.8809\n",
      "Epoch 399/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6087 - tp: 200.0000 - fp: 90.0000 - tn: 354.0000 - fn: 68.0000 - accuracy: 0.7781 - precision: 0.6897 - recall: 0.7463 - auc: 0.8206 - val_loss: 0.6323 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8690\n",
      "Epoch 400/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6202 - tp: 209.0000 - fp: 100.0000 - tn: 344.0000 - fn: 59.0000 - accuracy: 0.7767 - precision: 0.6764 - recall: 0.7799 - auc: 0.8199 - val_loss: 0.5456 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8736\n",
      "Epoch 401/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6159 - tp: 201.0000 - fp: 96.0000 - tn: 348.0000 - fn: 67.0000 - accuracy: 0.7711 - precision: 0.6768 - recall: 0.7500 - auc: 0.8108 - val_loss: 0.5582 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8685\n",
      "Epoch 402/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5974 - tp: 205.0000 - fp: 100.0000 - tn: 344.0000 - fn: 63.0000 - accuracy: 0.7711 - precision: 0.6721 - recall: 0.7649 - auc: 0.8278 - val_loss: 0.5626 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8795\n",
      "Epoch 403/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6101 - tp: 194.0000 - fp: 81.0000 - tn: 363.0000 - fn: 74.0000 - accuracy: 0.7823 - precision: 0.7055 - recall: 0.7239 - auc: 0.8236 - val_loss: 0.5808 - val_tp: 52.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 22.0000 - val_accuracy: 0.7821 - val_precision: 0.7536 - val_recall: 0.7027 - val_auc: 0.8793\n",
      "Epoch 404/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5958 - tp: 200.0000 - fp: 95.0000 - tn: 349.0000 - fn: 68.0000 - accuracy: 0.7711 - precision: 0.6780 - recall: 0.7463 - auc: 0.8250 - val_loss: 0.5557 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8808\n",
      "Epoch 405/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6325 - tp: 204.0000 - fp: 121.0000 - tn: 323.0000 - fn: 64.0000 - accuracy: 0.7402 - precision: 0.6277 - recall: 0.7612 - auc: 0.7968 - val_loss: 0.5942 - val_tp: 51.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 23.0000 - val_accuracy: 0.7933 - val_precision: 0.7846 - val_recall: 0.6892 - val_auc: 0.8799\n",
      "Epoch 406/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6085 - tp: 204.0000 - fp: 92.0000 - tn: 352.0000 - fn: 64.0000 - accuracy: 0.7809 - precision: 0.6892 - recall: 0.7612 - auc: 0.8165 - val_loss: 0.6786 - val_tp: 45.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 29.0000 - val_accuracy: 0.8045 - val_precision: 0.8824 - val_recall: 0.6081 - val_auc: 0.8836\n",
      "Epoch 407/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5997 - tp: 203.0000 - fp: 93.0000 - tn: 351.0000 - fn: 65.0000 - accuracy: 0.7781 - precision: 0.6858 - recall: 0.7575 - auc: 0.8320 - val_loss: 0.5752 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8791\n",
      "Epoch 408/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5969 - tp: 208.0000 - fp: 93.0000 - tn: 351.0000 - fn: 60.0000 - accuracy: 0.7851 - precision: 0.6910 - recall: 0.7761 - auc: 0.8299 - val_loss: 0.5545 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8725\n",
      "Epoch 409/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6144 - tp: 202.0000 - fp: 96.0000 - tn: 348.0000 - fn: 66.0000 - accuracy: 0.7725 - precision: 0.6779 - recall: 0.7537 - auc: 0.8152 - val_loss: 0.5469 - val_tp: 63.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 11.0000 - val_accuracy: 0.7709 - val_precision: 0.6774 - val_recall: 0.8514 - val_auc: 0.8777\n",
      "Epoch 410/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6107 - tp: 199.0000 - fp: 102.0000 - tn: 342.0000 - fn: 69.0000 - accuracy: 0.7598 - precision: 0.6611 - recall: 0.7425 - auc: 0.8141 - val_loss: 0.7300 - val_tp: 74.0000 - val_fp: 100.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4413 - val_precision: 0.4253 - val_recall: 1.0000 - val_auc: 0.8486\n",
      "Epoch 411/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6183 - tp: 203.0000 - fp: 103.0000 - tn: 341.0000 - fn: 65.0000 - accuracy: 0.7640 - precision: 0.6634 - recall: 0.7575 - auc: 0.8143 - val_loss: 0.6712 - val_tp: 70.0000 - val_fp: 42.0000 - val_tn: 63.0000 - val_fn: 4.0000 - val_accuracy: 0.7430 - val_precision: 0.6250 - val_recall: 0.9459 - val_auc: 0.8687\n",
      "Epoch 412/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5999 - tp: 204.0000 - fp: 111.0000 - tn: 333.0000 - fn: 64.0000 - accuracy: 0.7542 - precision: 0.6476 - recall: 0.7612 - auc: 0.8220 - val_loss: 0.6507 - val_tp: 69.0000 - val_fp: 38.0000 - val_tn: 67.0000 - val_fn: 5.0000 - val_accuracy: 0.7598 - val_precision: 0.6449 - val_recall: 0.9324 - val_auc: 0.8723\n",
      "Epoch 413/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5942 - tp: 205.0000 - fp: 98.0000 - tn: 346.0000 - fn: 63.0000 - accuracy: 0.7739 - precision: 0.6766 - recall: 0.7649 - auc: 0.8346 - val_loss: 0.5650 - val_tp: 58.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 16.0000 - val_accuracy: 0.7765 - val_precision: 0.7073 - val_recall: 0.7838 - val_auc: 0.8700\n",
      "Epoch 414/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5969 - tp: 210.0000 - fp: 90.0000 - tn: 354.0000 - fn: 58.0000 - accuracy: 0.7921 - precision: 0.7000 - recall: 0.7836 - auc: 0.8297 - val_loss: 0.5908 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8586\n",
      "Epoch 415/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6241 - tp: 203.0000 - fp: 101.0000 - tn: 343.0000 - fn: 65.0000 - accuracy: 0.7669 - precision: 0.6678 - recall: 0.7575 - auc: 0.8153 - val_loss: 0.6119 - val_tp: 69.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 5.0000 - val_accuracy: 0.7709 - val_precision: 0.6571 - val_recall: 0.9324 - val_auc: 0.8638\n",
      "Epoch 416/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6111 - tp: 207.0000 - fp: 113.0000 - tn: 331.0000 - fn: 61.0000 - accuracy: 0.7556 - precision: 0.6469 - recall: 0.7724 - auc: 0.8123 - val_loss: 0.5464 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8727\n",
      "Epoch 417/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5952 - tp: 202.0000 - fp: 98.0000 - tn: 346.0000 - fn: 66.0000 - accuracy: 0.7697 - precision: 0.6733 - recall: 0.7537 - auc: 0.8243 - val_loss: 0.5506 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8815\n",
      "Epoch 418/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6035 - tp: 205.0000 - fp: 86.0000 - tn: 358.0000 - fn: 63.0000 - accuracy: 0.7907 - precision: 0.7045 - recall: 0.7649 - auc: 0.8235 - val_loss: 0.6310 - val_tp: 49.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 25.0000 - val_accuracy: 0.7933 - val_precision: 0.8033 - val_recall: 0.6622 - val_auc: 0.8819\n",
      "Epoch 419/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6245 - tp: 202.0000 - fp: 97.0000 - tn: 347.0000 - fn: 66.0000 - accuracy: 0.7711 - precision: 0.6756 - recall: 0.7537 - auc: 0.8106 - val_loss: 0.6105 - val_tp: 66.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 8.0000 - val_accuracy: 0.7542 - val_precision: 0.6471 - val_recall: 0.8919 - val_auc: 0.8656\n",
      "Epoch 420/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5777 - tp: 212.0000 - fp: 96.0000 - tn: 348.0000 - fn: 56.0000 - accuracy: 0.7865 - precision: 0.6883 - recall: 0.7910 - auc: 0.8400 - val_loss: 0.5503 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8786\n",
      "Epoch 421/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5955 - tp: 206.0000 - fp: 95.0000 - tn: 349.0000 - fn: 62.0000 - accuracy: 0.7795 - precision: 0.6844 - recall: 0.7687 - auc: 0.8282 - val_loss: 0.6302 - val_tp: 38.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 36.0000 - val_accuracy: 0.7430 - val_precision: 0.7917 - val_recall: 0.5135 - val_auc: 0.8703\n",
      "Epoch 422/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6037 - tp: 202.0000 - fp: 100.0000 - tn: 344.0000 - fn: 66.0000 - accuracy: 0.7669 - precision: 0.6689 - recall: 0.7537 - auc: 0.8254 - val_loss: 0.7226 - val_tp: 28.0000 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 46.0000 - val_accuracy: 0.7430 - val_precision: 1.0000 - val_recall: 0.3784 - val_auc: 0.8779\n",
      "Epoch 423/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6021 - tp: 203.0000 - fp: 95.0000 - tn: 349.0000 - fn: 65.0000 - accuracy: 0.7753 - precision: 0.6812 - recall: 0.7575 - auc: 0.8252 - val_loss: 0.5437 - val_tp: 61.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 13.0000 - val_accuracy: 0.7765 - val_precision: 0.6932 - val_recall: 0.8243 - val_auc: 0.8689\n",
      "Epoch 424/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5783 - tp: 201.0000 - fp: 92.0000 - tn: 352.0000 - fn: 67.0000 - accuracy: 0.7767 - precision: 0.6860 - recall: 0.7500 - auc: 0.8392 - val_loss: 0.5636 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8802\n",
      "Epoch 425/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5861 - tp: 203.0000 - fp: 102.0000 - tn: 342.0000 - fn: 65.0000 - accuracy: 0.7654 - precision: 0.6656 - recall: 0.7575 - auc: 0.8360 - val_loss: 0.5978 - val_tp: 63.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 11.0000 - val_accuracy: 0.7430 - val_precision: 0.6429 - val_recall: 0.8514 - val_auc: 0.8698\n",
      "Epoch 426/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6098 - tp: 202.0000 - fp: 103.0000 - tn: 341.0000 - fn: 66.0000 - accuracy: 0.7626 - precision: 0.6623 - recall: 0.7537 - auc: 0.8212 - val_loss: 0.6908 - val_tp: 71.0000 - val_fp: 51.0000 - val_tn: 54.0000 - val_fn: 3.0000 - val_accuracy: 0.6983 - val_precision: 0.5820 - val_recall: 0.9595 - val_auc: 0.8668\n",
      "Epoch 427/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6135 - tp: 205.0000 - fp: 110.0000 - tn: 334.0000 - fn: 63.0000 - accuracy: 0.7570 - precision: 0.6508 - recall: 0.7649 - auc: 0.8167 - val_loss: 0.5649 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8718\n",
      "Epoch 428/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6052 - tp: 196.0000 - fp: 94.0000 - tn: 350.0000 - fn: 72.0000 - accuracy: 0.7669 - precision: 0.6759 - recall: 0.7313 - auc: 0.8178 - val_loss: 0.6650 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8631\n",
      "Epoch 429/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6053 - tp: 208.0000 - fp: 105.0000 - tn: 339.0000 - fn: 60.0000 - accuracy: 0.7683 - precision: 0.6645 - recall: 0.7761 - auc: 0.8186 - val_loss: 0.5576 - val_tp: 53.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 21.0000 - val_accuracy: 0.7933 - val_precision: 0.7681 - val_recall: 0.7162 - val_auc: 0.8778\n",
      "Epoch 430/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5764 - tp: 202.0000 - fp: 93.0000 - tn: 351.0000 - fn: 66.0000 - accuracy: 0.7767 - precision: 0.6847 - recall: 0.7537 - auc: 0.8428 - val_loss: 0.5697 - val_tp: 64.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 10.0000 - val_accuracy: 0.7542 - val_precision: 0.6531 - val_recall: 0.8649 - val_auc: 0.8758\n",
      "Epoch 431/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5898 - tp: 203.0000 - fp: 100.0000 - tn: 344.0000 - fn: 65.0000 - accuracy: 0.7683 - precision: 0.6700 - recall: 0.7575 - auc: 0.8326 - val_loss: 0.6819 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8631\n",
      "Epoch 432/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6137 - tp: 202.0000 - fp: 90.0000 - tn: 354.0000 - fn: 66.0000 - accuracy: 0.7809 - precision: 0.6918 - recall: 0.7537 - auc: 0.8197 - val_loss: 0.5917 - val_tp: 69.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 5.0000 - val_accuracy: 0.7709 - val_precision: 0.6571 - val_recall: 0.9324 - val_auc: 0.8624\n",
      "Epoch 433/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6067 - tp: 209.0000 - fp: 108.0000 - tn: 336.0000 - fn: 59.0000 - accuracy: 0.7654 - precision: 0.6593 - recall: 0.7799 - auc: 0.8222 - val_loss: 0.5605 - val_tp: 54.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 20.0000 - val_accuracy: 0.7933 - val_precision: 0.7606 - val_recall: 0.7297 - val_auc: 0.8824\n",
      "Epoch 434/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6028 - tp: 201.0000 - fp: 95.0000 - tn: 349.0000 - fn: 67.0000 - accuracy: 0.7725 - precision: 0.6791 - recall: 0.7500 - auc: 0.8243 - val_loss: 0.5800 - val_tp: 49.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 25.0000 - val_accuracy: 0.7709 - val_precision: 0.7538 - val_recall: 0.6622 - val_auc: 0.8768\n",
      "Epoch 435/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5979 - tp: 200.0000 - fp: 86.0000 - tn: 358.0000 - fn: 68.0000 - accuracy: 0.7837 - precision: 0.6993 - recall: 0.7463 - auc: 0.8256 - val_loss: 0.6372 - val_tp: 50.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 24.0000 - val_accuracy: 0.7933 - val_precision: 0.7937 - val_recall: 0.6757 - val_auc: 0.8839\n",
      "Epoch 436/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.5914 - tp: 207.0000 - fp: 85.0000 - tn: 359.0000 - fn: 61.0000 - accuracy: 0.7949 - precision: 0.7089 - recall: 0.7724 - auc: 0.8345 - val_loss: 0.7183 - val_tp: 30.0000 - val_fp: 2.0000 - val_tn: 103.0000 - val_fn: 44.0000 - val_accuracy: 0.7430 - val_precision: 0.9375 - val_recall: 0.4054 - val_auc: 0.8808\n",
      "Epoch 437/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6336 - tp: 201.0000 - fp: 94.0000 - tn: 350.0000 - fn: 67.0000 - accuracy: 0.7739 - precision: 0.6814 - recall: 0.7500 - auc: 0.8095 - val_loss: 0.5538 - val_tp: 54.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 20.0000 - val_accuracy: 0.7877 - val_precision: 0.7500 - val_recall: 0.7297 - val_auc: 0.8828\n",
      "Epoch 438/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5923 - tp: 204.0000 - fp: 88.0000 - tn: 356.0000 - fn: 64.0000 - accuracy: 0.7865 - precision: 0.6986 - recall: 0.7612 - auc: 0.8338 - val_loss: 0.5503 - val_tp: 53.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 21.0000 - val_accuracy: 0.7709 - val_precision: 0.7260 - val_recall: 0.7162 - val_auc: 0.8734\n",
      "Epoch 439/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6070 - tp: 200.0000 - fp: 91.0000 - tn: 353.0000 - fn: 68.0000 - accuracy: 0.7767 - precision: 0.6873 - recall: 0.7463 - auc: 0.8273 - val_loss: 0.5977 - val_tp: 64.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 10.0000 - val_accuracy: 0.7374 - val_precision: 0.6337 - val_recall: 0.8649 - val_auc: 0.8694\n",
      "Epoch 440/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5995 - tp: 195.0000 - fp: 83.0000 - tn: 361.0000 - fn: 73.0000 - accuracy: 0.7809 - precision: 0.7014 - recall: 0.7276 - auc: 0.8272 - val_loss: 0.6702 - val_tp: 46.0000 - val_fp: 5.0000 - val_tn: 100.0000 - val_fn: 28.0000 - val_accuracy: 0.8156 - val_precision: 0.9020 - val_recall: 0.6216 - val_auc: 0.8897\n",
      "Epoch 441/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6188 - tp: 202.0000 - fp: 96.0000 - tn: 348.0000 - fn: 66.0000 - accuracy: 0.7725 - precision: 0.6779 - recall: 0.7537 - auc: 0.8171 - val_loss: 0.5625 - val_tp: 64.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 10.0000 - val_accuracy: 0.7598 - val_precision: 0.6598 - val_recall: 0.8649 - val_auc: 0.8761\n",
      "Epoch 442/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5835 - tp: 203.0000 - fp: 88.0000 - tn: 356.0000 - fn: 65.0000 - accuracy: 0.7851 - precision: 0.6976 - recall: 0.7575 - auc: 0.8348 - val_loss: 0.5624 - val_tp: 61.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 13.0000 - val_accuracy: 0.7542 - val_precision: 0.6630 - val_recall: 0.8243 - val_auc: 0.8719\n",
      "Epoch 443/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.6147 - tp: 203.0000 - fp: 89.0000 - tn: 355.0000 - fn: 65.0000 - accuracy: 0.7837 - precision: 0.6952 - recall: 0.7575 - auc: 0.8145 - val_loss: 0.5479 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8752\n",
      "Epoch 444/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5862 - tp: 195.0000 - fp: 76.0000 - tn: 368.0000 - fn: 73.0000 - accuracy: 0.7907 - precision: 0.7196 - recall: 0.7276 - auc: 0.8363 - val_loss: 0.5733 - val_tp: 53.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 21.0000 - val_accuracy: 0.7933 - val_precision: 0.7681 - val_recall: 0.7162 - val_auc: 0.8788\n",
      "Epoch 445/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5938 - tp: 201.0000 - fp: 79.0000 - tn: 365.0000 - fn: 67.0000 - accuracy: 0.7949 - precision: 0.7179 - recall: 0.7500 - auc: 0.8295 - val_loss: 0.5535 - val_tp: 54.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 20.0000 - val_accuracy: 0.7877 - val_precision: 0.7500 - val_recall: 0.7297 - val_auc: 0.8739\n",
      "Epoch 446/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6130 - tp: 203.0000 - fp: 94.0000 - tn: 350.0000 - fn: 65.0000 - accuracy: 0.7767 - precision: 0.6835 - recall: 0.7575 - auc: 0.8189 - val_loss: 0.5907 - val_tp: 50.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 24.0000 - val_accuracy: 0.7877 - val_precision: 0.7812 - val_recall: 0.6757 - val_auc: 0.8811\n",
      "Epoch 447/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5917 - tp: 202.0000 - fp: 85.0000 - tn: 359.0000 - fn: 66.0000 - accuracy: 0.7879 - precision: 0.7038 - recall: 0.7537 - auc: 0.8317 - val_loss: 0.5461 - val_tp: 59.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 15.0000 - val_accuracy: 0.7709 - val_precision: 0.6941 - val_recall: 0.7973 - val_auc: 0.8746\n",
      "Epoch 448/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5914 - tp: 207.0000 - fp: 94.0000 - tn: 350.0000 - fn: 61.0000 - accuracy: 0.7823 - precision: 0.6877 - recall: 0.7724 - auc: 0.8308 - val_loss: 0.5561 - val_tp: 62.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 12.0000 - val_accuracy: 0.7709 - val_precision: 0.6813 - val_recall: 0.8378 - val_auc: 0.8717\n",
      "Epoch 449/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6107 - tp: 200.0000 - fp: 89.0000 - tn: 355.0000 - fn: 68.0000 - accuracy: 0.7795 - precision: 0.6920 - recall: 0.7463 - auc: 0.8224 - val_loss: 0.5571 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8803\n",
      "Epoch 450/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5888 - tp: 200.0000 - fp: 92.0000 - tn: 352.0000 - fn: 68.0000 - accuracy: 0.7753 - precision: 0.6849 - recall: 0.7463 - auc: 0.8320 - val_loss: 0.5628 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8679\n",
      "Epoch 451/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6083 - tp: 199.0000 - fp: 92.0000 - tn: 352.0000 - fn: 69.0000 - accuracy: 0.7739 - precision: 0.6838 - recall: 0.7425 - auc: 0.8267 - val_loss: 0.5439 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8781\n",
      "Epoch 452/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5846 - tp: 205.0000 - fp: 85.0000 - tn: 359.0000 - fn: 63.0000 - accuracy: 0.7921 - precision: 0.7069 - recall: 0.7649 - auc: 0.8432 - val_loss: 0.5599 - val_tp: 59.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 15.0000 - val_accuracy: 0.7709 - val_precision: 0.6941 - val_recall: 0.7973 - val_auc: 0.8770\n",
      "Epoch 453/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5980 - tp: 204.0000 - fp: 94.0000 - tn: 350.0000 - fn: 64.0000 - accuracy: 0.7781 - precision: 0.6846 - recall: 0.7612 - auc: 0.8290 - val_loss: 0.5513 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8732\n",
      "Epoch 454/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6006 - tp: 207.0000 - fp: 90.0000 - tn: 354.0000 - fn: 61.0000 - accuracy: 0.7879 - precision: 0.6970 - recall: 0.7724 - auc: 0.8318 - val_loss: 0.6667 - val_tp: 48.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 26.0000 - val_accuracy: 0.7821 - val_precision: 0.7869 - val_recall: 0.6486 - val_auc: 0.8814\n",
      "Epoch 455/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6130 - tp: 198.0000 - fp: 83.0000 - tn: 361.0000 - fn: 70.0000 - accuracy: 0.7851 - precision: 0.7046 - recall: 0.7388 - auc: 0.8257 - val_loss: 0.5751 - val_tp: 63.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 11.0000 - val_accuracy: 0.7654 - val_precision: 0.6702 - val_recall: 0.8514 - val_auc: 0.8759\n",
      "Epoch 456/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6162 - tp: 204.0000 - fp: 91.0000 - tn: 353.0000 - fn: 64.0000 - accuracy: 0.7823 - precision: 0.6915 - recall: 0.7612 - auc: 0.8243 - val_loss: 0.5539 - val_tp: 54.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 20.0000 - val_accuracy: 0.7933 - val_precision: 0.7606 - val_recall: 0.7297 - val_auc: 0.8772\n",
      "Epoch 457/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6030 - tp: 202.0000 - fp: 96.0000 - tn: 348.0000 - fn: 66.0000 - accuracy: 0.7725 - precision: 0.6779 - recall: 0.7537 - auc: 0.8293 - val_loss: 0.5857 - val_tp: 68.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 6.0000 - val_accuracy: 0.7821 - val_precision: 0.6733 - val_recall: 0.9189 - val_auc: 0.8660\n",
      "Epoch 458/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6243 - tp: 210.0000 - fp: 96.0000 - tn: 348.0000 - fn: 58.0000 - accuracy: 0.7837 - precision: 0.6863 - recall: 0.7836 - auc: 0.8199 - val_loss: 0.5634 - val_tp: 64.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 10.0000 - val_accuracy: 0.7374 - val_precision: 0.6337 - val_recall: 0.8649 - val_auc: 0.8651\n",
      "Epoch 459/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5958 - tp: 209.0000 - fp: 93.0000 - tn: 351.0000 - fn: 59.0000 - accuracy: 0.7865 - precision: 0.6921 - recall: 0.7799 - auc: 0.8331 - val_loss: 0.5769 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8763\n",
      "Epoch 460/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5909 - tp: 205.0000 - fp: 87.0000 - tn: 357.0000 - fn: 63.0000 - accuracy: 0.7893 - precision: 0.7021 - recall: 0.7649 - auc: 0.8413 - val_loss: 0.6624 - val_tp: 66.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 8.0000 - val_accuracy: 0.7374 - val_precision: 0.6286 - val_recall: 0.8919 - val_auc: 0.8549\n",
      "Epoch 461/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6179 - tp: 196.0000 - fp: 81.0000 - tn: 363.0000 - fn: 72.0000 - accuracy: 0.7851 - precision: 0.7076 - recall: 0.7313 - auc: 0.8124 - val_loss: 0.5646 - val_tp: 64.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 10.0000 - val_accuracy: 0.7374 - val_precision: 0.6337 - val_recall: 0.8649 - val_auc: 0.8725\n",
      "Epoch 462/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6109 - tp: 200.0000 - fp: 87.0000 - tn: 357.0000 - fn: 68.0000 - accuracy: 0.7823 - precision: 0.6969 - recall: 0.7463 - auc: 0.8188 - val_loss: 0.5602 - val_tp: 59.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 15.0000 - val_accuracy: 0.7486 - val_precision: 0.6629 - val_recall: 0.7973 - val_auc: 0.8695\n",
      "Epoch 463/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6194 - tp: 200.0000 - fp: 84.0000 - tn: 360.0000 - fn: 68.0000 - accuracy: 0.7865 - precision: 0.7042 - recall: 0.7463 - auc: 0.8116 - val_loss: 0.6638 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8639\n",
      "Epoch 464/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5960 - tp: 202.0000 - fp: 104.0000 - tn: 340.0000 - fn: 66.0000 - accuracy: 0.7612 - precision: 0.6601 - recall: 0.7537 - auc: 0.8291 - val_loss: 0.5735 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8806\n",
      "Epoch 465/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5965 - tp: 197.0000 - fp: 105.0000 - tn: 339.0000 - fn: 71.0000 - accuracy: 0.7528 - precision: 0.6523 - recall: 0.7351 - auc: 0.8270 - val_loss: 0.5634 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8732\n",
      "Epoch 466/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.6100 - tp: 205.0000 - fp: 101.0000 - tn: 343.0000 - fn: 63.0000 - accuracy: 0.7697 - precision: 0.6699 - recall: 0.7649 - auc: 0.8219 - val_loss: 0.5477 - val_tp: 54.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 20.0000 - val_accuracy: 0.7821 - val_precision: 0.7397 - val_recall: 0.7297 - val_auc: 0.8755\n",
      "Epoch 467/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6091 - tp: 201.0000 - fp: 99.0000 - tn: 345.0000 - fn: 67.0000 - accuracy: 0.7669 - precision: 0.6700 - recall: 0.7500 - auc: 0.8258 - val_loss: 0.5657 - val_tp: 63.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 11.0000 - val_accuracy: 0.7654 - val_precision: 0.6702 - val_recall: 0.8514 - val_auc: 0.8728\n",
      "Epoch 468/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6051 - tp: 201.0000 - fp: 89.0000 - tn: 355.0000 - fn: 67.0000 - accuracy: 0.7809 - precision: 0.6931 - recall: 0.7500 - auc: 0.8225 - val_loss: 0.7575 - val_tp: 74.0000 - val_fp: 87.0000 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5140 - val_precision: 0.4596 - val_recall: 1.0000 - val_auc: 0.8593\n",
      "Epoch 469/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6057 - tp: 205.0000 - fp: 105.0000 - tn: 339.0000 - fn: 63.0000 - accuracy: 0.7640 - precision: 0.6613 - recall: 0.7649 - auc: 0.8230 - val_loss: 0.5494 - val_tp: 53.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 21.0000 - val_accuracy: 0.7709 - val_precision: 0.7260 - val_recall: 0.7162 - val_auc: 0.8731\n",
      "Epoch 470/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6003 - tp: 199.0000 - fp: 94.0000 - tn: 350.0000 - fn: 69.0000 - accuracy: 0.7711 - precision: 0.6792 - recall: 0.7425 - auc: 0.8232 - val_loss: 0.5624 - val_tp: 52.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 22.0000 - val_accuracy: 0.7821 - val_precision: 0.7536 - val_recall: 0.7027 - val_auc: 0.8753\n",
      "Epoch 471/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5862 - tp: 200.0000 - fp: 89.0000 - tn: 355.0000 - fn: 68.0000 - accuracy: 0.7795 - precision: 0.6920 - recall: 0.7463 - auc: 0.8392 - val_loss: 0.6545 - val_tp: 46.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 28.0000 - val_accuracy: 0.7933 - val_precision: 0.8364 - val_recall: 0.6216 - val_auc: 0.8824\n",
      "Epoch 472/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6140 - tp: 198.0000 - fp: 98.0000 - tn: 346.0000 - fn: 70.0000 - accuracy: 0.7640 - precision: 0.6689 - recall: 0.7388 - auc: 0.8166 - val_loss: 0.5471 - val_tp: 62.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 12.0000 - val_accuracy: 0.7486 - val_precision: 0.6526 - val_recall: 0.8378 - val_auc: 0.8725\n",
      "Epoch 473/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5833 - tp: 204.0000 - fp: 91.0000 - tn: 353.0000 - fn: 64.0000 - accuracy: 0.7823 - precision: 0.6915 - recall: 0.7612 - auc: 0.8367 - val_loss: 0.5451 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8813\n",
      "Epoch 474/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6076 - tp: 197.0000 - fp: 102.0000 - tn: 342.0000 - fn: 71.0000 - accuracy: 0.7570 - precision: 0.6589 - recall: 0.7351 - auc: 0.8191 - val_loss: 0.7458 - val_tp: 74.0000 - val_fp: 97.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4581 - val_precision: 0.4327 - val_recall: 1.0000 - val_auc: 0.8633\n",
      "Epoch 475/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5938 - tp: 209.0000 - fp: 98.0000 - tn: 346.0000 - fn: 59.0000 - accuracy: 0.7795 - precision: 0.6808 - recall: 0.7799 - auc: 0.8419 - val_loss: 0.5805 - val_tp: 51.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 23.0000 - val_accuracy: 0.7877 - val_precision: 0.7727 - val_recall: 0.6892 - val_auc: 0.8818\n",
      "Epoch 476/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6107 - tp: 206.0000 - fp: 98.0000 - tn: 346.0000 - fn: 62.0000 - accuracy: 0.7753 - precision: 0.6776 - recall: 0.7687 - auc: 0.8221 - val_loss: 0.6675 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8571\n",
      "Epoch 477/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6068 - tp: 202.0000 - fp: 104.0000 - tn: 340.0000 - fn: 66.0000 - accuracy: 0.7612 - precision: 0.6601 - recall: 0.7537 - auc: 0.8309 - val_loss: 0.5505 - val_tp: 59.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 15.0000 - val_accuracy: 0.7765 - val_precision: 0.7024 - val_recall: 0.7973 - val_auc: 0.8717\n",
      "Epoch 478/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6029 - tp: 208.0000 - fp: 99.0000 - tn: 345.0000 - fn: 60.0000 - accuracy: 0.7767 - precision: 0.6775 - recall: 0.7761 - auc: 0.8280 - val_loss: 0.8562 - val_tp: 74.0000 - val_fp: 102.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4302 - val_precision: 0.4205 - val_recall: 1.0000 - val_auc: 0.8607\n",
      "Epoch 479/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6195 - tp: 207.0000 - fp: 104.0000 - tn: 340.0000 - fn: 61.0000 - accuracy: 0.7683 - precision: 0.6656 - recall: 0.7724 - auc: 0.8071 - val_loss: 0.5543 - val_tp: 58.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 16.0000 - val_accuracy: 0.7709 - val_precision: 0.6988 - val_recall: 0.7838 - val_auc: 0.8725\n",
      "Epoch 480/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6234 - tp: 200.0000 - fp: 91.0000 - tn: 353.0000 - fn: 68.0000 - accuracy: 0.7767 - precision: 0.6873 - recall: 0.7463 - auc: 0.8095 - val_loss: 0.5439 - val_tp: 59.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 15.0000 - val_accuracy: 0.7709 - val_precision: 0.6941 - val_recall: 0.7973 - val_auc: 0.8736\n",
      "Epoch 481/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5762 - tp: 202.0000 - fp: 86.0000 - tn: 358.0000 - fn: 66.0000 - accuracy: 0.7865 - precision: 0.7014 - recall: 0.7537 - auc: 0.8458 - val_loss: 0.5769 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8736\n",
      "Epoch 482/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6416 - tp: 193.0000 - fp: 91.0000 - tn: 353.0000 - fn: 75.0000 - accuracy: 0.7669 - precision: 0.6796 - recall: 0.7201 - auc: 0.8002 - val_loss: 0.6336 - val_tp: 49.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 25.0000 - val_accuracy: 0.7989 - val_precision: 0.8167 - val_recall: 0.6622 - val_auc: 0.8815\n",
      "Epoch 483/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6034 - tp: 198.0000 - fp: 91.0000 - tn: 353.0000 - fn: 70.0000 - accuracy: 0.7739 - precision: 0.6851 - recall: 0.7388 - auc: 0.8243 - val_loss: 0.5868 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8656\n",
      "Epoch 484/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6033 - tp: 197.0000 - fp: 98.0000 - tn: 346.0000 - fn: 71.0000 - accuracy: 0.7626 - precision: 0.6678 - recall: 0.7351 - auc: 0.8237 - val_loss: 0.5799 - val_tp: 54.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 20.0000 - val_accuracy: 0.7709 - val_precision: 0.7200 - val_recall: 0.7297 - val_auc: 0.8763\n",
      "Epoch 485/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6149 - tp: 196.0000 - fp: 100.0000 - tn: 344.0000 - fn: 72.0000 - accuracy: 0.7584 - precision: 0.6622 - recall: 0.7313 - auc: 0.8156 - val_loss: 0.5561 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8725\n",
      "Epoch 486/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5945 - tp: 202.0000 - fp: 93.0000 - tn: 351.0000 - fn: 66.0000 - accuracy: 0.7767 - precision: 0.6847 - recall: 0.7537 - auc: 0.8288 - val_loss: 0.5566 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8737\n",
      "Epoch 487/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.6101 - tp: 200.0000 - fp: 99.0000 - tn: 345.0000 - fn: 68.0000 - accuracy: 0.7654 - precision: 0.6689 - recall: 0.7463 - auc: 0.8184 - val_loss: 0.5406 - val_tp: 62.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 12.0000 - val_accuracy: 0.7709 - val_precision: 0.6813 - val_recall: 0.8378 - val_auc: 0.8673\n",
      "Epoch 488/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5923 - tp: 202.0000 - fp: 95.0000 - tn: 349.0000 - fn: 66.0000 - accuracy: 0.7739 - precision: 0.6801 - recall: 0.7537 - auc: 0.8319 - val_loss: 0.5935 - val_tp: 50.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 24.0000 - val_accuracy: 0.7933 - val_precision: 0.7937 - val_recall: 0.6757 - val_auc: 0.8856\n",
      "Epoch 489/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5856 - tp: 205.0000 - fp: 79.0000 - tn: 365.0000 - fn: 63.0000 - accuracy: 0.8006 - precision: 0.7218 - recall: 0.7649 - auc: 0.8378 - val_loss: 0.7431 - val_tp: 33.0000 - val_fp: 2.0000 - val_tn: 103.0000 - val_fn: 41.0000 - val_accuracy: 0.7598 - val_precision: 0.9429 - val_recall: 0.4459 - val_auc: 0.8866\n",
      "Epoch 490/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6027 - tp: 188.0000 - fp: 83.0000 - tn: 361.0000 - fn: 80.0000 - accuracy: 0.7711 - precision: 0.6937 - recall: 0.7015 - auc: 0.8200 - val_loss: 0.5804 - val_tp: 52.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 22.0000 - val_accuracy: 0.7989 - val_precision: 0.7879 - val_recall: 0.7027 - val_auc: 0.8840\n",
      "Epoch 491/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6009 - tp: 196.0000 - fp: 79.0000 - tn: 365.0000 - fn: 72.0000 - accuracy: 0.7879 - precision: 0.7127 - recall: 0.7313 - auc: 0.8221 - val_loss: 0.6946 - val_tp: 70.0000 - val_fp: 42.0000 - val_tn: 63.0000 - val_fn: 4.0000 - val_accuracy: 0.7430 - val_precision: 0.6250 - val_recall: 0.9459 - val_auc: 0.8580\n",
      "Epoch 492/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6375 - tp: 197.0000 - fp: 105.0000 - tn: 339.0000 - fn: 71.0000 - accuracy: 0.7528 - precision: 0.6523 - recall: 0.7351 - auc: 0.8029 - val_loss: 0.5498 - val_tp: 60.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 14.0000 - val_accuracy: 0.7654 - val_precision: 0.6818 - val_recall: 0.8108 - val_auc: 0.8716\n",
      "Epoch 493/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5884 - tp: 200.0000 - fp: 86.0000 - tn: 358.0000 - fn: 68.0000 - accuracy: 0.7837 - precision: 0.6993 - recall: 0.7463 - auc: 0.8277 - val_loss: 0.5913 - val_tp: 50.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 24.0000 - val_accuracy: 0.7765 - val_precision: 0.7576 - val_recall: 0.6757 - val_auc: 0.8753\n",
      "Epoch 494/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6104 - tp: 198.0000 - fp: 80.0000 - tn: 364.0000 - fn: 70.0000 - accuracy: 0.7893 - precision: 0.7122 - recall: 0.7388 - auc: 0.8201 - val_loss: 0.5618 - val_tp: 59.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 15.0000 - val_accuracy: 0.7654 - val_precision: 0.6860 - val_recall: 0.7973 - val_auc: 0.8725\n",
      "Epoch 495/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6030 - tp: 205.0000 - fp: 104.0000 - tn: 340.0000 - fn: 63.0000 - accuracy: 0.7654 - precision: 0.6634 - recall: 0.7649 - auc: 0.8249 - val_loss: 0.5431 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8805\n",
      "Epoch 496/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6106 - tp: 201.0000 - fp: 97.0000 - tn: 347.0000 - fn: 67.0000 - accuracy: 0.7697 - precision: 0.6745 - recall: 0.7500 - auc: 0.8164 - val_loss: 0.6322 - val_tp: 70.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 4.0000 - val_accuracy: 0.7765 - val_precision: 0.6604 - val_recall: 0.9459 - val_auc: 0.8671\n",
      "Epoch 497/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6105 - tp: 197.0000 - fp: 90.0000 - tn: 354.0000 - fn: 71.0000 - accuracy: 0.7739 - precision: 0.6864 - recall: 0.7351 - auc: 0.8198 - val_loss: 0.5510 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8805\n",
      "Epoch 498/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6071 - tp: 201.0000 - fp: 81.0000 - tn: 363.0000 - fn: 67.0000 - accuracy: 0.7921 - precision: 0.7128 - recall: 0.7500 - auc: 0.8253 - val_loss: 0.6494 - val_tp: 40.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 34.0000 - val_accuracy: 0.7709 - val_precision: 0.8511 - val_recall: 0.5405 - val_auc: 0.8846\n",
      "Epoch 499/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6159 - tp: 194.0000 - fp: 82.0000 - tn: 362.0000 - fn: 74.0000 - accuracy: 0.7809 - precision: 0.7029 - recall: 0.7239 - auc: 0.8175 - val_loss: 0.6370 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8686\n",
      "Epoch 500/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6195 - tp: 205.0000 - fp: 99.0000 - tn: 345.0000 - fn: 63.0000 - accuracy: 0.7725 - precision: 0.6743 - recall: 0.7649 - auc: 0.8156 - val_loss: 0.5914 - val_tp: 51.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 23.0000 - val_accuracy: 0.7989 - val_precision: 0.7969 - val_recall: 0.6892 - val_auc: 0.8835\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 6276bb95009a5a2911f1df8cd852927d</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7988826632499695</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-batch_size: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_0: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_1: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_2: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_1: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_2: 56</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_0: 0.3500000000000001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_1: 0.3500000000000001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_2: 0.3500000000000001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-epoch_number: 500</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_0: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_1: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_2: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_0: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_1: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_2: 0.1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: RMSprop</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 4s 6ms/sample - loss: 21.9445 - tp: 173.0000 - fp: 276.0000 - tn: 168.0000 - fn: 95.0000 - accuracy: 0.4789 - precision: 0.3853 - recall: 0.6455 - auc: 0.5438 - val_loss: 9.7069 - val_tp: 12.0000 - val_fp: 3.0000 - val_tn: 102.0000 - val_fn: 62.0000 - val_accuracy: 0.6369 - val_precision: 0.8000 - val_recall: 0.1622 - val_auc: 0.6679\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 193us/sample - loss: 5.4842 - tp: 93.0000 - fp: 132.0000 - tn: 312.0000 - fn: 175.0000 - accuracy: 0.5688 - precision: 0.4133 - recall: 0.3470 - auc: 0.4979 - val_loss: 2.5780 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 1.7452 - tp: 4.0000 - fp: 15.0000 - tn: 429.0000 - fn: 264.0000 - accuracy: 0.6081 - precision: 0.2105 - recall: 0.0149 - auc: 0.4576 - val_loss: 1.2007 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 1.0377 - tp: 93.0000 - fp: 172.0000 - tn: 272.0000 - fn: 175.0000 - accuracy: 0.5126 - precision: 0.3509 - recall: 0.3470 - auc: 0.4701 - val_loss: 0.9445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.9045 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4912 - val_loss: 0.9039 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.8856 - tp: 135.0000 - fp: 227.0000 - tn: 217.0000 - fn: 133.0000 - accuracy: 0.4944 - precision: 0.3729 - recall: 0.5037 - auc: 0.4941 - val_loss: 0.8966 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.8788 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4911 - val_loss: 0.8911 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 300us/sample - loss: 0.8765 - tp: 22.0000 - fp: 56.0000 - tn: 388.0000 - fn: 246.0000 - accuracy: 0.5758 - precision: 0.2821 - recall: 0.0821 - auc: 0.4666 - val_loss: 0.8921 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 237us/sample - loss: 0.8787 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - val_loss: 0.8916 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 224us/sample - loss: 0.8780 - tp: 20.0000 - fp: 33.0000 - tn: 411.0000 - fn: 248.0000 - accuracy: 0.6053 - precision: 0.3774 - recall: 0.0746 - auc: 0.4800 - val_loss: 0.8910 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 234us/sample - loss: 0.8793 - tp: 1.0000 - fp: 5.0000 - tn: 439.0000 - fn: 267.0000 - accuracy: 0.6180 - precision: 0.1667 - recall: 0.0037 - auc: 0.4659 - val_loss: 0.8934 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.8808 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4822 - val_loss: 0.8951 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.8834 - tp: 122.0000 - fp: 210.0000 - tn: 234.0000 - fn: 146.0000 - accuracy: 0.5000 - precision: 0.3675 - recall: 0.4552 - auc: 0.4710 - val_loss: 0.8971 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.8843 - tp: 105.0000 - fp: 188.0000 - tn: 256.0000 - fn: 163.0000 - accuracy: 0.5070 - precision: 0.3584 - recall: 0.3918 - auc: 0.4696 - val_loss: 0.8969 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.8835 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4792 - val_loss: 0.8969 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 198us/sample - loss: 0.8848 - tp: 38.0000 - fp: 88.0000 - tn: 356.0000 - fn: 230.0000 - accuracy: 0.5534 - precision: 0.3016 - recall: 0.1418 - auc: 0.4546 - val_loss: 0.9014 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 213us/sample - loss: 0.8878 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4420 - val_loss: 0.8989 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.8887 - tp: 95.0000 - fp: 178.0000 - tn: 266.0000 - fn: 173.0000 - accuracy: 0.5070 - precision: 0.3480 - recall: 0.3545 - auc: 0.4720 - val_loss: 0.8997 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 229us/sample - loss: 0.8867 - tp: 0.0000e+00 - fp: 2.0000 - tn: 442.0000 - fn: 268.0000 - accuracy: 0.6208 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4802 - val_loss: 0.9015 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.8892 - tp: 69.0000 - fp: 118.0000 - tn: 326.0000 - fn: 199.0000 - accuracy: 0.5548 - precision: 0.3690 - recall: 0.2575 - auc: 0.4554 - val_loss: 0.9006 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.8879 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4817 - val_loss: 0.9000 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 211us/sample - loss: 0.8886 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4505 - val_loss: 0.9003 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.8884 - tp: 61.0000 - fp: 108.0000 - tn: 336.0000 - fn: 207.0000 - accuracy: 0.5576 - precision: 0.3609 - recall: 0.2276 - auc: 0.4840 - val_loss: 0.9019 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.8884 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4893 - val_loss: 0.9022 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.8893 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4706 - val_loss: 0.9040 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 213us/sample - loss: 0.8893 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4734 - val_loss: 0.9048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.8890 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4784 - val_loss: 0.9032 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 229us/sample - loss: 0.8898 - tp: 12.0000 - fp: 39.0000 - tn: 405.0000 - fn: 256.0000 - accuracy: 0.5857 - precision: 0.2353 - recall: 0.0448 - auc: 0.4548 - val_loss: 0.8999 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.8896 - tp: 183.0000 - fp: 299.0000 - tn: 145.0000 - fn: 85.0000 - accuracy: 0.4607 - precision: 0.3797 - recall: 0.6828 - auc: 0.4876 - val_loss: 0.9023 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 193us/sample - loss: 0.8900 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4967 - val_loss: 0.9037 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 231us/sample - loss: 0.8895 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4809 - val_loss: 0.9043 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 255us/sample - loss: 0.8907 - tp: 78.0000 - fp: 135.0000 - tn: 309.0000 - fn: 190.0000 - accuracy: 0.5435 - precision: 0.3662 - recall: 0.2910 - auc: 0.4712 - val_loss: 0.9043 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 203us/sample - loss: 0.8906 - tp: 27.0000 - fp: 43.0000 - tn: 401.0000 - fn: 241.0000 - accuracy: 0.6011 - precision: 0.3857 - recall: 0.1007 - auc: 0.4857 - val_loss: 0.9025 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 231us/sample - loss: 0.8905 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4871 - val_loss: 0.9050 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 223us/sample - loss: 0.8919 - tp: 13.0000 - fp: 38.0000 - tn: 406.0000 - fn: 255.0000 - accuracy: 0.5885 - precision: 0.2549 - recall: 0.0485 - auc: 0.4838 - val_loss: 0.9045 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.8926 - tp: 165.0000 - fp: 310.0000 - tn: 134.0000 - fn: 103.0000 - accuracy: 0.4199 - precision: 0.3474 - recall: 0.6157 - auc: 0.4863 - val_loss: 0.9047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.8917 - tp: 22.0000 - fp: 41.0000 - tn: 403.0000 - fn: 246.0000 - accuracy: 0.5969 - precision: 0.3492 - recall: 0.0821 - auc: 0.4574 - val_loss: 0.9081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 200us/sample - loss: 0.8919 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4918 - val_loss: 0.9062 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 212us/sample - loss: 0.8912 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4674 - val_loss: 0.9043 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 205us/sample - loss: 0.8912 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4677 - val_loss: 0.9024 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.8914 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4970 - val_loss: 0.9047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.8926 - tp: 11.0000 - fp: 19.0000 - tn: 425.0000 - fn: 257.0000 - accuracy: 0.6124 - precision: 0.3667 - recall: 0.0410 - auc: 0.4734 - val_loss: 0.9068 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.8923 - tp: 0.0000e+00 - fp: 4.0000 - tn: 440.0000 - fn: 268.0000 - accuracy: 0.6180 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4597 - val_loss: 0.9069 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.8924 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4823 - val_loss: 0.9072 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 193us/sample - loss: 0.8926 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4684 - val_loss: 0.9056 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 253us/sample - loss: 0.8935 - tp: 0.0000e+00 - fp: 1.0000 - tn: 443.0000 - fn: 268.0000 - accuracy: 0.6222 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4674 - val_loss: 0.9048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.8922 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4755 - val_loss: 0.9057 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.8925 - tp: 155.0000 - fp: 248.0000 - tn: 196.0000 - fn: 113.0000 - accuracy: 0.4930 - precision: 0.3846 - recall: 0.5784 - auc: 0.4941 - val_loss: 0.9052 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.8924 - tp: 3.0000 - fp: 8.0000 - tn: 436.0000 - fn: 265.0000 - accuracy: 0.6166 - precision: 0.2727 - recall: 0.0112 - auc: 0.4630 - val_loss: 0.9080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 215us/sample - loss: 0.8938 - tp: 4.0000 - fp: 3.0000 - tn: 441.0000 - fn: 264.0000 - accuracy: 0.6250 - precision: 0.5714 - recall: 0.0149 - auc: 0.4841 - val_loss: 0.9076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 195us/sample - loss: 0.8944 - tp: 45.0000 - fp: 84.0000 - tn: 360.0000 - fn: 223.0000 - accuracy: 0.5688 - precision: 0.3488 - recall: 0.1679 - auc: 0.4841 - val_loss: 0.9068 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 198us/sample - loss: 0.8949 - tp: 32.0000 - fp: 71.0000 - tn: 373.0000 - fn: 236.0000 - accuracy: 0.5688 - precision: 0.3107 - recall: 0.1194 - auc: 0.4689 - val_loss: 0.9062 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.8935 - tp: 56.0000 - fp: 100.0000 - tn: 344.0000 - fn: 212.0000 - accuracy: 0.5618 - precision: 0.3590 - recall: 0.2090 - auc: 0.4832 - val_loss: 0.9043 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.8930 - tp: 16.0000 - fp: 34.0000 - tn: 410.0000 - fn: 252.0000 - accuracy: 0.5983 - precision: 0.3200 - recall: 0.0597 - auc: 0.4536 - val_loss: 0.9060 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 197us/sample - loss: 0.8929 - tp: 105.0000 - fp: 195.0000 - tn: 249.0000 - fn: 163.0000 - accuracy: 0.4972 - precision: 0.3500 - recall: 0.3918 - auc: 0.4912 - val_loss: 0.9074 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.8932 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4524 - val_loss: 0.9062 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 197us/sample - loss: 0.8934 - tp: 0.0000e+00 - fp: 1.0000 - tn: 443.0000 - fn: 268.0000 - accuracy: 0.6222 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4729 - val_loss: 0.9046 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 58/500\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.8928 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4776 - val_loss: 0.9047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 59/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.8934 - tp: 1.0000 - fp: 1.0000 - tn: 443.0000 - fn: 267.0000 - accuracy: 0.6236 - precision: 0.5000 - recall: 0.0037 - auc: 0.4749 - val_loss: 0.9073 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 60/500\n",
      "712/712 [==============================] - 0s 203us/sample - loss: 0.8929 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4836 - val_loss: 0.9071 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 61/500\n",
      "712/712 [==============================] - 0s 221us/sample - loss: 0.8927 - tp: 4.0000 - fp: 6.0000 - tn: 438.0000 - fn: 264.0000 - accuracy: 0.6208 - precision: 0.4000 - recall: 0.0149 - auc: 0.4568 - val_loss: 0.9067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 62/500\n",
      "712/712 [==============================] - 0s 200us/sample - loss: 0.8931 - tp: 4.0000 - fp: 10.0000 - tn: 434.0000 - fn: 264.0000 - accuracy: 0.6152 - precision: 0.2857 - recall: 0.0149 - auc: 0.4745 - val_loss: 0.9085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 63/500\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.8946 - tp: 5.0000 - fp: 13.0000 - tn: 431.0000 - fn: 263.0000 - accuracy: 0.6124 - precision: 0.2778 - recall: 0.0187 - auc: 0.4879 - val_loss: 0.9086 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 64/500\n",
      "712/712 [==============================] - 0s 200us/sample - loss: 0.8944 - tp: 1.0000 - fp: 4.0000 - tn: 440.0000 - fn: 267.0000 - accuracy: 0.6194 - precision: 0.2000 - recall: 0.0037 - auc: 0.5019 - val_loss: 0.9078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 65/500\n",
      "712/712 [==============================] - 0s 217us/sample - loss: 0.8945 - tp: 37.0000 - fp: 65.0000 - tn: 379.0000 - fn: 231.0000 - accuracy: 0.5843 - precision: 0.3627 - recall: 0.1381 - auc: 0.5026 - val_loss: 0.9066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 66/500\n",
      "712/712 [==============================] - 0s 214us/sample - loss: 0.8937 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4633 - val_loss: 0.9082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 67/500\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.8942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4797 - val_loss: 0.9103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 68/500\n",
      "712/712 [==============================] - 0s 211us/sample - loss: 0.8947 - tp: 94.0000 - fp: 158.0000 - tn: 286.0000 - fn: 174.0000 - accuracy: 0.5337 - precision: 0.3730 - recall: 0.3507 - auc: 0.5169 - val_loss: 0.9066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 69/500\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.8945 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4468 - val_loss: 0.9066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 70/500\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.8941 - tp: 5.0000 - fp: 16.0000 - tn: 428.0000 - fn: 263.0000 - accuracy: 0.6081 - precision: 0.2381 - recall: 0.0187 - auc: 0.4565 - val_loss: 0.9073 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 71/500\n",
      "712/712 [==============================] - 0s 192us/sample - loss: 0.8942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4631 - val_loss: 0.9070 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 72/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.8940 - tp: 2.0000 - fp: 13.0000 - tn: 431.0000 - fn: 266.0000 - accuracy: 0.6081 - precision: 0.1333 - recall: 0.0075 - auc: 0.4695 - val_loss: 0.9078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 73/500\n",
      "712/712 [==============================] - 0s 214us/sample - loss: 0.8945 - tp: 13.0000 - fp: 22.0000 - tn: 422.0000 - fn: 255.0000 - accuracy: 0.6110 - precision: 0.3714 - recall: 0.0485 - auc: 0.4793 - val_loss: 0.9093 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 74/500\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.8959 - tp: 89.0000 - fp: 167.0000 - tn: 277.0000 - fn: 179.0000 - accuracy: 0.5140 - precision: 0.3477 - recall: 0.3321 - auc: 0.4725 - val_loss: 0.9123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 75/500\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.8955 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4890 - val_loss: 0.9084 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 76/500\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.8954 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4838 - val_loss: 0.9075 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 77/500\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.8947 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4742 - val_loss: 0.9092 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 78/500\n",
      "712/712 [==============================] - 0s 197us/sample - loss: 0.8942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - val_loss: 0.9085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 79/500\n",
      "712/712 [==============================] - 0s 193us/sample - loss: 0.8957 - tp: 89.0000 - fp: 161.0000 - tn: 283.0000 - fn: 179.0000 - accuracy: 0.5225 - precision: 0.3560 - recall: 0.3321 - auc: 0.4740 - val_loss: 0.9085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 80/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.8942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4777 - val_loss: 0.9075 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 81/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.8944 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4620 - val_loss: 0.9080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 82/500\n",
      "712/712 [==============================] - 0s 197us/sample - loss: 0.8947 - tp: 14.0000 - fp: 33.0000 - tn: 411.0000 - fn: 254.0000 - accuracy: 0.5969 - precision: 0.2979 - recall: 0.0522 - auc: 0.4812 - val_loss: 0.9083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 83/500\n",
      "712/712 [==============================] - 0s 199us/sample - loss: 0.8938 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4944 - val_loss: 0.9071 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 84/500\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.8946 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4680 - val_loss: 0.9092 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 85/500\n",
      "712/712 [==============================] - 0s 211us/sample - loss: 0.8942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5234 - val_loss: 0.9091 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 86/500\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.8940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4849 - val_loss: 0.9083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 87/500\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.8942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4794 - val_loss: 0.9084 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 88/500\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.8955 - tp: 63.0000 - fp: 124.0000 - tn: 320.0000 - fn: 205.0000 - accuracy: 0.5379 - precision: 0.3369 - recall: 0.2351 - auc: 0.4783 - val_loss: 0.9074 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 89/500\n",
      "712/712 [==============================] - 0s 192us/sample - loss: 0.8953 - tp: 107.0000 - fp: 180.0000 - tn: 264.0000 - fn: 161.0000 - accuracy: 0.5211 - precision: 0.3728 - recall: 0.3993 - auc: 0.5196 - val_loss: 0.9075 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 90/500\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.8945 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4703 - val_loss: 0.9069 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 91/500\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.8943 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4792 - val_loss: 0.9092 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 92/500\n",
      "712/712 [==============================] - 0s 192us/sample - loss: 0.8948 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4876 - val_loss: 0.9088 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 93/500\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.8942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4688 - val_loss: 0.9060 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 94/500\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.8944 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4671 - val_loss: 0.9071 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 95/500\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.8953 - tp: 70.0000 - fp: 125.0000 - tn: 319.0000 - fn: 198.0000 - accuracy: 0.5463 - precision: 0.3590 - recall: 0.2612 - auc: 0.4736 - val_loss: 0.9098 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 96/500\n",
      "712/712 [==============================] - 0s 205us/sample - loss: 0.8960 - tp: 68.0000 - fp: 135.0000 - tn: 309.0000 - fn: 200.0000 - accuracy: 0.5295 - precision: 0.3350 - recall: 0.2537 - auc: 0.4955 - val_loss: 0.9083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 97/500\n",
      "712/712 [==============================] - 0s 206us/sample - loss: 0.8947 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4492 - val_loss: 0.9084 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 98/500\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.8944 - tp: 17.0000 - fp: 47.0000 - tn: 397.0000 - fn: 251.0000 - accuracy: 0.5815 - precision: 0.2656 - recall: 0.0634 - auc: 0.4834 - val_loss: 0.9088 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 99/500\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.8943 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4815 - val_loss: 0.9085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 100/500\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.8952 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4694 - val_loss: 0.9062 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 101/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.8942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4842 - val_loss: 0.9057 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 102/500\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.8944 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4648 - val_loss: 0.9100 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 103/500\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.8951 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4654 - val_loss: 0.9088 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 104/500\n",
      "712/712 [==============================] - 0s 199us/sample - loss: 0.8947 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5023 - val_loss: 0.9075 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 105/500\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.8954 - tp: 14.0000 - fp: 46.0000 - tn: 398.0000 - fn: 254.0000 - accuracy: 0.5787 - precision: 0.2333 - recall: 0.0522 - auc: 0.4827 - val_loss: 0.9072 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 106/500\n",
      "712/712 [==============================] - 0s 214us/sample - loss: 0.8957 - tp: 42.0000 - fp: 99.0000 - tn: 345.0000 - fn: 226.0000 - accuracy: 0.5435 - precision: 0.2979 - recall: 0.1567 - auc: 0.4760 - val_loss: 0.9074 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 107/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.8945 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4814 - val_loss: 0.9078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 108/500\n",
      "712/712 [==============================] - 0s 199us/sample - loss: 0.8944 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4725 - val_loss: 0.9068 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 109/500\n",
      "712/712 [==============================] - 0s 216us/sample - loss: 0.8945 - tp: 4.0000 - fp: 9.0000 - tn: 435.0000 - fn: 264.0000 - accuracy: 0.6166 - precision: 0.3077 - recall: 0.0149 - auc: 0.4815 - val_loss: 0.9102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 110/500\n",
      "712/712 [==============================] - 0s 207us/sample - loss: 0.8951 - tp: 74.0000 - fp: 134.0000 - tn: 310.0000 - fn: 194.0000 - accuracy: 0.5393 - precision: 0.3558 - recall: 0.2761 - auc: 0.4901 - val_loss: 0.9090 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 111/500\n",
      "712/712 [==============================] - 0s 200us/sample - loss: 0.8945 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4883 - val_loss: 0.9063 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 112/500\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.8953 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4370 - val_loss: 0.9085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 113/500\n",
      "712/712 [==============================] - 0s 195us/sample - loss: 0.8951 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4586 - val_loss: 0.9077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 114/500\n",
      "712/712 [==============================] - 0s 193us/sample - loss: 0.8944 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4925 - val_loss: 0.9094 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 115/500\n",
      "712/712 [==============================] - 0s 202us/sample - loss: 0.8951 - tp: 5.0000 - fp: 14.0000 - tn: 430.0000 - fn: 263.0000 - accuracy: 0.6110 - precision: 0.2632 - recall: 0.0187 - auc: 0.4771 - val_loss: 0.9088 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 116/500\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.8948 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4874 - val_loss: 0.9093 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 117/500\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.8948 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4932 - val_loss: 0.9103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 118/500\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.8951 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4746 - val_loss: 0.9074 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 119/500\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.8948 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4859 - val_loss: 0.9073 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 120/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.8944 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4697 - val_loss: 0.9091 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 121/500\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.8947 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4759 - val_loss: 0.9100 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 122/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.8952 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4375 - val_loss: 0.9095 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 123/500\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.8947 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4962 - val_loss: 0.9074 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 124/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.8947 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4773 - val_loss: 0.9082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 125/500\n",
      "712/712 [==============================] - 0s 192us/sample - loss: 0.8946 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4919 - val_loss: 0.9067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 126/500\n",
      "712/712 [==============================] - 0s 193us/sample - loss: 0.8942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4630 - val_loss: 0.9088 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 127/500\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.8943 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4835 - val_loss: 0.9112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 128/500\n",
      "712/712 [==============================] - 0s 192us/sample - loss: 0.8949 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.9076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 129/500\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.8950 - tp: 12.0000 - fp: 43.0000 - tn: 401.0000 - fn: 256.0000 - accuracy: 0.5801 - precision: 0.2182 - recall: 0.0448 - auc: 0.4688 - val_loss: 0.9066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 130/500\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.8952 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4861 - val_loss: 0.9073 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 131/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7075 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 111/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5019 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 112/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4581 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 113/600\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5005 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 114/600\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4859 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 115/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5016 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 116/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4817 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 117/600\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4740 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 118/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 119/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4694 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 120/600\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4805 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 121/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4858 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 122/600\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4964 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 123/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4834 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 124/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4917 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 125/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4759 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 126/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 127/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 128/600\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 129/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4805 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 130/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5004 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 131/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4977 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 132/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4708 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 133/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4765 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 134/600\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 135/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4664 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 136/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4614 - val_loss: 0.7075 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 137/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 138/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4985 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 139/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4782 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 140/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 141/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4853 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 142/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4934 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 143/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4888 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 144/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4914 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 145/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4837 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 146/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 147/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 148/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4875 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 149/600\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4879 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 150/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4816 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 151/600\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4840 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 152/600\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4914 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 153/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4735 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 154/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4973 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 155/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4682 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 156/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4792 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 157/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 158/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 159/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4848 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 160/600\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4920 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 161/600\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4746 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 162/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4919 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 163/600\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4969 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 164/600\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4851 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 165/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4947 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 166/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4976 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 167/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4880 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 168/600\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4911 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 169/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4961 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 170/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4939 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 171/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4874 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 172/600\n",
      "712/712 [==============================] - 0s 204us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 173/600\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 174/600\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4902 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 175/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 176/600\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 177/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 178/600\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 179/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 180/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 181/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 182/600\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 183/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4934 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 184/600\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 185/600\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4864 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 186/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 187/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 188/600\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 189/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 190/600\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4875 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 191/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 192/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4845 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 193/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4828 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 194/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 195/600\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 196/600\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 197/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 198/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 199/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 200/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 201/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 202/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 203/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 204/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 205/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 206/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 207/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 208/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 209/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 210/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 211/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 212/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 213/600\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 214/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 215/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 216/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 217/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 218/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 219/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 220/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 221/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 222/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 223/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 224/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 225/600\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 226/600\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 227/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 228/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4978 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 229/600\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 230/600\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4861 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 231/600\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4875 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 232/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4860 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 233/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 234/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 235/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 236/600\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4802 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 237/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4695 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 238/600\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 239/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4931 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 240/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 241/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 242/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 243/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 244/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 245/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4898 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 246/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 247/600\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 248/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 249/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 250/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 251/600\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 252/600\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 253/600\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 254/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 255/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 256/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 257/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 258/600\n",
      "712/712 [==============================] - 0s 197us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 259/600\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 260/600\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 261/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 262/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 263/600\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 264/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4992 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 265/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4937 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 266/600\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4932 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 267/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 268/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 269/600\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 270/600\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 271/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 272/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 273/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4848 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 274/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4939 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 275/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 276/600\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 277/600\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4904 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 278/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 279/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4909 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 280/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 281/600\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4831 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 282/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4849 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 283/600\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5041 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 284/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 285/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 286/600\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 287/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4915 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 288/600\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4739 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 289/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4935 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 290/600\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 291/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4788 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 292/600\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4862 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 293/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4877 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 294/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4775 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 295/600\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4728 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 296/600\n",
      "712/712 [==============================] - 0s 213us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4955 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 297/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 298/600\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4840 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 299/600\n",
      "712/712 [==============================] - 0s 201us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 300/600\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 301/600\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4938 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 302/600\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 303/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 304/600\n",
      "712/712 [==============================] - 0s 192us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 305/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 306/600\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 307/600\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 308/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 309/600\n",
      "712/712 [==============================] - 0s 201us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 310/600\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 311/600\n",
      "712/712 [==============================] - 0s 199us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4781 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 312/600\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 313/600\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 314/600\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 315/600\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5001 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 316/600\n",
      "712/712 [==============================] - 0s 200us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4879 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 317/600\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 318/600\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 319/600\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 320/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 321/600\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 322/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 323/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 324/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 325/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 326/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 327/600\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 328/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 329/600\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 330/600\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 331/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 332/600\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 333/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4934 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 334/600\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 335/600\n",
      "712/712 [==============================] - 0s 192us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4939 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 336/600\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4958 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 337/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4836 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 338/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4864 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 339/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4955 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 340/600\n",
      "712/712 [==============================] - 0s 316us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4987 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 341/600\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5019 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 342/600\n",
      "712/712 [==============================] - 0s 210us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4653 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 343/600\n",
      "712/712 [==============================] - 0s 226us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4694 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 344/600\n",
      "712/712 [==============================] - 0s 254us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 345/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4690 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 346/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4963 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 347/600\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4454 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 348/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4862 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 349/600\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 350/600\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 351/600\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 352/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 353/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4969 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 354/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 355/600\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 356/600\n",
      "712/712 [==============================] - 0s 195us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 357/600\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4883 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 358/600\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 359/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 360/600\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 361/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 362/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 363/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 364/600\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 365/600\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 366/600\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 367/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 368/600\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 369/600\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 370/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 371/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 372/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 373/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 374/600\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 375/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 376/600\n",
      "712/712 [==============================] - 0s 202us/sample - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 377/600\n",
      "712/712 [==============================] - 0s 200us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 378/600\n",
      "712/712 [==============================] - 0s 199us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 379/600\n",
      "712/712 [==============================] - 0s 221us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 380/600\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 381/600\n",
      "712/712 [==============================] - 0s 214us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 382/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 383/600\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 384/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 385/600\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 386/600\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 387/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 388/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4879 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 389/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 390/600\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4819 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 391/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 392/600\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4969 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 393/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4845 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 394/600\n",
      "712/712 [==============================] - 0s 202us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4681 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 395/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4888 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 396/600\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4812 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 397/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4820 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 398/600\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4533 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 399/600\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4908 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 400/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4725 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 401/600\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4739 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 402/600\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4947 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 403/600\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 404/600\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4909 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 405/600\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4819 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 406/600\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4886 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 407/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4866 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 408/600\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4863 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 409/600\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4897 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 410/600\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4918 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 411/600\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4883 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 412/600\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4942 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 413/600\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 414/600\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4922 - val_loss: 0.7075 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 415/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4913 - val_loss: 0.7075 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6469 - tp: 196.0000 - fp: 90.0000 - tn: 354.0000 - fn: 72.0000 - accuracy: 0.7725 - precision: 0.6853 - recall: 0.7313 - auc: 0.8207 - val_loss: 0.5892 - val_tp: 55.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 19.0000 - val_accuracy: 0.7933 - val_precision: 0.7534 - val_recall: 0.7432 - val_auc: 0.8844\n",
      "Epoch 565/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6641 - tp: 203.0000 - fp: 112.0000 - tn: 332.0000 - fn: 65.0000 - accuracy: 0.7514 - precision: 0.6444 - recall: 0.7575 - auc: 0.8028 - val_loss: 0.5973 - val_tp: 59.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 15.0000 - val_accuracy: 0.7765 - val_precision: 0.7024 - val_recall: 0.7973 - val_auc: 0.8764\n",
      "Epoch 566/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6340 - tp: 205.0000 - fp: 84.0000 - tn: 360.0000 - fn: 63.0000 - accuracy: 0.7935 - precision: 0.7093 - recall: 0.7649 - auc: 0.8302 - val_loss: 0.5874 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8766\n",
      "Epoch 567/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6376 - tp: 207.0000 - fp: 106.0000 - tn: 338.0000 - fn: 61.0000 - accuracy: 0.7654 - precision: 0.6613 - recall: 0.7724 - auc: 0.8255 - val_loss: 0.6130 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8783\n",
      "Epoch 568/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6564 - tp: 200.0000 - fp: 87.0000 - tn: 357.0000 - fn: 68.0000 - accuracy: 0.7823 - precision: 0.6969 - recall: 0.7463 - auc: 0.8140 - val_loss: 0.6494 - val_tp: 49.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 25.0000 - val_accuracy: 0.7989 - val_precision: 0.8167 - val_recall: 0.6622 - val_auc: 0.8890\n",
      "Epoch 569/600\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.6645 - tp: 187.0000 - fp: 82.0000 - tn: 362.0000 - fn: 81.0000 - accuracy: 0.7711 - precision: 0.6952 - recall: 0.6978 - auc: 0.8134 - val_loss: 0.6279 - val_tp: 53.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 21.0000 - val_accuracy: 0.8045 - val_precision: 0.7910 - val_recall: 0.7162 - val_auc: 0.8813\n",
      "Epoch 570/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6533 - tp: 191.0000 - fp: 90.0000 - tn: 354.0000 - fn: 77.0000 - accuracy: 0.7654 - precision: 0.6797 - recall: 0.7127 - auc: 0.8281 - val_loss: 0.6716 - val_tp: 59.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 15.0000 - val_accuracy: 0.7765 - val_precision: 0.7024 - val_recall: 0.7973 - val_auc: 0.8761\n",
      "Epoch 571/600\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6898 - tp: 209.0000 - fp: 114.0000 - tn: 330.0000 - fn: 59.0000 - accuracy: 0.7570 - precision: 0.6471 - recall: 0.7799 - auc: 0.8060 - val_loss: 0.6089 - val_tp: 58.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 16.0000 - val_accuracy: 0.7654 - val_precision: 0.6905 - val_recall: 0.7838 - val_auc: 0.8803\n",
      "Epoch 572/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6523 - tp: 204.0000 - fp: 99.0000 - tn: 345.0000 - fn: 64.0000 - accuracy: 0.7711 - precision: 0.6733 - recall: 0.7612 - auc: 0.8197 - val_loss: 0.6602 - val_tp: 65.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 9.0000 - val_accuracy: 0.7430 - val_precision: 0.6373 - val_recall: 0.8784 - val_auc: 0.8724\n",
      "Epoch 573/600\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.6737 - tp: 207.0000 - fp: 108.0000 - tn: 336.0000 - fn: 61.0000 - accuracy: 0.7626 - precision: 0.6571 - recall: 0.7724 - auc: 0.8150 - val_loss: 0.6581 - val_tp: 49.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 25.0000 - val_accuracy: 0.7877 - val_precision: 0.7903 - val_recall: 0.6622 - val_auc: 0.8824\n",
      "Epoch 574/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6657 - tp: 203.0000 - fp: 96.0000 - tn: 348.0000 - fn: 65.0000 - accuracy: 0.7739 - precision: 0.6789 - recall: 0.7575 - auc: 0.8197 - val_loss: 0.6168 - val_tp: 50.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 24.0000 - val_accuracy: 0.7765 - val_precision: 0.7576 - val_recall: 0.6757 - val_auc: 0.8804\n",
      "Epoch 575/600\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.6782 - tp: 206.0000 - fp: 123.0000 - tn: 321.0000 - fn: 62.0000 - accuracy: 0.7402 - precision: 0.6261 - recall: 0.7687 - auc: 0.8132 - val_loss: 0.6526 - val_tp: 64.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 10.0000 - val_accuracy: 0.7374 - val_precision: 0.6337 - val_recall: 0.8649 - val_auc: 0.8729\n",
      "Epoch 576/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6734 - tp: 195.0000 - fp: 90.0000 - tn: 354.0000 - fn: 73.0000 - accuracy: 0.7711 - precision: 0.6842 - recall: 0.7276 - auc: 0.8060 - val_loss: 0.6043 - val_tp: 61.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 13.0000 - val_accuracy: 0.7709 - val_precision: 0.6854 - val_recall: 0.8243 - val_auc: 0.8723\n",
      "Epoch 577/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7286 - tp: 175.0000 - fp: 117.0000 - tn: 327.0000 - fn: 93.0000 - accuracy: 0.7051 - precision: 0.5993 - recall: 0.6530 - auc: 0.7506 - val_loss: 0.6211 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8736\n",
      "Epoch 578/600\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6994 - tp: 198.0000 - fp: 91.0000 - tn: 353.0000 - fn: 70.0000 - accuracy: 0.7739 - precision: 0.6851 - recall: 0.7388 - auc: 0.7945 - val_loss: 0.6043 - val_tp: 54.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 20.0000 - val_accuracy: 0.7765 - val_precision: 0.7297 - val_recall: 0.7297 - val_auc: 0.8801\n",
      "Epoch 579/600\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6947 - tp: 205.0000 - fp: 95.0000 - tn: 349.0000 - fn: 63.0000 - accuracy: 0.7781 - precision: 0.6833 - recall: 0.7649 - auc: 0.8083 - val_loss: 0.6192 - val_tp: 54.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 20.0000 - val_accuracy: 0.7877 - val_precision: 0.7500 - val_recall: 0.7297 - val_auc: 0.8815\n",
      "Epoch 580/600\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6599 - tp: 197.0000 - fp: 99.0000 - tn: 345.0000 - fn: 71.0000 - accuracy: 0.7612 - precision: 0.6655 - recall: 0.7351 - auc: 0.8229 - val_loss: 0.6214 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8773\n",
      "Epoch 581/600\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6957 - tp: 186.0000 - fp: 96.0000 - tn: 348.0000 - fn: 82.0000 - accuracy: 0.7500 - precision: 0.6596 - recall: 0.6940 - auc: 0.7908 - val_loss: 0.6370 - val_tp: 67.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 7.0000 - val_accuracy: 0.7654 - val_precision: 0.6569 - val_recall: 0.9054 - val_auc: 0.8573\n",
      "Epoch 582/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6818 - tp: 200.0000 - fp: 99.0000 - tn: 345.0000 - fn: 68.0000 - accuracy: 0.7654 - precision: 0.6689 - recall: 0.7463 - auc: 0.8124 - val_loss: 0.6423 - val_tp: 54.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 20.0000 - val_accuracy: 0.7877 - val_precision: 0.7500 - val_recall: 0.7297 - val_auc: 0.8782\n",
      "Epoch 583/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.7142 - tp: 186.0000 - fp: 80.0000 - tn: 364.0000 - fn: 82.0000 - accuracy: 0.7725 - precision: 0.6992 - recall: 0.6940 - auc: 0.8001 - val_loss: 0.6804 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8722\n",
      "Epoch 584/600\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.7208 - tp: 195.0000 - fp: 119.0000 - tn: 325.0000 - fn: 73.0000 - accuracy: 0.7303 - precision: 0.6210 - recall: 0.7276 - auc: 0.7821 - val_loss: 0.6435 - val_tp: 52.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 22.0000 - val_accuracy: 0.7821 - val_precision: 0.7536 - val_recall: 0.7027 - val_auc: 0.8782\n",
      "Epoch 585/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6926 - tp: 203.0000 - fp: 91.0000 - tn: 353.0000 - fn: 65.0000 - accuracy: 0.7809 - precision: 0.6905 - recall: 0.7575 - auc: 0.8048 - val_loss: 0.6175 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8819\n",
      "Epoch 586/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6675 - tp: 200.0000 - fp: 99.0000 - tn: 345.0000 - fn: 68.0000 - accuracy: 0.7654 - precision: 0.6689 - recall: 0.7463 - auc: 0.8109 - val_loss: 0.6370 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8712\n",
      "Epoch 587/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6491 - tp: 194.0000 - fp: 79.0000 - tn: 365.0000 - fn: 74.0000 - accuracy: 0.7851 - precision: 0.7106 - recall: 0.7239 - auc: 0.8221 - val_loss: 0.6284 - val_tp: 49.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 25.0000 - val_accuracy: 0.7709 - val_precision: 0.7538 - val_recall: 0.6622 - val_auc: 0.8753\n",
      "Epoch 588/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6557 - tp: 204.0000 - fp: 102.0000 - tn: 342.0000 - fn: 64.0000 - accuracy: 0.7669 - precision: 0.6667 - recall: 0.7612 - auc: 0.8209 - val_loss: 0.6145 - val_tp: 52.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 22.0000 - val_accuracy: 0.7877 - val_precision: 0.7647 - val_recall: 0.7027 - val_auc: 0.8809\n",
      "Epoch 589/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6962 - tp: 175.0000 - fp: 85.0000 - tn: 359.0000 - fn: 93.0000 - accuracy: 0.7500 - precision: 0.6731 - recall: 0.6530 - auc: 0.8001 - val_loss: 0.6157 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8792\n",
      "Epoch 590/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.7150 - tp: 198.0000 - fp: 115.0000 - tn: 329.0000 - fn: 70.0000 - accuracy: 0.7402 - precision: 0.6326 - recall: 0.7388 - auc: 0.7910 - val_loss: 0.6198 - val_tp: 63.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 11.0000 - val_accuracy: 0.7654 - val_precision: 0.6702 - val_recall: 0.8514 - val_auc: 0.8813\n",
      "Epoch 591/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6961 - tp: 203.0000 - fp: 117.0000 - tn: 327.0000 - fn: 65.0000 - accuracy: 0.7444 - precision: 0.6344 - recall: 0.7575 - auc: 0.7889 - val_loss: 0.6005 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8822\n",
      "Epoch 592/600\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6777 - tp: 204.0000 - fp: 102.0000 - tn: 342.0000 - fn: 64.0000 - accuracy: 0.7669 - precision: 0.6667 - recall: 0.7612 - auc: 0.8093 - val_loss: 0.5998 - val_tp: 63.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 11.0000 - val_accuracy: 0.8045 - val_precision: 0.7241 - val_recall: 0.8514 - val_auc: 0.8793\n",
      "Epoch 593/600\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6482 - tp: 208.0000 - fp: 97.0000 - tn: 347.0000 - fn: 60.0000 - accuracy: 0.7795 - precision: 0.6820 - recall: 0.7761 - auc: 0.8229 - val_loss: 0.5965 - val_tp: 58.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 16.0000 - val_accuracy: 0.7709 - val_precision: 0.6988 - val_recall: 0.7838 - val_auc: 0.8779\n",
      "Epoch 594/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6244 - tp: 200.0000 - fp: 87.0000 - tn: 357.0000 - fn: 68.0000 - accuracy: 0.7823 - precision: 0.6969 - recall: 0.7463 - auc: 0.8400 - val_loss: 0.5867 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8840\n",
      "Epoch 595/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6550 - tp: 207.0000 - fp: 101.0000 - tn: 343.0000 - fn: 61.0000 - accuracy: 0.7725 - precision: 0.6721 - recall: 0.7724 - auc: 0.8180 - val_loss: 0.5929 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8795\n",
      "Epoch 596/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6263 - tp: 196.0000 - fp: 85.0000 - tn: 359.0000 - fn: 72.0000 - accuracy: 0.7795 - precision: 0.6975 - recall: 0.7313 - auc: 0.8309 - val_loss: 0.6007 - val_tp: 64.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 10.0000 - val_accuracy: 0.7486 - val_precision: 0.6465 - val_recall: 0.8649 - val_auc: 0.8723\n",
      "Epoch 597/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6571 - tp: 206.0000 - fp: 105.0000 - tn: 339.0000 - fn: 62.0000 - accuracy: 0.7654 - precision: 0.6624 - recall: 0.7687 - auc: 0.8185 - val_loss: 0.6030 - val_tp: 53.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 21.0000 - val_accuracy: 0.7933 - val_precision: 0.7681 - val_recall: 0.7162 - val_auc: 0.8871\n",
      "Epoch 598/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7053 - tp: 198.0000 - fp: 99.0000 - tn: 345.0000 - fn: 70.0000 - accuracy: 0.7626 - precision: 0.6667 - recall: 0.7388 - auc: 0.7881 - val_loss: 0.6392 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8728\n",
      "Epoch 599/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6498 - tp: 198.0000 - fp: 76.0000 - tn: 368.0000 - fn: 70.0000 - accuracy: 0.7949 - precision: 0.7226 - recall: 0.7388 - auc: 0.8259 - val_loss: 0.5952 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8880\n",
      "Epoch 600/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6582 - tp: 196.0000 - fp: 101.0000 - tn: 343.0000 - fn: 72.0000 - accuracy: 0.7570 - precision: 0.6599 - recall: 0.7313 - auc: 0.8156 - val_loss: 0.5949 - val_tp: 61.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 13.0000 - val_accuracy: 0.7486 - val_precision: 0.6559 - val_recall: 0.8243 - val_auc: 0.8822\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 81d69c5047b85ed7eea55f1b65bd39da</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.748603343963623</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-batch_size: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_0: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_1: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_2: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_3: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_4: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_5: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_6: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_0: 40</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_1: 56</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_2: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_3: 24</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_4: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_5: 48</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_6: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_0: 0.45000000000000007</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_1: 0.40000000000000013</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_2: 0.15</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_3: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_4: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_5: 0.45000000000000007</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_6: 0.2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-epoch_number: 600</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_0: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_1: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_2: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_3: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_4: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_5: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_6: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_0: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_1: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_2: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_3: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_4: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_5: 0.1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_6: 0.1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_layers: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 4s 6ms/sample - loss: 5.2219 - tp: 109.0000 - fp: 159.0000 - tn: 285.0000 - fn: 159.0000 - accuracy: 0.5534 - precision: 0.4067 - recall: 0.4067 - auc: 0.5496 - val_loss: 2.5248 - val_tp: 35.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 39.0000 - val_accuracy: 0.7095 - val_precision: 0.7292 - val_recall: 0.4730 - val_auc: 0.8295\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 1.8127 - tp: 118.0000 - fp: 126.0000 - tn: 318.0000 - fn: 150.0000 - accuracy: 0.6124 - precision: 0.4836 - recall: 0.4403 - auc: 0.5948 - val_loss: 1.2434 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7687\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.9827 - tp: 11.0000 - fp: 4.0000 - tn: 440.0000 - fn: 257.0000 - accuracy: 0.6334 - precision: 0.7333 - recall: 0.0410 - auc: 0.4862 - val_loss: 0.8190 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.7648 - tp: 158.0000 - fp: 295.0000 - tn: 149.0000 - fn: 110.0000 - accuracy: 0.4312 - precision: 0.3488 - recall: 0.5896 - auc: 0.4596 - val_loss: 0.7416 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.7157 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4950 - val_loss: 0.7184 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.7061 - tp: 235.0000 - fp: 392.0000 - tn: 52.0000 - fn: 33.0000 - accuracy: 0.4031 - precision: 0.3748 - recall: 0.8769 - auc: 0.4970 - val_loss: 0.7169 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.7016 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5127 - val_loss: 0.7133 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.7020 - tp: 241.0000 - fp: 408.0000 - tn: 36.0000 - fn: 27.0000 - accuracy: 0.3890 - precision: 0.3713 - recall: 0.8993 - auc: 0.4795 - val_loss: 0.7127 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.7012 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4895 - val_loss: 0.7125 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.7007 - tp: 152.0000 - fp: 271.0000 - tn: 173.0000 - fn: 116.0000 - accuracy: 0.4565 - precision: 0.3593 - recall: 0.5672 - auc: 0.4641 - val_loss: 0.7139 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6991 - tp: 13.0000 - fp: 24.0000 - tn: 420.0000 - fn: 255.0000 - accuracy: 0.6081 - precision: 0.3514 - recall: 0.0485 - auc: 0.5053 - val_loss: 0.7117 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6997 - tp: 161.0000 - fp: 275.0000 - tn: 169.0000 - fn: 107.0000 - accuracy: 0.4635 - precision: 0.3693 - recall: 0.6007 - auc: 0.4760 - val_loss: 0.7132 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.7001 - tp: 92.0000 - fp: 173.0000 - tn: 271.0000 - fn: 176.0000 - accuracy: 0.5098 - precision: 0.3472 - recall: 0.3433 - auc: 0.4577 - val_loss: 0.7129 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6997 - tp: 185.0000 - fp: 319.0000 - tn: 125.0000 - fn: 83.0000 - accuracy: 0.4354 - precision: 0.3671 - recall: 0.6903 - auc: 0.4786 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6998 - tp: 3.0000 - fp: 11.0000 - tn: 433.0000 - fn: 265.0000 - accuracy: 0.6124 - precision: 0.2143 - recall: 0.0112 - auc: 0.4670 - val_loss: 0.7110 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.6997 - tp: 166.0000 - fp: 309.0000 - tn: 135.0000 - fn: 102.0000 - accuracy: 0.4228 - precision: 0.3495 - recall: 0.6194 - auc: 0.4559 - val_loss: 0.7118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6992 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5043 - val_loss: 0.7164 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.7019 - tp: 100.0000 - fp: 210.0000 - tn: 234.0000 - fn: 168.0000 - accuracy: 0.4691 - precision: 0.3226 - recall: 0.3731 - auc: 0.4368 - val_loss: 0.7134 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4747 - val_loss: 0.7126 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 195us/sample - loss: 0.7000 - tp: 82.0000 - fp: 168.0000 - tn: 276.0000 - fn: 186.0000 - accuracy: 0.5028 - precision: 0.3280 - recall: 0.3060 - auc: 0.4251 - val_loss: 0.7118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.6996 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4688 - val_loss: 0.7132 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 192us/sample - loss: 0.6991 - tp: 70.0000 - fp: 121.0000 - tn: 323.0000 - fn: 198.0000 - accuracy: 0.5520 - precision: 0.3665 - recall: 0.2612 - auc: 0.4938 - val_loss: 0.7111 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.6998 - tp: 35.0000 - fp: 97.0000 - tn: 347.0000 - fn: 233.0000 - accuracy: 0.5365 - precision: 0.2652 - recall: 0.1306 - auc: 0.4330 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6989 - tp: 6.0000 - fp: 8.0000 - tn: 436.0000 - fn: 262.0000 - accuracy: 0.6208 - precision: 0.4286 - recall: 0.0224 - auc: 0.4858 - val_loss: 0.7125 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6994 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4429 - val_loss: 0.7124 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4363 - val_loss: 0.7125 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4765 - val_loss: 0.7122 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6994 - tp: 16.0000 - fp: 51.0000 - tn: 393.0000 - fn: 252.0000 - accuracy: 0.5744 - precision: 0.2388 - recall: 0.0597 - auc: 0.4505 - val_loss: 0.7126 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6991 - tp: 126.0000 - fp: 233.0000 - tn: 211.0000 - fn: 142.0000 - accuracy: 0.4733 - precision: 0.3510 - recall: 0.4701 - auc: 0.4810 - val_loss: 0.7116 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6991 - tp: 2.0000 - fp: 6.0000 - tn: 438.0000 - fn: 266.0000 - accuracy: 0.6180 - precision: 0.2500 - recall: 0.0075 - auc: 0.4963 - val_loss: 0.7139 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4765 - val_loss: 0.7125 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6992 - tp: 149.0000 - fp: 261.0000 - tn: 183.0000 - fn: 119.0000 - accuracy: 0.4663 - precision: 0.3634 - recall: 0.5560 - auc: 0.4828 - val_loss: 0.7114 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6988 - tp: 97.0000 - fp: 167.0000 - tn: 277.0000 - fn: 171.0000 - accuracy: 0.5253 - precision: 0.3674 - recall: 0.3619 - auc: 0.5004 - val_loss: 0.7128 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6995 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4809 - val_loss: 0.7135 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6998 - tp: 15.0000 - fp: 41.0000 - tn: 403.0000 - fn: 253.0000 - accuracy: 0.5871 - precision: 0.2679 - recall: 0.0560 - auc: 0.4575 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6995 - tp: 134.0000 - fp: 241.0000 - tn: 203.0000 - fn: 134.0000 - accuracy: 0.4733 - precision: 0.3573 - recall: 0.5000 - auc: 0.4733 - val_loss: 0.7109 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6987 - tp: 50.0000 - fp: 76.0000 - tn: 368.0000 - fn: 218.0000 - accuracy: 0.5871 - precision: 0.3968 - recall: 0.1866 - auc: 0.4952 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6993 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4664 - val_loss: 0.7126 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4889 - val_loss: 0.7132 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4723 - val_loss: 0.7121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6992 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4479 - val_loss: 0.7127 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4837 - val_loss: 0.7118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6987 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4874 - val_loss: 0.7126 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - val_loss: 0.7138 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4950 - val_loss: 0.7131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.6993 - tp: 4.0000 - fp: 13.0000 - tn: 431.0000 - fn: 264.0000 - accuracy: 0.6110 - precision: 0.2353 - recall: 0.0149 - auc: 0.4642 - val_loss: 0.7121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4891 - val_loss: 0.7126 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6989 - tp: 95.0000 - fp: 179.0000 - tn: 265.0000 - fn: 173.0000 - accuracy: 0.5056 - precision: 0.3467 - recall: 0.3545 - auc: 0.4954 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6991 - tp: 1.0000 - fp: 2.0000 - tn: 442.0000 - fn: 267.0000 - accuracy: 0.6222 - precision: 0.3333 - recall: 0.0037 - auc: 0.4711 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6994 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4564 - val_loss: 0.7121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4712 - val_loss: 0.7116 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4772 - val_loss: 0.7120 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4876 - val_loss: 0.7121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6989 - tp: 61.0000 - fp: 125.0000 - tn: 319.0000 - fn: 207.0000 - accuracy: 0.5337 - precision: 0.3280 - recall: 0.2276 - auc: 0.4734 - val_loss: 0.7117 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6990 - tp: 177.0000 - fp: 327.0000 - tn: 117.0000 - fn: 91.0000 - accuracy: 0.4129 - precision: 0.3512 - recall: 0.6604 - auc: 0.5018 - val_loss: 0.7118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4719 - val_loss: 0.7126 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4867 - val_loss: 0.7120 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 58/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4672 - val_loss: 0.7125 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 59/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4910 - val_loss: 0.7121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 60/500\n",
      "712/712 [==============================] - 0s 198us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4912 - val_loss: 0.7122 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 61/500\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4833 - val_loss: 0.7117 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 62/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4873 - val_loss: 0.7120 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 63/500\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5002 - val_loss: 0.7125 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 64/500\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6995 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4360 - val_loss: 0.7136 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 65/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4596 - val_loss: 0.7128 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 66/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7125 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 67/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4822 - val_loss: 0.7136 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 68/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4952 - val_loss: 0.7117 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 69/500\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4507 - val_loss: 0.7121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 70/500\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6990 - tp: 32.0000 - fp: 80.0000 - tn: 364.0000 - fn: 236.0000 - accuracy: 0.5562 - precision: 0.2857 - recall: 0.1194 - auc: 0.4833 - val_loss: 0.7118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 71/500\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6992 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4664 - val_loss: 0.7125 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 72/500\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4797 - val_loss: 0.7120 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 73/500\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4764 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 74/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6994 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4272 - val_loss: 0.7125 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 75/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4823 - val_loss: 0.7137 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 76/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4874 - val_loss: 0.7141 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 77/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4800 - val_loss: 0.7127 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 78/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4826 - val_loss: 0.7131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 79/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4745 - val_loss: 0.7120 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 80/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6987 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5014 - val_loss: 0.7128 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 81/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 82/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6993 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4589 - val_loss: 0.7124 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 83/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4846 - val_loss: 0.7128 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 84/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4646 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 85/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4866 - val_loss: 0.7133 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 86/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 87/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4835 - val_loss: 0.7120 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 88/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6992 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4598 - val_loss: 0.7122 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 89/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4715 - val_loss: 0.7119 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 90/500\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4624 - val_loss: 0.7122 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 91/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 92/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 93/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4893 - val_loss: 0.7127 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 94/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4593 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 95/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4674 - val_loss: 0.7120 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 96/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4845 - val_loss: 0.7117 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 97/500\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6990 - tp: 10.0000 - fp: 14.0000 - tn: 430.0000 - fn: 258.0000 - accuracy: 0.6180 - precision: 0.4167 - recall: 0.0373 - auc: 0.4820 - val_loss: 0.7119 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 98/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6991 - tp: 32.0000 - fp: 62.0000 - tn: 382.0000 - fn: 236.0000 - accuracy: 0.5815 - precision: 0.3404 - recall: 0.1194 - auc: 0.4838 - val_loss: 0.7118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 99/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4975 - val_loss: 0.7128 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 100/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4753 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 101/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6991 - tp: 13.0000 - fp: 34.0000 - tn: 410.0000 - fn: 255.0000 - accuracy: 0.5941 - precision: 0.2766 - recall: 0.0485 - auc: 0.4966 - val_loss: 0.7131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 102/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4875 - val_loss: 0.7131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 103/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4713 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 104/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5133 - val_loss: 0.7126 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 105/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6991 - tp: 45.0000 - fp: 90.0000 - tn: 354.0000 - fn: 223.0000 - accuracy: 0.5604 - precision: 0.3333 - recall: 0.1679 - auc: 0.4849 - val_loss: 0.7117 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 106/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6990 - tp: 6.0000 - fp: 17.0000 - tn: 427.0000 - fn: 262.0000 - accuracy: 0.6081 - precision: 0.2609 - recall: 0.0224 - auc: 0.4797 - val_loss: 0.7120 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 107/500\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7122 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 108/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4803 - val_loss: 0.7126 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 109/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4853 - val_loss: 0.7121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 110/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6989 - tp: 24.0000 - fp: 47.0000 - tn: 397.0000 - fn: 244.0000 - accuracy: 0.5913 - precision: 0.3380 - recall: 0.0896 - auc: 0.4912 - val_loss: 0.7117 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 111/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4965 - val_loss: 0.7121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 112/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6992 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4620 - val_loss: 0.7130 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 113/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4682 - val_loss: 0.7124 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 114/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 115/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6993 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4562 - val_loss: 0.7118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 116/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6987 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5112 - val_loss: 0.7131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 117/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4858 - val_loss: 0.7132 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 118/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6993 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4593 - val_loss: 0.7140 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 119/500\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6987 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5067 - val_loss: 0.7120 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 120/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4745 - val_loss: 0.7120 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 121/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7124 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 122/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4695 - val_loss: 0.7132 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 123/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.6987 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 124/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4825 - val_loss: 0.7125 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 125/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4864 - val_loss: 0.7127 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 126/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4895 - val_loss: 0.7135 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 127/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4849 - val_loss: 0.7127 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 128/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4878 - val_loss: 0.7128 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 129/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4632 - val_loss: 0.7119 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 130/500\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4533 - val_loss: 0.7122 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 131/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4805 - val_loss: 0.7122 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 132/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4721 - val_loss: 0.7118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 133/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4812 - val_loss: 0.7118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 134/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4836 - val_loss: 0.7135 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 135/500\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4877 - val_loss: 0.7124 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 136/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7119 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 137/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6989 - tp: 95.0000 - fp: 169.0000 - tn: 275.0000 - fn: 173.0000 - accuracy: 0.5197 - precision: 0.3598 - recall: 0.3545 - auc: 0.5064 - val_loss: 0.7115 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 138/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6987 - tp: 25.0000 - fp: 39.0000 - tn: 405.0000 - fn: 243.0000 - accuracy: 0.6039 - precision: 0.3906 - recall: 0.0933 - auc: 0.4992 - val_loss: 0.7122 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 139/500\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5007 - val_loss: 0.7131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 140/500\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4711 - val_loss: 0.7141 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 141/500\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 142/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6993 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4576 - val_loss: 0.7121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 143/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4858 - val_loss: 0.7131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 144/500\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4720 - val_loss: 0.7134 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 145/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4869 - val_loss: 0.7138 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 146/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.7000 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4796 - val_loss: 0.7134 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 147/500\n",
      "712/712 [==============================] - 0s 195us/sample - loss: 0.7001 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4723 - val_loss: 0.7144 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 148/500\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6995 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4750 - val_loss: 0.7122 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 149/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6993 - tp: 19.0000 - fp: 41.0000 - tn: 403.0000 - fn: 249.0000 - accuracy: 0.5927 - precision: 0.3167 - recall: 0.0709 - auc: 0.4812 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 150/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5216 - val_loss: 0.7124 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 151/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4938 - val_loss: 0.7123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 152/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4632 - tp: 202.0000 - fp: 54.0000 - tn: 390.0000 - fn: 66.0000 - accuracy: 0.8315 - precision: 0.7891 - recall: 0.7537 - auc: 0.8639 - val_loss: 0.4626 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8922\n",
      "Epoch 265/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.4681 - tp: 204.0000 - fp: 56.0000 - tn: 388.0000 - fn: 64.0000 - accuracy: 0.8315 - precision: 0.7846 - recall: 0.7612 - auc: 0.8656 - val_loss: 0.4704 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8921\n",
      "Epoch 266/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4627 - tp: 200.0000 - fp: 51.0000 - tn: 393.0000 - fn: 68.0000 - accuracy: 0.8329 - precision: 0.7968 - recall: 0.7463 - auc: 0.8669 - val_loss: 0.4654 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8915\n",
      "Epoch 267/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4666 - tp: 205.0000 - fp: 54.0000 - tn: 390.0000 - fn: 63.0000 - accuracy: 0.8357 - precision: 0.7915 - recall: 0.7649 - auc: 0.8667 - val_loss: 0.4643 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8917\n",
      "Epoch 268/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.4449 - tp: 205.0000 - fp: 54.0000 - tn: 390.0000 - fn: 63.0000 - accuracy: 0.8357 - precision: 0.7915 - recall: 0.7649 - auc: 0.8868 - val_loss: 0.4682 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8904\n",
      "Epoch 269/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.4565 - tp: 202.0000 - fp: 51.0000 - tn: 393.0000 - fn: 66.0000 - accuracy: 0.8357 - precision: 0.7984 - recall: 0.7537 - auc: 0.8754 - val_loss: 0.4645 - val_tp: 54.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 20.0000 - val_accuracy: 0.8156 - val_precision: 0.8060 - val_recall: 0.7297 - val_auc: 0.8925\n",
      "Epoch 270/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.4638 - tp: 203.0000 - fp: 46.0000 - tn: 398.0000 - fn: 65.0000 - accuracy: 0.8441 - precision: 0.8153 - recall: 0.7575 - auc: 0.8643 - val_loss: 0.4709 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8921\n",
      "Epoch 271/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.4643 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8656 - val_loss: 0.4704 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8920\n",
      "Epoch 272/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.4659 - tp: 202.0000 - fp: 50.0000 - tn: 394.0000 - fn: 66.0000 - accuracy: 0.8371 - precision: 0.8016 - recall: 0.7537 - auc: 0.8747 - val_loss: 0.4639 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8918\n",
      "Epoch 273/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.4668 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8667 - val_loss: 0.4650 - val_tp: 54.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 20.0000 - val_accuracy: 0.8156 - val_precision: 0.8060 - val_recall: 0.7297 - val_auc: 0.8920\n",
      "Epoch 274/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.4629 - tp: 197.0000 - fp: 45.0000 - tn: 399.0000 - fn: 71.0000 - accuracy: 0.8371 - precision: 0.8140 - recall: 0.7351 - auc: 0.8700 - val_loss: 0.4622 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8929\n",
      "Epoch 275/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4621 - tp: 203.0000 - fp: 52.0000 - tn: 392.0000 - fn: 65.0000 - accuracy: 0.8357 - precision: 0.7961 - recall: 0.7575 - auc: 0.8654 - val_loss: 0.4649 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8924\n",
      "Epoch 276/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4473 - tp: 203.0000 - fp: 55.0000 - tn: 389.0000 - fn: 65.0000 - accuracy: 0.8315 - precision: 0.7868 - recall: 0.7575 - auc: 0.8816 - val_loss: 0.4646 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8916\n",
      "Epoch 277/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4637 - tp: 199.0000 - fp: 52.0000 - tn: 392.0000 - fn: 69.0000 - accuracy: 0.8301 - precision: 0.7928 - recall: 0.7425 - auc: 0.8686 - val_loss: 0.4651 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8929\n",
      "Epoch 278/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4628 - tp: 196.0000 - fp: 48.0000 - tn: 396.0000 - fn: 72.0000 - accuracy: 0.8315 - precision: 0.8033 - recall: 0.7313 - auc: 0.8705 - val_loss: 0.4592 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8928\n",
      "Epoch 279/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4616 - tp: 201.0000 - fp: 54.0000 - tn: 390.0000 - fn: 67.0000 - accuracy: 0.8301 - precision: 0.7882 - recall: 0.7500 - auc: 0.8726 - val_loss: 0.4891 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 26.0000 - val_accuracy: 0.8045 - val_precision: 0.8421 - val_recall: 0.6486 - val_auc: 0.8883\n",
      "Epoch 280/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.4786 - tp: 192.0000 - fp: 42.0000 - tn: 402.0000 - fn: 76.0000 - accuracy: 0.8343 - precision: 0.8205 - recall: 0.7164 - auc: 0.8561 - val_loss: 0.4726 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8891\n",
      "Epoch 281/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.4688 - tp: 204.0000 - fp: 52.0000 - tn: 392.0000 - fn: 64.0000 - accuracy: 0.8371 - precision: 0.7969 - recall: 0.7612 - auc: 0.8638 - val_loss: 0.4663 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8914\n",
      "Epoch 282/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4561 - tp: 200.0000 - fp: 46.0000 - tn: 398.0000 - fn: 68.0000 - accuracy: 0.8399 - precision: 0.8130 - recall: 0.7463 - auc: 0.8707 - val_loss: 0.4642 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8910\n",
      "Epoch 283/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4606 - tp: 205.0000 - fp: 57.0000 - tn: 387.0000 - fn: 63.0000 - accuracy: 0.8315 - precision: 0.7824 - recall: 0.7649 - auc: 0.8710 - val_loss: 0.4584 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8934\n",
      "Epoch 284/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4666 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8655 - val_loss: 0.4603 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8929\n",
      "Epoch 285/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.4643 - tp: 199.0000 - fp: 51.0000 - tn: 393.0000 - fn: 69.0000 - accuracy: 0.8315 - precision: 0.7960 - recall: 0.7425 - auc: 0.8649 - val_loss: 0.4604 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8937\n",
      "Epoch 286/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4632 - tp: 205.0000 - fp: 58.0000 - tn: 386.0000 - fn: 63.0000 - accuracy: 0.8301 - precision: 0.7795 - recall: 0.7649 - auc: 0.8664 - val_loss: 0.4617 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8920\n",
      "Epoch 287/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4563 - tp: 203.0000 - fp: 52.0000 - tn: 392.0000 - fn: 65.0000 - accuracy: 0.8357 - precision: 0.7961 - recall: 0.7575 - auc: 0.8740 - val_loss: 0.4678 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8923\n",
      "Epoch 288/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.4583 - tp: 201.0000 - fp: 49.0000 - tn: 395.0000 - fn: 67.0000 - accuracy: 0.8371 - precision: 0.8040 - recall: 0.7500 - auc: 0.8721 - val_loss: 0.4637 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8916\n",
      "Epoch 289/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4753 - tp: 199.0000 - fp: 52.0000 - tn: 392.0000 - fn: 69.0000 - accuracy: 0.8301 - precision: 0.7928 - recall: 0.7425 - auc: 0.8624 - val_loss: 0.4608 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8909\n",
      "Epoch 290/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4665 - tp: 200.0000 - fp: 53.0000 - tn: 391.0000 - fn: 68.0000 - accuracy: 0.8301 - precision: 0.7905 - recall: 0.7463 - auc: 0.8648 - val_loss: 0.4612 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8916\n",
      "Epoch 291/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4639 - tp: 205.0000 - fp: 55.0000 - tn: 389.0000 - fn: 63.0000 - accuracy: 0.8343 - precision: 0.7885 - recall: 0.7649 - auc: 0.8672 - val_loss: 0.4690 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8915\n",
      "Epoch 292/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.4695 - tp: 190.0000 - fp: 43.0000 - tn: 401.0000 - fn: 78.0000 - accuracy: 0.8301 - precision: 0.8155 - recall: 0.7090 - auc: 0.8603 - val_loss: 0.4671 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8912\n",
      "Epoch 293/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.4553 - tp: 205.0000 - fp: 51.0000 - tn: 393.0000 - fn: 63.0000 - accuracy: 0.8399 - precision: 0.8008 - recall: 0.7649 - auc: 0.8723 - val_loss: 0.4640 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8936\n",
      "Epoch 294/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.4615 - tp: 201.0000 - fp: 52.0000 - tn: 392.0000 - fn: 67.0000 - accuracy: 0.8329 - precision: 0.7945 - recall: 0.7500 - auc: 0.8677 - val_loss: 0.4616 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8922\n",
      "Epoch 295/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4573 - tp: 200.0000 - fp: 52.0000 - tn: 392.0000 - fn: 68.0000 - accuracy: 0.8315 - precision: 0.7937 - recall: 0.7463 - auc: 0.8673 - val_loss: 0.4610 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8923\n",
      "Epoch 296/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4636 - tp: 198.0000 - fp: 47.0000 - tn: 397.0000 - fn: 70.0000 - accuracy: 0.8357 - precision: 0.8082 - recall: 0.7388 - auc: 0.8629 - val_loss: 0.4662 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8917\n",
      "Epoch 297/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4651 - tp: 193.0000 - fp: 49.0000 - tn: 395.0000 - fn: 75.0000 - accuracy: 0.8258 - precision: 0.7975 - recall: 0.7201 - auc: 0.8684 - val_loss: 0.4674 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8904\n",
      "Epoch 298/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.4546 - tp: 205.0000 - fp: 58.0000 - tn: 386.0000 - fn: 63.0000 - accuracy: 0.8301 - precision: 0.7795 - recall: 0.7649 - auc: 0.8756 - val_loss: 0.4630 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8921\n",
      "Epoch 299/500\n",
      "712/712 [==============================] - 0s 278us/sample - loss: 0.4720 - tp: 198.0000 - fp: 52.0000 - tn: 392.0000 - fn: 70.0000 - accuracy: 0.8287 - precision: 0.7920 - recall: 0.7388 - auc: 0.8645 - val_loss: 0.4632 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8913\n",
      "Epoch 300/500\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.4675 - tp: 198.0000 - fp: 45.0000 - tn: 399.0000 - fn: 70.0000 - accuracy: 0.8385 - precision: 0.8148 - recall: 0.7388 - auc: 0.8705 - val_loss: 0.4682 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8920\n",
      "Epoch 301/500\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.4560 - tp: 207.0000 - fp: 58.0000 - tn: 386.0000 - fn: 61.0000 - accuracy: 0.8329 - precision: 0.7811 - recall: 0.7724 - auc: 0.8744 - val_loss: 0.4650 - val_tp: 54.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 20.0000 - val_accuracy: 0.8156 - val_precision: 0.8060 - val_recall: 0.7297 - val_auc: 0.8905\n",
      "Epoch 302/500\n",
      "712/712 [==============================] - 4s 6ms/sample - loss: 8.9825 - tp: 147.0000 - fp: 253.0000 - tn: 191.0000 - fn: 121.0000 - accuracy: 0.4747 - precision: 0.3675 - recall: 0.5485 - auc: 0.4773 - val_loss: 3.7753 - val_tp: 3.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 71.0000 - val_accuracy: 0.5531 - val_precision: 0.2500 - val_recall: 0.0405 - val_auc: 0.6573\n",
      "Epoch 2/700\n",
      "712/712 [==============================] - 0s 192us/sample - loss: 2.1601 - tp: 105.0000 - fp: 152.0000 - tn: 292.0000 - fn: 163.0000 - accuracy: 0.5576 - precision: 0.4086 - recall: 0.3918 - auc: 0.5129 - val_loss: 1.1721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 3/700\n",
      "712/712 [==============================] - 0s 199us/sample - loss: 0.9523 - tp: 16.0000 - fp: 31.0000 - tn: 413.0000 - fn: 252.0000 - accuracy: 0.6025 - precision: 0.3404 - recall: 0.0597 - auc: 0.4665 - val_loss: 0.8467 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 4/700\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.8013 - tp: 118.0000 - fp: 250.0000 - tn: 194.0000 - fn: 150.0000 - accuracy: 0.4382 - precision: 0.3207 - recall: 0.4403 - auc: 0.4523 - val_loss: 0.7859 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 5/700\n",
      "712/712 [==============================] - 0s 198us/sample - loss: 0.7589 - tp: 3.0000 - fp: 2.0000 - tn: 442.0000 - fn: 265.0000 - accuracy: 0.6250 - precision: 0.6000 - recall: 0.0112 - auc: 0.5033 - val_loss: 0.7589 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 6/700\n",
      "712/712 [==============================] - 0s 193us/sample - loss: 0.7390 - tp: 238.0000 - fp: 380.0000 - tn: 64.0000 - fn: 30.0000 - accuracy: 0.4242 - precision: 0.3851 - recall: 0.8881 - auc: 0.4925 - val_loss: 0.7425 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 7/700\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.7248 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4826 - val_loss: 0.7339 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 8/700\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.7169 - tp: 101.0000 - fp: 178.0000 - tn: 266.0000 - fn: 167.0000 - accuracy: 0.5154 - precision: 0.3620 - recall: 0.3769 - auc: 0.4780 - val_loss: 0.7263 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 9/700\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.7109 - tp: 3.0000 - fp: 7.0000 - tn: 437.0000 - fn: 265.0000 - accuracy: 0.6180 - precision: 0.3000 - recall: 0.0112 - auc: 0.4571 - val_loss: 0.7210 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 10/700\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.7066 - tp: 69.0000 - fp: 116.0000 - tn: 328.0000 - fn: 199.0000 - accuracy: 0.5576 - precision: 0.3730 - recall: 0.2575 - auc: 0.4904 - val_loss: 0.7183 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 11/700\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.7032 - tp: 22.0000 - fp: 37.0000 - tn: 407.0000 - fn: 246.0000 - accuracy: 0.6025 - precision: 0.3729 - recall: 0.0821 - auc: 0.4946 - val_loss: 0.7146 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 12/700\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.7011 - tp: 35.0000 - fp: 58.0000 - tn: 386.0000 - fn: 233.0000 - accuracy: 0.5913 - precision: 0.3763 - recall: 0.1306 - auc: 0.4971 - val_loss: 0.7138 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 13/700\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.7001 - tp: 47.0000 - fp: 92.0000 - tn: 352.0000 - fn: 221.0000 - accuracy: 0.5604 - precision: 0.3381 - recall: 0.1754 - auc: 0.4698 - val_loss: 0.7126 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 14/700\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6989 - tp: 30.0000 - fp: 72.0000 - tn: 372.0000 - fn: 238.0000 - accuracy: 0.5646 - precision: 0.2941 - recall: 0.1119 - auc: 0.4658 - val_loss: 0.7117 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 15/700\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6978 - tp: 12.0000 - fp: 20.0000 - tn: 424.0000 - fn: 256.0000 - accuracy: 0.6124 - precision: 0.3750 - recall: 0.0448 - auc: 0.4928 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 16/700\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6979 - tp: 84.0000 - fp: 167.0000 - tn: 277.0000 - fn: 184.0000 - accuracy: 0.5070 - precision: 0.3347 - recall: 0.3134 - auc: 0.4721 - val_loss: 0.7102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 17/700\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.6980 - tp: 1.0000 - fp: 0.0000e+00 - tn: 444.0000 - fn: 267.0000 - accuracy: 0.6250 - precision: 1.0000 - recall: 0.0037 - auc: 0.4614 - val_loss: 0.7124 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 18/700\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.6984 - tp: 32.0000 - fp: 58.0000 - tn: 386.0000 - fn: 236.0000 - accuracy: 0.5871 - precision: 0.3556 - recall: 0.1194 - auc: 0.4597 - val_loss: 0.7124 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 19/700\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.6974 - tp: 9.0000 - fp: 18.0000 - tn: 426.0000 - fn: 259.0000 - accuracy: 0.6110 - precision: 0.3333 - recall: 0.0336 - auc: 0.4885 - val_loss: 0.7102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 20/700\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6980 - tp: 112.0000 - fp: 204.0000 - tn: 240.0000 - fn: 156.0000 - accuracy: 0.4944 - precision: 0.3544 - recall: 0.4179 - auc: 0.4766 - val_loss: 0.7097 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 21/700\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.6978 - tp: 2.0000 - fp: 6.0000 - tn: 438.0000 - fn: 266.0000 - accuracy: 0.6180 - precision: 0.2500 - recall: 0.0075 - auc: 0.4917 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 22/700\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.6975 - tp: 56.0000 - fp: 118.0000 - tn: 326.0000 - fn: 212.0000 - accuracy: 0.5365 - precision: 0.3218 - recall: 0.2090 - auc: 0.4863 - val_loss: 0.7098 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 23/700\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6974 - tp: 13.0000 - fp: 32.0000 - tn: 412.0000 - fn: 255.0000 - accuracy: 0.5969 - precision: 0.2889 - recall: 0.0485 - auc: 0.4706 - val_loss: 0.7097 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 24/700\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6971 - tp: 8.0000 - fp: 2.0000 - tn: 442.0000 - fn: 260.0000 - accuracy: 0.6320 - precision: 0.8000 - recall: 0.0299 - auc: 0.4647 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 25/700\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.6971 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4788 - val_loss: 0.7098 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 26/700\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5023 - val_loss: 0.7102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 27/700\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6967 - tp: 32.0000 - fp: 62.0000 - tn: 382.0000 - fn: 236.0000 - accuracy: 0.5815 - precision: 0.3404 - recall: 0.1194 - auc: 0.5028 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 28/700\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6975 - tp: 23.0000 - fp: 60.0000 - tn: 384.0000 - fn: 245.0000 - accuracy: 0.5716 - precision: 0.2771 - recall: 0.0858 - auc: 0.4695 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 29/700\n",
      "712/712 [==============================] - 0s 198us/sample - loss: 0.6972 - tp: 213.0000 - fp: 341.0000 - tn: 103.0000 - fn: 55.0000 - accuracy: 0.4438 - precision: 0.3845 - recall: 0.7948 - auc: 0.4985 - val_loss: 0.7094 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 30/700\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.6967 - tp: 2.0000 - fp: 3.0000 - tn: 441.0000 - fn: 266.0000 - accuracy: 0.6222 - precision: 0.4000 - recall: 0.0075 - auc: 0.5066 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 31/700\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4791 - val_loss: 0.7102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 32/700\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.6976 - tp: 168.0000 - fp: 267.0000 - tn: 177.0000 - fn: 100.0000 - accuracy: 0.4846 - precision: 0.3862 - recall: 0.6269 - auc: 0.5041 - val_loss: 0.7095 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 33/700\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.6968 - tp: 27.0000 - fp: 52.0000 - tn: 392.0000 - fn: 241.0000 - accuracy: 0.5885 - precision: 0.3418 - recall: 0.1007 - auc: 0.5025 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 34/700\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6972 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4667 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 35/700\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6975 - tp: 16.0000 - fp: 42.0000 - tn: 402.0000 - fn: 252.0000 - accuracy: 0.5871 - precision: 0.2759 - recall: 0.0597 - auc: 0.4678 - val_loss: 0.7108 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 36/700\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.6975 - tp: 92.0000 - fp: 159.0000 - tn: 285.0000 - fn: 176.0000 - accuracy: 0.5295 - precision: 0.3665 - recall: 0.3433 - auc: 0.4633 - val_loss: 0.7094 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 37/700\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.6973 - tp: 74.0000 - fp: 153.0000 - tn: 291.0000 - fn: 194.0000 - accuracy: 0.5126 - precision: 0.3260 - recall: 0.2761 - auc: 0.4688 - val_loss: 0.7094 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 38/700\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.6974 - tp: 2.0000 - fp: 0.0000e+00 - tn: 444.0000 - fn: 266.0000 - accuracy: 0.6264 - precision: 1.0000 - recall: 0.0075 - auc: 0.4547 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 39/700\n",
      "712/712 [==============================] - 0s 203us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4729 - val_loss: 0.7106 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 40/700\n",
      "712/712 [==============================] - 0s 195us/sample - loss: 0.6964 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4957 - val_loss: 0.7096 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 41/700\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.6971 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4676 - val_loss: 0.7106 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 42/700\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4779 - val_loss: 0.7095 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 43/700\n",
      "712/712 [==============================] - 0s 214us/sample - loss: 0.6966 - tp: 9.0000 - fp: 22.0000 - tn: 422.0000 - fn: 259.0000 - accuracy: 0.6053 - precision: 0.2903 - recall: 0.0336 - auc: 0.4854 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 44/700\n",
      "712/712 [==============================] - 0s 200us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4710 - val_loss: 0.7116 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 45/700\n",
      "712/712 [==============================] - 0s 233us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4722 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 46/700\n",
      "712/712 [==============================] - 0s 261us/sample - loss: 0.6976 - tp: 58.0000 - fp: 121.0000 - tn: 323.0000 - fn: 210.0000 - accuracy: 0.5351 - precision: 0.3240 - recall: 0.2164 - auc: 0.4715 - val_loss: 0.7106 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 47/700\n",
      "712/712 [==============================] - 0s 252us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4949 - val_loss: 0.7102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 48/700\n",
      "712/712 [==============================] - 0s 231us/sample - loss: 0.6968 - tp: 131.0000 - fp: 212.0000 - tn: 232.0000 - fn: 137.0000 - accuracy: 0.5098 - precision: 0.3819 - recall: 0.4888 - auc: 0.4980 - val_loss: 0.7094 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 49/700\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4626 - val_loss: 0.7098 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 50/700\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.6975 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4688 - val_loss: 0.7100 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 51/700\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.6976 - tp: 87.0000 - fp: 161.0000 - tn: 283.0000 - fn: 181.0000 - accuracy: 0.5197 - precision: 0.3508 - recall: 0.3246 - auc: 0.4615 - val_loss: 0.7100 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 52/700\n",
      "712/712 [==============================] - 0s 198us/sample - loss: 0.6977 - tp: 1.0000 - fp: 5.0000 - tn: 439.0000 - fn: 267.0000 - accuracy: 0.6180 - precision: 0.1667 - recall: 0.0037 - auc: 0.4614 - val_loss: 0.7096 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 53/700\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6971 - tp: 33.0000 - fp: 62.0000 - tn: 382.0000 - fn: 235.0000 - accuracy: 0.5829 - precision: 0.3474 - recall: 0.1231 - auc: 0.4709 - val_loss: 0.7096 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 54/700\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6971 - tp: 136.0000 - fp: 241.0000 - tn: 203.0000 - fn: 132.0000 - accuracy: 0.4761 - precision: 0.3607 - recall: 0.5075 - auc: 0.4941 - val_loss: 0.7094 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 55/700\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6966 - tp: 157.0000 - fp: 272.0000 - tn: 172.0000 - fn: 111.0000 - accuracy: 0.4621 - precision: 0.3660 - recall: 0.5858 - auc: 0.5099 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 56/700\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4702 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 57/700\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4811 - val_loss: 0.7096 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 58/700\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4681 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 59/700\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6971 - tp: 24.0000 - fp: 51.0000 - tn: 393.0000 - fn: 244.0000 - accuracy: 0.5857 - precision: 0.3200 - recall: 0.0896 - auc: 0.4693 - val_loss: 0.7106 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 60/700\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6964 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5052 - val_loss: 0.7102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 61/700\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6971 - tp: 150.0000 - fp: 259.0000 - tn: 185.0000 - fn: 118.0000 - accuracy: 0.4705 - precision: 0.3667 - recall: 0.5597 - auc: 0.4676 - val_loss: 0.7097 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 62/700\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5001 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 63/700\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 8.0000 - tn: 436.0000 - fn: 268.0000 - accuracy: 0.6124 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4647 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 64/700\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6976 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4583 - val_loss: 0.7110 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 65/700\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4729 - val_loss: 0.7102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 66/700\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.6965 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4836 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 67/700\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4760 - val_loss: 0.7108 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 68/700\n",
      "712/712 [==============================] - 0s 200us/sample - loss: 0.6969 - tp: 66.0000 - fp: 109.0000 - tn: 335.0000 - fn: 202.0000 - accuracy: 0.5632 - precision: 0.3771 - recall: 0.2463 - auc: 0.4911 - val_loss: 0.7096 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 69/700\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4665 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 70/700\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6969 - tp: 71.0000 - fp: 142.0000 - tn: 302.0000 - fn: 197.0000 - accuracy: 0.5239 - precision: 0.3333 - recall: 0.2649 - auc: 0.4749 - val_loss: 0.7097 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 71/700\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4700 - val_loss: 0.7100 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 72/700\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4675 - val_loss: 0.7097 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 73/700\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4963 - val_loss: 0.7107 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 74/700\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6975 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4366 - val_loss: 0.7108 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 75/700\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4839 - val_loss: 0.7117 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 76/700\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4875 - val_loss: 0.7116 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 77/700\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4632 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 78/700\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4825 - val_loss: 0.7108 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 79/700\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6972 - tp: 76.0000 - fp: 139.0000 - tn: 305.0000 - fn: 192.0000 - accuracy: 0.5351 - precision: 0.3535 - recall: 0.2836 - auc: 0.4785 - val_loss: 0.7098 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 80/700\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5020 - val_loss: 0.7107 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 81/700\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4747 - val_loss: 0.7111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 82/700\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6971 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4580 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 83/700\n",
      "712/712 [==============================] - 0s 197us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4880 - val_loss: 0.7106 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 84/700\n",
      "712/712 [==============================] - 0s 201us/sample - loss: 0.6970 - tp: 31.0000 - fp: 57.0000 - tn: 387.0000 - fn: 237.0000 - accuracy: 0.5871 - precision: 0.3523 - recall: 0.1157 - auc: 0.4878 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 85/700\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4893 - val_loss: 0.7110 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 86/700\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4698 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 87/700\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4671 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 88/700\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6972 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4577 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 89/700\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.6971 - tp: 54.0000 - fp: 104.0000 - tn: 340.0000 - fn: 214.0000 - accuracy: 0.5534 - precision: 0.3418 - recall: 0.2015 - auc: 0.4705 - val_loss: 0.7094 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 90/700\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4429 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 91/700\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 92/700\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 93/700\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.6965 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4905 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 94/700\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4622 - val_loss: 0.7102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 95/700\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4624 - val_loss: 0.7098 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 96/700\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6968 - tp: 1.0000 - fp: 4.0000 - tn: 440.0000 - fn: 267.0000 - accuracy: 0.6194 - precision: 0.2000 - recall: 0.0037 - auc: 0.4731 - val_loss: 0.7097 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 97/700\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4866 - val_loss: 0.7095 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 98/700\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6967 - tp: 47.0000 - fp: 96.0000 - tn: 348.0000 - fn: 221.0000 - accuracy: 0.5548 - precision: 0.3287 - recall: 0.1754 - auc: 0.4874 - val_loss: 0.7098 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 99/700\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4971 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 100/700\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4546 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 101/700\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 102/700\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4765 - val_loss: 0.7111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 103/700\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4815 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 104/700\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4911 - val_loss: 0.7100 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 105/700\n",
      "712/712 [==============================] - 0s 185us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4982 - val_loss: 0.7094 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 106/700\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6968 - tp: 19.0000 - fp: 50.0000 - tn: 394.0000 - fn: 249.0000 - accuracy: 0.5801 - precision: 0.2754 - recall: 0.0709 - auc: 0.4623 - val_loss: 0.7100 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 107/700\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 108/700\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4724 - val_loss: 0.7106 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 109/700\n",
      "712/712 [==============================] - 0s 192us/sample - loss: 0.6968 - tp: 27.0000 - fp: 44.0000 - tn: 400.0000 - fn: 241.0000 - accuracy: 0.5997 - precision: 0.3803 - recall: 0.1007 - auc: 0.4870 - val_loss: 0.7097 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 110/700\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.6968 - tp: 5.0000 - fp: 13.0000 - tn: 431.0000 - fn: 263.0000 - accuracy: 0.6124 - precision: 0.2778 - recall: 0.0187 - auc: 0.5034 - val_loss: 0.7096 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 111/700\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4946 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 112/700\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.6970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4565 - val_loss: 0.7107 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 113/700\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4634 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 114/700\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7110 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 115/700\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6972 - tp: 46.0000 - fp: 92.0000 - tn: 352.0000 - fn: 222.0000 - accuracy: 0.5590 - precision: 0.3333 - recall: 0.1716 - auc: 0.4645 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 116/700\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5083 - val_loss: 0.7110 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 117/700\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4761 - val_loss: 0.7109 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 118/700\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6972 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4576 - val_loss: 0.7120 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 119/700\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5022 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 120/700\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4716 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 121/700\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4882 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 122/700\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4655 - val_loss: 0.7110 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 123/700\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4964 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 124/700\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4773 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 125/700\n",
      "712/712 [==============================] - 0s 221us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4860 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 126/700\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4850 - val_loss: 0.7114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 127/700\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4829 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 128/700\n",
      "712/712 [==============================] - 0s 242us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4955 - val_loss: 0.7107 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 129/700\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4565 - val_loss: 0.7098 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 130/700\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4886 - val_loss: 0.7102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 131/700\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4776 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 132/700\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4763 - val_loss: 0.7095 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 133/700\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4909 - val_loss: 0.7098 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 134/700\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4814 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 135/700\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4790 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 136/700\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 137/700\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.6969 - tp: 146.0000 - fp: 249.0000 - tn: 195.0000 - fn: 122.0000 - accuracy: 0.4789 - precision: 0.3696 - recall: 0.5448 - auc: 0.5050 - val_loss: 0.7092 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 138/700\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6967 - tp: 20.0000 - fp: 32.0000 - tn: 412.0000 - fn: 248.0000 - accuracy: 0.6067 - precision: 0.3846 - recall: 0.0746 - auc: 0.4993 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 139/700\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5026 - val_loss: 0.7108 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 140/700\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4672 - val_loss: 0.7118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 141/700\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5021 - val_loss: 0.7114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 142/700\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6973 - tp: 1.0000 - fp: 8.0000 - tn: 436.0000 - fn: 267.0000 - accuracy: 0.6138 - precision: 0.1111 - recall: 0.0037 - auc: 0.4661 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 143/700\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.6970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4818 - val_loss: 0.7111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 144/700\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4650 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 145/700\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4732 - val_loss: 0.7109 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 146/700\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6972 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4638 - val_loss: 0.7119 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 147/700\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6974 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4697 - val_loss: 0.7121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 148/700\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.6974 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4371 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 149/700\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4950 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 150/700\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 151/700\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4715 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 152/700\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4906 - val_loss: 0.7095 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 153/700\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 154/700\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4840 - val_loss: 0.7108 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 155/700\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.6971 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4946 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 156/700\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5052 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 157/700\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5228 - val_loss: 0.7111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 158/700\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6981 - tp: 33.0000 - fp: 76.0000 - tn: 368.0000 - fn: 235.0000 - accuracy: 0.5632 - precision: 0.3028 - recall: 0.1231 - auc: 0.4782 - val_loss: 0.7124 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 159/700\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6971 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4773 - val_loss: 0.7111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 160/700\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6967 - tp: 2.0000 - fp: 14.0000 - tn: 430.0000 - fn: 266.0000 - accuracy: 0.6067 - precision: 0.1250 - recall: 0.0075 - auc: 0.5149 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 161/700\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4856 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 162/700\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6967 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4889 - val_loss: 0.7100 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 163/700\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6972 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4602 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 164/700\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6970 - tp: 37.0000 - fp: 70.0000 - tn: 374.0000 - fn: 231.0000 - accuracy: 0.5772 - precision: 0.3458 - recall: 0.1381 - auc: 0.5099 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 165/700\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6974 - tp: 2.0000 - fp: 14.0000 - tn: 430.0000 - fn: 266.0000 - accuracy: 0.6067 - precision: 0.1250 - recall: 0.0075 - auc: 0.4486 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 166/700\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 167/700\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4956 - val_loss: 0.7107 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 168/700\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7109 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 169/700\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4773 - val_loss: 0.7114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 170/700\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4847 - val_loss: 0.7114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 171/700\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6971 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4602 - val_loss: 0.7109 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 172/700\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7106 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 173/700\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 174/700\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.6970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4912 - val_loss: 0.7110 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 175/700\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4686 - val_loss: 0.7114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 176/700\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 177/700\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6971 - tp: 10.0000 - fp: 29.0000 - tn: 415.0000 - fn: 258.0000 - accuracy: 0.5969 - precision: 0.2564 - recall: 0.0373 - auc: 0.4847 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 178/700\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.6971 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4637 - val_loss: 0.7108 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 179/700\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6967 - tp: 28.0000 - fp: 42.0000 - tn: 402.0000 - fn: 240.0000 - accuracy: 0.6039 - precision: 0.4000 - recall: 0.1045 - auc: 0.5371 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 180/700\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6981 - tp: 20.0000 - fp: 45.0000 - tn: 399.0000 - fn: 248.0000 - accuracy: 0.5885 - precision: 0.3077 - recall: 0.0746 - auc: 0.4579 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 181/700\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6971 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5021 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 182/700\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6971 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4662 - val_loss: 0.7106 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 183/700\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6981 - tp: 114.0000 - fp: 217.0000 - tn: 227.0000 - fn: 154.0000 - accuracy: 0.4789 - precision: 0.3444 - recall: 0.4254 - auc: 0.4747 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 184/700\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6987 - tp: 2.0000 - fp: 3.0000 - tn: 441.0000 - fn: 266.0000 - accuracy: 0.6222 - precision: 0.4000 - recall: 0.0075 - auc: 0.4983 - val_loss: 0.7115 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 185/700\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6974 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4592 - val_loss: 0.7106 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 186/700\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 187/700\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4920 - val_loss: 0.7119 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 188/700\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6974 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4480 - val_loss: 0.7114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 189/700\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6968 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4860 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 190/700\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6971 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4656 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 191/700\n",
      "480/712 [===================>..........]Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/600\n",
      "712/712 [==============================] - 4s 5ms/sample - loss: 12.9854 - tp: 155.0000 - fp: 200.0000 - tn: 244.0000 - fn: 113.0000 - accuracy: 0.5604 - precision: 0.4366 - recall: 0.5784 - auc: 0.5803 - val_loss: 12.1531 - val_tp: 57.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 17.0000 - val_accuracy: 0.7486 - val_precision: 0.6706 - val_recall: 0.7703 - val_auc: 0.7995\n",
      "Epoch 2/600\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 11.6604 - tp: 139.0000 - fp: 145.0000 - tn: 299.0000 - fn: 129.0000 - accuracy: 0.6152 - precision: 0.4894 - recall: 0.5187 - auc: 0.6250 - val_loss: 11.0197 - val_tp: 49.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 25.0000 - val_accuracy: 0.8045 - val_precision: 0.8305 - val_recall: 0.6622 - val_auc: 0.8252\n",
      "Epoch 3/600\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 10.5375 - tp: 119.0000 - fp: 90.0000 - tn: 354.0000 - fn: 149.0000 - accuracy: 0.6643 - precision: 0.5694 - recall: 0.4440 - auc: 0.6934 - val_loss: 9.9411 - val_tp: 58.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 16.0000 - val_accuracy: 0.7821 - val_precision: 0.7160 - val_recall: 0.7838 - val_auc: 0.8363\n",
      "Epoch 4/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 9.5416 - tp: 126.0000 - fp: 104.0000 - tn: 340.0000 - fn: 142.0000 - accuracy: 0.6545 - precision: 0.5478 - recall: 0.4701 - auc: 0.7014 - val_loss: 8.9957 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8425\n",
      "Epoch 5/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 8.6279 - tp: 123.0000 - fp: 84.0000 - tn: 360.0000 - fn: 145.0000 - accuracy: 0.6784 - precision: 0.5942 - recall: 0.4590 - auc: 0.7184 - val_loss: 8.1238 - val_tp: 60.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 14.0000 - val_accuracy: 0.7821 - val_precision: 0.7059 - val_recall: 0.8108 - val_auc: 0.8625\n",
      "Epoch 6/600\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 7.7965 - tp: 165.0000 - fp: 124.0000 - tn: 320.0000 - fn: 103.0000 - accuracy: 0.6812 - precision: 0.5709 - recall: 0.6157 - auc: 0.7459 - val_loss: 7.3459 - val_tp: 54.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 20.0000 - val_accuracy: 0.7709 - val_precision: 0.7200 - val_recall: 0.7297 - val_auc: 0.8710\n",
      "Epoch 7/600\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 7.0414 - tp: 163.0000 - fp: 98.0000 - tn: 346.0000 - fn: 105.0000 - accuracy: 0.7149 - precision: 0.6245 - recall: 0.6082 - auc: 0.7640 - val_loss: 6.6272 - val_tp: 59.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 15.0000 - val_accuracy: 0.7709 - val_precision: 0.6941 - val_recall: 0.7973 - val_auc: 0.8640\n",
      "Epoch 8/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 6.3789 - tp: 180.0000 - fp: 149.0000 - tn: 295.0000 - fn: 88.0000 - accuracy: 0.6671 - precision: 0.5471 - recall: 0.6716 - auc: 0.7345 - val_loss: 5.9934 - val_tp: 54.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 20.0000 - val_accuracy: 0.7765 - val_precision: 0.7297 - val_recall: 0.7297 - val_auc: 0.8668\n",
      "Epoch 9/600\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 5.7566 - tp: 172.0000 - fp: 126.0000 - tn: 318.0000 - fn: 96.0000 - accuracy: 0.6882 - precision: 0.5772 - recall: 0.6418 - auc: 0.7518 - val_loss: 5.4133 - val_tp: 55.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 19.0000 - val_accuracy: 0.7598 - val_precision: 0.6962 - val_recall: 0.7432 - val_auc: 0.8626\n",
      "Epoch 10/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 5.2020 - tp: 173.0000 - fp: 126.0000 - tn: 318.0000 - fn: 95.0000 - accuracy: 0.6896 - precision: 0.5786 - recall: 0.6455 - auc: 0.7537 - val_loss: 4.8839 - val_tp: 57.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 17.0000 - val_accuracy: 0.7654 - val_precision: 0.6951 - val_recall: 0.7703 - val_auc: 0.8614\n",
      "Epoch 11/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 4.6967 - tp: 178.0000 - fp: 142.0000 - tn: 302.0000 - fn: 90.0000 - accuracy: 0.6742 - precision: 0.5562 - recall: 0.6642 - auc: 0.7606 - val_loss: 4.4132 - val_tp: 57.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 17.0000 - val_accuracy: 0.7654 - val_precision: 0.6951 - val_recall: 0.7703 - val_auc: 0.8650\n",
      "Epoch 12/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 4.2422 - tp: 187.0000 - fp: 128.0000 - tn: 316.0000 - fn: 81.0000 - accuracy: 0.7065 - precision: 0.5937 - recall: 0.6978 - auc: 0.7795 - val_loss: 3.9868 - val_tp: 58.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 16.0000 - val_accuracy: 0.7598 - val_precision: 0.6824 - val_recall: 0.7838 - val_auc: 0.8599\n",
      "Epoch 13/600\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 3.8329 - tp: 189.0000 - fp: 131.0000 - tn: 313.0000 - fn: 79.0000 - accuracy: 0.7051 - precision: 0.5906 - recall: 0.7052 - auc: 0.7743 - val_loss: 3.6019 - val_tp: 55.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 19.0000 - val_accuracy: 0.7542 - val_precision: 0.6875 - val_recall: 0.7432 - val_auc: 0.8625\n",
      "Epoch 14/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 3.4686 - tp: 193.0000 - fp: 132.0000 - tn: 312.0000 - fn: 75.0000 - accuracy: 0.7093 - precision: 0.5938 - recall: 0.7201 - auc: 0.7613 - val_loss: 3.2511 - val_tp: 55.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 19.0000 - val_accuracy: 0.7542 - val_precision: 0.6875 - val_recall: 0.7432 - val_auc: 0.8691\n",
      "Epoch 15/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 3.1290 - tp: 194.0000 - fp: 128.0000 - tn: 316.0000 - fn: 74.0000 - accuracy: 0.7163 - precision: 0.6025 - recall: 0.7239 - auc: 0.7694 - val_loss: 2.9351 - val_tp: 55.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 19.0000 - val_accuracy: 0.7654 - val_precision: 0.7051 - val_recall: 0.7432 - val_auc: 0.8732\n",
      "Epoch 16/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 2.8126 - tp: 189.0000 - fp: 122.0000 - tn: 322.0000 - fn: 79.0000 - accuracy: 0.7177 - precision: 0.6077 - recall: 0.7052 - auc: 0.7815 - val_loss: 2.6511 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8779\n",
      "Epoch 17/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 2.5380 - tp: 174.0000 - fp: 128.0000 - tn: 316.0000 - fn: 94.0000 - accuracy: 0.6882 - precision: 0.5762 - recall: 0.6493 - auc: 0.7784 - val_loss: 2.3839 - val_tp: 58.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 16.0000 - val_accuracy: 0.7654 - val_precision: 0.6905 - val_recall: 0.7838 - val_auc: 0.8662\n",
      "Epoch 18/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 2.3005 - tp: 191.0000 - fp: 140.0000 - tn: 304.0000 - fn: 77.0000 - accuracy: 0.6952 - precision: 0.5770 - recall: 0.7127 - auc: 0.7696 - val_loss: 2.1610 - val_tp: 54.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 20.0000 - val_accuracy: 0.7709 - val_precision: 0.7200 - val_recall: 0.7297 - val_auc: 0.8774\n",
      "Epoch 19/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 2.0627 - tp: 186.0000 - fp: 121.0000 - tn: 323.0000 - fn: 82.0000 - accuracy: 0.7149 - precision: 0.6059 - recall: 0.6940 - auc: 0.7938 - val_loss: 1.9435 - val_tp: 58.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 16.0000 - val_accuracy: 0.7654 - val_precision: 0.6905 - val_recall: 0.7838 - val_auc: 0.8698\n",
      "Epoch 20/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 1.8724 - tp: 196.0000 - fp: 130.0000 - tn: 314.0000 - fn: 72.0000 - accuracy: 0.7163 - precision: 0.6012 - recall: 0.7313 - auc: 0.7858 - val_loss: 1.7559 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8739\n",
      "Epoch 21/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 1.6903 - tp: 192.0000 - fp: 120.0000 - tn: 324.0000 - fn: 76.0000 - accuracy: 0.7247 - precision: 0.6154 - recall: 0.7164 - auc: 0.7840 - val_loss: 1.5833 - val_tp: 55.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 19.0000 - val_accuracy: 0.7542 - val_precision: 0.6875 - val_recall: 0.7432 - val_auc: 0.8750\n",
      "Epoch 22/600\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 1.5308 - tp: 194.0000 - fp: 135.0000 - tn: 309.0000 - fn: 74.0000 - accuracy: 0.7065 - precision: 0.5897 - recall: 0.7239 - auc: 0.7787 - val_loss: 1.4368 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8810\n",
      "Epoch 23/600\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 1.3862 - tp: 187.0000 - fp: 131.0000 - tn: 313.0000 - fn: 81.0000 - accuracy: 0.7022 - precision: 0.5881 - recall: 0.6978 - auc: 0.7744 - val_loss: 1.3020 - val_tp: 55.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 19.0000 - val_accuracy: 0.7654 - val_precision: 0.7051 - val_recall: 0.7432 - val_auc: 0.8766\n",
      "Epoch 24/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.2671 - tp: 183.0000 - fp: 141.0000 - tn: 303.0000 - fn: 85.0000 - accuracy: 0.6826 - precision: 0.5648 - recall: 0.6828 - auc: 0.7591 - val_loss: 1.1896 - val_tp: 55.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 19.0000 - val_accuracy: 0.7654 - val_precision: 0.7051 - val_recall: 0.7432 - val_auc: 0.8784\n",
      "Epoch 25/600\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 1.1496 - tp: 193.0000 - fp: 150.0000 - tn: 294.0000 - fn: 75.0000 - accuracy: 0.6840 - precision: 0.5627 - recall: 0.7201 - auc: 0.7782 - val_loss: 1.0898 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8770\n",
      "Epoch 26/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 1.0613 - tp: 185.0000 - fp: 126.0000 - tn: 318.0000 - fn: 83.0000 - accuracy: 0.7065 - precision: 0.5949 - recall: 0.6903 - auc: 0.7715 - val_loss: 1.0070 - val_tp: 55.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 19.0000 - val_accuracy: 0.7598 - val_precision: 0.6962 - val_recall: 0.7432 - val_auc: 0.8758\n",
      "Epoch 27/600\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.9867 - tp: 190.0000 - fp: 132.0000 - tn: 312.0000 - fn: 78.0000 - accuracy: 0.7051 - precision: 0.5901 - recall: 0.7090 - auc: 0.7723 - val_loss: 0.9316 - val_tp: 58.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 16.0000 - val_accuracy: 0.7654 - val_precision: 0.6905 - val_recall: 0.7838 - val_auc: 0.8740\n",
      "Epoch 28/600\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.9225 - tp: 194.0000 - fp: 139.0000 - tn: 305.0000 - fn: 74.0000 - accuracy: 0.7008 - precision: 0.5826 - recall: 0.7239 - auc: 0.7606 - val_loss: 0.8729 - val_tp: 61.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 13.0000 - val_accuracy: 0.7542 - val_precision: 0.6630 - val_recall: 0.8243 - val_auc: 0.8678\n",
      "Epoch 29/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.8656 - tp: 194.0000 - fp: 171.0000 - tn: 273.0000 - fn: 74.0000 - accuracy: 0.6559 - precision: 0.5315 - recall: 0.7239 - auc: 0.7593 - val_loss: 0.8281 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8782\n",
      "Epoch 30/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.8209 - tp: 180.0000 - fp: 125.0000 - tn: 319.0000 - fn: 88.0000 - accuracy: 0.7008 - precision: 0.5902 - recall: 0.6716 - auc: 0.7609 - val_loss: 0.7851 - val_tp: 60.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 14.0000 - val_accuracy: 0.7542 - val_precision: 0.6667 - val_recall: 0.8108 - val_auc: 0.8708\n",
      "Epoch 31/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7770 - tp: 178.0000 - fp: 119.0000 - tn: 325.0000 - fn: 90.0000 - accuracy: 0.7065 - precision: 0.5993 - recall: 0.6642 - auc: 0.7728 - val_loss: 0.7496 - val_tp: 58.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 16.0000 - val_accuracy: 0.7430 - val_precision: 0.6591 - val_recall: 0.7838 - val_auc: 0.8730\n",
      "Epoch 32/600\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.7468 - tp: 196.0000 - fp: 151.0000 - tn: 293.0000 - fn: 72.0000 - accuracy: 0.6868 - precision: 0.5648 - recall: 0.7313 - auc: 0.7817 - val_loss: 0.7214 - val_tp: 56.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 18.0000 - val_accuracy: 0.7598 - val_precision: 0.6914 - val_recall: 0.7568 - val_auc: 0.8751\n",
      "Epoch 33/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7497 - tp: 172.0000 - fp: 156.0000 - tn: 288.0000 - fn: 96.0000 - accuracy: 0.6461 - precision: 0.5244 - recall: 0.6418 - auc: 0.7224 - val_loss: 0.7121 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8773\n",
      "Epoch 34/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7110 - tp: 160.0000 - fp: 108.0000 - tn: 336.0000 - fn: 108.0000 - accuracy: 0.6966 - precision: 0.5970 - recall: 0.5970 - auc: 0.7736 - val_loss: 0.6961 - val_tp: 61.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 13.0000 - val_accuracy: 0.7821 - val_precision: 0.7011 - val_recall: 0.8243 - val_auc: 0.8725\n",
      "Epoch 35/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7201 - tp: 186.0000 - fp: 182.0000 - tn: 262.0000 - fn: 82.0000 - accuracy: 0.6292 - precision: 0.5054 - recall: 0.6940 - auc: 0.7298 - val_loss: 0.6834 - val_tp: 59.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 15.0000 - val_accuracy: 0.7709 - val_precision: 0.6941 - val_recall: 0.7973 - val_auc: 0.8703\n",
      "Epoch 36/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7089 - tp: 173.0000 - fp: 159.0000 - tn: 285.0000 - fn: 95.0000 - accuracy: 0.6433 - precision: 0.5211 - recall: 0.6455 - auc: 0.7310 - val_loss: 0.6842 - val_tp: 54.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 20.0000 - val_accuracy: 0.7709 - val_precision: 0.7200 - val_recall: 0.7297 - val_auc: 0.8766\n",
      "Epoch 37/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6900 - tp: 178.0000 - fp: 137.0000 - tn: 307.0000 - fn: 90.0000 - accuracy: 0.6812 - precision: 0.5651 - recall: 0.6642 - auc: 0.7672 - val_loss: 0.6798 - val_tp: 53.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 21.0000 - val_accuracy: 0.7933 - val_precision: 0.7681 - val_recall: 0.7162 - val_auc: 0.8790\n",
      "Epoch 38/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6916 - tp: 153.0000 - fp: 95.0000 - tn: 349.0000 - fn: 115.0000 - accuracy: 0.7051 - precision: 0.6169 - recall: 0.5709 - auc: 0.7496 - val_loss: 0.6727 - val_tp: 54.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 20.0000 - val_accuracy: 0.7765 - val_precision: 0.7297 - val_recall: 0.7297 - val_auc: 0.8752\n",
      "Epoch 39/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.5535 - tp: 197.0000 - fp: 84.0000 - tn: 360.0000 - fn: 71.0000 - accuracy: 0.7823 - precision: 0.7011 - recall: 0.7351 - auc: 0.8330 - val_loss: 0.5209 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8859\n",
      "Epoch 220/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5534 - tp: 193.0000 - fp: 73.0000 - tn: 371.0000 - fn: 75.0000 - accuracy: 0.7921 - precision: 0.7256 - recall: 0.7201 - auc: 0.8185 - val_loss: 0.5404 - val_tp: 54.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 20.0000 - val_accuracy: 0.8045 - val_precision: 0.7826 - val_recall: 0.7297 - val_auc: 0.8788\n",
      "Epoch 221/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5439 - tp: 201.0000 - fp: 68.0000 - tn: 376.0000 - fn: 67.0000 - accuracy: 0.8104 - precision: 0.7472 - recall: 0.7500 - auc: 0.8332 - val_loss: 0.5193 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8806\n",
      "Epoch 222/600\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5414 - tp: 201.0000 - fp: 75.0000 - tn: 369.0000 - fn: 67.0000 - accuracy: 0.8006 - precision: 0.7283 - recall: 0.7500 - auc: 0.8306 - val_loss: 0.5214 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8820\n",
      "Epoch 223/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5367 - tp: 190.0000 - fp: 76.0000 - tn: 368.0000 - fn: 78.0000 - accuracy: 0.7837 - precision: 0.7143 - recall: 0.7090 - auc: 0.8355 - val_loss: 0.5326 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8745\n",
      "Epoch 224/600\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5576 - tp: 192.0000 - fp: 69.0000 - tn: 375.0000 - fn: 76.0000 - accuracy: 0.7963 - precision: 0.7356 - recall: 0.7164 - auc: 0.8227 - val_loss: 0.5315 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8770\n",
      "Epoch 225/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5565 - tp: 194.0000 - fp: 70.0000 - tn: 374.0000 - fn: 74.0000 - accuracy: 0.7978 - precision: 0.7348 - recall: 0.7239 - auc: 0.8165 - val_loss: 0.5423 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8701\n",
      "Epoch 226/600\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5556 - tp: 194.0000 - fp: 74.0000 - tn: 370.0000 - fn: 74.0000 - accuracy: 0.7921 - precision: 0.7239 - recall: 0.7239 - auc: 0.8288 - val_loss: 0.5642 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8665\n",
      "Epoch 227/600\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5440 - tp: 194.0000 - fp: 62.0000 - tn: 382.0000 - fn: 74.0000 - accuracy: 0.8090 - precision: 0.7578 - recall: 0.7239 - auc: 0.8257 - val_loss: 0.5261 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8766\n",
      "Epoch 228/600\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.5614 - tp: 197.0000 - fp: 78.0000 - tn: 366.0000 - fn: 71.0000 - accuracy: 0.7907 - precision: 0.7164 - recall: 0.7351 - auc: 0.8267 - val_loss: 0.5238 - val_tp: 54.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 20.0000 - val_accuracy: 0.8101 - val_precision: 0.7941 - val_recall: 0.7297 - val_auc: 0.8819\n",
      "Epoch 229/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5397 - tp: 192.0000 - fp: 61.0000 - tn: 383.0000 - fn: 76.0000 - accuracy: 0.8076 - precision: 0.7589 - recall: 0.7164 - auc: 0.8367 - val_loss: 0.5312 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8732\n",
      "Epoch 230/600\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.5409 - tp: 205.0000 - fp: 82.0000 - tn: 362.0000 - fn: 63.0000 - accuracy: 0.7963 - precision: 0.7143 - recall: 0.7649 - auc: 0.8338 - val_loss: 0.5192 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8758\n",
      "Epoch 231/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.5416 - tp: 211.0000 - fp: 83.0000 - tn: 361.0000 - fn: 57.0000 - accuracy: 0.8034 - precision: 0.7177 - recall: 0.7873 - auc: 0.8346 - val_loss: 0.5295 - val_tp: 58.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 16.0000 - val_accuracy: 0.7821 - val_precision: 0.7160 - val_recall: 0.7838 - val_auc: 0.8789\n",
      "Epoch 232/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5223 - tp: 211.0000 - fp: 77.0000 - tn: 367.0000 - fn: 57.0000 - accuracy: 0.8118 - precision: 0.7326 - recall: 0.7873 - auc: 0.8502 - val_loss: 0.5189 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8763\n",
      "Epoch 233/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5747 - tp: 194.0000 - fp: 73.0000 - tn: 371.0000 - fn: 74.0000 - accuracy: 0.7935 - precision: 0.7266 - recall: 0.7239 - auc: 0.8053 - val_loss: 0.5385 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8744\n",
      "Epoch 234/600\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5412 - tp: 192.0000 - fp: 64.0000 - tn: 380.0000 - fn: 76.0000 - accuracy: 0.8034 - precision: 0.7500 - recall: 0.7164 - auc: 0.8452 - val_loss: 0.5471 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8734\n",
      "Epoch 235/600\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.5319 - tp: 199.0000 - fp: 77.0000 - tn: 367.0000 - fn: 69.0000 - accuracy: 0.7949 - precision: 0.7210 - recall: 0.7425 - auc: 0.8300 - val_loss: 0.5546 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8681\n",
      "Epoch 236/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.5441 - tp: 196.0000 - fp: 71.0000 - tn: 373.0000 - fn: 72.0000 - accuracy: 0.7992 - precision: 0.7341 - recall: 0.7313 - auc: 0.8223 - val_loss: 0.5575 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8735\n",
      "Epoch 237/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.5625 - tp: 191.0000 - fp: 80.0000 - tn: 364.0000 - fn: 77.0000 - accuracy: 0.7795 - precision: 0.7048 - recall: 0.7127 - auc: 0.8317 - val_loss: 0.5190 - val_tp: 58.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 16.0000 - val_accuracy: 0.7765 - val_precision: 0.7073 - val_recall: 0.7838 - val_auc: 0.8720\n",
      "Epoch 238/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.5643 - tp: 200.0000 - fp: 70.0000 - tn: 374.0000 - fn: 68.0000 - accuracy: 0.8062 - precision: 0.7407 - recall: 0.7463 - auc: 0.8175 - val_loss: 0.5236 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8716\n",
      "Epoch 239/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.5444 - tp: 201.0000 - fp: 71.0000 - tn: 373.0000 - fn: 67.0000 - accuracy: 0.8062 - precision: 0.7390 - recall: 0.7500 - auc: 0.8315 - val_loss: 0.5120 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8837\n",
      "Epoch 240/600\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.5281 - tp: 196.0000 - fp: 63.0000 - tn: 381.0000 - fn: 72.0000 - accuracy: 0.8104 - precision: 0.7568 - recall: 0.7313 - auc: 0.8478 - val_loss: 0.5442 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8713\n",
      "Epoch 241/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5530 - tp: 185.0000 - fp: 58.0000 - tn: 386.0000 - fn: 83.0000 - accuracy: 0.8020 - precision: 0.7613 - recall: 0.6903 - auc: 0.8250 - val_loss: 0.5155 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8793\n",
      "Epoch 242/600\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5577 - tp: 190.0000 - fp: 73.0000 - tn: 371.0000 - fn: 78.0000 - accuracy: 0.7879 - precision: 0.7224 - recall: 0.7090 - auc: 0.8224 - val_loss: 0.5186 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8878\n",
      "Epoch 243/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5663 - tp: 200.0000 - fp: 86.0000 - tn: 358.0000 - fn: 68.0000 - accuracy: 0.7837 - precision: 0.6993 - recall: 0.7463 - auc: 0.8264 - val_loss: 0.5284 - val_tp: 54.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 20.0000 - val_accuracy: 0.8212 - val_precision: 0.8182 - val_recall: 0.7297 - val_auc: 0.8837\n",
      "Epoch 244/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5496 - tp: 193.0000 - fp: 65.0000 - tn: 379.0000 - fn: 75.0000 - accuracy: 0.8034 - precision: 0.7481 - recall: 0.7201 - auc: 0.8321 - val_loss: 0.5131 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8795\n",
      "Epoch 245/600\n",
      "712/712 [==============================] - 0s 205us/sample - loss: 0.5485 - tp: 205.0000 - fp: 82.0000 - tn: 362.0000 - fn: 63.0000 - accuracy: 0.7963 - precision: 0.7143 - recall: 0.7649 - auc: 0.8356 - val_loss: 0.5138 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8782\n",
      "Epoch 246/600\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5406 - tp: 206.0000 - fp: 82.0000 - tn: 362.0000 - fn: 62.0000 - accuracy: 0.7978 - precision: 0.7153 - recall: 0.7687 - auc: 0.8361 - val_loss: 0.5270 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8736\n",
      "Epoch 247/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5601 - tp: 198.0000 - fp: 73.0000 - tn: 371.0000 - fn: 70.0000 - accuracy: 0.7992 - precision: 0.7306 - recall: 0.7388 - auc: 0.8202 - val_loss: 0.5254 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8756\n",
      "Epoch 248/600\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.5316 - tp: 211.0000 - fp: 87.0000 - tn: 357.0000 - fn: 57.0000 - accuracy: 0.7978 - precision: 0.7081 - recall: 0.7873 - auc: 0.8463 - val_loss: 0.5205 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8808\n",
      "Epoch 249/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5556 - tp: 197.0000 - fp: 75.0000 - tn: 369.0000 - fn: 71.0000 - accuracy: 0.7949 - precision: 0.7243 - recall: 0.7351 - auc: 0.8156 - val_loss: 0.5251 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8817\n",
      "Epoch 250/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5441 - tp: 195.0000 - fp: 67.0000 - tn: 377.0000 - fn: 73.0000 - accuracy: 0.8034 - precision: 0.7443 - recall: 0.7276 - auc: 0.8266 - val_loss: 0.5381 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8349\n",
      "Epoch 251/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.5337 - tp: 197.0000 - fp: 65.0000 - tn: 379.0000 - fn: 71.0000 - accuracy: 0.8090 - precision: 0.7519 - recall: 0.7351 - auc: 0.8319 - val_loss: 0.5181 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8746\n",
      "Epoch 252/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.5802 - tp: 205.0000 - fp: 106.0000 - tn: 338.0000 - fn: 63.0000 - accuracy: 0.7626 - precision: 0.6592 - recall: 0.7649 - auc: 0.8067 - val_loss: 0.5267 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8725\n",
      "Epoch 253/600\n",
      "712/712 [==============================] - 0s 204us/sample - loss: 0.5774 - tp: 200.0000 - fp: 84.0000 - tn: 360.0000 - fn: 68.0000 - accuracy: 0.7865 - precision: 0.7042 - recall: 0.7463 - auc: 0.8154 - val_loss: 0.5311 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8779\n",
      "Epoch 254/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5524 - tp: 200.0000 - fp: 74.0000 - tn: 370.0000 - fn: 68.0000 - accuracy: 0.8006 - precision: 0.7299 - recall: 0.7463 - auc: 0.8227 - val_loss: 0.5226 - val_tp: 53.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 21.0000 - val_accuracy: 0.8156 - val_precision: 0.8154 - val_recall: 0.7162 - val_auc: 0.8804\n",
      "Epoch 255/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5518 - tp: 201.0000 - fp: 76.0000 - tn: 368.0000 - fn: 67.0000 - accuracy: 0.7992 - precision: 0.7256 - recall: 0.7500 - auc: 0.8306 - val_loss: 0.5156 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8790\n",
      "Epoch 256/600\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5596 - tp: 198.0000 - fp: 86.0000 - tn: 358.0000 - fn: 70.0000 - accuracy: 0.7809 - precision: 0.6972 - recall: 0.7388 - auc: 0.8155 - val_loss: 0.5316 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8629\n",
      "Epoch 257/600\n",
      "712/712 [==============================] - 0s 226us/sample - loss: 1.2396 - tp: 161.0000 - fp: 110.0000 - tn: 334.0000 - fn: 107.0000 - accuracy: 0.6952 - precision: 0.5941 - recall: 0.6007 - auc: 0.7353 - val_loss: 1.1545 - val_tp: 61.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 13.0000 - val_accuracy: 0.7430 - val_precision: 0.6489 - val_recall: 0.8243 - val_auc: 0.8386\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 212us/sample - loss: 1.1284 - tp: 178.0000 - fp: 113.0000 - tn: 331.0000 - fn: 90.0000 - accuracy: 0.7149 - precision: 0.6117 - recall: 0.6642 - auc: 0.7679 - val_loss: 1.0557 - val_tp: 60.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 14.0000 - val_accuracy: 0.7542 - val_precision: 0.6667 - val_recall: 0.8108 - val_auc: 0.8461\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 197us/sample - loss: 1.0435 - tp: 168.0000 - fp: 84.0000 - tn: 360.0000 - fn: 100.0000 - accuracy: 0.7416 - precision: 0.6667 - recall: 0.6269 - auc: 0.7853 - val_loss: 0.9774 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8533\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 218us/sample - loss: 0.9869 - tp: 191.0000 - fp: 127.0000 - tn: 317.0000 - fn: 77.0000 - accuracy: 0.7135 - precision: 0.6006 - recall: 0.7127 - auc: 0.7705 - val_loss: 0.9209 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8544\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 200us/sample - loss: 0.9205 - tp: 184.0000 - fp: 89.0000 - tn: 355.0000 - fn: 84.0000 - accuracy: 0.7570 - precision: 0.6740 - recall: 0.6866 - auc: 0.7920 - val_loss: 0.8656 - val_tp: 58.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 16.0000 - val_accuracy: 0.7598 - val_precision: 0.6824 - val_recall: 0.7838 - val_auc: 0.8470\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 226us/sample - loss: 0.8736 - tp: 197.0000 - fp: 102.0000 - tn: 342.0000 - fn: 71.0000 - accuracy: 0.7570 - precision: 0.6589 - recall: 0.7351 - auc: 0.7984 - val_loss: 0.8193 - val_tp: 58.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 16.0000 - val_accuracy: 0.7598 - val_precision: 0.6824 - val_recall: 0.7838 - val_auc: 0.8510\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 221us/sample - loss: 0.8378 - tp: 193.0000 - fp: 95.0000 - tn: 349.0000 - fn: 75.0000 - accuracy: 0.7612 - precision: 0.6701 - recall: 0.7201 - auc: 0.8032 - val_loss: 0.7904 - val_tp: 60.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 14.0000 - val_accuracy: 0.7542 - val_precision: 0.6667 - val_recall: 0.8108 - val_auc: 0.8482\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 227us/sample - loss: 0.8072 - tp: 191.0000 - fp: 102.0000 - tn: 342.0000 - fn: 77.0000 - accuracy: 0.7486 - precision: 0.6519 - recall: 0.7127 - auc: 0.8000 - val_loss: 0.7661 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8593\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 226us/sample - loss: 0.7925 - tp: 191.0000 - fp: 102.0000 - tn: 342.0000 - fn: 77.0000 - accuracy: 0.7486 - precision: 0.6519 - recall: 0.7127 - auc: 0.7932 - val_loss: 0.7440 - val_tp: 57.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 17.0000 - val_accuracy: 0.7821 - val_precision: 0.7215 - val_recall: 0.7703 - val_auc: 0.8607\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 233us/sample - loss: 0.7734 - tp: 190.0000 - fp: 91.0000 - tn: 353.0000 - fn: 78.0000 - accuracy: 0.7626 - precision: 0.6762 - recall: 0.7090 - auc: 0.7968 - val_loss: 0.7217 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8619\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 194us/sample - loss: 0.7460 - tp: 189.0000 - fp: 92.0000 - tn: 352.0000 - fn: 79.0000 - accuracy: 0.7598 - precision: 0.6726 - recall: 0.7052 - auc: 0.8053 - val_loss: 0.7073 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8568\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 253us/sample - loss: 0.7415 - tp: 201.0000 - fp: 110.0000 - tn: 334.0000 - fn: 67.0000 - accuracy: 0.7514 - precision: 0.6463 - recall: 0.7500 - auc: 0.8051 - val_loss: 0.6951 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8591\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 238us/sample - loss: 0.7310 - tp: 198.0000 - fp: 97.0000 - tn: 347.0000 - fn: 70.0000 - accuracy: 0.7654 - precision: 0.6712 - recall: 0.7388 - auc: 0.8004 - val_loss: 0.6865 - val_tp: 58.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 16.0000 - val_accuracy: 0.7765 - val_precision: 0.7073 - val_recall: 0.7838 - val_auc: 0.8610\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 268us/sample - loss: 0.7050 - tp: 194.0000 - fp: 83.0000 - tn: 361.0000 - fn: 74.0000 - accuracy: 0.7795 - precision: 0.7004 - recall: 0.7239 - auc: 0.8240 - val_loss: 0.6725 - val_tp: 57.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 17.0000 - val_accuracy: 0.7821 - val_precision: 0.7215 - val_recall: 0.7703 - val_auc: 0.8617\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 249us/sample - loss: 0.6822 - tp: 209.0000 - fp: 103.0000 - tn: 341.0000 - fn: 59.0000 - accuracy: 0.7725 - precision: 0.6699 - recall: 0.7799 - auc: 0.8328 - val_loss: 0.6645 - val_tp: 54.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 20.0000 - val_accuracy: 0.7821 - val_precision: 0.7397 - val_recall: 0.7297 - val_auc: 0.8667\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 238us/sample - loss: 0.6975 - tp: 188.0000 - fp: 78.0000 - tn: 366.0000 - fn: 80.0000 - accuracy: 0.7781 - precision: 0.7068 - recall: 0.7015 - auc: 0.8135 - val_loss: 0.6673 - val_tp: 62.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 12.0000 - val_accuracy: 0.7654 - val_precision: 0.6739 - val_recall: 0.8378 - val_auc: 0.8542\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 230us/sample - loss: 0.6807 - tp: 205.0000 - fp: 96.0000 - tn: 348.0000 - fn: 63.0000 - accuracy: 0.7767 - precision: 0.6811 - recall: 0.7649 - auc: 0.8239 - val_loss: 0.6587 - val_tp: 54.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 20.0000 - val_accuracy: 0.7709 - val_precision: 0.7200 - val_recall: 0.7297 - val_auc: 0.8622\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 210us/sample - loss: 0.6787 - tp: 200.0000 - fp: 86.0000 - tn: 358.0000 - fn: 68.0000 - accuracy: 0.7837 - precision: 0.6993 - recall: 0.7463 - auc: 0.8219 - val_loss: 0.6477 - val_tp: 56.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 18.0000 - val_accuracy: 0.7877 - val_precision: 0.7368 - val_recall: 0.7568 - val_auc: 0.8666\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 230us/sample - loss: 0.6658 - tp: 195.0000 - fp: 77.0000 - tn: 367.0000 - fn: 73.0000 - accuracy: 0.7893 - precision: 0.7169 - recall: 0.7276 - auc: 0.8314 - val_loss: 0.6442 - val_tp: 53.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 21.0000 - val_accuracy: 0.7709 - val_precision: 0.7260 - val_recall: 0.7162 - val_auc: 0.8672\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 214us/sample - loss: 0.6588 - tp: 199.0000 - fp: 82.0000 - tn: 362.0000 - fn: 69.0000 - accuracy: 0.7879 - precision: 0.7082 - recall: 0.7425 - auc: 0.8332 - val_loss: 0.6405 - val_tp: 62.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 12.0000 - val_accuracy: 0.7654 - val_precision: 0.6739 - val_recall: 0.8378 - val_auc: 0.8607\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 201us/sample - loss: 0.6722 - tp: 203.0000 - fp: 93.0000 - tn: 351.0000 - fn: 65.0000 - accuracy: 0.7781 - precision: 0.6858 - recall: 0.7575 - auc: 0.8178 - val_loss: 0.6408 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8678\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6434 - tp: 205.0000 - fp: 80.0000 - tn: 364.0000 - fn: 63.0000 - accuracy: 0.7992 - precision: 0.7193 - recall: 0.7649 - auc: 0.8420 - val_loss: 0.6299 - val_tp: 58.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 16.0000 - val_accuracy: 0.7877 - val_precision: 0.7250 - val_recall: 0.7838 - val_auc: 0.8670\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6578 - tp: 198.0000 - fp: 92.0000 - tn: 352.0000 - fn: 70.0000 - accuracy: 0.7725 - precision: 0.6828 - recall: 0.7388 - auc: 0.8195 - val_loss: 0.6274 - val_tp: 54.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 20.0000 - val_accuracy: 0.7877 - val_precision: 0.7500 - val_recall: 0.7297 - val_auc: 0.8710\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6669 - tp: 195.0000 - fp: 70.0000 - tn: 374.0000 - fn: 73.0000 - accuracy: 0.7992 - precision: 0.7358 - recall: 0.7276 - auc: 0.8212 - val_loss: 0.6350 - val_tp: 60.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 14.0000 - val_accuracy: 0.7654 - val_precision: 0.6818 - val_recall: 0.8108 - val_auc: 0.8610\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6611 - tp: 193.0000 - fp: 78.0000 - tn: 366.0000 - fn: 75.0000 - accuracy: 0.7851 - precision: 0.7122 - recall: 0.7201 - auc: 0.8137 - val_loss: 0.6287 - val_tp: 57.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 17.0000 - val_accuracy: 0.7821 - val_precision: 0.7215 - val_recall: 0.7703 - val_auc: 0.8656\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.6395 - tp: 202.0000 - fp: 79.0000 - tn: 365.0000 - fn: 66.0000 - accuracy: 0.7963 - precision: 0.7189 - recall: 0.7537 - auc: 0.8314 - val_loss: 0.6215 - val_tp: 58.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 16.0000 - val_accuracy: 0.7877 - val_precision: 0.7250 - val_recall: 0.7838 - val_auc: 0.8679\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.6372 - tp: 192.0000 - fp: 69.0000 - tn: 375.0000 - fn: 76.0000 - accuracy: 0.7963 - precision: 0.7356 - recall: 0.7164 - auc: 0.8335 - val_loss: 0.6211 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8666\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 198us/sample - loss: 0.6559 - tp: 202.0000 - fp: 79.0000 - tn: 365.0000 - fn: 66.0000 - accuracy: 0.7963 - precision: 0.7189 - recall: 0.7537 - auc: 0.8174 - val_loss: 0.6228 - val_tp: 55.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 19.0000 - val_accuracy: 0.7877 - val_precision: 0.7432 - val_recall: 0.7432 - val_auc: 0.8718\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 198us/sample - loss: 0.6488 - tp: 193.0000 - fp: 75.0000 - tn: 369.0000 - fn: 75.0000 - accuracy: 0.7893 - precision: 0.7201 - recall: 0.7201 - auc: 0.8186 - val_loss: 0.6176 - val_tp: 55.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 19.0000 - val_accuracy: 0.7877 - val_precision: 0.7432 - val_recall: 0.7432 - val_auc: 0.8747\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 191us/sample - loss: 0.6332 - tp: 193.0000 - fp: 69.0000 - tn: 375.0000 - fn: 75.0000 - accuracy: 0.7978 - precision: 0.7366 - recall: 0.7201 - auc: 0.8314 - val_loss: 0.6099 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8698\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6416 - tp: 196.0000 - fp: 72.0000 - tn: 372.0000 - fn: 72.0000 - accuracy: 0.7978 - precision: 0.7313 - recall: 0.7313 - auc: 0.8251 - val_loss: 0.6096 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8721\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6409 - tp: 199.0000 - fp: 86.0000 - tn: 358.0000 - fn: 69.0000 - accuracy: 0.7823 - precision: 0.6982 - recall: 0.7425 - auc: 0.8227 - val_loss: 0.6127 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8703\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 202us/sample - loss: 0.6277 - tp: 201.0000 - fp: 69.0000 - tn: 375.0000 - fn: 67.0000 - accuracy: 0.8090 - precision: 0.7444 - recall: 0.7500 - auc: 0.8343 - val_loss: 0.6101 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8707\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5343 - tp: 200.0000 - fp: 62.0000 - tn: 382.0000 - fn: 68.0000 - accuracy: 0.8174 - precision: 0.7634 - recall: 0.7463 - auc: 0.8386 - val_loss: 0.5474 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8807\n",
      "Epoch 27/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5339 - tp: 201.0000 - fp: 65.0000 - tn: 379.0000 - fn: 67.0000 - accuracy: 0.8146 - precision: 0.7556 - recall: 0.7500 - auc: 0.8530 - val_loss: 0.5118 - val_tp: 53.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 21.0000 - val_accuracy: 0.8101 - val_precision: 0.8030 - val_recall: 0.7162 - val_auc: 0.8892\n",
      "Epoch 28/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5438 - tp: 197.0000 - fp: 63.0000 - tn: 381.0000 - fn: 71.0000 - accuracy: 0.8118 - precision: 0.7577 - recall: 0.7351 - auc: 0.8352 - val_loss: 0.5388 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8847\n",
      "Epoch 29/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5269 - tp: 201.0000 - fp: 64.0000 - tn: 380.0000 - fn: 67.0000 - accuracy: 0.8160 - precision: 0.7585 - recall: 0.7500 - auc: 0.8510 - val_loss: 0.5702 - val_tp: 42.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 32.0000 - val_accuracy: 0.7821 - val_precision: 0.8571 - val_recall: 0.5676 - val_auc: 0.8921\n",
      "Epoch 30/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5317 - tp: 193.0000 - fp: 68.0000 - tn: 376.0000 - fn: 75.0000 - accuracy: 0.7992 - precision: 0.7395 - recall: 0.7201 - auc: 0.8467 - val_loss: 0.5041 - val_tp: 53.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 21.0000 - val_accuracy: 0.7933 - val_precision: 0.7681 - val_recall: 0.7162 - val_auc: 0.8878\n",
      "Epoch 31/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5308 - tp: 195.0000 - fp: 70.0000 - tn: 374.0000 - fn: 73.0000 - accuracy: 0.7992 - precision: 0.7358 - recall: 0.7276 - auc: 0.8528 - val_loss: 0.5163 - val_tp: 62.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 12.0000 - val_accuracy: 0.7877 - val_precision: 0.7045 - val_recall: 0.8378 - val_auc: 0.8889\n",
      "Epoch 32/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5400 - tp: 200.0000 - fp: 66.0000 - tn: 378.0000 - fn: 68.0000 - accuracy: 0.8118 - precision: 0.7519 - recall: 0.7463 - auc: 0.8411 - val_loss: 0.5037 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8894\n",
      "Epoch 33/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5211 - tp: 200.0000 - fp: 61.0000 - tn: 383.0000 - fn: 68.0000 - accuracy: 0.8188 - precision: 0.7663 - recall: 0.7463 - auc: 0.8530 - val_loss: 0.5152 - val_tp: 53.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 21.0000 - val_accuracy: 0.8101 - val_precision: 0.8030 - val_recall: 0.7162 - val_auc: 0.8921\n",
      "Epoch 34/700\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5214 - tp: 202.0000 - fp: 61.0000 - tn: 383.0000 - fn: 66.0000 - accuracy: 0.8216 - precision: 0.7681 - recall: 0.7537 - auc: 0.8504 - val_loss: 0.5282 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8878\n",
      "Epoch 35/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5323 - tp: 196.0000 - fp: 59.0000 - tn: 385.0000 - fn: 72.0000 - accuracy: 0.8160 - precision: 0.7686 - recall: 0.7313 - auc: 0.8405 - val_loss: 0.5260 - val_tp: 44.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 30.0000 - val_accuracy: 0.7709 - val_precision: 0.8000 - val_recall: 0.5946 - val_auc: 0.8876\n",
      "Epoch 36/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5253 - tp: 195.0000 - fp: 60.0000 - tn: 384.0000 - fn: 73.0000 - accuracy: 0.8132 - precision: 0.7647 - recall: 0.7276 - auc: 0.8509 - val_loss: 0.5765 - val_tp: 39.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 35.0000 - val_accuracy: 0.7709 - val_precision: 0.8667 - val_recall: 0.5270 - val_auc: 0.8897\n",
      "Epoch 37/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5320 - tp: 197.0000 - fp: 60.0000 - tn: 384.0000 - fn: 71.0000 - accuracy: 0.8160 - precision: 0.7665 - recall: 0.7351 - auc: 0.8414 - val_loss: 0.5406 - val_tp: 53.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 21.0000 - val_accuracy: 0.8045 - val_precision: 0.7910 - val_recall: 0.7162 - val_auc: 0.8878\n",
      "Epoch 38/700\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5302 - tp: 198.0000 - fp: 65.0000 - tn: 379.0000 - fn: 70.0000 - accuracy: 0.8104 - precision: 0.7529 - recall: 0.7388 - auc: 0.8423 - val_loss: 0.5094 - val_tp: 51.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 23.0000 - val_accuracy: 0.7821 - val_precision: 0.7612 - val_recall: 0.6892 - val_auc: 0.8876\n",
      "Epoch 39/700\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5373 - tp: 190.0000 - fp: 64.0000 - tn: 380.0000 - fn: 78.0000 - accuracy: 0.8006 - precision: 0.7480 - recall: 0.7090 - auc: 0.8423 - val_loss: 0.5200 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 27.0000 - val_accuracy: 0.7933 - val_precision: 0.8246 - val_recall: 0.6351 - val_auc: 0.8930\n",
      "Epoch 40/700\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5294 - tp: 195.0000 - fp: 59.0000 - tn: 385.0000 - fn: 73.0000 - accuracy: 0.8146 - precision: 0.7677 - recall: 0.7276 - auc: 0.8397 - val_loss: 0.4960 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8922\n",
      "Epoch 41/700\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.5200 - tp: 202.0000 - fp: 66.0000 - tn: 378.0000 - fn: 66.0000 - accuracy: 0.8146 - precision: 0.7537 - recall: 0.7537 - auc: 0.8540 - val_loss: 0.4896 - val_tp: 64.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 10.0000 - val_accuracy: 0.7821 - val_precision: 0.6882 - val_recall: 0.8649 - val_auc: 0.8879\n",
      "Epoch 42/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5456 - tp: 194.0000 - fp: 78.0000 - tn: 366.0000 - fn: 74.0000 - accuracy: 0.7865 - precision: 0.7132 - recall: 0.7239 - auc: 0.8315 - val_loss: 0.4948 - val_tp: 55.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 19.0000 - val_accuracy: 0.8101 - val_precision: 0.7857 - val_recall: 0.7432 - val_auc: 0.8918\n",
      "Epoch 43/700\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5087 - tp: 202.0000 - fp: 69.0000 - tn: 375.0000 - fn: 66.0000 - accuracy: 0.8104 - precision: 0.7454 - recall: 0.7537 - auc: 0.8599 - val_loss: 0.5080 - val_tp: 46.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 28.0000 - val_accuracy: 0.7821 - val_precision: 0.8070 - val_recall: 0.6216 - val_auc: 0.8938\n",
      "Epoch 44/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5234 - tp: 195.0000 - fp: 56.0000 - tn: 388.0000 - fn: 73.0000 - accuracy: 0.8188 - precision: 0.7769 - recall: 0.7276 - auc: 0.8523 - val_loss: 0.5352 - val_tp: 63.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 11.0000 - val_accuracy: 0.7821 - val_precision: 0.6923 - val_recall: 0.8514 - val_auc: 0.8887\n",
      "Epoch 45/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5333 - tp: 199.0000 - fp: 61.0000 - tn: 383.0000 - fn: 69.0000 - accuracy: 0.8174 - precision: 0.7654 - recall: 0.7425 - auc: 0.8424 - val_loss: 0.5099 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8937\n",
      "Epoch 46/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5161 - tp: 202.0000 - fp: 63.0000 - tn: 381.0000 - fn: 66.0000 - accuracy: 0.8188 - precision: 0.7623 - recall: 0.7537 - auc: 0.8613 - val_loss: 0.4982 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8935\n",
      "Epoch 47/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5439 - tp: 199.0000 - fp: 75.0000 - tn: 369.0000 - fn: 69.0000 - accuracy: 0.7978 - precision: 0.7263 - recall: 0.7425 - auc: 0.8448 - val_loss: 0.5821 - val_tp: 65.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 9.0000 - val_accuracy: 0.7598 - val_precision: 0.6566 - val_recall: 0.8784 - val_auc: 0.8860\n",
      "Epoch 48/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5263 - tp: 200.0000 - fp: 60.0000 - tn: 384.0000 - fn: 68.0000 - accuracy: 0.8202 - precision: 0.7692 - recall: 0.7463 - auc: 0.8506 - val_loss: 0.5196 - val_tp: 64.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 10.0000 - val_accuracy: 0.7709 - val_precision: 0.6737 - val_recall: 0.8649 - val_auc: 0.8865\n",
      "Epoch 49/700\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5304 - tp: 201.0000 - fp: 82.0000 - tn: 362.0000 - fn: 67.0000 - accuracy: 0.7907 - precision: 0.7102 - recall: 0.7500 - auc: 0.8501 - val_loss: 0.4987 - val_tp: 55.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 19.0000 - val_accuracy: 0.7877 - val_precision: 0.7432 - val_recall: 0.7432 - val_auc: 0.8862\n",
      "Epoch 50/700\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5165 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8560 - val_loss: 0.5063 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8943\n",
      "Epoch 51/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5225 - tp: 200.0000 - fp: 65.0000 - tn: 379.0000 - fn: 68.0000 - accuracy: 0.8132 - precision: 0.7547 - recall: 0.7463 - auc: 0.8424 - val_loss: 0.5067 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8928\n",
      "Epoch 52/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5344 - tp: 187.0000 - fp: 56.0000 - tn: 388.0000 - fn: 81.0000 - accuracy: 0.8076 - precision: 0.7695 - recall: 0.6978 - auc: 0.8415 - val_loss: 0.4993 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8940\n",
      "Epoch 53/700\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5096 - tp: 198.0000 - fp: 53.0000 - tn: 391.0000 - fn: 70.0000 - accuracy: 0.8272 - precision: 0.7888 - recall: 0.7388 - auc: 0.8562 - val_loss: 0.4962 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8925\n",
      "Epoch 54/700\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5378 - tp: 202.0000 - fp: 63.0000 - tn: 381.0000 - fn: 66.0000 - accuracy: 0.8188 - precision: 0.7623 - recall: 0.7537 - auc: 0.8457 - val_loss: 0.5028 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8896\n",
      "Epoch 55/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5294 - tp: 199.0000 - fp: 66.0000 - tn: 378.0000 - fn: 69.0000 - accuracy: 0.8104 - precision: 0.7509 - recall: 0.7425 - auc: 0.8330 - val_loss: 0.5198 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8917\n",
      "Epoch 56/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5277 - tp: 194.0000 - fp: 56.0000 - tn: 388.0000 - fn: 74.0000 - accuracy: 0.8174 - precision: 0.7760 - recall: 0.7239 - auc: 0.8357 - val_loss: 0.5349 - val_tp: 62.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 12.0000 - val_accuracy: 0.7765 - val_precision: 0.6889 - val_recall: 0.8378 - val_auc: 0.8922\n",
      "Epoch 57/700\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5213 - tp: 193.0000 - fp: 48.0000 - tn: 396.0000 - fn: 75.0000 - accuracy: 0.8272 - precision: 0.8008 - recall: 0.7201 - auc: 0.8365 - val_loss: 0.4861 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8945\n",
      "Epoch 58/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5291 - tp: 194.0000 - fp: 63.0000 - tn: 381.0000 - fn: 74.0000 - accuracy: 0.8076 - precision: 0.7549 - recall: 0.7239 - auc: 0.8496 - val_loss: 0.5103 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8868\n",
      "Epoch 59/700\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5172 - tp: 195.0000 - fp: 51.0000 - tn: 393.0000 - fn: 73.0000 - accuracy: 0.8258 - precision: 0.7927 - recall: 0.7276 - auc: 0.8468 - val_loss: 0.5038 - val_tp: 54.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 20.0000 - val_accuracy: 0.8101 - val_precision: 0.7941 - val_recall: 0.7297 - val_auc: 0.8888\n",
      "Epoch 60/700\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5402 - tp: 197.0000 - fp: 65.0000 - tn: 379.0000 - fn: 71.0000 - accuracy: 0.8090 - precision: 0.7519 - recall: 0.7351 - auc: 0.8360 - val_loss: 0.5308 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8854\n",
      "Epoch 61/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5295 - tp: 197.0000 - fp: 66.0000 - tn: 378.0000 - fn: 71.0000 - accuracy: 0.8076 - precision: 0.7490 - recall: 0.7351 - auc: 0.8414 - val_loss: 0.5176 - val_tp: 53.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 21.0000 - val_accuracy: 0.8156 - val_precision: 0.8154 - val_recall: 0.7162 - val_auc: 0.8907\n",
      "Epoch 62/700\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.5249 - tp: 202.0000 - fp: 65.0000 - tn: 379.0000 - fn: 66.0000 - accuracy: 0.8160 - precision: 0.7566 - recall: 0.7537 - auc: 0.8431 - val_loss: 0.5498 - val_tp: 39.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 35.0000 - val_accuracy: 0.7709 - val_precision: 0.8667 - val_recall: 0.5270 - val_auc: 0.8911\n",
      "Epoch 63/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5206 - tp: 190.0000 - fp: 56.0000 - tn: 388.0000 - fn: 78.0000 - accuracy: 0.8118 - precision: 0.7724 - recall: 0.7090 - auc: 0.8481 - val_loss: 0.5223 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8885\n",
      "Epoch 64/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5241 - tp: 197.0000 - fp: 61.0000 - tn: 383.0000 - fn: 71.0000 - accuracy: 0.8146 - precision: 0.7636 - recall: 0.7351 - auc: 0.8518 - val_loss: 0.5179 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8860\n",
      "Epoch 65/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5353 - tp: 192.0000 - fp: 48.0000 - tn: 396.0000 - fn: 76.0000 - accuracy: 0.8258 - precision: 0.8000 - recall: 0.7164 - auc: 0.8252 - val_loss: 0.5144 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8864\n",
      "Epoch 66/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5571 - tp: 186.0000 - fp: 56.0000 - tn: 388.0000 - fn: 82.0000 - accuracy: 0.8062 - precision: 0.7686 - recall: 0.6940 - auc: 0.8265 - val_loss: 0.5393 - val_tp: 43.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 31.0000 - val_accuracy: 0.7821 - val_precision: 0.8431 - val_recall: 0.5811 - val_auc: 0.8899\n",
      "Epoch 67/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5059 - tp: 199.0000 - fp: 57.0000 - tn: 387.0000 - fn: 69.0000 - accuracy: 0.8230 - precision: 0.7773 - recall: 0.7425 - auc: 0.8550 - val_loss: 0.4939 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8890\n",
      "Epoch 68/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5199 - tp: 201.0000 - fp: 65.0000 - tn: 379.0000 - fn: 67.0000 - accuracy: 0.8146 - precision: 0.7556 - recall: 0.7500 - auc: 0.8455 - val_loss: 0.5266 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8843\n",
      "Epoch 69/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5232 - tp: 195.0000 - fp: 55.0000 - tn: 389.0000 - fn: 73.0000 - accuracy: 0.8202 - precision: 0.7800 - recall: 0.7276 - auc: 0.8543 - val_loss: 0.5315 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8856\n",
      "Epoch 70/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5413 - tp: 191.0000 - fp: 56.0000 - tn: 388.0000 - fn: 77.0000 - accuracy: 0.8132 - precision: 0.7733 - recall: 0.7127 - auc: 0.8256 - val_loss: 0.5266 - val_tp: 64.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 10.0000 - val_accuracy: 0.7877 - val_precision: 0.6957 - val_recall: 0.8649 - val_auc: 0.8891\n",
      "Epoch 71/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5347 - tp: 202.0000 - fp: 73.0000 - tn: 371.0000 - fn: 66.0000 - accuracy: 0.8048 - precision: 0.7345 - recall: 0.7537 - auc: 0.8393 - val_loss: 0.5098 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8887\n",
      "Epoch 72/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5108 - tp: 195.0000 - fp: 57.0000 - tn: 387.0000 - fn: 73.0000 - accuracy: 0.8174 - precision: 0.7738 - recall: 0.7276 - auc: 0.8576 - val_loss: 0.5161 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8909\n",
      "Epoch 73/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5285 - tp: 195.0000 - fp: 59.0000 - tn: 385.0000 - fn: 73.0000 - accuracy: 0.8146 - precision: 0.7677 - recall: 0.7276 - auc: 0.8411 - val_loss: 0.5548 - val_tp: 50.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 24.0000 - val_accuracy: 0.8101 - val_precision: 0.8333 - val_recall: 0.6757 - val_auc: 0.8829\n",
      "Epoch 74/700\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5321 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8430 - val_loss: 0.5272 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8831\n",
      "Epoch 75/700\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.5414 - tp: 197.0000 - fp: 66.0000 - tn: 378.0000 - fn: 71.0000 - accuracy: 0.8076 - precision: 0.7490 - recall: 0.7351 - auc: 0.8417 - val_loss: 0.5098 - val_tp: 53.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 21.0000 - val_accuracy: 0.8045 - val_precision: 0.7910 - val_recall: 0.7162 - val_auc: 0.8914\n",
      "Epoch 76/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5157 - tp: 194.0000 - fp: 52.0000 - tn: 392.0000 - fn: 74.0000 - accuracy: 0.8230 - precision: 0.7886 - recall: 0.7239 - auc: 0.8477 - val_loss: 0.5097 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8923\n",
      "Epoch 77/700\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.5263 - tp: 203.0000 - fp: 70.0000 - tn: 374.0000 - fn: 65.0000 - accuracy: 0.8104 - precision: 0.7436 - recall: 0.7575 - auc: 0.8522 - val_loss: 0.5124 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8903\n",
      "Epoch 78/700\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.5485 - tp: 199.0000 - fp: 58.0000 - tn: 386.0000 - fn: 69.0000 - accuracy: 0.8216 - precision: 0.7743 - recall: 0.7425 - auc: 0.8369 - val_loss: 0.5058 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8900\n",
      "Epoch 79/700\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5182 - tp: 202.0000 - fp: 61.0000 - tn: 383.0000 - fn: 66.0000 - accuracy: 0.8216 - precision: 0.7681 - recall: 0.7537 - auc: 0.8504 - val_loss: 0.5548 - val_tp: 48.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 26.0000 - val_accuracy: 0.7989 - val_precision: 0.8276 - val_recall: 0.6486 - val_auc: 0.8886\n",
      "Epoch 80/700\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5452 - tp: 188.0000 - fp: 48.0000 - tn: 396.0000 - fn: 80.0000 - accuracy: 0.8202 - precision: 0.7966 - recall: 0.7015 - auc: 0.8337 - val_loss: 0.5153 - val_tp: 49.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 25.0000 - val_accuracy: 0.7989 - val_precision: 0.8167 - val_recall: 0.6622 - val_auc: 0.8898\n",
      "Epoch 81/700\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5314 - tp: 191.0000 - fp: 59.0000 - tn: 385.0000 - fn: 77.0000 - accuracy: 0.8090 - precision: 0.7640 - recall: 0.7127 - auc: 0.8442 - val_loss: 0.5542 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8875\n",
      "Epoch 82/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5425 - tp: 194.0000 - fp: 63.0000 - tn: 381.0000 - fn: 74.0000 - accuracy: 0.8076 - precision: 0.7549 - recall: 0.7239 - auc: 0.8303 - val_loss: 0.5028 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8961\n",
      "Epoch 83/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5132 - tp: 192.0000 - fp: 56.0000 - tn: 388.0000 - fn: 76.0000 - accuracy: 0.8146 - precision: 0.7742 - recall: 0.7164 - auc: 0.8525 - val_loss: 0.5187 - val_tp: 50.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 24.0000 - val_accuracy: 0.8045 - val_precision: 0.8197 - val_recall: 0.6757 - val_auc: 0.8898\n",
      "Epoch 84/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5170 - tp: 188.0000 - fp: 47.0000 - tn: 397.0000 - fn: 80.0000 - accuracy: 0.8216 - precision: 0.8000 - recall: 0.7015 - auc: 0.8538 - val_loss: 0.5088 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8929\n",
      "Epoch 85/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5160 - tp: 202.0000 - fp: 54.0000 - tn: 390.0000 - fn: 66.0000 - accuracy: 0.8315 - precision: 0.7891 - recall: 0.7537 - auc: 0.8492 - val_loss: 0.5064 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8906\n",
      "Epoch 86/700\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.5264 - tp: 191.0000 - fp: 62.0000 - tn: 382.0000 - fn: 77.0000 - accuracy: 0.8048 - precision: 0.7549 - recall: 0.7127 - auc: 0.8488 - val_loss: 0.5147 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8915\n",
      "Epoch 87/700\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5313 - tp: 184.0000 - fp: 53.0000 - tn: 391.0000 - fn: 84.0000 - accuracy: 0.8076 - precision: 0.7764 - recall: 0.6866 - auc: 0.8428 - val_loss: 0.5270 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8931\n",
      "Epoch 88/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5433 - tp: 190.0000 - fp: 56.0000 - tn: 388.0000 - fn: 78.0000 - accuracy: 0.8118 - precision: 0.7724 - recall: 0.7090 - auc: 0.8402 - val_loss: 0.5292 - val_tp: 61.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 13.0000 - val_accuracy: 0.7989 - val_precision: 0.7262 - val_recall: 0.8243 - val_auc: 0.8899\n",
      "Epoch 89/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5136 - tp: 190.0000 - fp: 54.0000 - tn: 390.0000 - fn: 78.0000 - accuracy: 0.8146 - precision: 0.7787 - recall: 0.7090 - auc: 0.8341 - val_loss: 0.5719 - val_tp: 65.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 9.0000 - val_accuracy: 0.7542 - val_precision: 0.6500 - val_recall: 0.8784 - val_auc: 0.8829\n",
      "Epoch 90/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5272 - tp: 195.0000 - fp: 63.0000 - tn: 381.0000 - fn: 73.0000 - accuracy: 0.8090 - precision: 0.7558 - recall: 0.7276 - auc: 0.8472 - val_loss: 0.5126 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8931\n",
      "Epoch 91/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5355 - tp: 194.0000 - fp: 58.0000 - tn: 386.0000 - fn: 74.0000 - accuracy: 0.8146 - precision: 0.7698 - recall: 0.7239 - auc: 0.8554 - val_loss: 0.4912 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8909\n",
      "Epoch 92/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5083 - tp: 195.0000 - fp: 52.0000 - tn: 392.0000 - fn: 73.0000 - accuracy: 0.8244 - precision: 0.7895 - recall: 0.7276 - auc: 0.8587 - val_loss: 0.5540 - val_tp: 65.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 9.0000 - val_accuracy: 0.7877 - val_precision: 0.6915 - val_recall: 0.8784 - val_auc: 0.8871\n",
      "Epoch 93/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5352 - tp: 197.0000 - fp: 69.0000 - tn: 375.0000 - fn: 71.0000 - accuracy: 0.8034 - precision: 0.7406 - recall: 0.7351 - auc: 0.8378 - val_loss: 0.5092 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8898\n",
      "Epoch 94/700\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5267 - tp: 196.0000 - fp: 60.0000 - tn: 384.0000 - fn: 72.0000 - accuracy: 0.8146 - precision: 0.7656 - recall: 0.7313 - auc: 0.8406 - val_loss: 0.4888 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8895\n",
      "Epoch 95/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5016 - tp: 198.0000 - fp: 63.0000 - tn: 381.0000 - fn: 70.0000 - accuracy: 0.8132 - precision: 0.7586 - recall: 0.7388 - auc: 0.8641 - val_loss: 0.5181 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8889\n",
      "Epoch 96/700\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5310 - tp: 198.0000 - fp: 64.0000 - tn: 380.0000 - fn: 70.0000 - accuracy: 0.8118 - precision: 0.7557 - recall: 0.7388 - auc: 0.8437 - val_loss: 0.5606 - val_tp: 65.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 9.0000 - val_accuracy: 0.7821 - val_precision: 0.6842 - val_recall: 0.8784 - val_auc: 0.8882\n",
      "Epoch 97/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5333 - tp: 190.0000 - fp: 71.0000 - tn: 373.0000 - fn: 78.0000 - accuracy: 0.7907 - precision: 0.7280 - recall: 0.7090 - auc: 0.8411 - val_loss: 0.6233 - val_tp: 68.0000 - val_fp: 38.0000 - val_tn: 67.0000 - val_fn: 6.0000 - val_accuracy: 0.7542 - val_precision: 0.6415 - val_recall: 0.9189 - val_auc: 0.8761\n",
      "Epoch 98/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5374 - tp: 199.0000 - fp: 69.0000 - tn: 375.0000 - fn: 69.0000 - accuracy: 0.8062 - precision: 0.7425 - recall: 0.7425 - auc: 0.8405 - val_loss: 0.5456 - val_tp: 45.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 29.0000 - val_accuracy: 0.7654 - val_precision: 0.7759 - val_recall: 0.6081 - val_auc: 0.8914\n",
      "Epoch 99/700\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5125 - tp: 197.0000 - fp: 59.0000 - tn: 385.0000 - fn: 71.0000 - accuracy: 0.8174 - precision: 0.7695 - recall: 0.7351 - auc: 0.8558 - val_loss: 0.7630 - val_tp: 70.0000 - val_fp: 41.0000 - val_tn: 64.0000 - val_fn: 4.0000 - val_accuracy: 0.7486 - val_precision: 0.6306 - val_recall: 0.9459 - val_auc: 0.8748\n",
      "Epoch 100/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5520 - tp: 199.0000 - fp: 77.0000 - tn: 367.0000 - fn: 69.0000 - accuracy: 0.7949 - precision: 0.7210 - recall: 0.7425 - auc: 0.8331 - val_loss: 0.5112 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8916\n",
      "Epoch 101/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5212 - tp: 198.0000 - fp: 63.0000 - tn: 381.0000 - fn: 70.0000 - accuracy: 0.8132 - precision: 0.7586 - recall: 0.7388 - auc: 0.8493 - val_loss: 0.5070 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8893\n",
      "Epoch 102/700\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5252 - tp: 189.0000 - fp: 52.0000 - tn: 392.0000 - fn: 79.0000 - accuracy: 0.8160 - precision: 0.7842 - recall: 0.7052 - auc: 0.8464 - val_loss: 0.5494 - val_tp: 62.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 12.0000 - val_accuracy: 0.7933 - val_precision: 0.7126 - val_recall: 0.8378 - val_auc: 0.8880\n",
      "Epoch 103/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5321 - tp: 198.0000 - fp: 59.0000 - tn: 385.0000 - fn: 70.0000 - accuracy: 0.8188 - precision: 0.7704 - recall: 0.7388 - auc: 0.8295 - val_loss: 0.5328 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8879\n",
      "Epoch 104/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5232 - tp: 188.0000 - fp: 47.0000 - tn: 397.0000 - fn: 80.0000 - accuracy: 0.8216 - precision: 0.8000 - recall: 0.7015 - auc: 0.8402 - val_loss: 0.6886 - val_tp: 69.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 5.0000 - val_accuracy: 0.7542 - val_precision: 0.6389 - val_recall: 0.9324 - val_auc: 0.8770\n",
      "Epoch 105/700\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5269 - tp: 189.0000 - fp: 61.0000 - tn: 383.0000 - fn: 79.0000 - accuracy: 0.8034 - precision: 0.7560 - recall: 0.7052 - auc: 0.8423 - val_loss: 0.5123 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8911\n",
      "Epoch 106/700\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5205 - tp: 197.0000 - fp: 59.0000 - tn: 385.0000 - fn: 71.0000 - accuracy: 0.8174 - precision: 0.7695 - recall: 0.7351 - auc: 0.8500 - val_loss: 0.5171 - val_tp: 52.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 22.0000 - val_accuracy: 0.8101 - val_precision: 0.8125 - val_recall: 0.7027 - val_auc: 0.8882\n",
      "Epoch 107/700\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5255 - tp: 191.0000 - fp: 50.0000 - tn: 394.0000 - fn: 77.0000 - accuracy: 0.8216 - precision: 0.7925 - recall: 0.7127 - auc: 0.8447 - val_loss: 0.4914 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8889\n",
      "Epoch 108/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5249 - tp: 200.0000 - fp: 71.0000 - tn: 373.0000 - fn: 68.0000 - accuracy: 0.8048 - precision: 0.7380 - recall: 0.7463 - auc: 0.8520 - val_loss: 0.4989 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8921\n",
      "Epoch 109/700\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5159 - tp: 197.0000 - fp: 63.0000 - tn: 381.0000 - fn: 71.0000 - accuracy: 0.8118 - precision: 0.7577 - recall: 0.7351 - auc: 0.8582 - val_loss: 0.5189 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8900\n",
      "Epoch 110/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5250 - tp: 190.0000 - fp: 66.0000 - tn: 378.0000 - fn: 78.0000 - accuracy: 0.7978 - precision: 0.7422 - recall: 0.7090 - auc: 0.8475 - val_loss: 0.6746 - val_tp: 65.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 9.0000 - val_accuracy: 0.7654 - val_precision: 0.6633 - val_recall: 0.8784 - val_auc: 0.8708\n",
      "Epoch 111/700\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5260 - tp: 201.0000 - fp: 65.0000 - tn: 379.0000 - fn: 67.0000 - accuracy: 0.8146 - precision: 0.7556 - recall: 0.7500 - auc: 0.8530 - val_loss: 0.5068 - val_tp: 52.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 22.0000 - val_accuracy: 0.8101 - val_precision: 0.8125 - val_recall: 0.7027 - val_auc: 0.8913\n",
      "Epoch 112/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5247 - tp: 190.0000 - fp: 63.0000 - tn: 381.0000 - fn: 78.0000 - accuracy: 0.8020 - precision: 0.7510 - recall: 0.7090 - auc: 0.8453 - val_loss: 0.5059 - val_tp: 50.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 24.0000 - val_accuracy: 0.8101 - val_precision: 0.8333 - val_recall: 0.6757 - val_auc: 0.8927\n",
      "Epoch 113/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5247 - tp: 195.0000 - fp: 57.0000 - tn: 387.0000 - fn: 73.0000 - accuracy: 0.8174 - precision: 0.7738 - recall: 0.7276 - auc: 0.8452 - val_loss: 0.4983 - val_tp: 54.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 20.0000 - val_accuracy: 0.8156 - val_precision: 0.8060 - val_recall: 0.7297 - val_auc: 0.8876\n",
      "Epoch 114/700\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5195 - tp: 193.0000 - fp: 58.0000 - tn: 386.0000 - fn: 75.0000 - accuracy: 0.8132 - precision: 0.7689 - recall: 0.7201 - auc: 0.8483 - val_loss: 0.5488 - val_tp: 60.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 14.0000 - val_accuracy: 0.7765 - val_precision: 0.6977 - val_recall: 0.8108 - val_auc: 0.8899\n",
      "Epoch 115/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5366 - tp: 194.0000 - fp: 64.0000 - tn: 380.0000 - fn: 74.0000 - accuracy: 0.8062 - precision: 0.7519 - recall: 0.7239 - auc: 0.8405 - val_loss: 0.5375 - val_tp: 50.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 24.0000 - val_accuracy: 0.8045 - val_precision: 0.8197 - val_recall: 0.6757 - val_auc: 0.8915\n",
      "Epoch 116/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5327 - tp: 197.0000 - fp: 68.0000 - tn: 376.0000 - fn: 71.0000 - accuracy: 0.8048 - precision: 0.7434 - recall: 0.7351 - auc: 0.8453 - val_loss: 0.5370 - val_tp: 50.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 24.0000 - val_accuracy: 0.8101 - val_precision: 0.8333 - val_recall: 0.6757 - val_auc: 0.8925\n",
      "Epoch 117/700\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5405 - tp: 192.0000 - fp: 63.0000 - tn: 381.0000 - fn: 76.0000 - accuracy: 0.8048 - precision: 0.7529 - recall: 0.7164 - auc: 0.8409 - val_loss: 0.5015 - val_tp: 54.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 20.0000 - val_accuracy: 0.8156 - val_precision: 0.8060 - val_recall: 0.7297 - val_auc: 0.8930\n",
      "Epoch 118/700\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4946 - tp: 197.0000 - fp: 47.0000 - tn: 397.0000 - fn: 71.0000 - accuracy: 0.8343 - precision: 0.8074 - recall: 0.7351 - auc: 0.8770 - val_loss: 0.7264 - val_tp: 74.0000 - val_fp: 90.0000 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4972 - val_precision: 0.4512 - val_recall: 1.0000 - val_auc: 0.8860\n",
      "Epoch 119/700\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5396 - tp: 204.0000 - fp: 95.0000 - tn: 349.0000 - fn: 64.0000 - accuracy: 0.7767 - precision: 0.6823 - recall: 0.7612 - auc: 0.8374 - val_loss: 0.4980 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8917\n",
      "Epoch 120/700\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5216 - tp: 192.0000 - fp: 62.0000 - tn: 382.0000 - fn: 76.0000 - accuracy: 0.8062 - precision: 0.7559 - recall: 0.7164 - auc: 0.8490 - val_loss: 0.5131 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8924\n",
      "Epoch 121/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5405 - tp: 192.0000 - fp: 64.0000 - tn: 380.0000 - fn: 76.0000 - accuracy: 0.8034 - precision: 0.7500 - recall: 0.7164 - auc: 0.8346 - val_loss: 0.5268 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 27.0000 - val_accuracy: 0.7933 - val_precision: 0.8246 - val_recall: 0.6351 - val_auc: 0.8930\n",
      "Epoch 122/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5265 - tp: 200.0000 - fp: 54.0000 - tn: 390.0000 - fn: 68.0000 - accuracy: 0.8287 - precision: 0.7874 - recall: 0.7463 - auc: 0.8490 - val_loss: 0.5638 - val_tp: 65.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 9.0000 - val_accuracy: 0.7654 - val_precision: 0.6633 - val_recall: 0.8784 - val_auc: 0.8892\n",
      "Epoch 123/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5267 - tp: 207.0000 - fp: 66.0000 - tn: 378.0000 - fn: 61.0000 - accuracy: 0.8216 - precision: 0.7582 - recall: 0.7724 - auc: 0.8470 - val_loss: 0.5193 - val_tp: 47.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 27.0000 - val_accuracy: 0.7989 - val_precision: 0.8393 - val_recall: 0.6351 - val_auc: 0.8935\n",
      "Epoch 124/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5135 - tp: 189.0000 - fp: 60.0000 - tn: 384.0000 - fn: 79.0000 - accuracy: 0.8048 - precision: 0.7590 - recall: 0.7052 - auc: 0.8507 - val_loss: 0.5390 - val_tp: 41.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 33.0000 - val_accuracy: 0.7765 - val_precision: 0.8542 - val_recall: 0.5541 - val_auc: 0.8868\n",
      "Epoch 125/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5202 - tp: 196.0000 - fp: 50.0000 - tn: 394.0000 - fn: 72.0000 - accuracy: 0.8287 - precision: 0.7967 - recall: 0.7313 - auc: 0.8512 - val_loss: 0.5203 - val_tp: 51.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 23.0000 - val_accuracy: 0.8101 - val_precision: 0.8226 - val_recall: 0.6892 - val_auc: 0.8912\n",
      "Epoch 126/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5221 - tp: 196.0000 - fp: 56.0000 - tn: 388.0000 - fn: 72.0000 - accuracy: 0.8202 - precision: 0.7778 - recall: 0.7313 - auc: 0.8433 - val_loss: 0.5100 - val_tp: 55.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 19.0000 - val_accuracy: 0.8045 - val_precision: 0.7746 - val_recall: 0.7432 - val_auc: 0.8937\n",
      "Epoch 127/700\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5273 - tp: 195.0000 - fp: 60.0000 - tn: 384.0000 - fn: 73.0000 - accuracy: 0.8132 - precision: 0.7647 - recall: 0.7276 - auc: 0.8427 - val_loss: 0.5009 - val_tp: 53.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 21.0000 - val_accuracy: 0.8045 - val_precision: 0.7910 - val_recall: 0.7162 - val_auc: 0.8900\n",
      "Epoch 128/700\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.5209 - tp: 195.0000 - fp: 50.0000 - tn: 394.0000 - fn: 73.0000 - accuracy: 0.8272 - precision: 0.7959 - recall: 0.7276 - auc: 0.8458 - val_loss: 0.5241 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8864\n",
      "Epoch 129/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5244 - tp: 192.0000 - fp: 52.0000 - tn: 392.0000 - fn: 76.0000 - accuracy: 0.8202 - precision: 0.7869 - recall: 0.7164 - auc: 0.8402 - val_loss: 0.5662 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8876\n",
      "Epoch 130/700\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5422 - tp: 194.0000 - fp: 59.0000 - tn: 385.0000 - fn: 74.0000 - accuracy: 0.8132 - precision: 0.7668 - recall: 0.7239 - auc: 0.8384 - val_loss: 0.5305 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8838\n",
      "Epoch 131/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5171 - tp: 199.0000 - fp: 59.0000 - tn: 385.0000 - fn: 69.0000 - accuracy: 0.8202 - precision: 0.7713 - recall: 0.7425 - auc: 0.8515 - val_loss: 0.5687 - val_tp: 65.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 9.0000 - val_accuracy: 0.7765 - val_precision: 0.6771 - val_recall: 0.8784 - val_auc: 0.8836\n",
      "Epoch 132/700\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5481 - tp: 191.0000 - fp: 58.0000 - tn: 386.0000 - fn: 77.0000 - accuracy: 0.8104 - precision: 0.7671 - recall: 0.7127 - auc: 0.8325 - val_loss: 0.5193 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8876\n",
      "Epoch 133/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5378 - tp: 197.0000 - fp: 59.0000 - tn: 385.0000 - fn: 71.0000 - accuracy: 0.8174 - precision: 0.7695 - recall: 0.7351 - auc: 0.8343 - val_loss: 0.5505 - val_tp: 43.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 31.0000 - val_accuracy: 0.7765 - val_precision: 0.8269 - val_recall: 0.5811 - val_auc: 0.8922\n",
      "Epoch 134/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5137 - tp: 197.0000 - fp: 48.0000 - tn: 396.0000 - fn: 71.0000 - accuracy: 0.8329 - precision: 0.8041 - recall: 0.7351 - auc: 0.8525 - val_loss: 0.5973 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8841\n",
      "Epoch 135/700\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5348 - tp: 196.0000 - fp: 57.0000 - tn: 387.0000 - fn: 72.0000 - accuracy: 0.8188 - precision: 0.7747 - recall: 0.7313 - auc: 0.8456 - val_loss: 0.5405 - val_tp: 70.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 4.0000 - val_accuracy: 0.7821 - val_precision: 0.6667 - val_recall: 0.9459 - val_auc: 0.8936\n",
      "Epoch 136/700\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5333 - tp: 202.0000 - fp: 64.0000 - tn: 380.0000 - fn: 66.0000 - accuracy: 0.8174 - precision: 0.7594 - recall: 0.7537 - auc: 0.8544 - val_loss: 0.4971 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8911\n",
      "Epoch 137/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5019 - tp: 203.0000 - fp: 61.0000 - tn: 383.0000 - fn: 65.0000 - accuracy: 0.8230 - precision: 0.7689 - recall: 0.7575 - auc: 0.8567 - val_loss: 0.5934 - val_tp: 39.0000 - val_fp: 4.0000 - val_tn: 101.0000 - val_fn: 35.0000 - val_accuracy: 0.7821 - val_precision: 0.9070 - val_recall: 0.5270 - val_auc: 0.8838\n",
      "Epoch 138/700\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5289 - tp: 197.0000 - fp: 56.0000 - tn: 388.0000 - fn: 71.0000 - accuracy: 0.8216 - precision: 0.7787 - recall: 0.7351 - auc: 0.8446 - val_loss: 0.5182 - val_tp: 43.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 31.0000 - val_accuracy: 0.7709 - val_precision: 0.8113 - val_recall: 0.5811 - val_auc: 0.8936\n",
      "Epoch 139/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5132 - tp: 194.0000 - fp: 58.0000 - tn: 386.0000 - fn: 74.0000 - accuracy: 0.8146 - precision: 0.7698 - recall: 0.7239 - auc: 0.8579 - val_loss: 0.6160 - val_tp: 40.0000 - val_fp: 5.0000 - val_tn: 100.0000 - val_fn: 34.0000 - val_accuracy: 0.7821 - val_precision: 0.8889 - val_recall: 0.5405 - val_auc: 0.8929\n",
      "Epoch 140/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5100 - tp: 198.0000 - fp: 48.0000 - tn: 396.0000 - fn: 70.0000 - accuracy: 0.8343 - precision: 0.8049 - recall: 0.7388 - auc: 0.8597 - val_loss: 0.5060 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8943\n",
      "Epoch 141/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5188 - tp: 188.0000 - fp: 45.0000 - tn: 399.0000 - fn: 80.0000 - accuracy: 0.8244 - precision: 0.8069 - recall: 0.7015 - auc: 0.8521 - val_loss: 0.5158 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8866\n",
      "Epoch 142/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5247 - tp: 198.0000 - fp: 56.0000 - tn: 388.0000 - fn: 70.0000 - accuracy: 0.8230 - precision: 0.7795 - recall: 0.7388 - auc: 0.8430 - val_loss: 0.5859 - val_tp: 38.0000 - val_fp: 3.0000 - val_tn: 102.0000 - val_fn: 36.0000 - val_accuracy: 0.7821 - val_precision: 0.9268 - val_recall: 0.5135 - val_auc: 0.8911\n",
      "Epoch 143/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5436 - tp: 182.0000 - fp: 58.0000 - tn: 386.0000 - fn: 86.0000 - accuracy: 0.7978 - precision: 0.7583 - recall: 0.6791 - auc: 0.8390 - val_loss: 0.6167 - val_tp: 65.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 9.0000 - val_accuracy: 0.7821 - val_precision: 0.6842 - val_recall: 0.8784 - val_auc: 0.8800\n",
      "Epoch 144/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5370 - tp: 206.0000 - fp: 61.0000 - tn: 383.0000 - fn: 62.0000 - accuracy: 0.8272 - precision: 0.7715 - recall: 0.7687 - auc: 0.8407 - val_loss: 0.5390 - val_tp: 52.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 22.0000 - val_accuracy: 0.8101 - val_precision: 0.8125 - val_recall: 0.7027 - val_auc: 0.8879\n",
      "Epoch 145/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5385 - tp: 195.0000 - fp: 64.0000 - tn: 380.0000 - fn: 73.0000 - accuracy: 0.8076 - precision: 0.7529 - recall: 0.7276 - auc: 0.8398 - val_loss: 0.5150 - val_tp: 53.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 21.0000 - val_accuracy: 0.8156 - val_precision: 0.8154 - val_recall: 0.7162 - val_auc: 0.8914\n",
      "Epoch 146/700\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5308 - tp: 193.0000 - fp: 48.0000 - tn: 396.0000 - fn: 75.0000 - accuracy: 0.8272 - precision: 0.8008 - recall: 0.7201 - auc: 0.8483 - val_loss: 0.5311 - val_tp: 50.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 24.0000 - val_accuracy: 0.8101 - val_precision: 0.8333 - val_recall: 0.6757 - val_auc: 0.8876\n",
      "Epoch 147/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5307 - tp: 198.0000 - fp: 63.0000 - tn: 381.0000 - fn: 70.0000 - accuracy: 0.8132 - precision: 0.7586 - recall: 0.7388 - auc: 0.8442 - val_loss: 0.5837 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8837\n",
      "Epoch 148/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5530 - tp: 190.0000 - fp: 55.0000 - tn: 389.0000 - fn: 78.0000 - accuracy: 0.8132 - precision: 0.7755 - recall: 0.7090 - auc: 0.8324 - val_loss: 0.5054 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8888\n",
      "Epoch 149/700\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5226 - tp: 196.0000 - fp: 57.0000 - tn: 387.0000 - fn: 72.0000 - accuracy: 0.8188 - precision: 0.7747 - recall: 0.7313 - auc: 0.8468 - val_loss: 0.5816 - val_tp: 69.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 5.0000 - val_accuracy: 0.7765 - val_precision: 0.6635 - val_recall: 0.9324 - val_auc: 0.8681\n",
      "Epoch 150/700\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5414 - tp: 193.0000 - fp: 60.0000 - tn: 384.0000 - fn: 75.0000 - accuracy: 0.8104 - precision: 0.7628 - recall: 0.7201 - auc: 0.8435 - val_loss: 0.5202 - val_tp: 50.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 24.0000 - val_accuracy: 0.8045 - val_precision: 0.8197 - val_recall: 0.6757 - val_auc: 0.8902\n",
      "Epoch 151/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5261 - tp: 195.0000 - fp: 59.0000 - tn: 385.0000 - fn: 73.0000 - accuracy: 0.8146 - precision: 0.7677 - recall: 0.7276 - auc: 0.8404 - val_loss: 0.5138 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8881\n",
      "Epoch 152/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5160 - tp: 194.0000 - fp: 52.0000 - tn: 392.0000 - fn: 74.0000 - accuracy: 0.8230 - precision: 0.7886 - recall: 0.7239 - auc: 0.8497 - val_loss: 0.5014 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8882\n",
      "Epoch 153/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5132 - tp: 196.0000 - fp: 56.0000 - tn: 388.0000 - fn: 72.0000 - accuracy: 0.8202 - precision: 0.7778 - recall: 0.7313 - auc: 0.8431 - val_loss: 0.5208 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8849\n",
      "Epoch 154/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5254 - tp: 198.0000 - fp: 64.0000 - tn: 380.0000 - fn: 70.0000 - accuracy: 0.8118 - precision: 0.7557 - recall: 0.7388 - auc: 0.8436 - val_loss: 0.5146 - val_tp: 50.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 24.0000 - val_accuracy: 0.8045 - val_precision: 0.8197 - val_recall: 0.6757 - val_auc: 0.8911\n",
      "Epoch 155/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5374 - tp: 187.0000 - fp: 55.0000 - tn: 389.0000 - fn: 81.0000 - accuracy: 0.8090 - precision: 0.7727 - recall: 0.6978 - auc: 0.8422 - val_loss: 0.5451 - val_tp: 46.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 28.0000 - val_accuracy: 0.8101 - val_precision: 0.8846 - val_recall: 0.6216 - val_auc: 0.8941\n",
      "Epoch 156/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5218 - tp: 191.0000 - fp: 50.0000 - tn: 394.0000 - fn: 77.0000 - accuracy: 0.8216 - precision: 0.7925 - recall: 0.7127 - auc: 0.8439 - val_loss: 0.5039 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8929\n",
      "Epoch 157/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5149 - tp: 198.0000 - fp: 53.0000 - tn: 391.0000 - fn: 70.0000 - accuracy: 0.8272 - precision: 0.7888 - recall: 0.7388 - auc: 0.8528 - val_loss: 0.5713 - val_tp: 65.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 9.0000 - val_accuracy: 0.7598 - val_precision: 0.6566 - val_recall: 0.8784 - val_auc: 0.8824\n",
      "Epoch 158/700\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5205 - tp: 197.0000 - fp: 57.0000 - tn: 387.0000 - fn: 71.0000 - accuracy: 0.8202 - precision: 0.7756 - recall: 0.7351 - auc: 0.8472 - val_loss: 0.5196 - val_tp: 64.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 10.0000 - val_accuracy: 0.7765 - val_precision: 0.6809 - val_recall: 0.8649 - val_auc: 0.8866\n",
      "Epoch 159/700\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.5269 - tp: 198.0000 - fp: 70.0000 - tn: 374.0000 - fn: 70.0000 - accuracy: 0.8034 - precision: 0.7388 - recall: 0.7388 - auc: 0.8462 - val_loss: 0.5391 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8857\n",
      "Epoch 160/700\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5317 - tp: 193.0000 - fp: 55.0000 - tn: 389.0000 - fn: 75.0000 - accuracy: 0.8174 - precision: 0.7782 - recall: 0.7201 - auc: 0.8359 - val_loss: 0.4807 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8948\n",
      "Epoch 161/700\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.5284 - tp: 197.0000 - fp: 62.0000 - tn: 382.0000 - fn: 71.0000 - accuracy: 0.8132 - precision: 0.7606 - recall: 0.7351 - auc: 0.8409 - val_loss: 0.5438 - val_tp: 69.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 5.0000 - val_accuracy: 0.7877 - val_precision: 0.6765 - val_recall: 0.9324 - val_auc: 0.8860\n",
      "Epoch 162/700\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.5344 - tp: 200.0000 - fp: 70.0000 - tn: 374.0000 - fn: 68.0000 - accuracy: 0.8062 - precision: 0.7407 - recall: 0.7463 - auc: 0.8455 - val_loss: 0.4881 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8912\n",
      "Epoch 163/700\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5346 - tp: 196.0000 - fp: 60.0000 - tn: 384.0000 - fn: 72.0000 - accuracy: 0.8146 - precision: 0.7656 - recall: 0.7313 - auc: 0.8402 - val_loss: 0.5025 - val_tp: 64.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 10.0000 - val_accuracy: 0.7821 - val_precision: 0.6882 - val_recall: 0.8649 - val_auc: 0.8918\n",
      "Epoch 164/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5247 - tp: 203.0000 - fp: 70.0000 - tn: 374.0000 - fn: 65.0000 - accuracy: 0.8104 - precision: 0.7436 - recall: 0.7575 - auc: 0.8406 - val_loss: 0.5852 - val_tp: 40.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 34.0000 - val_accuracy: 0.7765 - val_precision: 0.8696 - val_recall: 0.5405 - val_auc: 0.8933\n",
      "Epoch 165/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5191 - tp: 196.0000 - fp: 65.0000 - tn: 379.0000 - fn: 72.0000 - accuracy: 0.8076 - precision: 0.7510 - recall: 0.7313 - auc: 0.8535 - val_loss: 0.4878 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8922\n",
      "Epoch 166/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5136 - tp: 201.0000 - fp: 64.0000 - tn: 380.0000 - fn: 67.0000 - accuracy: 0.8160 - precision: 0.7585 - recall: 0.7500 - auc: 0.8502 - val_loss: 0.5043 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8901\n",
      "Epoch 167/700\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5201 - tp: 202.0000 - fp: 68.0000 - tn: 376.0000 - fn: 66.0000 - accuracy: 0.8118 - precision: 0.7481 - recall: 0.7537 - auc: 0.8466 - val_loss: 0.5292 - val_tp: 53.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 21.0000 - val_accuracy: 0.8101 - val_precision: 0.8030 - val_recall: 0.7162 - val_auc: 0.8936\n",
      "Epoch 168/700\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5236 - tp: 202.0000 - fp: 63.0000 - tn: 381.0000 - fn: 66.0000 - accuracy: 0.8188 - precision: 0.7623 - recall: 0.7537 - auc: 0.8452 - val_loss: 0.5406 - val_tp: 55.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 19.0000 - val_accuracy: 0.8101 - val_precision: 0.7857 - val_recall: 0.7432 - val_auc: 0.8920\n",
      "Epoch 169/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5393 - tp: 186.0000 - fp: 54.0000 - tn: 390.0000 - fn: 82.0000 - accuracy: 0.8090 - precision: 0.7750 - recall: 0.6940 - auc: 0.8392 - val_loss: 0.5225 - val_tp: 50.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 24.0000 - val_accuracy: 0.8101 - val_precision: 0.8333 - val_recall: 0.6757 - val_auc: 0.8903\n",
      "Epoch 170/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5101 - tp: 195.0000 - fp: 54.0000 - tn: 390.0000 - fn: 73.0000 - accuracy: 0.8216 - precision: 0.7831 - recall: 0.7276 - auc: 0.8608 - val_loss: 0.5103 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8849\n",
      "Epoch 171/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5224 - tp: 201.0000 - fp: 61.0000 - tn: 383.0000 - fn: 67.0000 - accuracy: 0.8202 - precision: 0.7672 - recall: 0.7500 - auc: 0.8476 - val_loss: 0.5173 - val_tp: 53.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 21.0000 - val_accuracy: 0.8101 - val_precision: 0.8030 - val_recall: 0.7162 - val_auc: 0.8901\n",
      "Epoch 172/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5273 - tp: 198.0000 - fp: 55.0000 - tn: 389.0000 - fn: 70.0000 - accuracy: 0.8244 - precision: 0.7826 - recall: 0.7388 - auc: 0.8411 - val_loss: 0.6117 - val_tp: 39.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 35.0000 - val_accuracy: 0.7654 - val_precision: 0.8478 - val_recall: 0.5270 - val_auc: 0.8850\n",
      "Epoch 173/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5442 - tp: 196.0000 - fp: 60.0000 - tn: 384.0000 - fn: 72.0000 - accuracy: 0.8146 - precision: 0.7656 - recall: 0.7313 - auc: 0.8399 - val_loss: 0.5038 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8925\n",
      "Epoch 174/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5364 - tp: 195.0000 - fp: 64.0000 - tn: 380.0000 - fn: 73.0000 - accuracy: 0.8076 - precision: 0.7529 - recall: 0.7276 - auc: 0.8466 - val_loss: 0.4996 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8914\n",
      "Epoch 175/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5184 - tp: 200.0000 - fp: 54.0000 - tn: 390.0000 - fn: 68.0000 - accuracy: 0.8287 - precision: 0.7874 - recall: 0.7463 - auc: 0.8494 - val_loss: 0.6835 - val_tp: 65.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 9.0000 - val_accuracy: 0.7765 - val_precision: 0.6771 - val_recall: 0.8784 - val_auc: 0.8786\n",
      "Epoch 176/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5522 - tp: 195.0000 - fp: 76.0000 - tn: 368.0000 - fn: 73.0000 - accuracy: 0.7907 - precision: 0.7196 - recall: 0.7276 - auc: 0.8394 - val_loss: 0.5118 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8894\n",
      "Epoch 177/700\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.5302 - tp: 200.0000 - fp: 67.0000 - tn: 377.0000 - fn: 68.0000 - accuracy: 0.8104 - precision: 0.7491 - recall: 0.7463 - auc: 0.8499 - val_loss: 0.5025 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8872\n",
      "Epoch 178/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5213 - tp: 192.0000 - fp: 58.0000 - tn: 386.0000 - fn: 76.0000 - accuracy: 0.8118 - precision: 0.7680 - recall: 0.7164 - auc: 0.8539 - val_loss: 0.5084 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8820\n",
      "Epoch 179/700\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5359 - tp: 200.0000 - fp: 73.0000 - tn: 371.0000 - fn: 68.0000 - accuracy: 0.8020 - precision: 0.7326 - recall: 0.7463 - auc: 0.8468 - val_loss: 0.5268 - val_tp: 65.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 9.0000 - val_accuracy: 0.7709 - val_precision: 0.6701 - val_recall: 0.8784 - val_auc: 0.8876\n",
      "Epoch 180/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5108 - tp: 195.0000 - fp: 57.0000 - tn: 387.0000 - fn: 73.0000 - accuracy: 0.8174 - precision: 0.7738 - recall: 0.7276 - auc: 0.8522 - val_loss: 0.4970 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8889\n",
      "Epoch 181/700\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5172 - tp: 192.0000 - fp: 64.0000 - tn: 380.0000 - fn: 76.0000 - accuracy: 0.8034 - precision: 0.7500 - recall: 0.7164 - auc: 0.8518 - val_loss: 0.5027 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8898\n",
      "Epoch 182/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5390 - tp: 197.0000 - fp: 75.0000 - tn: 369.0000 - fn: 71.0000 - accuracy: 0.7949 - precision: 0.7243 - recall: 0.7351 - auc: 0.8427 - val_loss: 0.5438 - val_tp: 43.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 31.0000 - val_accuracy: 0.7654 - val_precision: 0.7963 - val_recall: 0.5811 - val_auc: 0.8872\n",
      "Epoch 183/700\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5343 - tp: 195.0000 - fp: 58.0000 - tn: 386.0000 - fn: 73.0000 - accuracy: 0.8160 - precision: 0.7708 - recall: 0.7276 - auc: 0.8476 - val_loss: 0.4986 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8915\n",
      "Epoch 184/700\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5223 - tp: 198.0000 - fp: 64.0000 - tn: 380.0000 - fn: 70.0000 - accuracy: 0.8118 - precision: 0.7557 - recall: 0.7388 - auc: 0.8423 - val_loss: 0.5341 - val_tp: 49.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 25.0000 - val_accuracy: 0.7877 - val_precision: 0.7903 - val_recall: 0.6622 - val_auc: 0.8830\n",
      "Epoch 185/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5164 - tp: 187.0000 - fp: 49.0000 - tn: 395.0000 - fn: 81.0000 - accuracy: 0.8174 - precision: 0.7924 - recall: 0.6978 - auc: 0.8462 - val_loss: 0.5463 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8866\n",
      "Epoch 186/700\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5239 - tp: 191.0000 - fp: 60.0000 - tn: 384.0000 - fn: 77.0000 - accuracy: 0.8076 - precision: 0.7610 - recall: 0.7127 - auc: 0.8465 - val_loss: 0.5261 - val_tp: 53.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 21.0000 - val_accuracy: 0.8101 - val_precision: 0.8030 - val_recall: 0.7162 - val_auc: 0.8899\n",
      "Epoch 187/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5273 - tp: 197.0000 - fp: 60.0000 - tn: 384.0000 - fn: 71.0000 - accuracy: 0.8160 - precision: 0.7665 - recall: 0.7351 - auc: 0.8431 - val_loss: 0.5014 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8842\n",
      "Epoch 188/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5409 - tp: 195.0000 - fp: 71.0000 - tn: 373.0000 - fn: 73.0000 - accuracy: 0.7978 - precision: 0.7331 - recall: 0.7276 - auc: 0.8445 - val_loss: 0.6509 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8860\n",
      "Epoch 189/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5259 - tp: 200.0000 - fp: 64.0000 - tn: 380.0000 - fn: 68.0000 - accuracy: 0.8146 - precision: 0.7576 - recall: 0.7463 - auc: 0.8516 - val_loss: 0.4903 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8904\n",
      "Epoch 190/700\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.5350 - tp: 195.0000 - fp: 62.0000 - tn: 382.0000 - fn: 73.0000 - accuracy: 0.8104 - precision: 0.7588 - recall: 0.7276 - auc: 0.8350 - val_loss: 0.4918 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8916\n",
      "Epoch 191/700\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.5330 - tp: 188.0000 - fp: 52.0000 - tn: 392.0000 - fn: 80.0000 - accuracy: 0.8146 - precision: 0.7833 - recall: 0.7015 - auc: 0.8350 - val_loss: 0.5177 - val_tp: 64.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 10.0000 - val_accuracy: 0.7654 - val_precision: 0.6667 - val_recall: 0.8649 - val_auc: 0.8775\n",
      "Epoch 192/700\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5077 - tp: 196.0000 - fp: 61.0000 - tn: 383.0000 - fn: 72.0000 - accuracy: 0.8132 - precision: 0.7626 - recall: 0.7313 - auc: 0.8570 - val_loss: 0.5871 - val_tp: 43.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 31.0000 - val_accuracy: 0.7821 - val_precision: 0.8431 - val_recall: 0.5811 - val_auc: 0.8932\n",
      "Epoch 193/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5393 - tp: 188.0000 - fp: 52.0000 - tn: 392.0000 - fn: 80.0000 - accuracy: 0.8146 - precision: 0.7833 - recall: 0.7015 - auc: 0.8356 - val_loss: 0.5337 - val_tp: 43.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 31.0000 - val_accuracy: 0.7765 - val_precision: 0.8269 - val_recall: 0.5811 - val_auc: 0.8921\n",
      "Epoch 194/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5207 - tp: 191.0000 - fp: 62.0000 - tn: 382.0000 - fn: 77.0000 - accuracy: 0.8048 - precision: 0.7549 - recall: 0.7127 - auc: 0.8438 - val_loss: 0.4973 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8933\n",
      "Epoch 195/700\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5280 - tp: 194.0000 - fp: 68.0000 - tn: 376.0000 - fn: 74.0000 - accuracy: 0.8006 - precision: 0.7405 - recall: 0.7239 - auc: 0.8520 - val_loss: 0.5217 - val_tp: 47.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 27.0000 - val_accuracy: 0.7877 - val_precision: 0.8103 - val_recall: 0.6351 - val_auc: 0.8910\n",
      "Epoch 196/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5251 - tp: 190.0000 - fp: 53.0000 - tn: 391.0000 - fn: 78.0000 - accuracy: 0.8160 - precision: 0.7819 - recall: 0.7090 - auc: 0.8430 - val_loss: 0.5896 - val_tp: 41.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 33.0000 - val_accuracy: 0.7821 - val_precision: 0.8723 - val_recall: 0.5541 - val_auc: 0.8912\n",
      "Epoch 197/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5155 - tp: 198.0000 - fp: 56.0000 - tn: 388.0000 - fn: 70.0000 - accuracy: 0.8230 - precision: 0.7795 - recall: 0.7388 - auc: 0.8501 - val_loss: 0.4979 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8890\n",
      "Epoch 198/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5154 - tp: 197.0000 - fp: 66.0000 - tn: 378.0000 - fn: 71.0000 - accuracy: 0.8076 - precision: 0.7490 - recall: 0.7351 - auc: 0.8484 - val_loss: 0.5144 - val_tp: 62.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 12.0000 - val_accuracy: 0.7877 - val_precision: 0.7045 - val_recall: 0.8378 - val_auc: 0.8887\n",
      "Epoch 199/700\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5399 - tp: 185.0000 - fp: 62.0000 - tn: 382.0000 - fn: 83.0000 - accuracy: 0.7963 - precision: 0.7490 - recall: 0.6903 - auc: 0.8440 - val_loss: 0.5085 - val_tp: 49.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 25.0000 - val_accuracy: 0.8101 - val_precision: 0.8448 - val_recall: 0.6622 - val_auc: 0.8976\n",
      "Epoch 200/700\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5111 - tp: 195.0000 - fp: 56.0000 - tn: 388.0000 - fn: 73.0000 - accuracy: 0.8188 - precision: 0.7769 - recall: 0.7276 - auc: 0.8504 - val_loss: 0.5084 - val_tp: 52.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 22.0000 - val_accuracy: 0.8268 - val_precision: 0.8525 - val_recall: 0.7027 - val_auc: 0.8983\n",
      "Epoch 201/700\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5248 - tp: 191.0000 - fp: 59.0000 - tn: 385.0000 - fn: 77.0000 - accuracy: 0.8090 - precision: 0.7640 - recall: 0.7127 - auc: 0.8508 - val_loss: 0.4874 - val_tp: 62.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 12.0000 - val_accuracy: 0.8156 - val_precision: 0.7470 - val_recall: 0.8378 - val_auc: 0.8920\n",
      "Epoch 202/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5154 - tp: 201.0000 - fp: 70.0000 - tn: 374.0000 - fn: 67.0000 - accuracy: 0.8076 - precision: 0.7417 - recall: 0.7500 - auc: 0.8531 - val_loss: 0.5600 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8867\n",
      "Epoch 203/700\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.5381 - tp: 185.0000 - fp: 63.0000 - tn: 381.0000 - fn: 83.0000 - accuracy: 0.7949 - precision: 0.7460 - recall: 0.6903 - auc: 0.8359 - val_loss: 0.5167 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8925\n",
      "Epoch 204/700\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5168 - tp: 195.0000 - fp: 58.0000 - tn: 386.0000 - fn: 73.0000 - accuracy: 0.8160 - precision: 0.7708 - recall: 0.7276 - auc: 0.8546 - val_loss: 0.5445 - val_tp: 65.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 9.0000 - val_accuracy: 0.7765 - val_precision: 0.6771 - val_recall: 0.8784 - val_auc: 0.8856\n",
      "Epoch 205/700\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5210 - tp: 196.0000 - fp: 68.0000 - tn: 376.0000 - fn: 72.0000 - accuracy: 0.8034 - precision: 0.7424 - recall: 0.7313 - auc: 0.8556 - val_loss: 0.4996 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8923\n",
      "Epoch 206/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5224 - tp: 194.0000 - fp: 60.0000 - tn: 384.0000 - fn: 74.0000 - accuracy: 0.8118 - precision: 0.7638 - recall: 0.7239 - auc: 0.8435 - val_loss: 0.5258 - val_tp: 55.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 19.0000 - val_accuracy: 0.8045 - val_precision: 0.7746 - val_recall: 0.7432 - val_auc: 0.8876\n",
      "Epoch 207/700\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5277 - tp: 194.0000 - fp: 52.0000 - tn: 392.0000 - fn: 74.0000 - accuracy: 0.8230 - precision: 0.7886 - recall: 0.7239 - auc: 0.8379 - val_loss: 0.5205 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8901\n",
      "Epoch 208/700\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5256 - tp: 187.0000 - fp: 59.0000 - tn: 385.0000 - fn: 81.0000 - accuracy: 0.8034 - precision: 0.7602 - recall: 0.6978 - auc: 0.8414 - val_loss: 0.5197 - val_tp: 50.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 24.0000 - val_accuracy: 0.8156 - val_precision: 0.8475 - val_recall: 0.6757 - val_auc: 0.8870\n",
      "Epoch 209/700\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5171 - tp: 193.0000 - fp: 47.0000 - tn: 397.0000 - fn: 75.0000 - accuracy: 0.8287 - precision: 0.8042 - recall: 0.7201 - auc: 0.8434 - val_loss: 0.5352 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8855\n",
      "Epoch 210/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5135 - tp: 192.0000 - fp: 61.0000 - tn: 383.0000 - fn: 76.0000 - accuracy: 0.8076 - precision: 0.7589 - recall: 0.7164 - auc: 0.8506 - val_loss: 0.5019 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8903\n",
      "Epoch 211/700\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.5267 - tp: 201.0000 - fp: 63.0000 - tn: 381.0000 - fn: 67.0000 - accuracy: 0.8174 - precision: 0.7614 - recall: 0.7500 - auc: 0.8541 - val_loss: 0.5482 - val_tp: 62.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 12.0000 - val_accuracy: 0.8045 - val_precision: 0.7294 - val_recall: 0.8378 - val_auc: 0.8854\n",
      "Epoch 212/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5395 - tp: 195.0000 - fp: 77.0000 - tn: 367.0000 - fn: 73.0000 - accuracy: 0.7893 - precision: 0.7169 - recall: 0.7276 - auc: 0.8432 - val_loss: 0.5418 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8898\n",
      "Epoch 213/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5342 - tp: 186.0000 - fp: 53.0000 - tn: 391.0000 - fn: 82.0000 - accuracy: 0.8104 - precision: 0.7782 - recall: 0.6940 - auc: 0.8320 - val_loss: 0.5040 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8928\n",
      "Epoch 214/700\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5307 - tp: 194.0000 - fp: 62.0000 - tn: 382.0000 - fn: 74.0000 - accuracy: 0.8090 - precision: 0.7578 - recall: 0.7239 - auc: 0.8488 - val_loss: 0.5111 - val_tp: 52.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 22.0000 - val_accuracy: 0.8101 - val_precision: 0.8125 - val_recall: 0.7027 - val_auc: 0.8891\n",
      "Epoch 215/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5566 - tp: 193.0000 - fp: 60.0000 - tn: 384.0000 - fn: 75.0000 - accuracy: 0.8104 - precision: 0.7628 - recall: 0.7201 - auc: 0.8376 - val_loss: 0.5174 - val_tp: 53.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 21.0000 - val_accuracy: 0.7989 - val_precision: 0.7794 - val_recall: 0.7162 - val_auc: 0.8928\n",
      "Epoch 216/700\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5342 - tp: 189.0000 - fp: 57.0000 - tn: 387.0000 - fn: 79.0000 - accuracy: 0.8090 - precision: 0.7683 - recall: 0.7052 - auc: 0.8252 - val_loss: 0.5258 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8860\n",
      "Epoch 217/700\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5342 - tp: 194.0000 - fp: 60.0000 - tn: 384.0000 - fn: 74.0000 - accuracy: 0.8118 - precision: 0.7638 - recall: 0.7239 - auc: 0.8362 - val_loss: 0.5057 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8862\n",
      "Epoch 218/700\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.5727 - tp: 199.0000 - fp: 65.0000 - tn: 379.0000 - fn: 69.0000 - accuracy: 0.8118 - precision: 0.7538 - recall: 0.7425 - auc: 0.8422 - val_loss: 0.5708 - val_tp: 51.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 23.0000 - val_accuracy: 0.8156 - val_precision: 0.8361 - val_recall: 0.6892 - val_auc: 0.8856\n",
      "Epoch 280/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.5644 - tp: 191.0000 - fp: 49.0000 - tn: 395.0000 - fn: 77.0000 - accuracy: 0.8230 - precision: 0.7958 - recall: 0.7127 - auc: 0.8373 - val_loss: 0.5533 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8807\n",
      "Epoch 281/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5570 - tp: 202.0000 - fp: 59.0000 - tn: 385.0000 - fn: 66.0000 - accuracy: 0.8244 - precision: 0.7739 - recall: 0.7537 - auc: 0.8458 - val_loss: 0.5527 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8866\n",
      "Epoch 282/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.5429 - tp: 195.0000 - fp: 61.0000 - tn: 383.0000 - fn: 73.0000 - accuracy: 0.8118 - precision: 0.7617 - recall: 0.7276 - auc: 0.8544 - val_loss: 0.5490 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8835\n",
      "Epoch 283/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.5621 - tp: 201.0000 - fp: 57.0000 - tn: 387.0000 - fn: 67.0000 - accuracy: 0.8258 - precision: 0.7791 - recall: 0.7500 - auc: 0.8383 - val_loss: 0.5506 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8899\n",
      "Epoch 284/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5733 - tp: 191.0000 - fp: 59.0000 - tn: 385.0000 - fn: 77.0000 - accuracy: 0.8090 - precision: 0.7640 - recall: 0.7127 - auc: 0.8387 - val_loss: 0.5527 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8824\n",
      "Epoch 285/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.5663 - tp: 194.0000 - fp: 52.0000 - tn: 392.0000 - fn: 74.0000 - accuracy: 0.8230 - precision: 0.7886 - recall: 0.7239 - auc: 0.8425 - val_loss: 0.5488 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8869\n",
      "Epoch 286/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.5732 - tp: 190.0000 - fp: 56.0000 - tn: 388.0000 - fn: 78.0000 - accuracy: 0.8118 - precision: 0.7724 - recall: 0.7090 - auc: 0.8415 - val_loss: 0.5497 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8835\n",
      "Epoch 287/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5561 - tp: 199.0000 - fp: 63.0000 - tn: 381.0000 - fn: 69.0000 - accuracy: 0.8146 - precision: 0.7595 - recall: 0.7425 - auc: 0.8431 - val_loss: 0.5528 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8830\n",
      "Epoch 288/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.5476 - tp: 196.0000 - fp: 55.0000 - tn: 389.0000 - fn: 72.0000 - accuracy: 0.8216 - precision: 0.7809 - recall: 0.7313 - auc: 0.8585 - val_loss: 0.5517 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8840\n",
      "Epoch 289/500\n",
      "712/712 [==============================] - 0s 203us/sample - loss: 0.5634 - tp: 197.0000 - fp: 58.0000 - tn: 386.0000 - fn: 71.0000 - accuracy: 0.8188 - precision: 0.7725 - recall: 0.7351 - auc: 0.8395 - val_loss: 0.5507 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8875\n",
      "Epoch 290/500\n",
      "712/712 [==============================] - 0s 203us/sample - loss: 0.5670 - tp: 204.0000 - fp: 68.0000 - tn: 376.0000 - fn: 64.0000 - accuracy: 0.8146 - precision: 0.7500 - recall: 0.7612 - auc: 0.8318 - val_loss: 0.5575 - val_tp: 52.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 22.0000 - val_accuracy: 0.8212 - val_precision: 0.8387 - val_recall: 0.7027 - val_auc: 0.8889\n",
      "Epoch 291/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5791 - tp: 189.0000 - fp: 58.0000 - tn: 386.0000 - fn: 79.0000 - accuracy: 0.8076 - precision: 0.7652 - recall: 0.7052 - auc: 0.8364 - val_loss: 0.5502 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8875\n",
      "Epoch 292/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.5527 - tp: 190.0000 - fp: 51.0000 - tn: 393.0000 - fn: 78.0000 - accuracy: 0.8188 - precision: 0.7884 - recall: 0.7090 - auc: 0.8564 - val_loss: 0.5519 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8860\n",
      "Epoch 293/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5583 - tp: 202.0000 - fp: 61.0000 - tn: 383.0000 - fn: 66.0000 - accuracy: 0.8216 - precision: 0.7681 - recall: 0.7537 - auc: 0.8533 - val_loss: 0.5521 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8875\n",
      "Epoch 294/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.5518 - tp: 204.0000 - fp: 54.0000 - tn: 390.0000 - fn: 64.0000 - accuracy: 0.8343 - precision: 0.7907 - recall: 0.7612 - auc: 0.8496 - val_loss: 0.5498 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8820\n",
      "Epoch 295/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.5484 - tp: 194.0000 - fp: 48.0000 - tn: 396.0000 - fn: 74.0000 - accuracy: 0.8287 - precision: 0.8017 - recall: 0.7239 - auc: 0.8539 - val_loss: 0.5557 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8868\n",
      "Epoch 296/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.5627 - tp: 195.0000 - fp: 53.0000 - tn: 391.0000 - fn: 73.0000 - accuracy: 0.8230 - precision: 0.7863 - recall: 0.7276 - auc: 0.8444 - val_loss: 0.5484 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8859\n",
      "Epoch 297/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.5692 - tp: 193.0000 - fp: 57.0000 - tn: 387.0000 - fn: 75.0000 - accuracy: 0.8146 - precision: 0.7720 - recall: 0.7201 - auc: 0.8444 - val_loss: 0.5498 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8842\n",
      "Epoch 298/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.5552 - tp: 203.0000 - fp: 66.0000 - tn: 378.0000 - fn: 65.0000 - accuracy: 0.8160 - precision: 0.7546 - recall: 0.7575 - auc: 0.8487 - val_loss: 0.5603 - val_tp: 55.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 19.0000 - val_accuracy: 0.8324 - val_precision: 0.8333 - val_recall: 0.7432 - val_auc: 0.8877\n",
      "Epoch 299/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.5838 - tp: 194.0000 - fp: 60.0000 - tn: 384.0000 - fn: 74.0000 - accuracy: 0.8118 - precision: 0.7638 - recall: 0.7239 - auc: 0.8280 - val_loss: 0.5507 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8824\n",
      "Epoch 300/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.5541 - tp: 193.0000 - fp: 46.0000 - tn: 398.0000 - fn: 75.0000 - accuracy: 0.8301 - precision: 0.8075 - recall: 0.7201 - auc: 0.8637 - val_loss: 0.5517 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8826\n",
      "Epoch 301/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5506 - tp: 203.0000 - fp: 62.0000 - tn: 382.0000 - fn: 65.0000 - accuracy: 0.8216 - precision: 0.7660 - recall: 0.7575 - auc: 0.8519 - val_loss: 0.5549 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8884\n",
      "Epoch 302/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.5607 - tp: 187.0000 - fp: 47.0000 - tn: 397.0000 - fn: 81.0000 - accuracy: 0.8202 - precision: 0.7991 - recall: 0.6978 - auc: 0.8458 - val_loss: 0.5494 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8853\n",
      "Epoch 303/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5590 - tp: 194.0000 - fp: 57.0000 - tn: 387.0000 - fn: 74.0000 - accuracy: 0.8160 - precision: 0.7729 - recall: 0.7239 - auc: 0.8465 - val_loss: 0.5526 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8868\n",
      "Epoch 304/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5521 - tp: 195.0000 - fp: 49.0000 - tn: 395.0000 - fn: 73.0000 - accuracy: 0.8287 - precision: 0.7992 - recall: 0.7276 - auc: 0.8463 - val_loss: 0.5509 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8858\n",
      "Epoch 305/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5514 - tp: 197.0000 - fp: 52.0000 - tn: 392.0000 - fn: 71.0000 - accuracy: 0.8272 - precision: 0.7912 - recall: 0.7351 - auc: 0.8452 - val_loss: 0.5467 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8865\n",
      "Epoch 306/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5593 - tp: 197.0000 - fp: 66.0000 - tn: 378.0000 - fn: 71.0000 - accuracy: 0.8076 - precision: 0.7490 - recall: 0.7351 - auc: 0.8518 - val_loss: 0.5397 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8907\n",
      "Epoch 307/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5500 - tp: 195.0000 - fp: 49.0000 - tn: 395.0000 - fn: 73.0000 - accuracy: 0.8287 - precision: 0.7992 - recall: 0.7276 - auc: 0.8507 - val_loss: 0.5460 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8811\n",
      "Epoch 308/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5550 - tp: 202.0000 - fp: 63.0000 - tn: 381.0000 - fn: 66.0000 - accuracy: 0.8188 - precision: 0.7623 - recall: 0.7537 - auc: 0.8515 - val_loss: 0.5449 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8873\n",
      "Epoch 309/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5542 - tp: 201.0000 - fp: 64.0000 - tn: 380.0000 - fn: 67.0000 - accuracy: 0.8160 - precision: 0.7585 - recall: 0.7500 - auc: 0.8471 - val_loss: 0.5467 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8886\n",
      "Epoch 310/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5474 - tp: 198.0000 - fp: 57.0000 - tn: 387.0000 - fn: 70.0000 - accuracy: 0.8216 - precision: 0.7765 - recall: 0.7388 - auc: 0.8503 - val_loss: 0.5444 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8838\n",
      "Epoch 311/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5514 - tp: 200.0000 - fp: 69.0000 - tn: 375.0000 - fn: 68.0000 - accuracy: 0.8076 - precision: 0.7435 - recall: 0.7463 - auc: 0.8519 - val_loss: 0.5493 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8860\n",
      "Epoch 312/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5645 - tp: 198.0000 - fp: 66.0000 - tn: 378.0000 - fn: 70.0000 - accuracy: 0.8090 - precision: 0.7500 - recall: 0.7388 - auc: 0.8371 - val_loss: 0.5467 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8873\n",
      "Epoch 313/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.5501 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8509 - val_loss: 0.5507 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8867\n",
      "Epoch 314/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5601 - tp: 195.0000 - fp: 58.0000 - tn: 386.0000 - fn: 73.0000 - accuracy: 0.8160 - precision: 0.7708 - recall: 0.7276 - auc: 0.8364 - val_loss: 0.5532 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8856\n",
      "Epoch 315/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5636 - tp: 203.0000 - fp: 64.0000 - tn: 380.0000 - fn: 65.0000 - accuracy: 0.8188 - precision: 0.7603 - recall: 0.7575 - auc: 0.8439 - val_loss: 0.5514 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8857\n",
      "Epoch 316/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5579 - tp: 191.0000 - fp: 53.0000 - tn: 391.0000 - fn: 77.0000 - accuracy: 0.8174 - precision: 0.7828 - recall: 0.7127 - auc: 0.8555 - val_loss: 0.5489 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8863\n",
      "Epoch 317/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.5516 - tp: 202.0000 - fp: 61.0000 - tn: 383.0000 - fn: 66.0000 - accuracy: 0.8216 - precision: 0.7681 - recall: 0.7537 - auc: 0.8442 - val_loss: 0.5514 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8844\n",
      "Epoch 318/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6372 - tp: 200.0000 - fp: 85.0000 - tn: 359.0000 - fn: 68.0000 - accuracy: 0.7851 - precision: 0.7018 - recall: 0.7463 - auc: 0.8280 - val_loss: 0.5904 - val_tp: 65.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 9.0000 - val_accuracy: 0.7709 - val_precision: 0.6701 - val_recall: 0.8784 - val_auc: 0.8792\n",
      "Epoch 174/600\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6012 - tp: 209.0000 - fp: 89.0000 - tn: 355.0000 - fn: 59.0000 - accuracy: 0.7921 - precision: 0.7013 - recall: 0.7799 - auc: 0.8557 - val_loss: 0.6532 - val_tp: 41.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 33.0000 - val_accuracy: 0.7765 - val_precision: 0.8542 - val_recall: 0.5541 - val_auc: 0.8836\n",
      "Epoch 175/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6295 - tp: 207.0000 - fp: 91.0000 - tn: 353.0000 - fn: 61.0000 - accuracy: 0.7865 - precision: 0.6946 - recall: 0.7724 - auc: 0.8367 - val_loss: 0.6207 - val_tp: 70.0000 - val_fp: 37.0000 - val_tn: 68.0000 - val_fn: 4.0000 - val_accuracy: 0.7709 - val_precision: 0.6542 - val_recall: 0.9459 - val_auc: 0.8732\n",
      "Epoch 176/600\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6238 - tp: 199.0000 - fp: 94.0000 - tn: 350.0000 - fn: 69.0000 - accuracy: 0.7711 - precision: 0.6792 - recall: 0.7425 - auc: 0.8378 - val_loss: 0.5808 - val_tp: 65.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 9.0000 - val_accuracy: 0.7821 - val_precision: 0.6842 - val_recall: 0.8784 - val_auc: 0.8743\n",
      "Epoch 177/600\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6304 - tp: 203.0000 - fp: 85.0000 - tn: 359.0000 - fn: 65.0000 - accuracy: 0.7893 - precision: 0.7049 - recall: 0.7575 - auc: 0.8300 - val_loss: 0.5942 - val_tp: 52.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 22.0000 - val_accuracy: 0.7877 - val_precision: 0.7647 - val_recall: 0.7027 - val_auc: 0.8774\n",
      "Epoch 178/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6321 - tp: 199.0000 - fp: 80.0000 - tn: 364.0000 - fn: 69.0000 - accuracy: 0.7907 - precision: 0.7133 - recall: 0.7425 - auc: 0.8315 - val_loss: 0.5828 - val_tp: 54.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 20.0000 - val_accuracy: 0.7765 - val_precision: 0.7297 - val_recall: 0.7297 - val_auc: 0.8790\n",
      "Epoch 179/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.5989 - tp: 197.0000 - fp: 78.0000 - tn: 366.0000 - fn: 71.0000 - accuracy: 0.7907 - precision: 0.7164 - recall: 0.7351 - auc: 0.8578 - val_loss: 0.6605 - val_tp: 70.0000 - val_fp: 39.0000 - val_tn: 66.0000 - val_fn: 4.0000 - val_accuracy: 0.7598 - val_precision: 0.6422 - val_recall: 0.9459 - val_auc: 0.8763\n",
      "Epoch 180/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6372 - tp: 202.0000 - fp: 83.0000 - tn: 361.0000 - fn: 66.0000 - accuracy: 0.7907 - precision: 0.7088 - recall: 0.7537 - auc: 0.8353 - val_loss: 0.6112 - val_tp: 69.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 5.0000 - val_accuracy: 0.7709 - val_precision: 0.6571 - val_recall: 0.9324 - val_auc: 0.8742\n",
      "Epoch 181/600\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6473 - tp: 197.0000 - fp: 86.0000 - tn: 358.0000 - fn: 71.0000 - accuracy: 0.7795 - precision: 0.6961 - recall: 0.7351 - auc: 0.8220 - val_loss: 0.5759 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8799\n",
      "Epoch 182/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6359 - tp: 203.0000 - fp: 85.0000 - tn: 359.0000 - fn: 65.0000 - accuracy: 0.7893 - precision: 0.7049 - recall: 0.7575 - auc: 0.8349 - val_loss: 0.5917 - val_tp: 61.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 13.0000 - val_accuracy: 0.7765 - val_precision: 0.6932 - val_recall: 0.8243 - val_auc: 0.8790\n",
      "Epoch 183/600\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6117 - tp: 198.0000 - fp: 79.0000 - tn: 365.0000 - fn: 70.0000 - accuracy: 0.7907 - precision: 0.7148 - recall: 0.7388 - auc: 0.8433 - val_loss: 0.5687 - val_tp: 61.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 13.0000 - val_accuracy: 0.7821 - val_precision: 0.7011 - val_recall: 0.8243 - val_auc: 0.8828\n",
      "Epoch 184/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6231 - tp: 209.0000 - fp: 93.0000 - tn: 351.0000 - fn: 59.0000 - accuracy: 0.7865 - precision: 0.6921 - recall: 0.7799 - auc: 0.8386 - val_loss: 0.6427 - val_tp: 48.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 26.0000 - val_accuracy: 0.7933 - val_precision: 0.8136 - val_recall: 0.6486 - val_auc: 0.8895\n",
      "Epoch 185/600\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6298 - tp: 206.0000 - fp: 92.0000 - tn: 352.0000 - fn: 62.0000 - accuracy: 0.7837 - precision: 0.6913 - recall: 0.7687 - auc: 0.8339 - val_loss: 0.5786 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8853\n",
      "Epoch 186/600\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.6134 - tp: 203.0000 - fp: 83.0000 - tn: 361.0000 - fn: 65.0000 - accuracy: 0.7921 - precision: 0.7098 - recall: 0.7575 - auc: 0.8483 - val_loss: 0.6320 - val_tp: 48.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 26.0000 - val_accuracy: 0.7877 - val_precision: 0.8000 - val_recall: 0.6486 - val_auc: 0.8845\n",
      "Epoch 187/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6355 - tp: 204.0000 - fp: 86.0000 - tn: 358.0000 - fn: 64.0000 - accuracy: 0.7893 - precision: 0.7034 - recall: 0.7612 - auc: 0.8288 - val_loss: 0.6023 - val_tp: 52.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 22.0000 - val_accuracy: 0.7989 - val_precision: 0.7879 - val_recall: 0.7027 - val_auc: 0.8840\n",
      "Epoch 188/600\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.6469 - tp: 193.0000 - fp: 73.0000 - tn: 371.0000 - fn: 75.0000 - accuracy: 0.7921 - precision: 0.7256 - recall: 0.7201 - auc: 0.8298 - val_loss: 0.6873 - val_tp: 70.0000 - val_fp: 45.0000 - val_tn: 60.0000 - val_fn: 4.0000 - val_accuracy: 0.7263 - val_precision: 0.6087 - val_recall: 0.9459 - val_auc: 0.8754\n",
      "Epoch 189/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6277 - tp: 204.0000 - fp: 89.0000 - tn: 355.0000 - fn: 64.0000 - accuracy: 0.7851 - precision: 0.6962 - recall: 0.7612 - auc: 0.8323 - val_loss: 0.6103 - val_tp: 70.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 4.0000 - val_accuracy: 0.7765 - val_precision: 0.6604 - val_recall: 0.9459 - val_auc: 0.8754\n",
      "Epoch 190/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6331 - tp: 194.0000 - fp: 75.0000 - tn: 369.0000 - fn: 74.0000 - accuracy: 0.7907 - precision: 0.7212 - recall: 0.7239 - auc: 0.8225 - val_loss: 0.5790 - val_tp: 63.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 11.0000 - val_accuracy: 0.7821 - val_precision: 0.6923 - val_recall: 0.8514 - val_auc: 0.8777\n",
      "Epoch 191/600\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6475 - tp: 192.0000 - fp: 87.0000 - tn: 357.0000 - fn: 76.0000 - accuracy: 0.7711 - precision: 0.6882 - recall: 0.7164 - auc: 0.8143 - val_loss: 0.5964 - val_tp: 51.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 23.0000 - val_accuracy: 0.7821 - val_precision: 0.7612 - val_recall: 0.6892 - val_auc: 0.8856\n",
      "Epoch 192/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6359 - tp: 199.0000 - fp: 77.0000 - tn: 367.0000 - fn: 69.0000 - accuracy: 0.7949 - precision: 0.7210 - recall: 0.7425 - auc: 0.8297 - val_loss: 0.5695 - val_tp: 63.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 11.0000 - val_accuracy: 0.7989 - val_precision: 0.7159 - val_recall: 0.8514 - val_auc: 0.8807\n",
      "Epoch 193/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6208 - tp: 206.0000 - fp: 82.0000 - tn: 362.0000 - fn: 62.0000 - accuracy: 0.7978 - precision: 0.7153 - recall: 0.7687 - auc: 0.8342 - val_loss: 0.5718 - val_tp: 54.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 20.0000 - val_accuracy: 0.7877 - val_precision: 0.7500 - val_recall: 0.7297 - val_auc: 0.8848\n",
      "Epoch 194/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6226 - tp: 204.0000 - fp: 73.0000 - tn: 371.0000 - fn: 64.0000 - accuracy: 0.8076 - precision: 0.7365 - recall: 0.7612 - auc: 0.8369 - val_loss: 0.6235 - val_tp: 48.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 26.0000 - val_accuracy: 0.7821 - val_precision: 0.7869 - val_recall: 0.6486 - val_auc: 0.8854\n",
      "Epoch 195/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6118 - tp: 201.0000 - fp: 77.0000 - tn: 367.0000 - fn: 67.0000 - accuracy: 0.7978 - precision: 0.7230 - recall: 0.7500 - auc: 0.8445 - val_loss: 0.6562 - val_tp: 40.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 34.0000 - val_accuracy: 0.7709 - val_precision: 0.8511 - val_recall: 0.5405 - val_auc: 0.8867\n",
      "Epoch 196/600\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.6134 - tp: 196.0000 - fp: 65.0000 - tn: 379.0000 - fn: 72.0000 - accuracy: 0.8076 - precision: 0.7510 - recall: 0.7313 - auc: 0.8390 - val_loss: 0.6112 - val_tp: 50.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 24.0000 - val_accuracy: 0.7877 - val_precision: 0.7812 - val_recall: 0.6757 - val_auc: 0.8854\n",
      "Epoch 197/600\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.6298 - tp: 195.0000 - fp: 82.0000 - tn: 362.0000 - fn: 73.0000 - accuracy: 0.7823 - precision: 0.7040 - recall: 0.7276 - auc: 0.8272 - val_loss: 0.5983 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8752\n",
      "Epoch 198/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6436 - tp: 195.0000 - fp: 86.0000 - tn: 358.0000 - fn: 73.0000 - accuracy: 0.7767 - precision: 0.6940 - recall: 0.7276 - auc: 0.8135 - val_loss: 0.5739 - val_tp: 63.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 11.0000 - val_accuracy: 0.7821 - val_precision: 0.6923 - val_recall: 0.8514 - val_auc: 0.8786\n",
      "Epoch 199/600\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6388 - tp: 193.0000 - fp: 76.0000 - tn: 368.0000 - fn: 75.0000 - accuracy: 0.7879 - precision: 0.7175 - recall: 0.7201 - auc: 0.8218 - val_loss: 0.6003 - val_tp: 55.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 19.0000 - val_accuracy: 0.7877 - val_precision: 0.7432 - val_recall: 0.7432 - val_auc: 0.8851\n",
      "Epoch 200/600\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6221 - tp: 201.0000 - fp: 77.0000 - tn: 367.0000 - fn: 67.0000 - accuracy: 0.7978 - precision: 0.7230 - recall: 0.7500 - auc: 0.8419 - val_loss: 0.6395 - val_tp: 47.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 27.0000 - val_accuracy: 0.7989 - val_precision: 0.8393 - val_recall: 0.6351 - val_auc: 0.8873\n",
      "Epoch 201/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6324 - tp: 193.0000 - fp: 78.0000 - tn: 366.0000 - fn: 75.0000 - accuracy: 0.7851 - precision: 0.7122 - recall: 0.7201 - auc: 0.8269 - val_loss: 0.5807 - val_tp: 56.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 18.0000 - val_accuracy: 0.7877 - val_precision: 0.7368 - val_recall: 0.7568 - val_auc: 0.8797\n",
      "Epoch 202/600\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6403 - tp: 191.0000 - fp: 81.0000 - tn: 363.0000 - fn: 77.0000 - accuracy: 0.7781 - precision: 0.7022 - recall: 0.7127 - auc: 0.8149 - val_loss: 0.5740 - val_tp: 55.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 19.0000 - val_accuracy: 0.7877 - val_precision: 0.7432 - val_recall: 0.7432 - val_auc: 0.8802\n",
      "Epoch 203/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6207 - tp: 197.0000 - fp: 79.0000 - tn: 365.0000 - fn: 71.0000 - accuracy: 0.7893 - precision: 0.7138 - recall: 0.7351 - auc: 0.8360 - val_loss: 0.5673 - val_tp: 54.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 20.0000 - val_accuracy: 0.7877 - val_precision: 0.7500 - val_recall: 0.7297 - val_auc: 0.8836\n",
      "Epoch 204/600\n",
      "712/712 [==============================] - 0s 182us/sample - loss: 0.5998 - tp: 194.0000 - fp: 69.0000 - tn: 375.0000 - fn: 74.0000 - accuracy: 0.7992 - precision: 0.7376 - recall: 0.7239 - auc: 0.8443 - val_loss: 0.6782 - val_tp: 70.0000 - val_fp: 40.0000 - val_tn: 65.0000 - val_fn: 4.0000 - val_accuracy: 0.7542 - val_precision: 0.6364 - val_recall: 0.9459 - val_auc: 0.8759\n",
      "Epoch 205/600\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.6223 - tp: 200.0000 - fp: 79.0000 - tn: 365.0000 - fn: 68.0000 - accuracy: 0.7935 - precision: 0.7168 - recall: 0.7463 - auc: 0.8359 - val_loss: 0.6041 - val_tp: 66.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 8.0000 - val_accuracy: 0.7598 - val_precision: 0.6535 - val_recall: 0.8919 - val_auc: 0.8816\n",
      "Epoch 206/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6417 - tp: 198.0000 - fp: 95.0000 - tn: 349.0000 - fn: 70.0000 - accuracy: 0.7683 - precision: 0.6758 - recall: 0.7388 - auc: 0.8138 - val_loss: 0.5832 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8837\n",
      "Epoch 207/600\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.6114 - tp: 196.0000 - fp: 72.0000 - tn: 372.0000 - fn: 72.0000 - accuracy: 0.7978 - precision: 0.7313 - recall: 0.7313 - auc: 0.8436 - val_loss: 0.6166 - val_tp: 69.0000 - val_fp: 36.0000 - val_tn: 69.0000 - val_fn: 5.0000 - val_accuracy: 0.7709 - val_precision: 0.6571 - val_recall: 0.9324 - val_auc: 0.8792\n",
      "Epoch 208/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6099 - tp: 204.0000 - fp: 81.0000 - tn: 363.0000 - fn: 64.0000 - accuracy: 0.7963 - precision: 0.7158 - recall: 0.7612 - auc: 0.8493 - val_loss: 0.6143 - val_tp: 50.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 24.0000 - val_accuracy: 0.7933 - val_precision: 0.7937 - val_recall: 0.6757 - val_auc: 0.8849\n",
      "Epoch 209/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6221 - tp: 203.0000 - fp: 72.0000 - tn: 372.0000 - fn: 65.0000 - accuracy: 0.8076 - precision: 0.7382 - recall: 0.7575 - auc: 0.8335 - val_loss: 0.5910 - val_tp: 65.0000 - val_fp: 35.0000 - val_tn: 70.0000 - val_fn: 9.0000 - val_accuracy: 0.7542 - val_precision: 0.6500 - val_recall: 0.8784 - val_auc: 0.8802\n",
      "Epoch 210/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.6258 - tp: 202.0000 - fp: 77.0000 - tn: 367.0000 - fn: 66.0000 - accuracy: 0.7992 - precision: 0.7240 - recall: 0.7537 - auc: 0.8346 - val_loss: 0.5727 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8822\n",
      "Epoch 211/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4581 - val_loss: 0.7443 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 191/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7310 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4836 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 192/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4971 - val_loss: 0.7444 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 193/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4855 - val_loss: 0.7434 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 194/500\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4723 - val_loss: 0.7452 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 195/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4846 - val_loss: 0.7461 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 196/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4799 - val_loss: 0.7457 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 197/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4724 - val_loss: 0.7465 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 198/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.7310 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7454 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 199/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7310 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5091 - val_loss: 0.7451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 200/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.7309 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7447 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 201/500\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.7319 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4282 - val_loss: 0.7463 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 202/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4896 - val_loss: 0.7448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 203/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.7310 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7443 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 204/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4906 - val_loss: 0.7452 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 205/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4947 - val_loss: 0.7439 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 206/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4678 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 207/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4823 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 208/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4732 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 209/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4869 - val_loss: 0.7464 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 210/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4913 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 211/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4878 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 212/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4793 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 213/500\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4941 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 214/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.7318 - tp: 39.0000 - fp: 79.0000 - tn: 365.0000 - fn: 229.0000 - accuracy: 0.5674 - precision: 0.3305 - recall: 0.1455 - auc: 0.4860 - val_loss: 0.7447 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 215/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5004 - val_loss: 0.7453 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 216/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4643 - val_loss: 0.7454 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 217/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 218/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4708 - val_loss: 0.7440 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 219/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4592 - val_loss: 0.7452 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 220/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4935 - val_loss: 0.7465 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 221/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4796 - val_loss: 0.7463 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 222/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4949 - val_loss: 0.7448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 223/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7449 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 224/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7452 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 225/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.7310 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5039 - val_loss: 0.7449 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 226/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 227/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7310 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 228/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.7318 - tp: 172.0000 - fp: 316.0000 - tn: 128.0000 - fn: 96.0000 - accuracy: 0.4213 - precision: 0.3525 - recall: 0.6418 - auc: 0.4483 - val_loss: 0.7432 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 229/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.7313 - tp: 12.0000 - fp: 20.0000 - tn: 424.0000 - fn: 256.0000 - accuracy: 0.6124 - precision: 0.3750 - recall: 0.0448 - auc: 0.4766 - val_loss: 0.7451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 230/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4662 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 231/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.7316 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4822 - val_loss: 0.7451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 232/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.7317 - tp: 6.0000 - fp: 11.0000 - tn: 433.0000 - fn: 262.0000 - accuracy: 0.6166 - precision: 0.3529 - recall: 0.0224 - auc: 0.4642 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 233/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5008 - val_loss: 0.7453 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 234/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4669 - val_loss: 0.7455 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 235/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4763 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 236/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4856 - val_loss: 0.7444 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 237/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 238/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4870 - val_loss: 0.7461 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 239/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.7317 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4572 - val_loss: 0.7451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 240/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.7317 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4738 - val_loss: 0.7460 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 241/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4745 - val_loss: 0.7452 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 242/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4535 - val_loss: 0.7456 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 243/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4883 - val_loss: 0.7448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 244/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4842 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 245/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4752 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 246/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4808 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 247/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4489 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 248/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 249/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7453 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 250/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4916 - val_loss: 0.7448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 251/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4726 - val_loss: 0.7458 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 252/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4740 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 253/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.7320 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4453 - val_loss: 0.7452 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 254/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4721 - val_loss: 0.7458 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 255/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4786 - val_loss: 0.7459 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 256/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4755 - val_loss: 0.7462 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 257/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4931 - val_loss: 0.7457 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 258/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4821 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 259/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.7318 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4665 - val_loss: 0.7449 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 260/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.7318 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4731 - val_loss: 0.7451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 261/500\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.7318 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4678 - val_loss: 0.7467 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 262/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7322 - tp: 43.0000 - fp: 71.0000 - tn: 373.0000 - fn: 225.0000 - accuracy: 0.5843 - precision: 0.3772 - recall: 0.1604 - auc: 0.4702 - val_loss: 0.7451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 263/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.7316 - tp: 63.0000 - fp: 122.0000 - tn: 322.0000 - fn: 205.0000 - accuracy: 0.5407 - precision: 0.3405 - recall: 0.2351 - auc: 0.4673 - val_loss: 0.7444 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 264/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7320 - tp: 176.0000 - fp: 338.0000 - tn: 106.0000 - fn: 92.0000 - accuracy: 0.3961 - precision: 0.3424 - recall: 0.6567 - auc: 0.4454 - val_loss: 0.7439 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 265/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4822 - val_loss: 0.7440 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 266/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4614 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 267/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4596 - val_loss: 0.7455 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 268/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4962 - val_loss: 0.7449 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 269/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4890 - val_loss: 0.7454 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 270/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4680 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 271/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4879 - val_loss: 0.7444 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 272/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 273/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4992 - val_loss: 0.7444 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 274/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 275/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 276/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 277/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.7316 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4566 - val_loss: 0.7442 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 278/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4768 - val_loss: 0.7461 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 279/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.7323 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4338 - val_loss: 0.7454 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 280/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4648 - val_loss: 0.7458 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 281/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7320 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4718 - val_loss: 0.7447 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 282/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4985 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 283/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7316 - tp: 125.0000 - fp: 215.0000 - tn: 229.0000 - fn: 143.0000 - accuracy: 0.4972 - precision: 0.3676 - recall: 0.4664 - auc: 0.4757 - val_loss: 0.7440 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 284/500\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.7317 - tp: 7.0000 - fp: 16.0000 - tn: 428.0000 - fn: 261.0000 - accuracy: 0.6110 - precision: 0.3043 - recall: 0.0261 - auc: 0.4673 - val_loss: 0.7452 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 285/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5142 - val_loss: 0.7469 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 286/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 287/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4757 - val_loss: 0.7443 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 288/500\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4840 - val_loss: 0.7439 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 289/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4675 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 290/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4696 - val_loss: 0.7453 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 291/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.7310 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5150 - val_loss: 0.7442 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 292/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.7313 - tp: 110.0000 - fp: 210.0000 - tn: 234.0000 - fn: 158.0000 - accuracy: 0.4831 - precision: 0.3438 - recall: 0.4104 - auc: 0.4973 - val_loss: 0.7441 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 293/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4778 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 294/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4929 - val_loss: 0.7455 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 295/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 296/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4350 - val_loss: 0.7458 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 297/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4831 - val_loss: 0.7469 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 298/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.7318 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4690 - val_loss: 0.7449 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 299/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.7317 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4673 - val_loss: 0.7478 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 300/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5172 - val_loss: 0.7449 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 301/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4800 - val_loss: 0.7438 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 302/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4798 - val_loss: 0.7449 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 303/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4978 - val_loss: 0.7456 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 304/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4718 - val_loss: 0.7460 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 305/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4988 - val_loss: 0.7455 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 306/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7453 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 307/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4636 - val_loss: 0.7454 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 308/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4671 - val_loss: 0.7442 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 309/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4869 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 310/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7319 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4378 - val_loss: 0.7453 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 311/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7321 - tp: 166.0000 - fp: 311.0000 - tn: 133.0000 - fn: 102.0000 - accuracy: 0.4199 - precision: 0.3480 - recall: 0.6194 - auc: 0.4459 - val_loss: 0.7442 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 312/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7312 - tp: 9.0000 - fp: 23.0000 - tn: 421.0000 - fn: 259.0000 - accuracy: 0.6039 - precision: 0.2812 - recall: 0.0336 - auc: 0.4867 - val_loss: 0.7449 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 313/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.7318 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4813 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 314/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5011 - val_loss: 0.7457 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 315/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7319 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4488 - val_loss: 0.7444 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 316/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7319 - tp: 86.0000 - fp: 141.0000 - tn: 303.0000 - fn: 182.0000 - accuracy: 0.5463 - precision: 0.3789 - recall: 0.3209 - auc: 0.4971 - val_loss: 0.7465 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 317/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4864 - val_loss: 0.7463 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 318/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.7317 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4483 - val_loss: 0.7447 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 319/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4853 - val_loss: 0.7462 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 320/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.7318 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4732 - val_loss: 0.7454 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 321/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4840 - val_loss: 0.7456 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 322/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7457 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 323/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7454 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 324/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7456 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 325/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7316 - tp: 12.0000 - fp: 31.0000 - tn: 413.0000 - fn: 256.0000 - accuracy: 0.5969 - precision: 0.2791 - recall: 0.0448 - auc: 0.4862 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 326/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4880 - val_loss: 0.7459 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 327/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4872 - val_loss: 0.7461 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 328/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4608 - val_loss: 0.7456 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 329/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4856 - val_loss: 0.7459 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 330/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4948 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 331/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4846 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 332/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.7319 - tp: 150.0000 - fp: 285.0000 - tn: 159.0000 - fn: 118.0000 - accuracy: 0.4340 - precision: 0.3448 - recall: 0.5597 - auc: 0.4531 - val_loss: 0.7440 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 333/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.7315 - tp: 136.0000 - fp: 253.0000 - tn: 191.0000 - fn: 132.0000 - accuracy: 0.4593 - precision: 0.3496 - recall: 0.5075 - auc: 0.4996 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 334/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4615 - val_loss: 0.7459 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 335/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4580 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 336/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7317 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4654 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 337/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4707 - val_loss: 0.7438 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 338/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.7313 - tp: 4.0000 - fp: 5.0000 - tn: 439.0000 - fn: 264.0000 - accuracy: 0.6222 - precision: 0.4444 - recall: 0.0149 - auc: 0.4910 - val_loss: 0.7441 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 339/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4721 - val_loss: 0.7454 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 340/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7321 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4543 - val_loss: 0.7463 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 341/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.7321 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4787 - val_loss: 0.7463 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 342/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7316 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4929 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 343/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5028 - val_loss: 0.7442 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 344/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4902 - val_loss: 0.7456 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 345/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4890 - val_loss: 0.7449 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 346/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4544 - val_loss: 0.7453 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 347/500\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4852 - val_loss: 0.7447 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 348/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4841 - val_loss: 0.7440 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 349/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4707 - val_loss: 0.7456 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 350/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4796 - val_loss: 0.7452 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 351/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4890 - val_loss: 0.7464 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 352/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4726 - val_loss: 0.7451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 353/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4947 - val_loss: 0.7451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 354/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4932 - val_loss: 0.7452 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 355/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.7317 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4695 - val_loss: 0.7456 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 356/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7317 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4889 - val_loss: 0.7455 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 357/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.7317 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4455 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 358/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7325 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4472 - val_loss: 0.7464 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 359/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.7317 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4678 - val_loss: 0.7467 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 360/500\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.7316 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5086 - val_loss: 0.7456 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 361/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4693 - val_loss: 0.7451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 362/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4712 - val_loss: 0.7466 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 363/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4831 - val_loss: 0.7460 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 364/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.7324 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4823 - val_loss: 0.7456 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 365/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4876 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 366/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4943 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 367/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4950 - val_loss: 0.7441 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 368/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 369/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5029 - val_loss: 0.7460 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 370/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4716 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 371/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4764 - val_loss: 0.7455 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 372/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.7327 - tp: 133.0000 - fp: 208.0000 - tn: 236.0000 - fn: 135.0000 - accuracy: 0.5183 - precision: 0.3900 - recall: 0.4963 - auc: 0.4934 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 373/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7322 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4605 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 374/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.7328 - tp: 5.0000 - fp: 9.0000 - tn: 435.0000 - fn: 263.0000 - accuracy: 0.6180 - precision: 0.3571 - recall: 0.0187 - auc: 0.4679 - val_loss: 0.7448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 375/500\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.7318 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4769 - val_loss: 0.7454 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 376/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.7322 - tp: 3.0000 - fp: 18.0000 - tn: 426.0000 - fn: 265.0000 - accuracy: 0.6025 - precision: 0.1429 - recall: 0.0112 - auc: 0.4458 - val_loss: 0.7450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 377/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4735 - val_loss: 0.7458 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 378/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5081 - val_loss: 0.7445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 379/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.7314 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 380/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4851 - val_loss: 0.7452 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 381/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.7317 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4758 - val_loss: 0.7455 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 382/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5093 - tp: 204.0000 - fp: 56.0000 - tn: 388.0000 - fn: 64.0000 - accuracy: 0.8315 - precision: 0.7846 - recall: 0.7612 - auc: 0.8661 - val_loss: 0.4777 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8903\n",
      "Epoch 283/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4984 - tp: 211.0000 - fp: 68.0000 - tn: 376.0000 - fn: 57.0000 - accuracy: 0.8244 - precision: 0.7563 - recall: 0.7873 - auc: 0.8677 - val_loss: 0.4729 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8917\n",
      "Epoch 284/400\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5161 - tp: 206.0000 - fp: 57.0000 - tn: 387.0000 - fn: 62.0000 - accuracy: 0.8329 - precision: 0.7833 - recall: 0.7687 - auc: 0.8587 - val_loss: 0.4714 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8936\n",
      "Epoch 285/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.5093 - tp: 213.0000 - fp: 75.0000 - tn: 369.0000 - fn: 55.0000 - accuracy: 0.8174 - precision: 0.7396 - recall: 0.7948 - auc: 0.8702 - val_loss: 0.4701 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8937\n",
      "Epoch 286/400\n",
      "712/712 [==============================] - 0s 211us/sample - loss: 0.4946 - tp: 212.0000 - fp: 83.0000 - tn: 361.0000 - fn: 56.0000 - accuracy: 0.8048 - precision: 0.7186 - recall: 0.7910 - auc: 0.8718 - val_loss: 0.4706 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8927\n",
      "Epoch 287/400\n",
      "712/712 [==============================] - 0s 199us/sample - loss: 0.5042 - tp: 207.0000 - fp: 74.0000 - tn: 370.0000 - fn: 61.0000 - accuracy: 0.8104 - precision: 0.7367 - recall: 0.7724 - auc: 0.8611 - val_loss: 0.4688 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8932\n",
      "Epoch 288/400\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.4969 - tp: 204.0000 - fp: 58.0000 - tn: 386.0000 - fn: 64.0000 - accuracy: 0.8287 - precision: 0.7786 - recall: 0.7612 - auc: 0.8697 - val_loss: 0.4727 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8918\n",
      "Epoch 289/400\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.5252 - tp: 203.0000 - fp: 70.0000 - tn: 374.0000 - fn: 65.0000 - accuracy: 0.8104 - precision: 0.7436 - recall: 0.7575 - auc: 0.8528 - val_loss: 0.4698 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8940\n",
      "Epoch 290/400\n",
      "712/712 [==============================] - 0s 214us/sample - loss: 0.4920 - tp: 204.0000 - fp: 61.0000 - tn: 383.0000 - fn: 64.0000 - accuracy: 0.8244 - precision: 0.7698 - recall: 0.7612 - auc: 0.8691 - val_loss: 0.4711 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8913\n",
      "Epoch 291/400\n",
      "712/712 [==============================] - 0s 184us/sample - loss: 0.5150 - tp: 212.0000 - fp: 79.0000 - tn: 365.0000 - fn: 56.0000 - accuracy: 0.8104 - precision: 0.7285 - recall: 0.7910 - auc: 0.8550 - val_loss: 0.4773 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8936\n",
      "Epoch 292/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4906 - tp: 199.0000 - fp: 58.0000 - tn: 386.0000 - fn: 69.0000 - accuracy: 0.8216 - precision: 0.7743 - recall: 0.7425 - auc: 0.8718 - val_loss: 0.4742 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8897\n",
      "Epoch 293/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5103 - tp: 205.0000 - fp: 65.0000 - tn: 379.0000 - fn: 63.0000 - accuracy: 0.8202 - precision: 0.7593 - recall: 0.7649 - auc: 0.8567 - val_loss: 0.4757 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8914\n",
      "Epoch 294/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.5017 - tp: 202.0000 - fp: 54.0000 - tn: 390.0000 - fn: 66.0000 - accuracy: 0.8315 - precision: 0.7891 - recall: 0.7537 - auc: 0.8679 - val_loss: 0.4720 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8923\n",
      "Epoch 295/400\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.5034 - tp: 206.0000 - fp: 70.0000 - tn: 374.0000 - fn: 62.0000 - accuracy: 0.8146 - precision: 0.7464 - recall: 0.7687 - auc: 0.8678 - val_loss: 0.4714 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8927\n",
      "Epoch 296/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4778 - tp: 207.0000 - fp: 68.0000 - tn: 376.0000 - fn: 61.0000 - accuracy: 0.8188 - precision: 0.7527 - recall: 0.7724 - auc: 0.8763 - val_loss: 0.4724 - val_tp: 61.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 13.0000 - val_accuracy: 0.8156 - val_precision: 0.7531 - val_recall: 0.8243 - val_auc: 0.8937\n",
      "Epoch 297/400\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.4976 - tp: 204.0000 - fp: 56.0000 - tn: 388.0000 - fn: 64.0000 - accuracy: 0.8315 - precision: 0.7846 - recall: 0.7612 - auc: 0.8747 - val_loss: 0.4717 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8931\n",
      "Epoch 298/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4857 - tp: 211.0000 - fp: 76.0000 - tn: 368.0000 - fn: 57.0000 - accuracy: 0.8132 - precision: 0.7352 - recall: 0.7873 - auc: 0.8730 - val_loss: 0.4702 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8940\n",
      "Epoch 299/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.4988 - tp: 195.0000 - fp: 49.0000 - tn: 395.0000 - fn: 73.0000 - accuracy: 0.8287 - precision: 0.7992 - recall: 0.7276 - auc: 0.8666 - val_loss: 0.4723 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8927\n",
      "Epoch 300/400\n",
      "712/712 [==============================] - 0s 179us/sample - loss: 0.4830 - tp: 211.0000 - fp: 69.0000 - tn: 375.0000 - fn: 57.0000 - accuracy: 0.8230 - precision: 0.7536 - recall: 0.7873 - auc: 0.8789 - val_loss: 0.4747 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8943\n",
      "Epoch 301/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4981 - tp: 210.0000 - fp: 74.0000 - tn: 370.0000 - fn: 58.0000 - accuracy: 0.8146 - precision: 0.7394 - recall: 0.7836 - auc: 0.8659 - val_loss: 0.4723 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8950\n",
      "Epoch 302/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4965 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8723 - val_loss: 0.4730 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8923\n",
      "Epoch 303/400\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.4943 - tp: 208.0000 - fp: 68.0000 - tn: 376.0000 - fn: 60.0000 - accuracy: 0.8202 - precision: 0.7536 - recall: 0.7761 - auc: 0.8622 - val_loss: 0.4721 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8947\n",
      "Epoch 304/400\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.5113 - tp: 200.0000 - fp: 58.0000 - tn: 386.0000 - fn: 68.0000 - accuracy: 0.8230 - precision: 0.7752 - recall: 0.7463 - auc: 0.8545 - val_loss: 0.4785 - val_tp: 61.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 13.0000 - val_accuracy: 0.7989 - val_precision: 0.7262 - val_recall: 0.8243 - val_auc: 0.8923\n",
      "Epoch 305/400\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.5113 - tp: 204.0000 - fp: 65.0000 - tn: 379.0000 - fn: 64.0000 - accuracy: 0.8188 - precision: 0.7584 - recall: 0.7612 - auc: 0.8571 - val_loss: 0.4709 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8950\n",
      "Epoch 306/400\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.5038 - tp: 200.0000 - fp: 56.0000 - tn: 388.0000 - fn: 68.0000 - accuracy: 0.8258 - precision: 0.7812 - recall: 0.7463 - auc: 0.8606 - val_loss: 0.4769 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8937\n",
      "Epoch 307/400\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.4991 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8636 - val_loss: 0.4792 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8925\n",
      "Epoch 308/400\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.5212 - tp: 206.0000 - fp: 78.0000 - tn: 366.0000 - fn: 62.0000 - accuracy: 0.8034 - precision: 0.7254 - recall: 0.7687 - auc: 0.8488 - val_loss: 0.4802 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8932\n",
      "Epoch 309/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.5053 - tp: 205.0000 - fp: 63.0000 - tn: 381.0000 - fn: 63.0000 - accuracy: 0.8230 - precision: 0.7649 - recall: 0.7649 - auc: 0.8653 - val_loss: 0.4736 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8924\n",
      "Epoch 310/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5144 - tp: 189.0000 - fp: 53.0000 - tn: 391.0000 - fn: 79.0000 - accuracy: 0.8146 - precision: 0.7810 - recall: 0.7052 - auc: 0.8550 - val_loss: 0.4824 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8898\n",
      "Epoch 311/400\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.5274 - tp: 210.0000 - fp: 83.0000 - tn: 361.0000 - fn: 58.0000 - accuracy: 0.8020 - precision: 0.7167 - recall: 0.7836 - auc: 0.8558 - val_loss: 0.4725 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8928\n",
      "Epoch 312/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4844 - tp: 208.0000 - fp: 62.0000 - tn: 382.0000 - fn: 60.0000 - accuracy: 0.8287 - precision: 0.7704 - recall: 0.7761 - auc: 0.8758 - val_loss: 0.4702 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8938\n",
      "Epoch 313/400\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 0.5038 - tp: 198.0000 - fp: 62.0000 - tn: 382.0000 - fn: 70.0000 - accuracy: 0.8146 - precision: 0.7615 - recall: 0.7388 - auc: 0.8609 - val_loss: 0.4721 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8941\n",
      "Epoch 314/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4986 - tp: 205.0000 - fp: 69.0000 - tn: 375.0000 - fn: 63.0000 - accuracy: 0.8146 - precision: 0.7482 - recall: 0.7649 - auc: 0.8619 - val_loss: 0.4711 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8932\n",
      "Epoch 315/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5233 - tp: 206.0000 - fp: 72.0000 - tn: 372.0000 - fn: 62.0000 - accuracy: 0.8118 - precision: 0.7410 - recall: 0.7687 - auc: 0.8569 - val_loss: 0.4709 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8937\n",
      "Epoch 316/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.4946 - tp: 206.0000 - fp: 56.0000 - tn: 388.0000 - fn: 62.0000 - accuracy: 0.8343 - precision: 0.7863 - recall: 0.7687 - auc: 0.8712 - val_loss: 0.4718 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8940\n",
      "Epoch 317/400\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.4983 - tp: 204.0000 - fp: 59.0000 - tn: 385.0000 - fn: 64.0000 - accuracy: 0.8272 - precision: 0.7757 - recall: 0.7612 - auc: 0.8608 - val_loss: 0.4767 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8918\n",
      "Epoch 318/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.5197 - tp: 203.0000 - fp: 75.0000 - tn: 369.0000 - fn: 65.0000 - accuracy: 0.8034 - precision: 0.7302 - recall: 0.7575 - auc: 0.8572 - val_loss: 0.4710 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8956\n",
      "Epoch 319/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4945 - tp: 192.0000 - fp: 49.0000 - tn: 395.0000 - fn: 76.0000 - accuracy: 0.8244 - precision: 0.7967 - recall: 0.7164 - auc: 0.8693 - val_loss: 0.4721 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8936\n",
      "Epoch 320/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4910 - tp: 207.0000 - fp: 67.0000 - tn: 377.0000 - fn: 61.0000 - accuracy: 0.8202 - precision: 0.7555 - recall: 0.7724 - auc: 0.8675 - val_loss: 0.4707 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8943\n",
      "Epoch 321/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4979 - tp: 206.0000 - fp: 62.0000 - tn: 382.0000 - fn: 62.0000 - accuracy: 0.8258 - precision: 0.7687 - recall: 0.7687 - auc: 0.8635 - val_loss: 0.4806 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8904\n",
      "Epoch 322/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4899 - tp: 195.0000 - fp: 52.0000 - tn: 392.0000 - fn: 73.0000 - accuracy: 0.8244 - precision: 0.7895 - recall: 0.7276 - auc: 0.8674 - val_loss: 0.4774 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8930\n",
      "Epoch 323/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5065 - tp: 205.0000 - fp: 72.0000 - tn: 372.0000 - fn: 63.0000 - accuracy: 0.8104 - precision: 0.7401 - recall: 0.7649 - auc: 0.8690 - val_loss: 0.4697 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8946\n",
      "Epoch 324/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5006 - tp: 211.0000 - fp: 66.0000 - tn: 378.0000 - fn: 57.0000 - accuracy: 0.8272 - precision: 0.7617 - recall: 0.7873 - auc: 0.8631 - val_loss: 0.4710 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8942\n",
      "Epoch 325/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4929 - tp: 208.0000 - fp: 72.0000 - tn: 372.0000 - fn: 60.0000 - accuracy: 0.8146 - precision: 0.7429 - recall: 0.7761 - auc: 0.8698 - val_loss: 0.4702 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8945\n",
      "Epoch 326/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.5119 - tp: 205.0000 - fp: 59.0000 - tn: 385.0000 - fn: 63.0000 - accuracy: 0.8287 - precision: 0.7765 - recall: 0.7649 - auc: 0.8584 - val_loss: 0.4733 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8940\n",
      "Epoch 327/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.4876 - tp: 204.0000 - fp: 58.0000 - tn: 386.0000 - fn: 64.0000 - accuracy: 0.8287 - precision: 0.7786 - recall: 0.7612 - auc: 0.8760 - val_loss: 0.4716 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8934\n",
      "Epoch 328/400\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 0.5115 - tp: 203.0000 - fp: 70.0000 - tn: 374.0000 - fn: 65.0000 - accuracy: 0.8104 - precision: 0.7436 - recall: 0.7575 - auc: 0.8546 - val_loss: 0.4707 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8938\n",
      "Epoch 329/400\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 0.4892 - tp: 204.0000 - fp: 61.0000 - tn: 383.0000 - fn: 64.0000 - accuracy: 0.8244 - precision: 0.7698 - recall: 0.7612 - auc: 0.8700 - val_loss: 0.4680 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8941\n",
      "Epoch 330/400\n",
      "712/712 [==============================] - 0s 195us/sample - loss: 0.4902 - tp: 205.0000 - fp: 71.0000 - tn: 373.0000 - fn: 63.0000 - accuracy: 0.8118 - precision: 0.7428 - recall: 0.7649 - auc: 0.8689 - val_loss: 0.4718 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8931\n",
      "Epoch 331/400\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 0.5028 - tp: 207.0000 - fp: 75.0000 - tn: 369.0000 - fn: 61.0000 - accuracy: 0.8090 - precision: 0.7340 - recall: 0.7724 - auc: 0.8606 - val_loss: 0.4689 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8933\n",
      "Epoch 332/400\n",
      "712/712 [==============================] - 0s 204us/sample - loss: 0.4976 - tp: 211.0000 - fp: 80.0000 - tn: 364.0000 - fn: 57.0000 - accuracy: 0.8076 - precision: 0.7251 - recall: 0.7873 - auc: 0.8622 - val_loss: 0.4720 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8949\n",
      "Epoch 333/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.5038 - tp: 191.0000 - fp: 48.0000 - tn: 396.0000 - fn: 77.0000 - accuracy: 0.8244 - precision: 0.7992 - recall: 0.7127 - auc: 0.8616 - val_loss: 0.4708 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8929\n",
      "Epoch 334/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.4840 - tp: 208.0000 - fp: 64.0000 - tn: 380.0000 - fn: 60.0000 - accuracy: 0.8258 - precision: 0.7647 - recall: 0.7761 - auc: 0.8711 - val_loss: 0.4694 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8936\n",
      "Epoch 335/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.5048 - tp: 204.0000 - fp: 61.0000 - tn: 383.0000 - fn: 64.0000 - accuracy: 0.8244 - precision: 0.7698 - recall: 0.7612 - auc: 0.8611 - val_loss: 0.4719 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8939\n",
      "Epoch 336/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5031 - tp: 206.0000 - fp: 63.0000 - tn: 381.0000 - fn: 62.0000 - accuracy: 0.8244 - precision: 0.7658 - recall: 0.7687 - auc: 0.8584 - val_loss: 0.4706 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8928\n",
      "Epoch 337/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4868 - tp: 202.0000 - fp: 57.0000 - tn: 387.0000 - fn: 66.0000 - accuracy: 0.8272 - precision: 0.7799 - recall: 0.7537 - auc: 0.8701 - val_loss: 0.4723 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8931\n",
      "Epoch 338/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.5000 - tp: 197.0000 - fp: 52.0000 - tn: 392.0000 - fn: 71.0000 - accuracy: 0.8272 - precision: 0.7912 - recall: 0.7351 - auc: 0.8621 - val_loss: 0.4759 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8918\n",
      "Epoch 339/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.4920 - tp: 209.0000 - fp: 60.0000 - tn: 384.0000 - fn: 59.0000 - accuracy: 0.8329 - precision: 0.7770 - recall: 0.7799 - auc: 0.8708 - val_loss: 0.4692 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8929\n",
      "Epoch 340/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.5084 - tp: 191.0000 - fp: 49.0000 - tn: 395.0000 - fn: 77.0000 - accuracy: 0.8230 - precision: 0.7958 - recall: 0.7127 - auc: 0.8580 - val_loss: 0.4766 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8925\n",
      "Epoch 341/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5178 - tp: 201.0000 - fp: 57.0000 - tn: 387.0000 - fn: 67.0000 - accuracy: 0.8258 - precision: 0.7791 - recall: 0.7500 - auc: 0.8546 - val_loss: 0.4775 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8921\n",
      "Epoch 342/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4874 - tp: 207.0000 - fp: 65.0000 - tn: 379.0000 - fn: 61.0000 - accuracy: 0.8230 - precision: 0.7610 - recall: 0.7724 - auc: 0.8725 - val_loss: 0.4687 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8939\n",
      "Epoch 343/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5028 - tp: 207.0000 - fp: 70.0000 - tn: 374.0000 - fn: 61.0000 - accuracy: 0.8160 - precision: 0.7473 - recall: 0.7724 - auc: 0.8665 - val_loss: 0.4681 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8937\n",
      "Epoch 344/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5141 - tp: 206.0000 - fp: 71.0000 - tn: 373.0000 - fn: 62.0000 - accuracy: 0.8132 - precision: 0.7437 - recall: 0.7687 - auc: 0.8566 - val_loss: 0.4695 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8936\n",
      "Epoch 345/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4857 - tp: 213.0000 - fp: 74.0000 - tn: 370.0000 - fn: 55.0000 - accuracy: 0.8188 - precision: 0.7422 - recall: 0.7948 - auc: 0.8747 - val_loss: 0.4684 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8932\n",
      "Epoch 346/400\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.4995 - tp: 207.0000 - fp: 70.0000 - tn: 374.0000 - fn: 61.0000 - accuracy: 0.8160 - precision: 0.7473 - recall: 0.7724 - auc: 0.8697 - val_loss: 0.4717 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8916\n",
      "Epoch 347/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5070 - tp: 209.0000 - fp: 79.0000 - tn: 365.0000 - fn: 59.0000 - accuracy: 0.8062 - precision: 0.7257 - recall: 0.7799 - auc: 0.8622 - val_loss: 0.4719 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8907\n",
      "Epoch 348/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5106 - tp: 203.0000 - fp: 75.0000 - tn: 369.0000 - fn: 65.0000 - accuracy: 0.8034 - precision: 0.7302 - recall: 0.7575 - auc: 0.8582 - val_loss: 0.4719 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8914\n",
      "Epoch 349/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5079 - tp: 194.0000 - fp: 54.0000 - tn: 390.0000 - fn: 74.0000 - accuracy: 0.8202 - precision: 0.7823 - recall: 0.7239 - auc: 0.8593 - val_loss: 0.4720 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8912\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4941 - tp: 211.0000 - fp: 77.0000 - tn: 367.0000 - fn: 57.0000 - accuracy: 0.8118 - precision: 0.7326 - recall: 0.7873 - auc: 0.8717 - val_loss: 0.4698 - val_tp: 61.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 13.0000 - val_accuracy: 0.7989 - val_precision: 0.7262 - val_recall: 0.8243 - val_auc: 0.8932\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.5031 - tp: 206.0000 - fp: 71.0000 - tn: 373.0000 - fn: 62.0000 - accuracy: 0.8132 - precision: 0.7437 - recall: 0.7687 - auc: 0.8647 - val_loss: 0.4679 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8929\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5117 - tp: 210.0000 - fp: 77.0000 - tn: 367.0000 - fn: 58.0000 - accuracy: 0.8104 - precision: 0.7317 - recall: 0.7836 - auc: 0.8552 - val_loss: 0.4722 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8916\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.5137 - tp: 195.0000 - fp: 54.0000 - tn: 390.0000 - fn: 73.0000 - accuracy: 0.8216 - precision: 0.7831 - recall: 0.7276 - auc: 0.8583 - val_loss: 0.4714 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8915\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.5049 - tp: 196.0000 - fp: 51.0000 - tn: 393.0000 - fn: 72.0000 - accuracy: 0.8272 - precision: 0.7935 - recall: 0.7313 - auc: 0.8649 - val_loss: 0.4698 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8926\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.4952 - tp: 196.0000 - fp: 57.0000 - tn: 387.0000 - fn: 72.0000 - accuracy: 0.8188 - precision: 0.7747 - recall: 0.7313 - auc: 0.8679 - val_loss: 0.4747 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8908\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5057 - tp: 211.0000 - fp: 71.0000 - tn: 373.0000 - fn: 57.0000 - accuracy: 0.8202 - precision: 0.7482 - recall: 0.7873 - auc: 0.8612 - val_loss: 0.4657 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8934\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.5147 - tp: 212.0000 - fp: 76.0000 - tn: 368.0000 - fn: 56.0000 - accuracy: 0.8146 - precision: 0.7361 - recall: 0.7910 - auc: 0.8531 - val_loss: 0.4646 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8932\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5159 - tp: 192.0000 - fp: 48.0000 - tn: 396.0000 - fn: 76.0000 - accuracy: 0.8258 - precision: 0.8000 - recall: 0.7164 - auc: 0.8608 - val_loss: 0.4932 - val_tp: 64.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 10.0000 - val_accuracy: 0.7821 - val_precision: 0.6882 - val_recall: 0.8649 - val_auc: 0.8914\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5161 - tp: 208.0000 - fp: 77.0000 - tn: 367.0000 - fn: 60.0000 - accuracy: 0.8076 - precision: 0.7298 - recall: 0.7761 - auc: 0.8575 - val_loss: 0.4687 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8936\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4994 - tp: 203.0000 - fp: 57.0000 - tn: 387.0000 - fn: 65.0000 - accuracy: 0.8287 - precision: 0.7808 - recall: 0.7575 - auc: 0.8630 - val_loss: 0.4707 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8940\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.4875 - tp: 200.0000 - fp: 64.0000 - tn: 380.0000 - fn: 68.0000 - accuracy: 0.8146 - precision: 0.7576 - recall: 0.7463 - auc: 0.8683 - val_loss: 0.4677 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8940\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.4835 - tp: 193.0000 - fp: 51.0000 - tn: 393.0000 - fn: 75.0000 - accuracy: 0.8230 - precision: 0.7910 - recall: 0.7201 - auc: 0.8723 - val_loss: 0.4696 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8929\n",
      "Epoch 363/400\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.5020 - tp: 208.0000 - fp: 69.0000 - tn: 375.0000 - fn: 60.0000 - accuracy: 0.8188 - precision: 0.7509 - recall: 0.7761 - auc: 0.8630 - val_loss: 0.4689 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8939\n",
      "Epoch 364/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.4948 - tp: 201.0000 - fp: 59.0000 - tn: 385.0000 - fn: 67.0000 - accuracy: 0.8230 - precision: 0.7731 - recall: 0.7500 - auc: 0.8686 - val_loss: 0.4677 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8939\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5076 - tp: 201.0000 - fp: 61.0000 - tn: 383.0000 - fn: 67.0000 - accuracy: 0.8202 - precision: 0.7672 - recall: 0.7500 - auc: 0.8591 - val_loss: 0.4738 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8916\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5089 - tp: 206.0000 - fp: 73.0000 - tn: 371.0000 - fn: 62.0000 - accuracy: 0.8104 - precision: 0.7384 - recall: 0.7687 - auc: 0.8639 - val_loss: 0.4670 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8923\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4855 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8775 - val_loss: 0.4713 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8911\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4952 - tp: 212.0000 - fp: 62.0000 - tn: 382.0000 - fn: 56.0000 - accuracy: 0.8343 - precision: 0.7737 - recall: 0.7910 - auc: 0.8664 - val_loss: 0.4686 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8934\n",
      "Epoch 369/400\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.4990 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8599 - val_loss: 0.4752 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8923\n",
      "Epoch 370/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4882 - tp: 207.0000 - fp: 65.0000 - tn: 379.0000 - fn: 61.0000 - accuracy: 0.8230 - precision: 0.7610 - recall: 0.7724 - auc: 0.8736 - val_loss: 0.4701 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8915\n",
      "Epoch 371/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4918 - tp: 196.0000 - fp: 53.0000 - tn: 391.0000 - fn: 72.0000 - accuracy: 0.8244 - precision: 0.7871 - recall: 0.7313 - auc: 0.8681 - val_loss: 0.4740 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8913\n",
      "Epoch 372/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5073 - tp: 211.0000 - fp: 82.0000 - tn: 362.0000 - fn: 57.0000 - accuracy: 0.8048 - precision: 0.7201 - recall: 0.7873 - auc: 0.8626 - val_loss: 0.4669 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8923\n",
      "Epoch 373/400\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.5082 - tp: 190.0000 - fp: 67.0000 - tn: 377.0000 - fn: 78.0000 - accuracy: 0.7963 - precision: 0.7393 - recall: 0.7090 - auc: 0.8585 - val_loss: 0.4801 - val_tp: 64.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 10.0000 - val_accuracy: 0.7877 - val_precision: 0.6957 - val_recall: 0.8649 - val_auc: 0.8932\n",
      "Epoch 374/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5086 - tp: 212.0000 - fp: 84.0000 - tn: 360.0000 - fn: 56.0000 - accuracy: 0.8034 - precision: 0.7162 - recall: 0.7910 - auc: 0.8583 - val_loss: 0.4659 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8938\n",
      "Epoch 375/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4864 - tp: 200.0000 - fp: 52.0000 - tn: 392.0000 - fn: 68.0000 - accuracy: 0.8315 - precision: 0.7937 - recall: 0.7463 - auc: 0.8763 - val_loss: 0.4718 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8907\n",
      "Epoch 376/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5111 - tp: 211.0000 - fp: 78.0000 - tn: 366.0000 - fn: 57.0000 - accuracy: 0.8104 - precision: 0.7301 - recall: 0.7873 - auc: 0.8585 - val_loss: 0.4708 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8923\n",
      "Epoch 377/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5214 - tp: 203.0000 - fp: 66.0000 - tn: 378.0000 - fn: 65.0000 - accuracy: 0.8160 - precision: 0.7546 - recall: 0.7575 - auc: 0.8510 - val_loss: 0.4683 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8944\n",
      "Epoch 378/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.4944 - tp: 207.0000 - fp: 65.0000 - tn: 379.0000 - fn: 61.0000 - accuracy: 0.8230 - precision: 0.7610 - recall: 0.7724 - auc: 0.8707 - val_loss: 0.4680 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8931\n",
      "Epoch 379/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4888 - tp: 211.0000 - fp: 75.0000 - tn: 369.0000 - fn: 57.0000 - accuracy: 0.8146 - precision: 0.7378 - recall: 0.7873 - auc: 0.8771 - val_loss: 0.4638 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8928\n",
      "Epoch 380/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.5064 - tp: 206.0000 - fp: 66.0000 - tn: 378.0000 - fn: 62.0000 - accuracy: 0.8202 - precision: 0.7574 - recall: 0.7687 - auc: 0.8623 - val_loss: 0.4719 - val_tp: 62.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 12.0000 - val_accuracy: 0.7877 - val_precision: 0.7045 - val_recall: 0.8378 - val_auc: 0.8932\n",
      "Epoch 381/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4993 - tp: 206.0000 - fp: 63.0000 - tn: 381.0000 - fn: 62.0000 - accuracy: 0.8244 - precision: 0.7658 - recall: 0.7687 - auc: 0.8692 - val_loss: 0.4693 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8908\n",
      "Epoch 382/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4885 - tp: 212.0000 - fp: 83.0000 - tn: 361.0000 - fn: 56.0000 - accuracy: 0.8048 - precision: 0.7186 - recall: 0.7910 - auc: 0.8729 - val_loss: 0.4665 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8915\n",
      "Epoch 383/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4927 - tp: 207.0000 - fp: 70.0000 - tn: 374.0000 - fn: 61.0000 - accuracy: 0.8160 - precision: 0.7473 - recall: 0.7724 - auc: 0.8689 - val_loss: 0.4690 - val_tp: 62.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 12.0000 - val_accuracy: 0.7933 - val_precision: 0.7126 - val_recall: 0.8378 - val_auc: 0.8932\n",
      "Epoch 384/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5079 - tp: 211.0000 - fp: 82.0000 - tn: 362.0000 - fn: 57.0000 - accuracy: 0.8048 - precision: 0.7201 - recall: 0.7873 - auc: 0.8668 - val_loss: 0.4644 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8925\n",
      "Epoch 385/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.5162 - tp: 206.0000 - fp: 70.0000 - tn: 374.0000 - fn: 62.0000 - accuracy: 0.8146 - precision: 0.7464 - recall: 0.7687 - auc: 0.8639 - val_loss: 0.4654 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8929\n",
      "Epoch 386/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.4988 - tp: 203.0000 - fp: 68.0000 - tn: 376.0000 - fn: 65.0000 - accuracy: 0.8132 - precision: 0.7491 - recall: 0.7575 - auc: 0.8643 - val_loss: 0.4669 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8914\n",
      "Epoch 387/400\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4942 - tp: 214.0000 - fp: 81.0000 - tn: 363.0000 - fn: 54.0000 - accuracy: 0.8104 - precision: 0.7254 - recall: 0.7985 - auc: 0.8679 - val_loss: 0.4635 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8938\n",
      "Epoch 388/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4904 - tp: 203.0000 - fp: 69.0000 - tn: 375.0000 - fn: 65.0000 - accuracy: 0.8118 - precision: 0.7463 - recall: 0.7575 - auc: 0.8691 - val_loss: 0.4658 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8931\n",
      "Epoch 389/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.5049 - tp: 204.0000 - fp: 63.0000 - tn: 381.0000 - fn: 64.0000 - accuracy: 0.8216 - precision: 0.7640 - recall: 0.7612 - auc: 0.8596 - val_loss: 0.4683 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8932\n",
      "Epoch 390/400\n",
      "712/712 [==============================] - 0s 196us/sample - loss: 0.4969 - tp: 207.0000 - fp: 66.0000 - tn: 378.0000 - fn: 61.0000 - accuracy: 0.8216 - precision: 0.7582 - recall: 0.7724 - auc: 0.8660 - val_loss: 0.4766 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8900\n",
      "Epoch 391/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4740 - tp: 215.0000 - fp: 79.0000 - tn: 365.0000 - fn: 53.0000 - accuracy: 0.8146 - precision: 0.7313 - recall: 0.8022 - auc: 0.8750 - val_loss: 0.4684 - val_tp: 56.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 18.0000 - val_accuracy: 0.8045 - val_precision: 0.7671 - val_recall: 0.7568 - val_auc: 0.8910\n",
      "Epoch 392/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4933 - tp: 204.0000 - fp: 65.0000 - tn: 379.0000 - fn: 64.0000 - accuracy: 0.8188 - precision: 0.7584 - recall: 0.7612 - auc: 0.8649 - val_loss: 0.4658 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8925\n",
      "Epoch 393/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4923 - tp: 205.0000 - fp: 58.0000 - tn: 386.0000 - fn: 63.0000 - accuracy: 0.8301 - precision: 0.7795 - recall: 0.7649 - auc: 0.8667 - val_loss: 0.4644 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8931\n",
      "Epoch 394/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.4966 - tp: 216.0000 - fp: 86.0000 - tn: 358.0000 - fn: 52.0000 - accuracy: 0.8062 - precision: 0.7152 - recall: 0.8060 - auc: 0.8614 - val_loss: 0.4673 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8927\n",
      "Epoch 395/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5012 - tp: 206.0000 - fp: 60.0000 - tn: 384.0000 - fn: 62.0000 - accuracy: 0.8287 - precision: 0.7744 - recall: 0.7687 - auc: 0.8646 - val_loss: 0.4653 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8929\n",
      "Epoch 396/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.4997 - tp: 205.0000 - fp: 63.0000 - tn: 381.0000 - fn: 63.0000 - accuracy: 0.8230 - precision: 0.7649 - recall: 0.7649 - auc: 0.8642 - val_loss: 0.4640 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8927\n",
      "Epoch 397/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4910 - tp: 205.0000 - fp: 64.0000 - tn: 380.0000 - fn: 63.0000 - accuracy: 0.8216 - precision: 0.7621 - recall: 0.7649 - auc: 0.8673 - val_loss: 0.4631 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8937\n",
      "Epoch 398/400\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4888 - tp: 213.0000 - fp: 86.0000 - tn: 358.0000 - fn: 55.0000 - accuracy: 0.8020 - precision: 0.7124 - recall: 0.7948 - auc: 0.8742 - val_loss: 0.4625 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8923\n",
      "Epoch 399/400\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.5098 - tp: 209.0000 - fp: 63.0000 - tn: 381.0000 - fn: 59.0000 - accuracy: 0.8287 - precision: 0.7684 - recall: 0.7799 - auc: 0.8611 - val_loss: 0.4637 - val_tp: 61.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 13.0000 - val_accuracy: 0.7989 - val_precision: 0.7262 - val_recall: 0.8243 - val_auc: 0.8924\n",
      "Epoch 400/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5018 - tp: 208.0000 - fp: 87.0000 - tn: 357.0000 - fn: 60.0000 - accuracy: 0.7935 - precision: 0.7051 - recall: 0.7761 - auc: 0.8688 - val_loss: 0.4633 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8927\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 673312de8d91fbf0883110d848d53c0a</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8100558519363403</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-batch_size: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_0: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_1: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_2: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_3: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_4: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_5: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_6: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_1: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_2: 48</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_3: 24</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_4: 40</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_5: 40</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_6: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_0: 0.40000000000000013</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_1: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_2: 0.2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_3: 0.3500000000000001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_4: 0.2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_5: 0.40000000000000013</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_6: 0.45000000000000007</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-epoch_number: 400</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_0: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_1: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_2: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_3: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_4: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_5: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_6: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_0: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_1: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_2: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_3: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_4: 0.1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_5: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_6: 0.1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_layers: 4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/600\n",
      "712/712 [==============================] - 3s 5ms/sample - loss: 4.8712 - tp: 117.0000 - fp: 173.0000 - tn: 271.0000 - fn: 151.0000 - accuracy: 0.5449 - precision: 0.4034 - recall: 0.4366 - auc: 0.5141 - val_loss: 1.4556 - val_tp: 38.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 36.0000 - val_accuracy: 0.6983 - val_precision: 0.6786 - val_recall: 0.5135 - val_auc: 0.8125\n",
      "Epoch 2/600\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 1.0572 - tp: 131.0000 - fp: 128.0000 - tn: 316.0000 - fn: 137.0000 - accuracy: 0.6278 - precision: 0.5058 - recall: 0.4888 - auc: 0.6600 - val_loss: 0.9131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8382\n",
      "Epoch 3/600\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.8655 - tp: 94.0000 - fp: 137.0000 - tn: 307.0000 - fn: 174.0000 - accuracy: 0.5632 - precision: 0.4069 - recall: 0.3507 - auc: 0.5221 - val_loss: 0.8582 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 4/600\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.8401 - tp: 146.0000 - fp: 225.0000 - tn: 219.0000 - fn: 122.0000 - accuracy: 0.5126 - precision: 0.3935 - recall: 0.5448 - auc: 0.5296 - val_loss: 0.8623 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 5/600\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.8394 - tp: 58.0000 - fp: 90.0000 - tn: 354.0000 - fn: 210.0000 - accuracy: 0.5787 - precision: 0.3919 - recall: 0.2164 - auc: 0.4991 - val_loss: 0.8545 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 6/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.8393 - tp: 167.0000 - fp: 267.0000 - tn: 177.0000 - fn: 101.0000 - accuracy: 0.4831 - precision: 0.3848 - recall: 0.6231 - auc: 0.5005 - val_loss: 0.8581 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 7/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.8390 - tp: 30.0000 - fp: 52.0000 - tn: 392.0000 - fn: 238.0000 - accuracy: 0.5927 - precision: 0.3659 - recall: 0.1119 - auc: 0.4850 - val_loss: 0.8540 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 8/600\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.8393 - tp: 148.0000 - fp: 244.0000 - tn: 200.0000 - fn: 120.0000 - accuracy: 0.4888 - precision: 0.3776 - recall: 0.5522 - auc: 0.5003 - val_loss: 0.8620 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 9/600\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.8398 - tp: 49.0000 - fp: 72.0000 - tn: 372.0000 - fn: 219.0000 - accuracy: 0.5913 - precision: 0.4050 - recall: 0.1828 - auc: 0.4703 - val_loss: 0.8516 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 10/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.8380 - tp: 78.0000 - fp: 113.0000 - tn: 331.0000 - fn: 190.0000 - accuracy: 0.5744 - precision: 0.4084 - recall: 0.2910 - auc: 0.5055 - val_loss: 0.8528 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 11/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.8390 - tp: 92.0000 - fp: 150.0000 - tn: 294.0000 - fn: 176.0000 - accuracy: 0.5421 - precision: 0.3802 - recall: 0.3433 - auc: 0.4979 - val_loss: 0.8514 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 12/600\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.8389 - tp: 65.0000 - fp: 100.0000 - tn: 344.0000 - fn: 203.0000 - accuracy: 0.5744 - precision: 0.3939 - recall: 0.2425 - auc: 0.4746 - val_loss: 0.8547 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 13/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.8393 - tp: 110.0000 - fp: 182.0000 - tn: 262.0000 - fn: 158.0000 - accuracy: 0.5225 - precision: 0.3767 - recall: 0.4104 - auc: 0.4977 - val_loss: 0.8518 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 14/600\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.8387 - tp: 115.0000 - fp: 192.0000 - tn: 252.0000 - fn: 153.0000 - accuracy: 0.5154 - precision: 0.3746 - recall: 0.4291 - auc: 0.5093 - val_loss: 0.8531 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 15/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.8395 - tp: 75.0000 - fp: 140.0000 - tn: 304.0000 - fn: 193.0000 - accuracy: 0.5323 - precision: 0.3488 - recall: 0.2799 - auc: 0.4768 - val_loss: 0.8516 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 16/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.8384 - tp: 99.0000 - fp: 160.0000 - tn: 284.0000 - fn: 169.0000 - accuracy: 0.5379 - precision: 0.3822 - recall: 0.3694 - auc: 0.5000 - val_loss: 0.8671 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 17/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.8388 - tp: 31.0000 - fp: 55.0000 - tn: 389.0000 - fn: 237.0000 - accuracy: 0.5899 - precision: 0.3605 - recall: 0.1157 - auc: 0.4800 - val_loss: 0.8530 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 18/600\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.8379 - tp: 128.0000 - fp: 178.0000 - tn: 266.0000 - fn: 140.0000 - accuracy: 0.5534 - precision: 0.4183 - recall: 0.4776 - auc: 0.5318 - val_loss: 0.8518 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 19/600\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.8388 - tp: 54.0000 - fp: 84.0000 - tn: 360.0000 - fn: 214.0000 - accuracy: 0.5815 - precision: 0.3913 - recall: 0.2015 - auc: 0.4840 - val_loss: 0.8546 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 20/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.8388 - tp: 109.0000 - fp: 173.0000 - tn: 271.0000 - fn: 159.0000 - accuracy: 0.5337 - precision: 0.3865 - recall: 0.4067 - auc: 0.5137 - val_loss: 0.8605 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 21/600\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.8393 - tp: 22.0000 - fp: 42.0000 - tn: 402.0000 - fn: 246.0000 - accuracy: 0.5955 - precision: 0.3438 - recall: 0.0821 - auc: 0.4689 - val_loss: 0.8508 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 22/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.8376 - tp: 72.0000 - fp: 113.0000 - tn: 331.0000 - fn: 196.0000 - accuracy: 0.5660 - precision: 0.3892 - recall: 0.2687 - auc: 0.4974 - val_loss: 0.8515 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 23/600\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.8378 - tp: 95.0000 - fp: 157.0000 - tn: 287.0000 - fn: 173.0000 - accuracy: 0.5365 - precision: 0.3770 - recall: 0.3545 - auc: 0.5060 - val_loss: 0.8539 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 24/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.8381 - tp: 36.0000 - fp: 64.0000 - tn: 380.0000 - fn: 232.0000 - accuracy: 0.5843 - precision: 0.3600 - recall: 0.1343 - auc: 0.4966 - val_loss: 0.8563 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 25/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.8400 - tp: 59.0000 - fp: 117.0000 - tn: 327.0000 - fn: 209.0000 - accuracy: 0.5421 - precision: 0.3352 - recall: 0.2201 - auc: 0.4728 - val_loss: 0.8509 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 26/600\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.8378 - tp: 22.0000 - fp: 25.0000 - tn: 419.0000 - fn: 246.0000 - accuracy: 0.6194 - precision: 0.4681 - recall: 0.0821 - auc: 0.4998 - val_loss: 0.8522 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 27/600\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.8377 - tp: 32.0000 - fp: 61.0000 - tn: 383.0000 - fn: 236.0000 - accuracy: 0.5829 - precision: 0.3441 - recall: 0.1194 - auc: 0.5083 - val_loss: 0.8526 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 28/600\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.8392 - tp: 72.0000 - fp: 150.0000 - tn: 294.0000 - fn: 196.0000 - accuracy: 0.5140 - precision: 0.3243 - recall: 0.2687 - auc: 0.4832 - val_loss: 0.8521 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 29/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.8385 - tp: 150.0000 - fp: 261.0000 - tn: 183.0000 - fn: 118.0000 - accuracy: 0.4677 - precision: 0.3650 - recall: 0.5597 - auc: 0.4733 - val_loss: 0.8617 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 30/600\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.8378 - tp: 5.0000 - fp: 10.0000 - tn: 434.0000 - fn: 263.0000 - accuracy: 0.6166 - precision: 0.3333 - recall: 0.0187 - auc: 0.4781 - val_loss: 0.8515 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 31/600\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.8378 - tp: 11.0000 - fp: 17.0000 - tn: 427.0000 - fn: 257.0000 - accuracy: 0.6152 - precision: 0.3929 - recall: 0.0410 - auc: 0.4814 - val_loss: 0.8545 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 32/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.8389 - tp: 99.0000 - fp: 189.0000 - tn: 255.0000 - fn: 169.0000 - accuracy: 0.4972 - precision: 0.3438 - recall: 0.3694 - auc: 0.4779 - val_loss: 0.8518 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 33/600\n",
      "712/712 [==============================] - 0s 186us/sample - loss: 0.8375 - tp: 51.0000 - fp: 84.0000 - tn: 360.0000 - fn: 217.0000 - accuracy: 0.5772 - precision: 0.3778 - recall: 0.1903 - auc: 0.4892 - val_loss: 0.8561 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 34/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.8381 - tp: 9.0000 - fp: 17.0000 - tn: 427.0000 - fn: 259.0000 - accuracy: 0.6124 - precision: 0.3462 - recall: 0.0336 - auc: 0.4951 - val_loss: 0.8510 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 35/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.8382 - tp: 74.0000 - fp: 132.0000 - tn: 312.0000 - fn: 194.0000 - accuracy: 0.5421 - precision: 0.3592 - recall: 0.2761 - auc: 0.4874 - val_loss: 0.8543 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 36/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.8380 - tp: 152.0000 - fp: 257.0000 - tn: 187.0000 - fn: 116.0000 - accuracy: 0.4761 - precision: 0.3716 - recall: 0.5672 - auc: 0.4948 - val_loss: 0.8573 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 37/600\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.8388 - tp: 61.0000 - fp: 136.0000 - tn: 308.0000 - fn: 207.0000 - accuracy: 0.5183 - precision: 0.3096 - recall: 0.2276 - auc: 0.4772 - val_loss: 0.8537 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 38/600\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.8378 - tp: 39.0000 - fp: 70.0000 - tn: 374.0000 - fn: 229.0000 - accuracy: 0.5801 - precision: 0.3578 - recall: 0.1455 - auc: 0.4966 - val_loss: 0.8575 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 39/600\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.8387 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4507 - val_loss: 0.8515 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 40/600\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.8376 - tp: 11.0000 - fp: 19.0000 - tn: 425.0000 - fn: 257.0000 - accuracy: 0.6124 - precision: 0.3667 - recall: 0.0410 - auc: 0.4731 - val_loss: 0.8516 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 41/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.8372 - tp: 47.0000 - fp: 60.0000 - tn: 384.0000 - fn: 221.0000 - accuracy: 0.6053 - precision: 0.4393 - recall: 0.1754 - auc: 0.5188 - val_loss: 0.8515 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 42/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.8397 - tp: 104.0000 - fp: 197.0000 - tn: 247.0000 - fn: 164.0000 - accuracy: 0.4930 - precision: 0.3455 - recall: 0.3881 - auc: 0.4798 - val_loss: 0.8572 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 43/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.8380 - tp: 29.0000 - fp: 41.0000 - tn: 403.0000 - fn: 239.0000 - accuracy: 0.6067 - precision: 0.4143 - recall: 0.1082 - auc: 0.4816 - val_loss: 0.8612 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 44/600\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.8386 - tp: 8.0000 - fp: 13.0000 - tn: 431.0000 - fn: 260.0000 - accuracy: 0.6166 - precision: 0.3810 - recall: 0.0299 - auc: 0.4597 - val_loss: 0.8530 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 45/600\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.8386 - tp: 10.0000 - fp: 20.0000 - tn: 424.0000 - fn: 258.0000 - accuracy: 0.6096 - precision: 0.3333 - recall: 0.0373 - auc: 0.4518 - val_loss: 0.8522 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 46/600\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.8379 - tp: 51.0000 - fp: 92.0000 - tn: 352.0000 - fn: 217.0000 - accuracy: 0.5660 - precision: 0.3566 - recall: 0.1903 - auc: 0.4769 - val_loss: 0.8509 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 47/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.8379 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4393 - val_loss: 0.8539 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 48/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.8377 - tp: 31.0000 - fp: 69.0000 - tn: 375.0000 - fn: 237.0000 - accuracy: 0.5702 - precision: 0.3100 - recall: 0.1157 - auc: 0.4762 - val_loss: 0.8509 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 49/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.8383 - tp: 35.0000 - fp: 64.0000 - tn: 380.0000 - fn: 233.0000 - accuracy: 0.5829 - precision: 0.3535 - recall: 0.1306 - auc: 0.4612 - val_loss: 0.8505 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 50/600\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.8375 - tp: 48.0000 - fp: 73.0000 - tn: 371.0000 - fn: 220.0000 - accuracy: 0.5885 - precision: 0.3967 - recall: 0.1791 - auc: 0.5176 - val_loss: 0.8513 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 51/600\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.8383 - tp: 107.0000 - fp: 157.0000 - tn: 287.0000 - fn: 161.0000 - accuracy: 0.5534 - precision: 0.4053 - recall: 0.3993 - auc: 0.5059 - val_loss: 0.8521 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 52/600\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.8382 - tp: 69.0000 - fp: 120.0000 - tn: 324.0000 - fn: 199.0000 - accuracy: 0.5520 - precision: 0.3651 - recall: 0.2575 - auc: 0.5113 - val_loss: 0.8524 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 53/600\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.8388 - tp: 59.0000 - fp: 116.0000 - tn: 328.0000 - fn: 209.0000 - accuracy: 0.5435 - precision: 0.3371 - recall: 0.2201 - auc: 0.4665 - val_loss: 0.8515 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 54/600\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.8386 - tp: 95.0000 - fp: 162.0000 - tn: 282.0000 - fn: 173.0000 - accuracy: 0.5295 - precision: 0.3696 - recall: 0.3545 - auc: 0.5054 - val_loss: 0.8529 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 55/600\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.8384 - tp: 104.0000 - fp: 184.0000 - tn: 260.0000 - fn: 164.0000 - accuracy: 0.5112 - precision: 0.3611 - recall: 0.3881 - auc: 0.4920 - val_loss: 0.8529 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 56/600\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.8387 - tp: 25.0000 - fp: 53.0000 - tn: 391.0000 - fn: 243.0000 - accuracy: 0.5843 - precision: 0.3205 - recall: 0.0933 - auc: 0.4702 - val_loss: 0.8518 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 57/600\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.8383 - tp: 86.0000 - fp: 147.0000 - tn: 297.0000 - fn: 182.0000 - accuracy: 0.5379 - precision: 0.3691 - recall: 0.3209 - auc: 0.4796 - val_loss: 0.8509 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 58/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.8373 - tp: 26.0000 - fp: 29.0000 - tn: 415.0000 - fn: 242.0000 - accuracy: 0.6194 - precision: 0.4727 - recall: 0.0970 - auc: 0.5081 - val_loss: 0.8516 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 59/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.8387 - tp: 84.0000 - fp: 156.0000 - tn: 288.0000 - fn: 184.0000 - accuracy: 0.5225 - precision: 0.3500 - recall: 0.3134 - auc: 0.4845 - val_loss: 0.8514 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 60/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.8388 - tp: 26.0000 - fp: 80.0000 - tn: 364.0000 - fn: 242.0000 - accuracy: 0.5478 - precision: 0.2453 - recall: 0.0970 - auc: 0.4477 - val_loss: 0.8501 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 61/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.8376 - tp: 119.0000 - fp: 205.0000 - tn: 239.0000 - fn: 149.0000 - accuracy: 0.5028 - precision: 0.3673 - recall: 0.4440 - auc: 0.4924 - val_loss: 0.8502 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 62/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.8379 - tp: 85.0000 - fp: 147.0000 - tn: 297.0000 - fn: 183.0000 - accuracy: 0.5365 - precision: 0.3664 - recall: 0.3172 - auc: 0.4876 - val_loss: 0.8615 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 63/600\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.8385 - tp: 57.0000 - fp: 94.0000 - tn: 350.0000 - fn: 211.0000 - accuracy: 0.5716 - precision: 0.3775 - recall: 0.2127 - auc: 0.4935 - val_loss: 0.8521 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 64/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.8376 - tp: 63.0000 - fp: 85.0000 - tn: 359.0000 - fn: 205.0000 - accuracy: 0.5927 - precision: 0.4257 - recall: 0.2351 - auc: 0.5356 - val_loss: 0.8543 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 65/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.8393 - tp: 52.0000 - fp: 104.0000 - tn: 340.0000 - fn: 216.0000 - accuracy: 0.5506 - precision: 0.3333 - recall: 0.1940 - auc: 0.4665 - val_loss: 0.8520 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 66/600\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.8386 - tp: 29.0000 - fp: 61.0000 - tn: 383.0000 - fn: 239.0000 - accuracy: 0.5787 - precision: 0.3222 - recall: 0.1082 - auc: 0.4365 - val_loss: 0.8578 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 67/600\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.8380 - tp: 4.0000 - fp: 13.0000 - tn: 431.0000 - fn: 264.0000 - accuracy: 0.6110 - precision: 0.2353 - recall: 0.0149 - auc: 0.4891 - val_loss: 0.8551 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 68/600\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.8384 - tp: 60.0000 - fp: 121.0000 - tn: 323.0000 - fn: 208.0000 - accuracy: 0.5379 - precision: 0.3315 - recall: 0.2239 - auc: 0.4751 - val_loss: 0.8511 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 69/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.8381 - tp: 38.0000 - fp: 71.0000 - tn: 373.0000 - fn: 230.0000 - accuracy: 0.5772 - precision: 0.3486 - recall: 0.1418 - auc: 0.4875 - val_loss: 0.8514 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 70/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.8383 - tp: 114.0000 - fp: 187.0000 - tn: 257.0000 - fn: 154.0000 - accuracy: 0.5211 - precision: 0.3787 - recall: 0.4254 - auc: 0.4922 - val_loss: 0.8548 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.7112 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4730 - val_loss: 0.7239 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 412/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.7117 - tp: 165.0000 - fp: 277.0000 - tn: 167.0000 - fn: 103.0000 - accuracy: 0.4663 - precision: 0.3733 - recall: 0.6157 - auc: 0.4968 - val_loss: 0.7251 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 413/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.7132 - tp: 131.0000 - fp: 254.0000 - tn: 190.0000 - fn: 137.0000 - accuracy: 0.4508 - precision: 0.3403 - recall: 0.4888 - auc: 0.4423 - val_loss: 0.7238 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 414/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.7118 - tp: 13.0000 - fp: 21.0000 - tn: 423.0000 - fn: 255.0000 - accuracy: 0.6124 - precision: 0.3824 - recall: 0.0485 - auc: 0.4606 - val_loss: 0.7246 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 415/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7112 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4807 - val_loss: 0.7241 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 416/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7119 - tp: 123.0000 - fp: 229.0000 - tn: 215.0000 - fn: 145.0000 - accuracy: 0.4747 - precision: 0.3494 - recall: 0.4590 - auc: 0.4761 - val_loss: 0.7237 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 417/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7110 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4990 - val_loss: 0.7250 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 418/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.7118 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5030 - val_loss: 0.7249 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 419/500\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.7110 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4741 - val_loss: 0.7248 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 420/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.7109 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4995 - val_loss: 0.7238 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 421/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.7109 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4953 - val_loss: 0.7240 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 422/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7118 - tp: 58.0000 - fp: 109.0000 - tn: 335.0000 - fn: 210.0000 - accuracy: 0.5520 - precision: 0.3473 - recall: 0.2164 - auc: 0.4738 - val_loss: 0.7242 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 423/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7114 - tp: 12.0000 - fp: 24.0000 - tn: 420.0000 - fn: 256.0000 - accuracy: 0.6067 - precision: 0.3333 - recall: 0.0448 - auc: 0.4799 - val_loss: 0.7245 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 424/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7112 - tp: 54.0000 - fp: 110.0000 - tn: 334.0000 - fn: 214.0000 - accuracy: 0.5449 - precision: 0.3293 - recall: 0.2015 - auc: 0.4850 - val_loss: 0.7253 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 425/500\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.7111 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4856 - val_loss: 0.7262 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 426/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.7110 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4870 - val_loss: 0.7241 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 427/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.7117 - tp: 141.0000 - fp: 274.0000 - tn: 170.0000 - fn: 127.0000 - accuracy: 0.4368 - precision: 0.3398 - recall: 0.5261 - auc: 0.4564 - val_loss: 0.7233 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 428/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.7116 - tp: 3.0000 - fp: 3.0000 - tn: 441.0000 - fn: 265.0000 - accuracy: 0.6236 - precision: 0.5000 - recall: 0.0112 - auc: 0.4947 - val_loss: 0.7244 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 429/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.7113 - tp: 112.0000 - fp: 201.0000 - tn: 243.0000 - fn: 156.0000 - accuracy: 0.4986 - precision: 0.3578 - recall: 0.4179 - auc: 0.4968 - val_loss: 0.7241 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 430/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7117 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4603 - val_loss: 0.7248 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 431/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7114 - tp: 124.0000 - fp: 216.0000 - tn: 228.0000 - fn: 144.0000 - accuracy: 0.4944 - precision: 0.3647 - recall: 0.4627 - auc: 0.4937 - val_loss: 0.7230 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 432/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.7119 - tp: 58.0000 - fp: 113.0000 - tn: 331.0000 - fn: 210.0000 - accuracy: 0.5463 - precision: 0.3392 - recall: 0.2164 - auc: 0.4730 - val_loss: 0.7245 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 433/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.7110 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4972 - val_loss: 0.7236 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 434/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7110 - tp: 162.0000 - fp: 278.0000 - tn: 166.0000 - fn: 106.0000 - accuracy: 0.4607 - precision: 0.3682 - recall: 0.6045 - auc: 0.4958 - val_loss: 0.7248 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 435/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.7116 - tp: 10.0000 - fp: 18.0000 - tn: 426.0000 - fn: 258.0000 - accuracy: 0.6124 - precision: 0.3571 - recall: 0.0373 - auc: 0.4813 - val_loss: 0.7247 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 436/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.7112 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4953 - val_loss: 0.7250 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 437/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7119 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4629 - val_loss: 0.7249 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 438/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.7109 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4697 - val_loss: 0.7253 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 439/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7110 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4775 - val_loss: 0.7245 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 440/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7110 - tp: 25.0000 - fp: 57.0000 - tn: 387.0000 - fn: 243.0000 - accuracy: 0.5787 - precision: 0.3049 - recall: 0.0933 - auc: 0.4751 - val_loss: 0.7240 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 441/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7110 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4674 - val_loss: 0.7242 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 442/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.7111 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4586 - val_loss: 0.7251 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 443/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7108 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4902 - val_loss: 0.7243 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 444/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7111 - tp: 7.0000 - fp: 14.0000 - tn: 430.0000 - fn: 261.0000 - accuracy: 0.6138 - precision: 0.3333 - recall: 0.0261 - auc: 0.4656 - val_loss: 0.7241 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 445/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.7111 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5004 - val_loss: 0.7255 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 446/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7119 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4859 - val_loss: 0.7243 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 447/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.7112 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4735 - val_loss: 0.7249 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 448/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.7109 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4645 - val_loss: 0.7249 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 449/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.7114 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4596 - val_loss: 0.7244 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 450/500\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, Y_train, validation_data=(X_dev, Y_dev))\n",
    "\n",
    "# tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Results of the tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tuned model 0\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.4399 - tp: 208.0000 - fp: 58.0000 - tn: 386.0000 - fn: 60.0000 - accuracy: 0.8343 - precision: 0.7820 - recall: 0.7761 - auc: 0.8806\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 111us/sample - loss: 0.4701 - tp: 61.0000 - fp: 16.0000 - tn: 89.0000 - fn: 13.0000 - accuracy: 0.8380 - precision: 0.7922 - recall: 0.8243 - auc: 0.8954\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 48)                816       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 3,473\n",
      "Trainable params: 3,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 3, 'dense_units_0': 16, 'dense_activation_0': 'relu', 'l1_0': 0.001, 'l2_0': 0.1, 'dropout_0': 0.30000000000000004, 'dense_units_1': 48, 'dense_activation_1': 'tanh', 'l1_1': 0.0, 'l2_1': 0.001, 'dropout_1': 0.3500000000000001, 'dense_units_2': 48, 'dense_activation_2': 'tanh', 'l1_2': 0.0, 'l2_2': 0.001, 'dropout_2': 0.45000000000000007, 'learning_rate': 0.001, 'optimizer': 'adam', 'epoch_number': 600, 'dense_units_3': 56, 'dense_activation_3': 'tanh', 'l1_3': 0.01, 'l2_3': 0.001, 'dropout_3': 0.40000000000000013, 'dense_units_4': 8, 'dense_activation_4': 'tanh', 'l1_4': 0.0, 'l2_4': 0.001, 'dropout_4': 0.3500000000000001, 'dense_units_5': 8, 'dense_activation_5': 'relu', 'l1_5': 1e-05, 'l2_5': 0.1, 'dropout_5': 0.40000000000000013, 'dense_units_6': 56, 'dense_activation_6': 'tanh', 'l1_6': 0.0, 'l2_6': 0.1, 'dropout_6': 0.45000000000000007}\n",
      "\n",
      "\n",
      "Tuned model 1\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.4161 - tp: 201.0000 - fp: 30.0000 - tn: 414.0000 - fn: 67.0000 - accuracy: 0.8638 - precision: 0.8701 - recall: 0.7500 - auc: 0.8893\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 115us/sample - loss: 0.4609 - tp: 56.0000 - fp: 12.0000 - tn: 93.0000 - fn: 18.0000 - accuracy: 0.8324 - precision: 0.8235 - recall: 0.7568 - auc: 0.9031\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                640       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 328       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,617\n",
      "Trainable params: 2,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 3, 'dense_units_0': 40, 'dense_activation_0': 'relu', 'l1_0': 0.0001, 'l2_0': 0.001, 'dropout_0': 0.15, 'dense_units_1': 40, 'dense_activation_1': 'relu', 'l1_1': 0.001, 'l2_1': 0.01, 'dropout_1': 0.30000000000000004, 'dense_units_2': 8, 'dense_activation_2': 'relu', 'l1_2': 1e-05, 'l2_2': 0.001, 'dropout_2': 0.45000000000000007, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'epoch_number': 600, 'dense_units_3': 48, 'dense_activation_3': 'relu', 'l1_3': 1e-05, 'l2_3': 0.001, 'dropout_3': 0.45000000000000007, 'dense_units_4': 8, 'dense_activation_4': 'relu', 'l1_4': 0.01, 'l2_4': 0.01, 'dropout_4': 0.40000000000000013, 'dense_units_5': 32, 'dense_activation_5': 'relu', 'l1_5': 1e-05, 'l2_5': 0.01, 'dropout_5': 0.30000000000000004, 'dense_units_6': 8, 'dense_activation_6': 'relu', 'l1_6': 0.01, 'l2_6': 0.01, 'dropout_6': 0.45000000000000007}\n",
      "\n",
      "\n",
      "Tuned model 2\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.3994 - tp: 200.0000 - fp: 35.0000 - tn: 409.0000 - fn: 68.0000 - accuracy: 0.8553 - precision: 0.8511 - recall: 0.7463 - auc: 0.8873\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 109us/sample - loss: 0.4361 - tp: 56.0000 - fp: 13.0000 - tn: 92.0000 - fn: 18.0000 - accuracy: 0.8268 - precision: 0.8116 - recall: 0.7568 - auc: 0.9039\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 56)                896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 57        \n",
      "=================================================================\n",
      "Total params: 4,145\n",
      "Trainable params: 4,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 2, 'dense_units_0': 56, 'dense_activation_0': 'relu', 'l1_0': 0.0, 'l2_0': 0.01, 'dropout_0': 0.2, 'dense_units_1': 56, 'dense_activation_1': 'relu', 'l1_1': 1e-05, 'l2_1': 0.01, 'dropout_1': 0.2, 'dense_units_2': 24, 'dense_activation_2': 'relu', 'l1_2': 0.0, 'l2_2': 0.01, 'dropout_2': 0.45000000000000007, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'epoch_number': 600, 'dense_units_3': 32, 'dense_activation_3': 'tanh', 'l1_3': 0.01, 'l2_3': 0.1, 'dropout_3': 0.2, 'dense_units_4': 56, 'dense_activation_4': 'tanh', 'l1_4': 0.0001, 'l2_4': 0.01, 'dropout_4': 0.40000000000000013, 'dense_units_5': 40, 'dense_activation_5': 'relu', 'l1_5': 0.0, 'l2_5': 0.001, 'dropout_5': 0.40000000000000013, 'dense_units_6': 40, 'dense_activation_6': 'tanh', 'l1_6': 0.0, 'l2_6': 0.001, 'dropout_6': 0.5000000000000001}\n",
      "\n",
      "\n",
      "Tuned model 3\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 2ms/sample - loss: 0.4510 - tp: 198.0000 - fp: 34.0000 - tn: 410.0000 - fn: 70.0000 - accuracy: 0.8539 - precision: 0.8534 - recall: 0.7388 - auc: 0.8833\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 123us/sample - loss: 0.5055 - tp: 56.0000 - fp: 13.0000 - tn: 92.0000 - fn: 18.0000 - accuracy: 0.8268 - precision: 0.8116 - recall: 0.7568 - auc: 0.8961\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 56)                896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 456       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 48)                432       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                784       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,385\n",
      "Trainable params: 3,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 6, 'dense_units_0': 56, 'dense_activation_0': 'relu', 'l1_0': 0.0, 'l2_0': 0.01, 'dropout_0': 0.25, 'dense_units_1': 8, 'dense_activation_1': 'relu', 'l1_1': 1e-05, 'l2_1': 0.001, 'dropout_1': 0.5000000000000001, 'dense_units_2': 48, 'dense_activation_2': 'tanh', 'l1_2': 1e-05, 'l2_2': 0.01, 'dropout_2': 0.3500000000000001, 'learning_rate': 0.001, 'optimizer': 'adam', 'epoch_number': 600, 'dense_units_3': 16, 'dense_activation_3': 'relu', 'l1_3': 0.01, 'l2_3': 0.01, 'dropout_3': 0.2, 'dense_units_4': 32, 'dense_activation_4': 'tanh', 'l1_4': 1e-05, 'l2_4': 0.001, 'dropout_4': 0.15, 'dense_units_5': 8, 'dense_activation_5': 'tanh', 'l1_5': 1e-05, 'l2_5': 0.001, 'dropout_5': 0.5000000000000001, 'dense_units_6': 32, 'dense_activation_6': 'tanh', 'l1_6': 0.01, 'l2_6': 0.1, 'dropout_6': 0.3500000000000001}\n",
      "\n",
      "\n",
      "Tuned model 4\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 2ms/sample - loss: 0.4661 - tp: 197.0000 - fp: 39.0000 - tn: 405.0000 - fn: 71.0000 - accuracy: 0.8455 - precision: 0.8347 - recall: 0.7351 - auc: 0.8748\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 112us/sample - loss: 0.4964 - tp: 56.0000 - fp: 13.0000 - tn: 92.0000 - fn: 18.0000 - accuracy: 0.8268 - precision: 0.8116 - recall: 0.7568 - auc: 0.8972\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                1320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 328       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 56)                504       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 48)                2736      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 5,449\n",
      "Trainable params: 5,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 5, 'dense_units_0': 32, 'dense_activation_0': 'tanh', 'l1_0': 0.0, 'l2_0': 0.001, 'dropout_0': 0.30000000000000004, 'dense_units_1': 40, 'dense_activation_1': 'tanh', 'l1_1': 1e-05, 'l2_1': 0.001, 'dropout_1': 0.3500000000000001, 'dense_units_2': 8, 'dense_activation_2': 'relu', 'l1_2': 0.01, 'l2_2': 0.001, 'dropout_2': 0.15, 'learning_rate': 0.001, 'optimizer': 'adam', 'epoch_number': 600, 'dense_units_3': 56, 'dense_activation_3': 'relu', 'l1_3': 0.0001, 'l2_3': 0.001, 'dropout_3': 0.3500000000000001, 'dense_units_4': 48, 'dense_activation_4': 'relu', 'l1_4': 0.001, 'l2_4': 0.1, 'dropout_4': 0.45000000000000007, 'dense_units_5': 48, 'dense_activation_5': 'tanh', 'l1_5': 1e-05, 'l2_5': 0.1, 'dropout_5': 0.15, 'dense_units_6': 16, 'dense_activation_6': 'tanh', 'l1_6': 0.01, 'l2_6': 0.1, 'dropout_6': 0.45000000000000007}\n",
      "\n",
      "\n",
      "Tuned model 5\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.4419 - tp: 202.0000 - fp: 39.0000 - tn: 405.0000 - fn: 66.0000 - accuracy: 0.8525 - precision: 0.8382 - recall: 0.7537 - auc: 0.8818\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 115us/sample - loss: 0.4778 - tp: 56.0000 - fp: 13.0000 - tn: 92.0000 - fn: 18.0000 - accuracy: 0.8268 - precision: 0.8116 - recall: 0.7568 - auc: 0.9023\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 48)                768       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                1176      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 48)                1200      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 5,145\n",
      "Trainable params: 5,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 4, 'dense_units_0': 48, 'dense_activation_0': 'relu', 'l1_0': 0.001, 'l2_0': 0.001, 'dropout_0': 0.5000000000000001, 'dense_units_1': 24, 'dense_activation_1': 'relu', 'l1_1': 0.0001, 'l2_1': 0.001, 'dropout_1': 0.40000000000000013, 'dense_units_2': 48, 'dense_activation_2': 'relu', 'l1_2': 0.0001, 'l2_2': 0.001, 'dropout_2': 0.30000000000000004, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'epoch_number': 600, 'dense_units_3': 40, 'dense_activation_3': 'relu', 'l1_3': 0.001, 'l2_3': 0.001, 'dropout_3': 0.15, 'dense_units_4': 16, 'dense_activation_4': 'relu', 'l1_4': 0.001, 'l2_4': 0.01, 'dropout_4': 0.2, 'dense_units_5': 40, 'dense_activation_5': 'relu', 'l1_5': 1e-05, 'l2_5': 0.001, 'dropout_5': 0.5000000000000001, 'dense_units_6': 56, 'dense_activation_6': 'tanh', 'l1_6': 0.0, 'l2_6': 0.001, 'dropout_6': 0.45000000000000007}\n",
      "\n",
      "\n",
      "Tuned model 6\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.4213 - tp: 200.0000 - fp: 33.0000 - tn: 411.0000 - fn: 68.0000 - accuracy: 0.8581 - precision: 0.8584 - recall: 0.7463 - auc: 0.8895\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 117us/sample - loss: 0.4716 - tp: 56.0000 - fp: 13.0000 - tn: 92.0000 - fn: 18.0000 - accuracy: 0.8268 - precision: 0.8116 - recall: 0.7568 - auc: 0.9044\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                792       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 56)                1400      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 57        \n",
      "=================================================================\n",
      "Total params: 5,353\n",
      "Trainable params: 5,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 4, 'dense_units_0': 64, 'dense_activation_0': 'relu', 'l1_0': 0.0001, 'l2_0': 0.001, 'dropout_0': 0.40000000000000013, 'dense_units_1': 32, 'dense_activation_1': 'relu', 'l1_1': 0.0, 'l2_1': 0.01, 'dropout_1': 0.40000000000000013, 'dense_units_2': 24, 'dense_activation_2': 'tanh', 'l1_2': 1e-05, 'l2_2': 0.1, 'dropout_2': 0.3500000000000001, 'learning_rate': 0.001, 'optimizer': 'adam', 'epoch_number': 500, 'dense_units_3': 56, 'dense_activation_3': 'tanh', 'l1_3': 1e-05, 'l2_3': 0.001, 'dropout_3': 0.40000000000000013, 'dense_units_4': 56, 'dense_activation_4': 'relu', 'l1_4': 0.0, 'l2_4': 0.1, 'dropout_4': 0.25, 'dense_units_5': 56, 'dense_activation_5': 'tanh', 'l1_5': 0.001, 'l2_5': 0.01, 'dropout_5': 0.5000000000000001, 'dense_units_6': 32, 'dense_activation_6': 'tanh', 'l1_6': 0.0, 'l2_6': 0.001, 'dropout_6': 0.2}\n",
      "\n",
      "\n",
      "Tuned model 7\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.4291 - tp: 197.0000 - fp: 41.0000 - tn: 403.0000 - fn: 71.0000 - accuracy: 0.8427 - precision: 0.8277 - recall: 0.7351 - auc: 0.8774\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 110us/sample - loss: 0.4519 - tp: 56.0000 - fp: 14.0000 - tn: 91.0000 - fn: 18.0000 - accuracy: 0.8212 - precision: 0.8000 - recall: 0.7568 - auc: 0.8932\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 4,193\n",
      "Trainable params: 4,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 2, 'dense_units_0': 64, 'dense_activation_0': 'relu', 'l1_0': 0.0, 'l2_0': 0.1, 'dropout_0': 0.5000000000000001, 'dense_units_1': 48, 'dense_activation_1': 'relu', 'l1_1': 0.0001, 'l2_1': 0.001, 'dropout_1': 0.2, 'dense_units_2': 32, 'dense_activation_2': 'tanh', 'l1_2': 0.001, 'l2_2': 0.001, 'dropout_2': 0.40000000000000013, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'epoch_number': 600, 'dense_units_3': 32, 'dense_activation_3': 'tanh', 'l1_3': 0.001, 'l2_3': 0.001, 'dropout_3': 0.25, 'dense_units_4': 8, 'dense_activation_4': 'relu', 'l1_4': 0.01, 'l2_4': 0.001, 'dropout_4': 0.45000000000000007, 'dense_units_5': 40, 'dense_activation_5': 'relu', 'l1_5': 1e-05, 'l2_5': 0.001, 'dropout_5': 0.2, 'dense_units_6': 48, 'dense_activation_6': 'relu', 'l1_6': 1e-05, 'l2_6': 0.1, 'dropout_6': 0.40000000000000013}\n",
      "\n",
      "\n",
      "Tuned model 8\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.4331 - tp: 203.0000 - fp: 46.0000 - tn: 398.0000 - fn: 65.0000 - accuracy: 0.8441 - precision: 0.8153 - recall: 0.7575 - auc: 0.8755\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 114us/sample - loss: 0.4556 - tp: 56.0000 - fp: 14.0000 - tn: 91.0000 - fn: 18.0000 - accuracy: 0.8212 - precision: 0.8000 - recall: 0.7568 - auc: 0.8926\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,697\n",
      "Trainable params: 3,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 4, 'dense_units_0': 64, 'dense_activation_0': 'tanh', 'l1_0': 0.0, 'l2_0': 0.01, 'dropout_0': 0.25, 'dense_units_1': 16, 'dense_activation_1': 'tanh', 'l1_1': 0.0001, 'l2_1': 0.001, 'dropout_1': 0.15, 'dense_units_2': 32, 'dense_activation_2': 'tanh', 'l1_2': 0.0, 'l2_2': 0.001, 'dropout_2': 0.3500000000000001, 'learning_rate': 0.001, 'optimizer': 'adam', 'epoch_number': 500, 'dense_units_3': 32, 'dense_activation_3': 'relu', 'l1_3': 0.0001, 'l2_3': 0.01, 'dropout_3': 0.2, 'dense_units_4': 24, 'dense_activation_4': 'tanh', 'l1_4': 1e-05, 'l2_4': 0.1, 'dropout_4': 0.30000000000000004, 'dense_units_5': 16, 'dense_activation_5': 'tanh', 'l1_5': 0.001, 'l2_5': 0.001, 'dropout_5': 0.40000000000000013, 'dense_units_6': 24, 'dense_activation_6': 'tanh', 'l1_6': 0.01, 'l2_6': 0.01, 'dropout_6': 0.45000000000000007}\n",
      "\n",
      "\n",
      "Tuned model 9\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 2ms/sample - loss: 0.5929 - tp: 200.0000 - fp: 50.0000 - tn: 394.0000 - fn: 68.0000 - accuracy: 0.8343 - precision: 0.8000 - recall: 0.7463 - auc: 0.8520\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 119us/sample - loss: 0.6387 - tp: 57.0000 - fp: 15.0000 - tn: 90.0000 - fn: 17.0000 - accuracy: 0.8212 - precision: 0.7917 - recall: 0.7703 - auc: 0.8468\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 56)                952       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1824      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 56)                1848      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                912       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 48)                816       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 6,657\n",
      "Trainable params: 6,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 6, 'dense_units_0': 16, 'dense_activation_0': 'relu', 'l1_0': 1e-05, 'l2_0': 0.001, 'dropout_0': 0.2, 'dense_units_1': 56, 'dense_activation_1': 'tanh', 'l1_1': 0.001, 'l2_1': 0.001, 'dropout_1': 0.2, 'dense_units_2': 32, 'dense_activation_2': 'tanh', 'l1_2': 0.01, 'l2_2': 0.001, 'dropout_2': 0.2, 'learning_rate': 0.01, 'optimizer': 'adam', 'epoch_number': 600, 'dense_units_3': 56, 'dense_activation_3': 'tanh', 'l1_3': 1e-05, 'l2_3': 0.01, 'dropout_3': 0.3500000000000001, 'dense_units_4': 16, 'dense_activation_4': 'relu', 'l1_4': 0.0001, 'l2_4': 0.001, 'dropout_4': 0.25, 'dense_units_5': 48, 'dense_activation_5': 'relu', 'l1_5': 1e-05, 'l2_5': 0.1, 'dropout_5': 0.45000000000000007, 'dense_units_6': 56, 'dense_activation_6': 'tanh', 'l1_6': 0.01, 'l2_6': 0.001, 'dropout_6': 0.30000000000000004}\n"
     ]
    }
   ],
   "source": [
    "NUM_TOP_MODELS = min(10, MAX_TRIALS)\n",
    "\n",
    "top_models = tuner.get_best_models(num_models=NUM_TOP_MODELS)\n",
    "top_hyperparameters = tuner.get_best_hyperparameters(num_trials=NUM_TOP_MODELS)\n",
    "\n",
    "for exp_id in range(NUM_TOP_MODELS):\n",
    "    print(f\"\\n\\nTuned model {exp_id}\\n\\n\")\n",
    "    cur_model = top_models[exp_id]\n",
    "    \n",
    "    print(\"Tuned train:\")\n",
    "    evaluation_tuned_train = cur_model.evaluate(X_train, Y_train)\n",
    "    # draw_confusion_matrix(evaluation_tuned_train, f\"tuned train {exp_id}\")\n",
    "\n",
    "    print(\"Tuned dev:\")\n",
    "    evaluation_tuned_dev = cur_model.evaluate(X_dev, Y_dev)\n",
    "    # draw_confusion_matrix(evaluation_tuned_dev, f\"tuned dev {exp_id}\")\n",
    "\n",
    "    print(\"Model summary\")\n",
    "    cur_model.summary()\n",
    "    \n",
    "    print(\"Hyperparameters\")\n",
    "    print(top_hyperparameters[exp_id].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Predict with the Tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl_tuned_0_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1\n",
      " 1 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 1 1 1 1 1 1 0 1 0 0 1]\n",
      "dl_tuned_1_submission:\n",
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1]\n",
      "dl_tuned_2_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1]\n",
      "dl_tuned_3_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1]\n",
      "dl_tuned_4_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1]\n",
      "dl_tuned_5_submission:\n",
      "[0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 1 1 0 1 1 1 0 1 0 0 1]\n",
      "dl_tuned_6_submission:\n",
      "[0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1]\n",
      "dl_tuned_7_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1]\n",
      "dl_tuned_8_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1]\n",
      "dl_tuned_9_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "for exp_id in range(NUM_TOP_MODELS):\n",
    "    store_predictions(top_models[exp_id], f\"dl_tuned_{exp_id}_submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
