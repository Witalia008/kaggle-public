{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONHASHSEED=0\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONHASHSEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\r\n",
      "  Downloading pip-20.1.1-py2.py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 4.8 MB/s \r\n",
      "\u001b[?25hInstalling collected packages: pip\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 20.1\r\n",
      "    Uninstalling pip-20.1:\r\n",
      "      Successfully uninstalled pip-20.1\r\n",
      "Successfully installed pip-20.1.1\r\n",
      "Collecting keras-tuner\r\n",
      "  Downloading keras-tuner-1.0.1.tar.gz (54 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 54 kB 1.3 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (1.18.1)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.8.7)\r\n",
      "Collecting terminaltables\r\n",
      "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (4.45.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (2.23.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (1.4.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.22.2.post1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (2020.4.5.1)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (2.9)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (1.24.3)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (3.0.4)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->keras-tuner) (0.14.1)\r\n",
      "Building wheels for collected packages: keras-tuner, terminaltables\r\n",
      "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-py3-none-any.whl size=73198 sha256=d94b2641f3f778ed5193648fd24928147f47085054f478c502ce9bf740a67446\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/cf/2f/1a1749d3a3650fac3305a8d7f9237b6de7c41068e2f8520ca2\r\n",
      "  Building wheel for terminaltables (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=4c75eb01332f59d7628bfd7139e99520fae1794beab0c1c7c3a117b8a502fcaa\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\r\n",
      "Successfully built keras-tuner terminaltables\r\n",
      "Installing collected packages: terminaltables, keras-tuner\r\n",
      "Successfully installed keras-tuner-1.0.1 terminaltables-3.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# To display all the columns from left to right without breaking into next line.\n",
    "pd.set_option(\"display.width\", 1500)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define seed to reprodicibility of random generation\n",
    "SEED = 42\n",
    "\n",
    "DEV_SPLIT=0.2\n",
    "\n",
    "# MODE = \"DEV\"\n",
    "MODE = \"EVAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as python_random\n",
    "\n",
    "# Make sure Keras produces reproducible results.\n",
    "\n",
    "np.random.seed(SEED)\n",
    "python_random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print(physical_devices)\n",
    "for device in (physical_devices or []):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Read data and extract usable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n",
      "(891,)\n",
      "(418, 9)\n"
     ]
    }
   ],
   "source": [
    "features = \"Pclass Sex SibSp Parch Fare Embarked Name Cabin Age\".split()\n",
    "\n",
    "X_train_init = train_data[features]\n",
    "Y_train_init = train_data.Survived\n",
    "\n",
    "print(X_train_init.shape)\n",
    "print(Y_train_init.shape)\n",
    "\n",
    "X_test_init = test_data[features]\n",
    "\n",
    "print(X_test_init.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Split into train/dev sets\n",
    "## Needs to be done before pre-processing to avoid test-train contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 9) (712,)\n",
      "(179, 9) (179,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# if MODE == \"DEV\":\n",
    "X_train_unproc, X_dev_unproc, Y_train_unproc, Y_dev_unproc = train_test_split(X_train_init, Y_train_init, test_size=DEV_SPLIT, random_state=SEED)\n",
    "\n",
    "print(X_train_unproc.shape, Y_train_unproc.shape)\n",
    "print(X_dev_unproc.shape, Y_dev_unproc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Data observations\n",
    "*Have NaNs:* Age, Fare (some zeros, nans too), Cabin, Embarked\n",
    "*NOTE:* maybe need to approximate missing values using some other technique, like an additional model?\n",
    "\n",
    "* (+) Pclass:\n",
    "  * 1 - 3 number, 1 being the highest\n",
    "  * Range: 1-3\n",
    "  * Current approach: convert to one-hot.\n",
    "  * Previous approaches:\n",
    "      * normalize by 3.\n",
    "* (+) Name:\n",
    "  * has person's title, which could be used (Mr, Ms, Mrs, etc.)\n",
    "  * From title, can infer marital status?\n",
    "  * Current approach: extract titles, replace infrequent ones with \"Others\", convert them to one-hot, and calculate 'Married' based on title (1 - married (Mr, Mrs), -1 - unmarried (Miss, Master), 0 - unknown (other titles))\n",
    "  * Potential improvements: use more titles for getting 'married'; use 'maiden name' in calculation of 'married'; use 'nickname' somehow?\n",
    "* (+) Sex:\n",
    "  * Either male or female\n",
    "  * male: 65%, female: 35%\n",
    "  * Current approach: convert to one-hot.\n",
    "  * Potential improvements: use 1 and -1 for sexes?\n",
    "* (+) Age:\n",
    "  * has fractions if approximated. Has missing values.\n",
    "  * Range: 0.42-80\n",
    "  * Current approach: fill NaN with average in group-by Pclass-Sex, but create a column that identifies missing values. Also, normalize by 80.\n",
    "  * Potential improvements: have a better approximation of age. Convert to age categories?\n",
    "* (+) SibSp:\n",
    "  * how many siblings or spouses on board.\n",
    "  * Range: 0-8\n",
    "  * Current approach: Add to 'Family'.\n",
    "  * Previous approaches:\n",
    "    * normalize by 8.\n",
    "* (+) Parch:\n",
    "  * How many parents/children. (can be 0 for babies, if with nannies)\n",
    "  * Range: 0-6\n",
    "  * Current approach: Add to 'Family'\n",
    "  * Previous approachesL\n",
    "    * normalize by 6.\n",
    "* Ticket:\n",
    "  * A number with some optional letters (which can have some meaning?).\n",
    "  * Has repetitions (maybe for people travelling together).\n",
    "* (+) Fare:\n",
    "  * can have zeros (what do they mean?). Can have omitted (just one in test).\n",
    "  * Range: 0-512.3292\n",
    "  * Current approach: fill nan with mean, normalize by 512.\n",
    "  * Potential improvements: most fare is <= 30 USD, so maybe use fare categories.\n",
    "* (+) Cabin:\n",
    "  * has a lot of omitted values (78%). Can have multiple values (probably for families?).\n",
    "  * One value is a letter with a number. (both probably have meaning and impact?)\n",
    "  * Current approach: convert to one-hot (based on letter), include a 'nan' column for those that are missing values. Create a column for cabin number, and a column to identify missing numbers.\n",
    "  * Potential improvements: maybe cabin number itself doesn't mean much? Also, maybe need to deal with missing values in a different way? Also, maybe deal with multiple values better?\n",
    "* (+) Embarked:\n",
    "  * Either of 3 letters (with different frequency). Has just a few omitted.\n",
    "  * S - 72/65%, C - 19/24%, Q - 9/11%\n",
    "  * Current approach: convert to one-hot matrix (fill 2 missing with mode)\n",
    "  * Potential improvements: somehow take into the account different distribution of embarkation city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X):\n",
    "    import re\n",
    "    \n",
    "    titles = ['Mr', 'Mrs', 'Miss', 'Master', 'Ms', 'Don', 'Rev', 'Dr', 'Mme', 'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess', 'Jonkheer', 'Dona']\n",
    "    \n",
    "    X = X.copy()\n",
    "    \n",
    "    # === Get X - the features. ===\n",
    "\n",
    "    # == Post-process data ==\n",
    "\n",
    "#     if \"SibSp\" in X:\n",
    "#         X.SibSp = X.SibSp.divide(8)\n",
    "\n",
    "#     if \"Parch\" in X:\n",
    "#         X.Parch = X.Parch.divide(6)\n",
    "        \n",
    "    if \"Parch\" in X and \"SibSp\" in X:\n",
    "        X[\"Family\"] = X.Parch + X.SibSp\n",
    "#         X.Family = X.Family.divide(14)\n",
    "        X = X.drop(columns=\"Parch SibSp\".split())\n",
    "\n",
    "    if \"Fare\" in X:\n",
    "        # Since only a few would miss 'fare' value, it's okay to fill with average.\n",
    "        X.Fare = X.Fare.fillna(X.Fare.mean())\n",
    "        \n",
    "        X.Fare = np.where(X.Fare < 50, 1, 2)\n",
    "        \n",
    "#         X.Fare = X.Fare.divide(512)\n",
    "\n",
    "    if \"Embarked\" in X:\n",
    "        X.Embarked = X.Embarked.fillna(X.Embarked.mode()[0])\n",
    "        X.Embarked = X.Embarked.astype(pd.api.types.CategoricalDtype(categories=\"C Q S\".split()))\n",
    "        X = pd.get_dummies(X, columns=[\"Embarked\"])\n",
    "\n",
    "    if \"Name\" in X:\n",
    "        X[\"Title\"] = X.Name.apply(lambda name: re.search(\", ([\\w ]+).\", name).group(1))\n",
    "\n",
    "        # Try to see if the person is married (1), or not (-1), or unknown (0).\n",
    "        X[\"Married\"] = X.Title.apply(lambda title: 1 if title in \"Mrs Mr\".split() else -1 if title in \"Miss Master\".split() else 0)\n",
    "\n",
    "        # Get dummies for title\n",
    "        \n",
    "        # Include all possible values, even those not present in current dataset.\n",
    "#         X.Title = X.Title.astype(pd.api.types.CategoricalDtype(categories=titles))\n",
    "        \n",
    "        # Titles that are rare are converted to 'Others'\n",
    "        important_titles = ['Mr', 'Mrs', 'Miss', 'Master']\n",
    "        X.Title = X.Title.apply(lambda title: title if title in important_titles else \"Others\")\n",
    "        \n",
    "        X = pd.get_dummies(X, columns=[\"Title\"])\n",
    "        \n",
    "        # We don't need the name itself.\n",
    "        X = X.drop(columns=[\"Name\"])\n",
    "        \n",
    "    if \"Cabin\" in X:\n",
    "        X[\"Cabin_Missing\"] = np.where(X.Cabin.isnull(), 1, 0)\n",
    "        X.Cabin = X.Cabin.fillna(\"-\")\n",
    "        \n",
    "#         X[\"Cabin_Number\"] = X.Cabin.apply(lambda cabin: int(re.search(\"\\w(\\d+)\", cabin).group(1)) if len(cabin) > 1 else 0)\n",
    "#         # Do some sort of normalization.\n",
    "#         X.Cabin_Number = X.Cabin_Number.divide(200)\n",
    "#         X[\"Cabin_Number_Missing\"] = np.where(X.Cabin_Number == 0, 1, 0)\n",
    "        \n",
    "        X.Cabin = X.Cabin.apply(lambda cabin: cabin[:1])\n",
    "        \n",
    "        # Convert to one-hot\n",
    "#         X.Cabin = X.Cabin.astype(pd.api.types.CategoricalDtype(categories=list(\"ABCDEFGT\")))\n",
    "#         X = pd.get_dummies(X, columns=[\"Cabin\"], dummy_na=True)\n",
    "\n",
    "        # Convert to numbers with T beeing the lowest deck and S - the highest (sun deck).\n",
    "        X[\"Deck_Level\"] = X.Cabin.apply(lambda cabin: \"SABCDEFGT\".find(cabin[0]))\n",
    "        X = X.drop(columns=[\"Cabin\"])\n",
    "\n",
    "    if \"Age\" in X:\n",
    "        X[\"Age_Missing\"] = np.where(X.Age.isnull(), 1, 0)\n",
    "\n",
    "        # No need to skip 'nan' for Age when calculating mean, as Pandas does that automatically.\n",
    "        # 'transform' will go through each group, and fill its nan values with its mean value.\n",
    "        # Then, all that will be aggregated back into the column, thus replacing nan values with group's mean.\n",
    "        X[\"Age\"] = X.groupby(\"Pclass Sex\".split())[\"Age\"].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "#         X.Age = X.Age.divide(80)\n",
    "\n",
    "        # Convert age to categories 1 - child, 2 - young, 3 - older, 4 - senile\n",
    "        X.Age = pd.cut(X.Age, bins=[0, 16, 30, 50, 80], labels=False) + 1\n",
    "        \n",
    "    # Needs to be after 'Age', since age is using original Sex column.\n",
    "    if \"Sex\" in X:\n",
    "        X.Sex = X.Sex.astype(pd.api.types.CategoricalDtype(categories=\"male female\".split()))\n",
    "        X = pd.get_dummies(X, columns=[\"Sex\"])\n",
    "\n",
    "    if \"Pclass\" in X:\n",
    "        X = pd.get_dummies(X, columns=[\"Pclass\"])\n",
    "        # Do not normalize small numbers\n",
    "#         X.Pclass = X.Pclass.divide(3)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_clean(X):\n",
    "    import re\n",
    "\n",
    "    important_titles = [\"Mr\", \"Mrs\", \"Miss\", \"Master\"]\n",
    "    \n",
    "    X = X.copy()\n",
    "    \n",
    "    # Remember missing values\n",
    "    for col in \"Age\".split():\n",
    "        X[f\"{col}_Missing\"] = np.where(X[col].isnull(), 1, 0)\n",
    "        \n",
    "    if \"Parch\" in X and \"SibSp\" in X:\n",
    "        X[\"Family\"] = X.Parch + X.SibSp\n",
    "\n",
    "    if \"Fare\" in X:\n",
    "        X.Fare = X.Fare.fillna(X.Fare.mean())\n",
    "        X.Fare = pd.cut(X.Fare, bins=[-1, 15, 30, 50, 70, 100, 600], labels=False) + 1\n",
    "\n",
    "    if \"Embarked\" in X:\n",
    "        X.Embarked = X.Embarked.fillna(X.Embarked.mode()[0])\n",
    "        X.Embarked = X.Embarked.astype(pd.api.types.CategoricalDtype(categories=\"C Q S\".split()))\n",
    "\n",
    "    if \"Name\" in X:\n",
    "        X[\"Title\"] = X.Name.apply(lambda name: re.search(\", ([\\w ]+).\", name).group(1))\n",
    "\n",
    "        X.Title = X.Title.apply(lambda title: title if title in important_titles else \"Others\")\n",
    "\n",
    "#         X[\"Married\"] = X.Title.apply(lambda title: 1 if title in \"Mrs Mr\".split() else -1 if title in \"Miss Master\".split() else 0)\n",
    "        \n",
    "#     if \"Cabin\" in X:   \n",
    "#         X[\"Deck_Level\"] = X.Cabin.fillna(\"-\").apply(lambda cabin: \"SABCDEFGT\".find(cabin[0]))\n",
    "\n",
    "    if \"Age\" in X:\n",
    "        X[\"Age\"] = X.groupby(\"Pclass Sex\".split())[\"Age\"].transform(lambda x: x.fillna(x.mean()))\n",
    "        X.Age = pd.cut(X.Age, bins=[0, 16, 30, 50, 80], labels=False) + 1\n",
    "        \n",
    "    X = X.drop(columns=\"Name Cabin Parch SibSp\".split())\n",
    "        \n",
    "    X = pd.get_dummies(X, columns=\"Sex Embarked Title\".split())\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "     Pclass  Fare  Age  Age_Missing  Family  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Others\n",
      "331       1     2    3            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "733       2     1    2            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "382       3     1    3            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "704       3     1    2            0       1           0         1           0           0           1             0           0         1          0             0\n",
      "813       3     3    1            0       6           1         0           0           0           1             0           1         0          0             0\n",
      "Dev data:\n",
      "     Pclass  Fare  Age  Age_Missing  Family  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Others\n",
      "709       3     2    2            1       2           0         1           1           0           0             1           0         0          0             0\n",
      "439       2     1    3            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "840       3     1    2            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "720       2     3    1            0       1           1         0           0           0           1             0           1         0          0             0\n",
      "39        3     1    1            0       1           1         0           1           0           0             0           1         0          0             0\n",
      "Test data:\n",
      "   Pclass  Fare  Age  Age_Missing  Family  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Others\n",
      "0       3     1    3            0       0           0         1           0           1           0             0           0         1          0             0\n",
      "1       3     1    3            0       1           1         0           0           0           1             0           0         0          1             0\n",
      "2       2     1    4            0       0           0         1           0           1           0             0           0         1          0             0\n",
      "3       3     1    2            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "4       3     1    2            0       2           1         0           0           0           1             0           0         0          1             0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\")\n",
    "X_train = prepare_data_clean(X_train_unproc)\n",
    "Y_train = Y_train_unproc\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"Dev data:\")\n",
    "X_dev = prepare_data_clean(X_dev_unproc)\n",
    "Y_dev = Y_dev_unproc\n",
    "print(X_dev.head())\n",
    "\n",
    "print(\"Test data:\")\n",
    "X_test = prepare_data_clean(X_test_init)\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# DL model using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name=\"tp\"),\n",
    "      keras.metrics.FalsePositives(name=\"fp\"),\n",
    "      keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "      keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "      keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "      keras.metrics.Precision(name=\"precision\"),\n",
    "      keras.metrics.Recall(name=\"recall\"),\n",
    "      keras.metrics.AUC(name=\"auc\"),\n",
    "]\n",
    "\n",
    "def get_model(input_size):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(128, input_shape=(input_size,), activation=\"relu\", kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation=\"relu\", kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),\n",
    "        Dense(20, activation=\"relu\", kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.25),\n",
    "        Dense(6, activation=\"tanh\", kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), metrics=METRICS, loss=\"binary_crossentropy\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "died_cnt, survived_cnt = np.bincount(Y_train_init)\n",
    "total_cnt = died_cnt + survived_cnt\n",
    "\n",
    "weight_died = total_cnt / died_cnt / 2\n",
    "weight_survived = total_cnt / survived_cnt / 2\n",
    "\n",
    "class_weights = {0: weight_died, 1: weight_survived}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 4s 5ms/sample - loss: 1.7119 - tp: 71.0000 - fp: 111.0000 - tn: 333.0000 - fn: 197.0000 - accuracy: 0.5674 - precision: 0.3901 - recall: 0.2649 - auc: 0.5337 - val_loss: 1.5482 - val_tp: 57.0000 - val_fp: 44.0000 - val_tn: 61.0000 - val_fn: 17.0000 - val_accuracy: 0.6592 - val_precision: 0.5644 - val_recall: 0.7703 - val_auc: 0.7886\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.4760 - tp: 170.0000 - fp: 164.0000 - tn: 280.0000 - fn: 98.0000 - accuracy: 0.6320 - precision: 0.5090 - recall: 0.6343 - auc: 0.6768 - val_loss: 1.3488 - val_tp: 47.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 27.0000 - val_accuracy: 0.7039 - val_precision: 0.6438 - val_recall: 0.6351 - val_auc: 0.8332\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.2907 - tp: 168.0000 - fp: 100.0000 - tn: 344.0000 - fn: 100.0000 - accuracy: 0.7191 - precision: 0.6269 - recall: 0.6269 - auc: 0.7671 - val_loss: 1.1731 - val_tp: 62.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 12.0000 - val_accuracy: 0.7542 - val_precision: 0.6596 - val_recall: 0.8378 - val_auc: 0.8400\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.1697 - tp: 197.0000 - fp: 127.0000 - tn: 317.0000 - fn: 71.0000 - accuracy: 0.7219 - precision: 0.6080 - recall: 0.7351 - auc: 0.7678 - val_loss: 1.0596 - val_tp: 58.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 16.0000 - val_accuracy: 0.7374 - val_precision: 0.6517 - val_recall: 0.7838 - val_auc: 0.8567\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.0694 - tp: 182.0000 - fp: 96.0000 - tn: 348.0000 - fn: 86.0000 - accuracy: 0.7444 - precision: 0.6547 - recall: 0.6791 - auc: 0.7917 - val_loss: 0.9729 - val_tp: 61.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 13.0000 - val_accuracy: 0.7542 - val_precision: 0.6630 - val_recall: 0.8243 - val_auc: 0.8508\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.9830 - tp: 204.0000 - fp: 109.0000 - tn: 335.0000 - fn: 64.0000 - accuracy: 0.7570 - precision: 0.6518 - recall: 0.7612 - auc: 0.8048 - val_loss: 0.9014 - val_tp: 58.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 16.0000 - val_accuracy: 0.7542 - val_precision: 0.6744 - val_recall: 0.7838 - val_auc: 0.8626\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.8971 - tp: 189.0000 - fp: 72.0000 - tn: 372.0000 - fn: 79.0000 - accuracy: 0.7879 - precision: 0.7241 - recall: 0.7052 - auc: 0.8352 - val_loss: 0.8477 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8678\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.8688 - tp: 203.0000 - fp: 93.0000 - tn: 351.0000 - fn: 65.0000 - accuracy: 0.7781 - precision: 0.6858 - recall: 0.7575 - auc: 0.8158 - val_loss: 0.8053 - val_tp: 54.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 20.0000 - val_accuracy: 0.7765 - val_precision: 0.7297 - val_recall: 0.7297 - val_auc: 0.8720\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.8287 - tp: 195.0000 - fp: 73.0000 - tn: 371.0000 - fn: 73.0000 - accuracy: 0.7949 - precision: 0.7276 - recall: 0.7276 - auc: 0.8188 - val_loss: 0.7716 - val_tp: 62.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 12.0000 - val_accuracy: 0.7709 - val_precision: 0.6813 - val_recall: 0.8378 - val_auc: 0.8643\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7857 - tp: 199.0000 - fp: 90.0000 - tn: 354.0000 - fn: 69.0000 - accuracy: 0.7767 - precision: 0.6886 - recall: 0.7425 - auc: 0.8262 - val_loss: 0.7416 - val_tp: 54.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 20.0000 - val_accuracy: 0.7821 - val_precision: 0.7397 - val_recall: 0.7297 - val_auc: 0.8745\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7550 - tp: 201.0000 - fp: 87.0000 - tn: 357.0000 - fn: 67.0000 - accuracy: 0.7837 - precision: 0.6979 - recall: 0.7500 - auc: 0.8330 - val_loss: 0.7096 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8732\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7437 - tp: 198.0000 - fp: 84.0000 - tn: 360.0000 - fn: 70.0000 - accuracy: 0.7837 - precision: 0.7021 - recall: 0.7388 - auc: 0.8225 - val_loss: 0.6875 - val_tp: 56.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 18.0000 - val_accuracy: 0.7933 - val_precision: 0.7467 - val_recall: 0.7568 - val_auc: 0.8759\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7043 - tp: 208.0000 - fp: 82.0000 - tn: 362.0000 - fn: 60.0000 - accuracy: 0.8006 - precision: 0.7172 - recall: 0.7761 - auc: 0.8422 - val_loss: 0.6708 - val_tp: 56.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 18.0000 - val_accuracy: 0.7877 - val_precision: 0.7368 - val_recall: 0.7568 - val_auc: 0.8790\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6909 - tp: 203.0000 - fp: 78.0000 - tn: 366.0000 - fn: 65.0000 - accuracy: 0.7992 - precision: 0.7224 - recall: 0.7575 - auc: 0.8373 - val_loss: 0.6521 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8760\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6814 - tp: 204.0000 - fp: 80.0000 - tn: 364.0000 - fn: 64.0000 - accuracy: 0.7978 - precision: 0.7183 - recall: 0.7612 - auc: 0.8337 - val_loss: 0.6382 - val_tp: 59.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 15.0000 - val_accuracy: 0.7765 - val_precision: 0.7024 - val_recall: 0.7973 - val_auc: 0.8754\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6816 - tp: 208.0000 - fp: 90.0000 - tn: 354.0000 - fn: 60.0000 - accuracy: 0.7893 - precision: 0.6980 - recall: 0.7761 - auc: 0.8216 - val_loss: 0.6309 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8754\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6630 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8317 - val_loss: 0.6169 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8827\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6501 - tp: 211.0000 - fp: 78.0000 - tn: 366.0000 - fn: 57.0000 - accuracy: 0.8104 - precision: 0.7301 - recall: 0.7873 - auc: 0.8345 - val_loss: 0.6132 - val_tp: 56.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 18.0000 - val_accuracy: 0.7933 - val_precision: 0.7467 - val_recall: 0.7568 - val_auc: 0.8814\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6360 - tp: 198.0000 - fp: 69.0000 - tn: 375.0000 - fn: 70.0000 - accuracy: 0.8048 - precision: 0.7416 - recall: 0.7388 - auc: 0.8378 - val_loss: 0.5992 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8825\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6220 - tp: 209.0000 - fp: 71.0000 - tn: 373.0000 - fn: 59.0000 - accuracy: 0.8174 - precision: 0.7464 - recall: 0.7799 - auc: 0.8431 - val_loss: 0.5893 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8824\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6234 - tp: 201.0000 - fp: 60.0000 - tn: 384.0000 - fn: 67.0000 - accuracy: 0.8216 - precision: 0.7701 - recall: 0.7500 - auc: 0.8353 - val_loss: 0.5883 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8778\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6107 - tp: 211.0000 - fp: 78.0000 - tn: 366.0000 - fn: 57.0000 - accuracy: 0.8104 - precision: 0.7301 - recall: 0.7873 - auc: 0.8407 - val_loss: 0.5839 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8825\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6250 - tp: 203.0000 - fp: 66.0000 - tn: 378.0000 - fn: 65.0000 - accuracy: 0.8160 - precision: 0.7546 - recall: 0.7575 - auc: 0.8277 - val_loss: 0.5822 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8808\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5875 - tp: 203.0000 - fp: 65.0000 - tn: 379.0000 - fn: 65.0000 - accuracy: 0.8174 - precision: 0.7575 - recall: 0.7575 - auc: 0.8546 - val_loss: 0.5686 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8829\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5946 - tp: 205.0000 - fp: 72.0000 - tn: 372.0000 - fn: 63.0000 - accuracy: 0.8104 - precision: 0.7401 - recall: 0.7649 - auc: 0.8465 - val_loss: 0.5626 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8822\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5931 - tp: 204.0000 - fp: 69.0000 - tn: 375.0000 - fn: 64.0000 - accuracy: 0.8132 - precision: 0.7473 - recall: 0.7612 - auc: 0.8434 - val_loss: 0.5601 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8831\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5661 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8581 - val_loss: 0.5534 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8838\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5690 - tp: 205.0000 - fp: 53.0000 - tn: 391.0000 - fn: 63.0000 - accuracy: 0.8371 - precision: 0.7946 - recall: 0.7649 - auc: 0.8580 - val_loss: 0.5532 - val_tp: 61.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 13.0000 - val_accuracy: 0.7821 - val_precision: 0.7011 - val_recall: 0.8243 - val_auc: 0.8804\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5544 - tp: 210.0000 - fp: 86.0000 - tn: 358.0000 - fn: 58.0000 - accuracy: 0.7978 - precision: 0.7095 - recall: 0.7836 - auc: 0.8647 - val_loss: 0.5485 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8867\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5907 - tp: 197.0000 - fp: 69.0000 - tn: 375.0000 - fn: 71.0000 - accuracy: 0.8034 - precision: 0.7406 - recall: 0.7351 - auc: 0.8373 - val_loss: 0.5524 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8794\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5856 - tp: 199.0000 - fp: 64.0000 - tn: 380.0000 - fn: 69.0000 - accuracy: 0.8132 - precision: 0.7567 - recall: 0.7425 - auc: 0.8425 - val_loss: 0.5481 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8832\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.5606 - tp: 205.0000 - fp: 72.0000 - tn: 372.0000 - fn: 63.0000 - accuracy: 0.8104 - precision: 0.7401 - recall: 0.7649 - auc: 0.8519 - val_loss: 0.5417 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8862\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5444 - tp: 204.0000 - fp: 62.0000 - tn: 382.0000 - fn: 64.0000 - accuracy: 0.8230 - precision: 0.7669 - recall: 0.7612 - auc: 0.8681 - val_loss: 0.5395 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8849\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5622 - tp: 207.0000 - fp: 79.0000 - tn: 365.0000 - fn: 61.0000 - accuracy: 0.8034 - precision: 0.7238 - recall: 0.7724 - auc: 0.8517 - val_loss: 0.5361 - val_tp: 63.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 11.0000 - val_accuracy: 0.7821 - val_precision: 0.6923 - val_recall: 0.8514 - val_auc: 0.8793\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.5425 - tp: 210.0000 - fp: 63.0000 - tn: 381.0000 - fn: 58.0000 - accuracy: 0.8301 - precision: 0.7692 - recall: 0.7836 - auc: 0.8607 - val_loss: 0.5332 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8874\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5557 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8558 - val_loss: 0.5374 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8869\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5590 - tp: 204.0000 - fp: 76.0000 - tn: 368.0000 - fn: 64.0000 - accuracy: 0.8034 - precision: 0.7286 - recall: 0.7612 - auc: 0.8545 - val_loss: 0.5308 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8846\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5696 - tp: 198.0000 - fp: 60.0000 - tn: 384.0000 - fn: 70.0000 - accuracy: 0.8174 - precision: 0.7674 - recall: 0.7388 - auc: 0.8390 - val_loss: 0.5448 - val_tp: 65.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 9.0000 - val_accuracy: 0.7709 - val_precision: 0.6701 - val_recall: 0.8784 - val_auc: 0.8773\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5557 - tp: 213.0000 - fp: 73.0000 - tn: 371.0000 - fn: 55.0000 - accuracy: 0.8202 - precision: 0.7448 - recall: 0.7948 - auc: 0.8475 - val_loss: 0.5328 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8833\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5417 - tp: 209.0000 - fp: 66.0000 - tn: 378.0000 - fn: 59.0000 - accuracy: 0.8244 - precision: 0.7600 - recall: 0.7799 - auc: 0.8601 - val_loss: 0.5293 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8851\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5456 - tp: 204.0000 - fp: 61.0000 - tn: 383.0000 - fn: 64.0000 - accuracy: 0.8244 - precision: 0.7698 - recall: 0.7612 - auc: 0.8575 - val_loss: 0.5263 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8855\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5572 - tp: 206.0000 - fp: 76.0000 - tn: 368.0000 - fn: 62.0000 - accuracy: 0.8062 - precision: 0.7305 - recall: 0.7687 - auc: 0.8456 - val_loss: 0.5268 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8864\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5261 - tp: 210.0000 - fp: 63.0000 - tn: 381.0000 - fn: 58.0000 - accuracy: 0.8301 - precision: 0.7692 - recall: 0.7836 - auc: 0.8696 - val_loss: 0.5201 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8894\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5500 - tp: 209.0000 - fp: 63.0000 - tn: 381.0000 - fn: 59.0000 - accuracy: 0.8287 - precision: 0.7684 - recall: 0.7799 - auc: 0.8559 - val_loss: 0.5188 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8874\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5411 - tp: 200.0000 - fp: 67.0000 - tn: 377.0000 - fn: 68.0000 - accuracy: 0.8104 - precision: 0.7491 - recall: 0.7463 - auc: 0.8563 - val_loss: 0.5170 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8866\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5476 - tp: 206.0000 - fp: 69.0000 - tn: 375.0000 - fn: 62.0000 - accuracy: 0.8160 - precision: 0.7491 - recall: 0.7687 - auc: 0.8513 - val_loss: 0.5217 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8869\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5481 - tp: 205.0000 - fp: 72.0000 - tn: 372.0000 - fn: 63.0000 - accuracy: 0.8104 - precision: 0.7401 - recall: 0.7649 - auc: 0.8503 - val_loss: 0.5157 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8902\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5268 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8653 - val_loss: 0.5138 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8884\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5586 - tp: 205.0000 - fp: 73.0000 - tn: 371.0000 - fn: 63.0000 - accuracy: 0.8090 - precision: 0.7374 - recall: 0.7649 - auc: 0.8391 - val_loss: 0.5175 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8869\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5389 - tp: 209.0000 - fp: 60.0000 - tn: 384.0000 - fn: 59.0000 - accuracy: 0.8329 - precision: 0.7770 - recall: 0.7799 - auc: 0.8522 - val_loss: 0.5172 - val_tp: 61.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 13.0000 - val_accuracy: 0.7765 - val_precision: 0.6932 - val_recall: 0.8243 - val_auc: 0.8851\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5479 - tp: 204.0000 - fp: 78.0000 - tn: 366.0000 - fn: 64.0000 - accuracy: 0.8006 - precision: 0.7234 - recall: 0.7612 - auc: 0.8492 - val_loss: 0.5138 - val_tp: 64.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 10.0000 - val_accuracy: 0.7877 - val_precision: 0.6957 - val_recall: 0.8649 - val_auc: 0.8887\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5316 - tp: 201.0000 - fp: 60.0000 - tn: 384.0000 - fn: 67.0000 - accuracy: 0.8216 - precision: 0.7701 - recall: 0.7500 - auc: 0.8599 - val_loss: 0.5159 - val_tp: 64.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 10.0000 - val_accuracy: 0.7709 - val_precision: 0.6737 - val_recall: 0.8649 - val_auc: 0.8871\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5391 - tp: 206.0000 - fp: 72.0000 - tn: 372.0000 - fn: 62.0000 - accuracy: 0.8118 - precision: 0.7410 - recall: 0.7687 - auc: 0.8513 - val_loss: 0.5145 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8860\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5465 - tp: 209.0000 - fp: 78.0000 - tn: 366.0000 - fn: 59.0000 - accuracy: 0.8076 - precision: 0.7282 - recall: 0.7799 - auc: 0.8487 - val_loss: 0.5131 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8919\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5354 - tp: 204.0000 - fp: 71.0000 - tn: 373.0000 - fn: 64.0000 - accuracy: 0.8104 - precision: 0.7418 - recall: 0.7612 - auc: 0.8549 - val_loss: 0.5128 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8927\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5308 - tp: 203.0000 - fp: 57.0000 - tn: 387.0000 - fn: 65.0000 - accuracy: 0.8287 - precision: 0.7808 - recall: 0.7575 - auc: 0.8560 - val_loss: 0.5174 - val_tp: 64.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 10.0000 - val_accuracy: 0.7821 - val_precision: 0.6882 - val_recall: 0.8649 - val_auc: 0.8878\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5403 - tp: 207.0000 - fp: 83.0000 - tn: 361.0000 - fn: 61.0000 - accuracy: 0.7978 - precision: 0.7138 - recall: 0.7724 - auc: 0.8504 - val_loss: 0.5083 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8919\n",
      "Epoch 58/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5357 - tp: 205.0000 - fp: 74.0000 - tn: 370.0000 - fn: 63.0000 - accuracy: 0.8076 - precision: 0.7348 - recall: 0.7649 - auc: 0.8497 - val_loss: 0.5080 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8902\n",
      "Epoch 59/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5311 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8526 - val_loss: 0.5084 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8898\n",
      "Epoch 60/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5429 - tp: 202.0000 - fp: 71.0000 - tn: 373.0000 - fn: 66.0000 - accuracy: 0.8076 - precision: 0.7399 - recall: 0.7537 - auc: 0.8458 - val_loss: 0.5040 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8912\n",
      "Epoch 61/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5214 - tp: 212.0000 - fp: 81.0000 - tn: 363.0000 - fn: 56.0000 - accuracy: 0.8076 - precision: 0.7235 - recall: 0.7910 - auc: 0.8669 - val_loss: 0.5067 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8921\n",
      "Epoch 62/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5371 - tp: 202.0000 - fp: 57.0000 - tn: 387.0000 - fn: 66.0000 - accuracy: 0.8272 - precision: 0.7799 - recall: 0.7537 - auc: 0.8493 - val_loss: 0.5149 - val_tp: 65.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 9.0000 - val_accuracy: 0.7821 - val_precision: 0.6842 - val_recall: 0.8784 - val_auc: 0.8859\n",
      "Epoch 63/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5305 - tp: 205.0000 - fp: 66.0000 - tn: 378.0000 - fn: 63.0000 - accuracy: 0.8188 - precision: 0.7565 - recall: 0.7649 - auc: 0.8569 - val_loss: 0.5024 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8902\n",
      "Epoch 64/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5211 - tp: 198.0000 - fp: 59.0000 - tn: 385.0000 - fn: 70.0000 - accuracy: 0.8188 - precision: 0.7704 - recall: 0.7388 - auc: 0.8637 - val_loss: 0.5022 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8912\n",
      "Epoch 65/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5483 - tp: 209.0000 - fp: 68.0000 - tn: 376.0000 - fn: 59.0000 - accuracy: 0.8216 - precision: 0.7545 - recall: 0.7799 - auc: 0.8403 - val_loss: 0.5010 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8937\n",
      "Epoch 66/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5161 - tp: 212.0000 - fp: 63.0000 - tn: 381.0000 - fn: 56.0000 - accuracy: 0.8329 - precision: 0.7709 - recall: 0.7910 - auc: 0.8672 - val_loss: 0.5014 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8909\n",
      "Epoch 67/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5182 - tp: 203.0000 - fp: 63.0000 - tn: 381.0000 - fn: 65.0000 - accuracy: 0.8202 - precision: 0.7632 - recall: 0.7575 - auc: 0.8626 - val_loss: 0.4937 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8931\n",
      "Epoch 68/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5279 - tp: 207.0000 - fp: 79.0000 - tn: 365.0000 - fn: 61.0000 - accuracy: 0.8034 - precision: 0.7238 - recall: 0.7724 - auc: 0.8559 - val_loss: 0.4981 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8943\n",
      "Epoch 69/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5297 - tp: 205.0000 - fp: 67.0000 - tn: 377.0000 - fn: 63.0000 - accuracy: 0.8174 - precision: 0.7537 - recall: 0.7649 - auc: 0.8530 - val_loss: 0.5027 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8910\n",
      "Epoch 70/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5209 - tp: 208.0000 - fp: 64.0000 - tn: 380.0000 - fn: 60.0000 - accuracy: 0.8258 - precision: 0.7647 - recall: 0.7761 - auc: 0.8540 - val_loss: 0.5020 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8925\n",
      "Epoch 71/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5138 - tp: 208.0000 - fp: 70.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.8174 - precision: 0.7482 - recall: 0.7761 - auc: 0.8655 - val_loss: 0.4962 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8921\n",
      "Epoch 72/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5260 - tp: 208.0000 - fp: 67.0000 - tn: 377.0000 - fn: 60.0000 - accuracy: 0.8216 - precision: 0.7564 - recall: 0.7761 - auc: 0.8555 - val_loss: 0.4993 - val_tp: 61.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 13.0000 - val_accuracy: 0.8156 - val_precision: 0.7531 - val_recall: 0.8243 - val_auc: 0.8916\n",
      "Epoch 73/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5123 - tp: 204.0000 - fp: 63.0000 - tn: 381.0000 - fn: 64.0000 - accuracy: 0.8216 - precision: 0.7640 - recall: 0.7612 - auc: 0.8620 - val_loss: 0.4982 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8949\n",
      "Epoch 74/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5219 - tp: 207.0000 - fp: 76.0000 - tn: 368.0000 - fn: 61.0000 - accuracy: 0.8076 - precision: 0.7314 - recall: 0.7724 - auc: 0.8571 - val_loss: 0.5042 - val_tp: 54.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 20.0000 - val_accuracy: 0.8156 - val_precision: 0.8060 - val_recall: 0.7297 - val_auc: 0.8922\n",
      "Epoch 75/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5363 - tp: 199.0000 - fp: 58.0000 - tn: 386.0000 - fn: 69.0000 - accuracy: 0.8216 - precision: 0.7743 - recall: 0.7425 - auc: 0.8488 - val_loss: 0.4959 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8903\n",
      "Epoch 76/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5157 - tp: 203.0000 - fp: 65.0000 - tn: 379.0000 - fn: 65.0000 - accuracy: 0.8174 - precision: 0.7575 - recall: 0.7575 - auc: 0.8610 - val_loss: 0.4976 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8917\n",
      "Epoch 77/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5157 - tp: 203.0000 - fp: 61.0000 - tn: 383.0000 - fn: 65.0000 - accuracy: 0.8230 - precision: 0.7689 - recall: 0.7575 - auc: 0.8564 - val_loss: 0.4950 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8918\n",
      "Epoch 78/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5194 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8585 - val_loss: 0.4945 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8921\n",
      "Epoch 79/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5202 - tp: 212.0000 - fp: 78.0000 - tn: 366.0000 - fn: 56.0000 - accuracy: 0.8118 - precision: 0.7310 - recall: 0.7910 - auc: 0.8606 - val_loss: 0.5057 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8910\n",
      "Epoch 80/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5308 - tp: 199.0000 - fp: 54.0000 - tn: 390.0000 - fn: 69.0000 - accuracy: 0.8272 - precision: 0.7866 - recall: 0.7425 - auc: 0.8484 - val_loss: 0.4968 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8905\n",
      "Epoch 81/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5130 - tp: 209.0000 - fp: 69.0000 - tn: 375.0000 - fn: 59.0000 - accuracy: 0.8202 - precision: 0.7518 - recall: 0.7799 - auc: 0.8631 - val_loss: 0.4920 - val_tp: 62.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 12.0000 - val_accuracy: 0.8268 - val_precision: 0.7654 - val_recall: 0.8378 - val_auc: 0.8921\n",
      "Epoch 82/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5291 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8500 - val_loss: 0.4996 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8936\n",
      "Epoch 83/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5018 - tp: 209.0000 - fp: 71.0000 - tn: 373.0000 - fn: 59.0000 - accuracy: 0.8174 - precision: 0.7464 - recall: 0.7799 - auc: 0.8747 - val_loss: 0.4893 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8933\n",
      "Epoch 84/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5126 - tp: 210.0000 - fp: 68.0000 - tn: 376.0000 - fn: 58.0000 - accuracy: 0.8230 - precision: 0.7554 - recall: 0.7836 - auc: 0.8647 - val_loss: 0.4930 - val_tp: 62.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 12.0000 - val_accuracy: 0.8436 - val_precision: 0.7949 - val_recall: 0.8378 - val_auc: 0.8914\n",
      "Epoch 85/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4953 - tp: 208.0000 - fp: 63.0000 - tn: 381.0000 - fn: 60.0000 - accuracy: 0.8272 - precision: 0.7675 - recall: 0.7761 - auc: 0.8766 - val_loss: 0.4907 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8939\n",
      "Epoch 86/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5198 - tp: 199.0000 - fp: 61.0000 - tn: 383.0000 - fn: 69.0000 - accuracy: 0.8174 - precision: 0.7654 - recall: 0.7425 - auc: 0.8637 - val_loss: 0.4921 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8937\n",
      "Epoch 87/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5213 - tp: 208.0000 - fp: 76.0000 - tn: 368.0000 - fn: 60.0000 - accuracy: 0.8090 - precision: 0.7324 - recall: 0.7761 - auc: 0.8567 - val_loss: 0.4936 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8943\n",
      "Epoch 88/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5130 - tp: 206.0000 - fp: 66.0000 - tn: 378.0000 - fn: 62.0000 - accuracy: 0.8202 - precision: 0.7574 - recall: 0.7687 - auc: 0.8623 - val_loss: 0.4943 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8940\n",
      "Epoch 89/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5135 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8616 - val_loss: 0.4913 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8930\n",
      "Epoch 90/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5076 - tp: 204.0000 - fp: 52.0000 - tn: 392.0000 - fn: 64.0000 - accuracy: 0.8371 - precision: 0.7969 - recall: 0.7612 - auc: 0.8675 - val_loss: 0.4981 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8939\n",
      "Epoch 91/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5078 - tp: 206.0000 - fp: 70.0000 - tn: 374.0000 - fn: 62.0000 - accuracy: 0.8146 - precision: 0.7464 - recall: 0.7687 - auc: 0.8623 - val_loss: 0.4915 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8950\n",
      "Epoch 92/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5189 - tp: 201.0000 - fp: 57.0000 - tn: 387.0000 - fn: 67.0000 - accuracy: 0.8258 - precision: 0.7791 - recall: 0.7500 - auc: 0.8574 - val_loss: 0.4970 - val_tp: 62.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 12.0000 - val_accuracy: 0.7877 - val_precision: 0.7045 - val_recall: 0.8378 - val_auc: 0.8941\n",
      "Epoch 93/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5124 - tp: 209.0000 - fp: 61.0000 - tn: 383.0000 - fn: 59.0000 - accuracy: 0.8315 - precision: 0.7741 - recall: 0.7799 - auc: 0.8618 - val_loss: 0.4944 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8921\n",
      "Epoch 94/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5138 - tp: 207.0000 - fp: 67.0000 - tn: 377.0000 - fn: 61.0000 - accuracy: 0.8202 - precision: 0.7555 - recall: 0.7724 - auc: 0.8621 - val_loss: 0.5044 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8940\n",
      "Epoch 95/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5227 - tp: 206.0000 - fp: 71.0000 - tn: 373.0000 - fn: 62.0000 - accuracy: 0.8132 - precision: 0.7437 - recall: 0.7687 - auc: 0.8588 - val_loss: 0.4967 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8941\n",
      "Epoch 96/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5131 - tp: 201.0000 - fp: 51.0000 - tn: 393.0000 - fn: 67.0000 - accuracy: 0.8343 - precision: 0.7976 - recall: 0.7500 - auc: 0.8591 - val_loss: 0.4969 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8922\n",
      "Epoch 97/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5090 - tp: 205.0000 - fp: 58.0000 - tn: 386.0000 - fn: 63.0000 - accuracy: 0.8301 - precision: 0.7795 - recall: 0.7649 - auc: 0.8572 - val_loss: 0.4917 - val_tp: 62.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 12.0000 - val_accuracy: 0.8212 - val_precision: 0.7561 - val_recall: 0.8378 - val_auc: 0.8940\n",
      "Epoch 98/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5028 - tp: 215.0000 - fp: 68.0000 - tn: 376.0000 - fn: 53.0000 - accuracy: 0.8301 - precision: 0.7597 - recall: 0.8022 - auc: 0.8708 - val_loss: 0.4993 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8945\n",
      "Epoch 99/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5146 - tp: 198.0000 - fp: 51.0000 - tn: 393.0000 - fn: 70.0000 - accuracy: 0.8301 - precision: 0.7952 - recall: 0.7388 - auc: 0.8581 - val_loss: 0.4938 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8933\n",
      "Epoch 100/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5164 - tp: 206.0000 - fp: 70.0000 - tn: 374.0000 - fn: 62.0000 - accuracy: 0.8146 - precision: 0.7464 - recall: 0.7687 - auc: 0.8548 - val_loss: 0.4899 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8941\n",
      "Epoch 101/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5006 - tp: 200.0000 - fp: 44.0000 - tn: 400.0000 - fn: 68.0000 - accuracy: 0.8427 - precision: 0.8197 - recall: 0.7463 - auc: 0.8704 - val_loss: 0.4920 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8921\n",
      "Epoch 102/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5120 - tp: 199.0000 - fp: 51.0000 - tn: 393.0000 - fn: 69.0000 - accuracy: 0.8315 - precision: 0.7960 - recall: 0.7425 - auc: 0.8583 - val_loss: 0.4931 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8934\n",
      "Epoch 103/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4983 - tp: 205.0000 - fp: 62.0000 - tn: 382.0000 - fn: 63.0000 - accuracy: 0.8244 - precision: 0.7678 - recall: 0.7649 - auc: 0.8708 - val_loss: 0.4896 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8938\n",
      "Epoch 104/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5190 - tp: 206.0000 - fp: 66.0000 - tn: 378.0000 - fn: 62.0000 - accuracy: 0.8202 - precision: 0.7574 - recall: 0.7687 - auc: 0.8530 - val_loss: 0.4878 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8951\n",
      "Epoch 105/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5108 - tp: 206.0000 - fp: 60.0000 - tn: 384.0000 - fn: 62.0000 - accuracy: 0.8287 - precision: 0.7744 - recall: 0.7687 - auc: 0.8625 - val_loss: 0.4922 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8937\n",
      "Epoch 106/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5123 - tp: 209.0000 - fp: 65.0000 - tn: 379.0000 - fn: 59.0000 - accuracy: 0.8258 - precision: 0.7628 - recall: 0.7799 - auc: 0.8619 - val_loss: 0.4962 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8925\n",
      "Epoch 107/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4985 - tp: 200.0000 - fp: 59.0000 - tn: 385.0000 - fn: 68.0000 - accuracy: 0.8216 - precision: 0.7722 - recall: 0.7463 - auc: 0.8690 - val_loss: 0.4919 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8915\n",
      "Epoch 108/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5025 - tp: 204.0000 - fp: 63.0000 - tn: 381.0000 - fn: 64.0000 - accuracy: 0.8216 - precision: 0.7640 - recall: 0.7612 - auc: 0.8674 - val_loss: 0.4887 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8916\n",
      "Epoch 109/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5055 - tp: 208.0000 - fp: 67.0000 - tn: 377.0000 - fn: 60.0000 - accuracy: 0.8216 - precision: 0.7564 - recall: 0.7761 - auc: 0.8633 - val_loss: 0.4967 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8947\n",
      "Epoch 110/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5148 - tp: 202.0000 - fp: 59.0000 - tn: 385.0000 - fn: 66.0000 - accuracy: 0.8244 - precision: 0.7739 - recall: 0.7537 - auc: 0.8506 - val_loss: 0.4928 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8950\n",
      "Epoch 111/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5160 - tp: 206.0000 - fp: 71.0000 - tn: 373.0000 - fn: 62.0000 - accuracy: 0.8132 - precision: 0.7437 - recall: 0.7687 - auc: 0.8608 - val_loss: 0.4872 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8945\n",
      "Epoch 112/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4917 - tp: 198.0000 - fp: 50.0000 - tn: 394.0000 - fn: 70.0000 - accuracy: 0.8315 - precision: 0.7984 - recall: 0.7388 - auc: 0.8717 - val_loss: 0.4915 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8940\n",
      "Epoch 113/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5130 - tp: 199.0000 - fp: 49.0000 - tn: 395.0000 - fn: 69.0000 - accuracy: 0.8343 - precision: 0.8024 - recall: 0.7425 - auc: 0.8557 - val_loss: 0.4956 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8905\n",
      "Epoch 114/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5123 - tp: 199.0000 - fp: 58.0000 - tn: 386.0000 - fn: 69.0000 - accuracy: 0.8216 - precision: 0.7743 - recall: 0.7425 - auc: 0.8665 - val_loss: 0.4852 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8944\n",
      "Epoch 115/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5130 - tp: 207.0000 - fp: 72.0000 - tn: 372.0000 - fn: 61.0000 - accuracy: 0.8132 - precision: 0.7419 - recall: 0.7724 - auc: 0.8612 - val_loss: 0.4923 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8957\n",
      "Epoch 116/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5155 - tp: 202.0000 - fp: 62.0000 - tn: 382.0000 - fn: 66.0000 - accuracy: 0.8202 - precision: 0.7652 - recall: 0.7537 - auc: 0.8574 - val_loss: 0.4851 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8956\n",
      "Epoch 117/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5085 - tp: 203.0000 - fp: 59.0000 - tn: 385.0000 - fn: 65.0000 - accuracy: 0.8258 - precision: 0.7748 - recall: 0.7575 - auc: 0.8619 - val_loss: 0.4891 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8940\n",
      "Epoch 118/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4953 - tp: 202.0000 - fp: 40.0000 - tn: 404.0000 - fn: 66.0000 - accuracy: 0.8511 - precision: 0.8347 - recall: 0.7537 - auc: 0.8690 - val_loss: 0.4988 - val_tp: 62.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 12.0000 - val_accuracy: 0.7877 - val_precision: 0.7045 - val_recall: 0.8378 - val_auc: 0.8887\n",
      "Epoch 119/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5015 - tp: 211.0000 - fp: 77.0000 - tn: 367.0000 - fn: 57.0000 - accuracy: 0.8118 - precision: 0.7326 - recall: 0.7873 - auc: 0.8668 - val_loss: 0.4949 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8937\n",
      "Epoch 120/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5076 - tp: 201.0000 - fp: 60.0000 - tn: 384.0000 - fn: 67.0000 - accuracy: 0.8216 - precision: 0.7701 - recall: 0.7500 - auc: 0.8631 - val_loss: 0.4885 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8945\n",
      "Epoch 121/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5205 - tp: 206.0000 - fp: 66.0000 - tn: 378.0000 - fn: 62.0000 - accuracy: 0.8202 - precision: 0.7574 - recall: 0.7687 - auc: 0.8514 - val_loss: 0.4882 - val_tp: 61.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 13.0000 - val_accuracy: 0.8380 - val_precision: 0.7922 - val_recall: 0.8243 - val_auc: 0.8934\n",
      "Epoch 122/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5070 - tp: 194.0000 - fp: 53.0000 - tn: 391.0000 - fn: 74.0000 - accuracy: 0.8216 - precision: 0.7854 - recall: 0.7239 - auc: 0.8582 - val_loss: 0.4918 - val_tp: 64.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 10.0000 - val_accuracy: 0.7877 - val_precision: 0.6957 - val_recall: 0.8649 - val_auc: 0.8916\n",
      "Epoch 123/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5140 - tp: 213.0000 - fp: 75.0000 - tn: 369.0000 - fn: 55.0000 - accuracy: 0.8174 - precision: 0.7396 - recall: 0.7948 - auc: 0.8586 - val_loss: 0.4879 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8945\n",
      "Epoch 124/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5039 - tp: 202.0000 - fp: 61.0000 - tn: 383.0000 - fn: 66.0000 - accuracy: 0.8216 - precision: 0.7681 - recall: 0.7537 - auc: 0.8643 - val_loss: 0.4915 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8951\n",
      "Epoch 125/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5126 - tp: 204.0000 - fp: 67.0000 - tn: 377.0000 - fn: 64.0000 - accuracy: 0.8160 - precision: 0.7528 - recall: 0.7612 - auc: 0.8613 - val_loss: 0.4833 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8954\n",
      "Epoch 126/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5187 - tp: 191.0000 - fp: 43.0000 - tn: 401.0000 - fn: 77.0000 - accuracy: 0.8315 - precision: 0.8162 - recall: 0.7127 - auc: 0.8560 - val_loss: 0.4903 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8908\n",
      "Epoch 127/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5051 - tp: 201.0000 - fp: 52.0000 - tn: 392.0000 - fn: 67.0000 - accuracy: 0.8329 - precision: 0.7945 - recall: 0.7500 - auc: 0.8596 - val_loss: 0.4863 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8936\n",
      "Epoch 128/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4935 - tp: 208.0000 - fp: 67.0000 - tn: 377.0000 - fn: 60.0000 - accuracy: 0.8216 - precision: 0.7564 - recall: 0.7761 - auc: 0.8717 - val_loss: 0.4854 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8934\n",
      "Epoch 129/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4989 - tp: 205.0000 - fp: 71.0000 - tn: 373.0000 - fn: 63.0000 - accuracy: 0.8118 - precision: 0.7428 - recall: 0.7649 - auc: 0.8688 - val_loss: 0.4920 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8936\n",
      "Epoch 130/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5005 - tp: 204.0000 - fp: 65.0000 - tn: 379.0000 - fn: 64.0000 - accuracy: 0.8188 - precision: 0.7584 - recall: 0.7612 - auc: 0.8669 - val_loss: 0.4843 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8946\n",
      "Epoch 131/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4958 - tp: 199.0000 - fp: 49.0000 - tn: 395.0000 - fn: 69.0000 - accuracy: 0.8343 - precision: 0.8024 - recall: 0.7425 - auc: 0.8700 - val_loss: 0.4869 - val_tp: 62.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 12.0000 - val_accuracy: 0.8324 - val_precision: 0.7750 - val_recall: 0.8378 - val_auc: 0.8949\n",
      "Epoch 132/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4980 - tp: 204.0000 - fp: 64.0000 - tn: 380.0000 - fn: 64.0000 - accuracy: 0.8202 - precision: 0.7612 - recall: 0.7612 - auc: 0.8722 - val_loss: 0.4862 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8956\n",
      "Epoch 133/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4930 - tp: 210.0000 - fp: 59.0000 - tn: 385.0000 - fn: 58.0000 - accuracy: 0.8357 - precision: 0.7807 - recall: 0.7836 - auc: 0.8758 - val_loss: 0.4837 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8955\n",
      "Epoch 134/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5015 - tp: 202.0000 - fp: 53.0000 - tn: 391.0000 - fn: 66.0000 - accuracy: 0.8329 - precision: 0.7922 - recall: 0.7537 - auc: 0.8693 - val_loss: 0.4876 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8942\n",
      "Epoch 135/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5022 - tp: 201.0000 - fp: 52.0000 - tn: 392.0000 - fn: 67.0000 - accuracy: 0.8329 - precision: 0.7945 - recall: 0.7500 - auc: 0.8657 - val_loss: 0.4792 - val_tp: 61.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 13.0000 - val_accuracy: 0.8380 - val_precision: 0.7922 - val_recall: 0.8243 - val_auc: 0.8969\n",
      "Epoch 136/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5093 - tp: 206.0000 - fp: 62.0000 - tn: 382.0000 - fn: 62.0000 - accuracy: 0.8258 - precision: 0.7687 - recall: 0.7687 - auc: 0.8607 - val_loss: 0.4884 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8939\n",
      "Epoch 137/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4824 - tp: 212.0000 - fp: 65.0000 - tn: 379.0000 - fn: 56.0000 - accuracy: 0.8301 - precision: 0.7653 - recall: 0.7910 - auc: 0.8771 - val_loss: 0.4871 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8970\n",
      "Epoch 138/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4984 - tp: 202.0000 - fp: 47.0000 - tn: 397.0000 - fn: 66.0000 - accuracy: 0.8413 - precision: 0.8112 - recall: 0.7537 - auc: 0.8674 - val_loss: 0.4870 - val_tp: 61.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 13.0000 - val_accuracy: 0.8380 - val_precision: 0.7922 - val_recall: 0.8243 - val_auc: 0.8939\n",
      "Epoch 139/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4952 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8718 - val_loss: 0.4853 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8956\n",
      "Epoch 140/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5146 - tp: 196.0000 - fp: 54.0000 - tn: 390.0000 - fn: 72.0000 - accuracy: 0.8230 - precision: 0.7840 - recall: 0.7313 - auc: 0.8546 - val_loss: 0.4827 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8984\n",
      "Epoch 141/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5004 - tp: 199.0000 - fp: 55.0000 - tn: 389.0000 - fn: 69.0000 - accuracy: 0.8258 - precision: 0.7835 - recall: 0.7425 - auc: 0.8652 - val_loss: 0.4793 - val_tp: 61.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 13.0000 - val_accuracy: 0.8380 - val_precision: 0.7922 - val_recall: 0.8243 - val_auc: 0.8964\n",
      "Epoch 142/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5159 - tp: 204.0000 - fp: 63.0000 - tn: 381.0000 - fn: 64.0000 - accuracy: 0.8216 - precision: 0.7640 - recall: 0.7612 - auc: 0.8596 - val_loss: 0.4815 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8950\n",
      "Epoch 143/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5012 - tp: 191.0000 - fp: 47.0000 - tn: 397.0000 - fn: 77.0000 - accuracy: 0.8258 - precision: 0.8025 - recall: 0.7127 - auc: 0.8661 - val_loss: 0.4847 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8947\n",
      "Epoch 144/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5050 - tp: 204.0000 - fp: 62.0000 - tn: 382.0000 - fn: 64.0000 - accuracy: 0.8230 - precision: 0.7669 - recall: 0.7612 - auc: 0.8657 - val_loss: 0.5107 - val_tp: 69.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 5.0000 - val_accuracy: 0.7989 - val_precision: 0.6900 - val_recall: 0.9324 - val_auc: 0.8894\n",
      "Epoch 145/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5001 - tp: 210.0000 - fp: 71.0000 - tn: 373.0000 - fn: 58.0000 - accuracy: 0.8188 - precision: 0.7473 - recall: 0.7836 - auc: 0.8704 - val_loss: 0.4842 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8952\n",
      "Epoch 146/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5062 - tp: 203.0000 - fp: 62.0000 - tn: 382.0000 - fn: 65.0000 - accuracy: 0.8216 - precision: 0.7660 - recall: 0.7575 - auc: 0.8638 - val_loss: 0.4811 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8936\n",
      "Epoch 147/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5078 - tp: 195.0000 - fp: 46.0000 - tn: 398.0000 - fn: 73.0000 - accuracy: 0.8329 - precision: 0.8091 - recall: 0.7276 - auc: 0.8575 - val_loss: 0.4851 - val_tp: 61.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 13.0000 - val_accuracy: 0.8156 - val_precision: 0.7531 - val_recall: 0.8243 - val_auc: 0.8916\n",
      "Epoch 148/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4924 - tp: 208.0000 - fp: 68.0000 - tn: 376.0000 - fn: 60.0000 - accuracy: 0.8202 - precision: 0.7536 - recall: 0.7761 - auc: 0.8711 - val_loss: 0.4821 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8943\n",
      "Epoch 149/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4997 - tp: 203.0000 - fp: 58.0000 - tn: 386.0000 - fn: 65.0000 - accuracy: 0.8272 - precision: 0.7778 - recall: 0.7575 - auc: 0.8686 - val_loss: 0.5009 - val_tp: 64.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 10.0000 - val_accuracy: 0.7821 - val_precision: 0.6882 - val_recall: 0.8649 - val_auc: 0.8893\n",
      "Epoch 150/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5152 - tp: 201.0000 - fp: 73.0000 - tn: 371.0000 - fn: 67.0000 - accuracy: 0.8034 - precision: 0.7336 - recall: 0.7500 - auc: 0.8546 - val_loss: 0.4902 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8940\n",
      "Epoch 151/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5015 - tp: 205.0000 - fp: 56.0000 - tn: 388.0000 - fn: 63.0000 - accuracy: 0.8329 - precision: 0.7854 - recall: 0.7649 - auc: 0.8669 - val_loss: 0.4868 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8923\n",
      "Epoch 152/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4903 - tp: 203.0000 - fp: 59.0000 - tn: 385.0000 - fn: 65.0000 - accuracy: 0.8258 - precision: 0.7748 - recall: 0.7575 - auc: 0.8775 - val_loss: 0.4836 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8929\n",
      "Epoch 153/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4941 - tp: 201.0000 - fp: 61.0000 - tn: 383.0000 - fn: 67.0000 - accuracy: 0.8202 - precision: 0.7672 - recall: 0.7500 - auc: 0.8697 - val_loss: 0.4857 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8939\n",
      "Epoch 154/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4862 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8747 - val_loss: 0.4896 - val_tp: 62.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 12.0000 - val_accuracy: 0.8156 - val_precision: 0.7470 - val_recall: 0.8378 - val_auc: 0.8897\n",
      "Epoch 155/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4989 - tp: 201.0000 - fp: 55.0000 - tn: 389.0000 - fn: 67.0000 - accuracy: 0.8287 - precision: 0.7852 - recall: 0.7500 - auc: 0.8646 - val_loss: 0.4949 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8952\n",
      "Epoch 156/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4861 - tp: 198.0000 - fp: 38.0000 - tn: 406.0000 - fn: 70.0000 - accuracy: 0.8483 - precision: 0.8390 - recall: 0.7388 - auc: 0.8741 - val_loss: 0.4889 - val_tp: 62.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 12.0000 - val_accuracy: 0.8045 - val_precision: 0.7294 - val_recall: 0.8378 - val_auc: 0.8925\n",
      "Epoch 157/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5024 - tp: 203.0000 - fp: 62.0000 - tn: 382.0000 - fn: 65.0000 - accuracy: 0.8216 - precision: 0.7660 - recall: 0.7575 - auc: 0.8657 - val_loss: 0.4874 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8936\n",
      "Epoch 158/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5034 - tp: 200.0000 - fp: 58.0000 - tn: 386.0000 - fn: 68.0000 - accuracy: 0.8230 - precision: 0.7752 - recall: 0.7463 - auc: 0.8606 - val_loss: 0.4792 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8947\n",
      "Epoch 159/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5146 - tp: 202.0000 - fp: 73.0000 - tn: 371.0000 - fn: 66.0000 - accuracy: 0.8048 - precision: 0.7345 - recall: 0.7537 - auc: 0.8556 - val_loss: 0.4815 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8928\n",
      "Epoch 160/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4901 - tp: 204.0000 - fp: 66.0000 - tn: 378.0000 - fn: 64.0000 - accuracy: 0.8174 - precision: 0.7556 - recall: 0.7612 - auc: 0.8721 - val_loss: 0.4827 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8970\n",
      "Epoch 161/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4944 - tp: 203.0000 - fp: 60.0000 - tn: 384.0000 - fn: 65.0000 - accuracy: 0.8244 - precision: 0.7719 - recall: 0.7575 - auc: 0.8627 - val_loss: 0.4772 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8941\n",
      "Epoch 162/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4993 - tp: 199.0000 - fp: 57.0000 - tn: 387.0000 - fn: 69.0000 - accuracy: 0.8230 - precision: 0.7773 - recall: 0.7425 - auc: 0.8666 - val_loss: 0.4798 - val_tp: 62.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 12.0000 - val_accuracy: 0.7933 - val_precision: 0.7126 - val_recall: 0.8378 - val_auc: 0.8954\n",
      "Epoch 163/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4970 - tp: 200.0000 - fp: 61.0000 - tn: 383.0000 - fn: 68.0000 - accuracy: 0.8188 - precision: 0.7663 - recall: 0.7463 - auc: 0.8644 - val_loss: 0.4780 - val_tp: 60.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 14.0000 - val_accuracy: 0.8380 - val_precision: 0.8000 - val_recall: 0.8108 - val_auc: 0.8932\n",
      "Epoch 164/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5023 - tp: 206.0000 - fp: 73.0000 - tn: 371.0000 - fn: 62.0000 - accuracy: 0.8104 - precision: 0.7384 - recall: 0.7687 - auc: 0.8626 - val_loss: 0.4813 - val_tp: 60.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 14.0000 - val_accuracy: 0.8380 - val_precision: 0.8000 - val_recall: 0.8108 - val_auc: 0.8948\n",
      "Epoch 165/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4890 - tp: 205.0000 - fp: 60.0000 - tn: 384.0000 - fn: 63.0000 - accuracy: 0.8272 - precision: 0.7736 - recall: 0.7649 - auc: 0.8730 - val_loss: 0.4839 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8949\n",
      "Epoch 166/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5005 - tp: 203.0000 - fp: 52.0000 - tn: 392.0000 - fn: 65.0000 - accuracy: 0.8357 - precision: 0.7961 - recall: 0.7575 - auc: 0.8672 - val_loss: 0.4843 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8938\n",
      "Epoch 167/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4845 - tp: 206.0000 - fp: 63.0000 - tn: 381.0000 - fn: 62.0000 - accuracy: 0.8244 - precision: 0.7658 - recall: 0.7687 - auc: 0.8749 - val_loss: 0.4855 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8943\n",
      "Epoch 168/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5060 - tp: 201.0000 - fp: 59.0000 - tn: 385.0000 - fn: 67.0000 - accuracy: 0.8230 - precision: 0.7731 - recall: 0.7500 - auc: 0.8561 - val_loss: 0.4761 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8983\n",
      "Epoch 169/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5037 - tp: 202.0000 - fp: 66.0000 - tn: 378.0000 - fn: 66.0000 - accuracy: 0.8146 - precision: 0.7537 - recall: 0.7537 - auc: 0.8646 - val_loss: 0.4845 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8969\n",
      "Epoch 170/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4922 - tp: 194.0000 - fp: 53.0000 - tn: 391.0000 - fn: 74.0000 - accuracy: 0.8216 - precision: 0.7854 - recall: 0.7239 - auc: 0.8717 - val_loss: 0.4826 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8924\n",
      "Epoch 171/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4864 - tp: 199.0000 - fp: 53.0000 - tn: 391.0000 - fn: 69.0000 - accuracy: 0.8287 - precision: 0.7897 - recall: 0.7425 - auc: 0.8729 - val_loss: 0.4855 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8955\n",
      "Epoch 172/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4827 - tp: 205.0000 - fp: 55.0000 - tn: 389.0000 - fn: 63.0000 - accuracy: 0.8343 - precision: 0.7885 - recall: 0.7649 - auc: 0.8787 - val_loss: 0.4806 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8940\n",
      "Epoch 173/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5052 - tp: 203.0000 - fp: 62.0000 - tn: 382.0000 - fn: 65.0000 - accuracy: 0.8216 - precision: 0.7660 - recall: 0.7575 - auc: 0.8639 - val_loss: 0.4766 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8963\n",
      "Epoch 174/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5048 - tp: 211.0000 - fp: 66.0000 - tn: 378.0000 - fn: 57.0000 - accuracy: 0.8272 - precision: 0.7617 - recall: 0.7873 - auc: 0.8655 - val_loss: 0.4794 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8972\n",
      "Epoch 175/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4983 - tp: 197.0000 - fp: 47.0000 - tn: 397.0000 - fn: 71.0000 - accuracy: 0.8343 - precision: 0.8074 - recall: 0.7351 - auc: 0.8688 - val_loss: 0.4819 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8940\n",
      "Epoch 176/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4953 - tp: 205.0000 - fp: 58.0000 - tn: 386.0000 - fn: 63.0000 - accuracy: 0.8301 - precision: 0.7795 - recall: 0.7649 - auc: 0.8663 - val_loss: 0.4797 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8921\n",
      "Epoch 177/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4954 - tp: 207.0000 - fp: 55.0000 - tn: 389.0000 - fn: 61.0000 - accuracy: 0.8371 - precision: 0.7901 - recall: 0.7724 - auc: 0.8688 - val_loss: 0.4758 - val_tp: 61.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 13.0000 - val_accuracy: 0.8380 - val_precision: 0.7922 - val_recall: 0.8243 - val_auc: 0.8955\n",
      "Epoch 178/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5008 - tp: 196.0000 - fp: 58.0000 - tn: 386.0000 - fn: 72.0000 - accuracy: 0.8174 - precision: 0.7717 - recall: 0.7313 - auc: 0.8577 - val_loss: 0.4805 - val_tp: 64.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 10.0000 - val_accuracy: 0.7989 - val_precision: 0.7111 - val_recall: 0.8649 - val_auc: 0.8950\n",
      "Epoch 179/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5020 - tp: 198.0000 - fp: 56.0000 - tn: 388.0000 - fn: 70.0000 - accuracy: 0.8230 - precision: 0.7795 - recall: 0.7388 - auc: 0.8626 - val_loss: 0.4812 - val_tp: 62.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 12.0000 - val_accuracy: 0.8268 - val_precision: 0.7654 - val_recall: 0.8378 - val_auc: 0.8939\n",
      "Epoch 180/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5117 - tp: 205.0000 - fp: 76.0000 - tn: 368.0000 - fn: 63.0000 - accuracy: 0.8048 - precision: 0.7295 - recall: 0.7649 - auc: 0.8534 - val_loss: 0.4772 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8949\n",
      "Epoch 181/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5044 - tp: 205.0000 - fp: 65.0000 - tn: 379.0000 - fn: 63.0000 - accuracy: 0.8202 - precision: 0.7593 - recall: 0.7649 - auc: 0.8607 - val_loss: 0.4773 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8967\n",
      "Epoch 182/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4866 - tp: 209.0000 - fp: 64.0000 - tn: 380.0000 - fn: 59.0000 - accuracy: 0.8272 - precision: 0.7656 - recall: 0.7799 - auc: 0.8733 - val_loss: 0.4783 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8949\n",
      "Epoch 183/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4959 - tp: 199.0000 - fp: 48.0000 - tn: 396.0000 - fn: 69.0000 - accuracy: 0.8357 - precision: 0.8057 - recall: 0.7425 - auc: 0.8648 - val_loss: 0.4792 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8948\n",
      "Epoch 184/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4922 - tp: 205.0000 - fp: 55.0000 - tn: 389.0000 - fn: 63.0000 - accuracy: 0.8343 - precision: 0.7885 - recall: 0.7649 - auc: 0.8685 - val_loss: 0.4734 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8964\n",
      "Epoch 185/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4907 - tp: 207.0000 - fp: 59.0000 - tn: 385.0000 - fn: 61.0000 - accuracy: 0.8315 - precision: 0.7782 - recall: 0.7724 - auc: 0.8692 - val_loss: 0.4771 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8943\n",
      "Epoch 186/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4872 - tp: 198.0000 - fp: 54.0000 - tn: 390.0000 - fn: 70.0000 - accuracy: 0.8258 - precision: 0.7857 - recall: 0.7388 - auc: 0.8735 - val_loss: 0.4767 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8959\n",
      "Epoch 187/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4870 - tp: 207.0000 - fp: 60.0000 - tn: 384.0000 - fn: 61.0000 - accuracy: 0.8301 - precision: 0.7753 - recall: 0.7724 - auc: 0.8712 - val_loss: 0.4773 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8950\n",
      "Epoch 188/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4918 - tp: 199.0000 - fp: 51.0000 - tn: 393.0000 - fn: 69.0000 - accuracy: 0.8315 - precision: 0.7960 - recall: 0.7425 - auc: 0.8684 - val_loss: 0.4797 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8954\n",
      "Epoch 189/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4725 - tp: 208.0000 - fp: 51.0000 - tn: 393.0000 - fn: 60.0000 - accuracy: 0.8441 - precision: 0.8031 - recall: 0.7761 - auc: 0.8835 - val_loss: 0.4720 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8952\n",
      "Epoch 190/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5041 - tp: 203.0000 - fp: 73.0000 - tn: 371.0000 - fn: 65.0000 - accuracy: 0.8062 - precision: 0.7355 - recall: 0.7575 - auc: 0.8602 - val_loss: 0.4755 - val_tp: 60.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 14.0000 - val_accuracy: 0.8380 - val_precision: 0.8000 - val_recall: 0.8108 - val_auc: 0.8946\n",
      "Epoch 191/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4900 - tp: 202.0000 - fp: 52.0000 - tn: 392.0000 - fn: 66.0000 - accuracy: 0.8343 - precision: 0.7953 - recall: 0.7537 - auc: 0.8706 - val_loss: 0.4839 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8968\n",
      "Epoch 192/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4873 - tp: 207.0000 - fp: 64.0000 - tn: 380.0000 - fn: 61.0000 - accuracy: 0.8244 - precision: 0.7638 - recall: 0.7724 - auc: 0.8761 - val_loss: 0.4782 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8940\n",
      "Epoch 193/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4933 - tp: 202.0000 - fp: 58.0000 - tn: 386.0000 - fn: 66.0000 - accuracy: 0.8258 - precision: 0.7769 - recall: 0.7537 - auc: 0.8636 - val_loss: 0.4839 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8946\n",
      "Epoch 194/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5173 - tp: 197.0000 - fp: 64.0000 - tn: 380.0000 - fn: 71.0000 - accuracy: 0.8104 - precision: 0.7548 - recall: 0.7351 - auc: 0.8539 - val_loss: 0.4807 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8934\n",
      "Epoch 195/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5065 - tp: 197.0000 - fp: 46.0000 - tn: 398.0000 - fn: 71.0000 - accuracy: 0.8357 - precision: 0.8107 - recall: 0.7351 - auc: 0.8584 - val_loss: 0.4770 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8945\n",
      "Epoch 196/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4948 - tp: 208.0000 - fp: 58.0000 - tn: 386.0000 - fn: 60.0000 - accuracy: 0.8343 - precision: 0.7820 - recall: 0.7761 - auc: 0.8728 - val_loss: 0.4791 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8994\n",
      "Epoch 197/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4882 - tp: 204.0000 - fp: 56.0000 - tn: 388.0000 - fn: 64.0000 - accuracy: 0.8315 - precision: 0.7846 - recall: 0.7612 - auc: 0.8677 - val_loss: 0.4805 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8979\n",
      "Epoch 198/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5019 - tp: 196.0000 - fp: 48.0000 - tn: 396.0000 - fn: 72.0000 - accuracy: 0.8315 - precision: 0.8033 - recall: 0.7313 - auc: 0.8621 - val_loss: 0.4769 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8956\n",
      "Epoch 199/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5068 - tp: 197.0000 - fp: 61.0000 - tn: 383.0000 - fn: 71.0000 - accuracy: 0.8146 - precision: 0.7636 - recall: 0.7351 - auc: 0.8549 - val_loss: 0.4750 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8965\n",
      "Epoch 200/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4952 - tp: 203.0000 - fp: 60.0000 - tn: 384.0000 - fn: 65.0000 - accuracy: 0.8244 - precision: 0.7719 - recall: 0.7575 - auc: 0.8671 - val_loss: 0.4814 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8970\n",
      "Epoch 201/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4955 - tp: 192.0000 - fp: 40.0000 - tn: 404.0000 - fn: 76.0000 - accuracy: 0.8371 - precision: 0.8276 - recall: 0.7164 - auc: 0.8626 - val_loss: 0.5008 - val_tp: 69.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 5.0000 - val_accuracy: 0.7877 - val_precision: 0.6765 - val_recall: 0.9324 - val_auc: 0.8922\n",
      "Epoch 202/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5046 - tp: 199.0000 - fp: 72.0000 - tn: 372.0000 - fn: 69.0000 - accuracy: 0.8020 - precision: 0.7343 - recall: 0.7425 - auc: 0.8646 - val_loss: 0.4768 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8935\n",
      "Epoch 203/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5059 - tp: 206.0000 - fp: 61.0000 - tn: 383.0000 - fn: 62.0000 - accuracy: 0.8272 - precision: 0.7715 - recall: 0.7687 - auc: 0.8574 - val_loss: 0.4907 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8945\n",
      "Epoch 204/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4982 - tp: 197.0000 - fp: 48.0000 - tn: 396.0000 - fn: 71.0000 - accuracy: 0.8329 - precision: 0.8041 - recall: 0.7351 - auc: 0.8634 - val_loss: 0.4793 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8938\n",
      "Epoch 205/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4945 - tp: 213.0000 - fp: 64.0000 - tn: 380.0000 - fn: 55.0000 - accuracy: 0.8329 - precision: 0.7690 - recall: 0.7948 - auc: 0.8632 - val_loss: 0.4798 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8958\n",
      "Epoch 206/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4832 - tp: 203.0000 - fp: 48.0000 - tn: 396.0000 - fn: 65.0000 - accuracy: 0.8413 - precision: 0.8088 - recall: 0.7575 - auc: 0.8717 - val_loss: 0.4830 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8940\n",
      "Epoch 207/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4763 - tp: 206.0000 - fp: 60.0000 - tn: 384.0000 - fn: 62.0000 - accuracy: 0.8287 - precision: 0.7744 - recall: 0.7687 - auc: 0.8847 - val_loss: 0.4815 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8954\n",
      "Epoch 208/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4973 - tp: 203.0000 - fp: 60.0000 - tn: 384.0000 - fn: 65.0000 - accuracy: 0.8244 - precision: 0.7719 - recall: 0.7575 - auc: 0.8671 - val_loss: 0.4760 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8965\n",
      "Epoch 209/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4948 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8629 - val_loss: 0.4754 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8964\n",
      "Epoch 210/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4809 - tp: 206.0000 - fp: 50.0000 - tn: 394.0000 - fn: 62.0000 - accuracy: 0.8427 - precision: 0.8047 - recall: 0.7687 - auc: 0.8761 - val_loss: 0.4698 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8968\n",
      "Epoch 211/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5008 - tp: 206.0000 - fp: 61.0000 - tn: 383.0000 - fn: 62.0000 - accuracy: 0.8272 - precision: 0.7715 - recall: 0.7687 - auc: 0.8576 - val_loss: 0.4715 - val_tp: 61.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 13.0000 - val_accuracy: 0.8101 - val_precision: 0.7439 - val_recall: 0.8243 - val_auc: 0.8946\n",
      "Epoch 212/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4920 - tp: 205.0000 - fp: 65.0000 - tn: 379.0000 - fn: 63.0000 - accuracy: 0.8202 - precision: 0.7593 - recall: 0.7649 - auc: 0.8663 - val_loss: 0.4751 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8988\n",
      "Epoch 213/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4979 - tp: 198.0000 - fp: 50.0000 - tn: 394.0000 - fn: 70.0000 - accuracy: 0.8315 - precision: 0.7984 - recall: 0.7388 - auc: 0.8635 - val_loss: 0.4770 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8974\n",
      "Epoch 214/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4919 - tp: 203.0000 - fp: 73.0000 - tn: 371.0000 - fn: 65.0000 - accuracy: 0.8062 - precision: 0.7355 - recall: 0.7575 - auc: 0.8672 - val_loss: 0.4752 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8979\n",
      "Epoch 215/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5033 - tp: 201.0000 - fp: 62.0000 - tn: 382.0000 - fn: 67.0000 - accuracy: 0.8188 - precision: 0.7643 - recall: 0.7500 - auc: 0.8554 - val_loss: 0.4753 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8958\n",
      "Epoch 216/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4951 - tp: 197.0000 - fp: 48.0000 - tn: 396.0000 - fn: 71.0000 - accuracy: 0.8329 - precision: 0.8041 - recall: 0.7351 - auc: 0.8728 - val_loss: 0.4770 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.9018\n",
      "Epoch 217/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4904 - tp: 208.0000 - fp: 60.0000 - tn: 384.0000 - fn: 60.0000 - accuracy: 0.8315 - precision: 0.7761 - recall: 0.7761 - auc: 0.8684 - val_loss: 0.4771 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8960\n",
      "Epoch 218/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4845 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8727 - val_loss: 0.4811 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.9001\n",
      "Epoch 219/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5030 - tp: 201.0000 - fp: 58.0000 - tn: 386.0000 - fn: 67.0000 - accuracy: 0.8244 - precision: 0.7761 - recall: 0.7500 - auc: 0.8524 - val_loss: 0.4726 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8975\n",
      "Epoch 220/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4975 - tp: 199.0000 - fp: 49.0000 - tn: 395.0000 - fn: 69.0000 - accuracy: 0.8343 - precision: 0.8024 - recall: 0.7425 - auc: 0.8608 - val_loss: 0.4748 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.9005\n",
      "Epoch 221/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5019 - tp: 197.0000 - fp: 61.0000 - tn: 383.0000 - fn: 71.0000 - accuracy: 0.8146 - precision: 0.7636 - recall: 0.7351 - auc: 0.8595 - val_loss: 0.4769 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8925\n",
      "Epoch 222/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4928 - tp: 203.0000 - fp: 60.0000 - tn: 384.0000 - fn: 65.0000 - accuracy: 0.8244 - precision: 0.7719 - recall: 0.7575 - auc: 0.8651 - val_loss: 0.4808 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8948\n",
      "Epoch 223/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4958 - tp: 198.0000 - fp: 49.0000 - tn: 395.0000 - fn: 70.0000 - accuracy: 0.8329 - precision: 0.8016 - recall: 0.7388 - auc: 0.8712 - val_loss: 0.4760 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8950\n",
      "Epoch 224/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4994 - tp: 200.0000 - fp: 48.0000 - tn: 396.0000 - fn: 68.0000 - accuracy: 0.8371 - precision: 0.8065 - recall: 0.7463 - auc: 0.8562 - val_loss: 0.4790 - val_tp: 62.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 12.0000 - val_accuracy: 0.8380 - val_precision: 0.7848 - val_recall: 0.8378 - val_auc: 0.8985\n",
      "Epoch 225/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4970 - tp: 202.0000 - fp: 46.0000 - tn: 398.0000 - fn: 66.0000 - accuracy: 0.8427 - precision: 0.8145 - recall: 0.7537 - auc: 0.8631 - val_loss: 0.4773 - val_tp: 60.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 14.0000 - val_accuracy: 0.8380 - val_precision: 0.8000 - val_recall: 0.8108 - val_auc: 0.8956\n",
      "Epoch 226/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4971 - tp: 197.0000 - fp: 50.0000 - tn: 394.0000 - fn: 71.0000 - accuracy: 0.8301 - precision: 0.7976 - recall: 0.7351 - auc: 0.8633 - val_loss: 0.4779 - val_tp: 62.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 12.0000 - val_accuracy: 0.8268 - val_precision: 0.7654 - val_recall: 0.8378 - val_auc: 0.8966\n",
      "Epoch 227/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4827 - tp: 205.0000 - fp: 55.0000 - tn: 389.0000 - fn: 63.0000 - accuracy: 0.8343 - precision: 0.7885 - recall: 0.7649 - auc: 0.8704 - val_loss: 0.4768 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8945\n",
      "Epoch 228/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5066 - tp: 201.0000 - fp: 58.0000 - tn: 386.0000 - fn: 67.0000 - accuracy: 0.8244 - precision: 0.7761 - recall: 0.7500 - auc: 0.8511 - val_loss: 0.4777 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8964\n",
      "Epoch 229/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4967 - tp: 199.0000 - fp: 55.0000 - tn: 389.0000 - fn: 69.0000 - accuracy: 0.8258 - precision: 0.7835 - recall: 0.7425 - auc: 0.8691 - val_loss: 0.4814 - val_tp: 62.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 12.0000 - val_accuracy: 0.7933 - val_precision: 0.7126 - val_recall: 0.8378 - val_auc: 0.8956\n",
      "Epoch 230/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4952 - tp: 197.0000 - fp: 60.0000 - tn: 384.0000 - fn: 71.0000 - accuracy: 0.8160 - precision: 0.7665 - recall: 0.7351 - auc: 0.8679 - val_loss: 0.4754 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8975\n",
      "Epoch 231/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4970 - tp: 205.0000 - fp: 59.0000 - tn: 385.0000 - fn: 63.0000 - accuracy: 0.8287 - precision: 0.7765 - recall: 0.7649 - auc: 0.8641 - val_loss: 0.4787 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8960\n",
      "Epoch 232/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4896 - tp: 200.0000 - fp: 56.0000 - tn: 388.0000 - fn: 68.0000 - accuracy: 0.8258 - precision: 0.7812 - recall: 0.7463 - auc: 0.8694 - val_loss: 0.4812 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.9016\n",
      "Epoch 233/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4977 - tp: 198.0000 - fp: 46.0000 - tn: 398.0000 - fn: 70.0000 - accuracy: 0.8371 - precision: 0.8115 - recall: 0.7388 - auc: 0.8603 - val_loss: 0.4749 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8955\n",
      "Epoch 234/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4893 - tp: 199.0000 - fp: 49.0000 - tn: 395.0000 - fn: 69.0000 - accuracy: 0.8343 - precision: 0.8024 - recall: 0.7425 - auc: 0.8683 - val_loss: 0.4768 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8986\n",
      "Epoch 235/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4930 - tp: 204.0000 - fp: 58.0000 - tn: 386.0000 - fn: 64.0000 - accuracy: 0.8287 - precision: 0.7786 - recall: 0.7612 - auc: 0.8708 - val_loss: 0.4747 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8975\n",
      "Epoch 236/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4976 - tp: 206.0000 - fp: 57.0000 - tn: 387.0000 - fn: 62.0000 - accuracy: 0.8329 - precision: 0.7833 - recall: 0.7687 - auc: 0.8601 - val_loss: 0.4771 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8972\n",
      "Epoch 237/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4930 - tp: 200.0000 - fp: 56.0000 - tn: 388.0000 - fn: 68.0000 - accuracy: 0.8258 - precision: 0.7812 - recall: 0.7463 - auc: 0.8730 - val_loss: 0.4725 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8975\n",
      "Epoch 238/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4913 - tp: 195.0000 - fp: 47.0000 - tn: 397.0000 - fn: 73.0000 - accuracy: 0.8315 - precision: 0.8058 - recall: 0.7276 - auc: 0.8654 - val_loss: 0.4753 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8968\n",
      "Epoch 239/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4892 - tp: 206.0000 - fp: 58.0000 - tn: 386.0000 - fn: 62.0000 - accuracy: 0.8315 - precision: 0.7803 - recall: 0.7687 - auc: 0.8676 - val_loss: 0.4729 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8963\n",
      "Epoch 240/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5046 - tp: 193.0000 - fp: 62.0000 - tn: 382.0000 - fn: 75.0000 - accuracy: 0.8076 - precision: 0.7569 - recall: 0.7201 - auc: 0.8593 - val_loss: 0.4818 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8944\n",
      "Epoch 241/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4898 - tp: 197.0000 - fp: 45.0000 - tn: 399.0000 - fn: 71.0000 - accuracy: 0.8371 - precision: 0.8140 - recall: 0.7351 - auc: 0.8678 - val_loss: 0.4794 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8998\n",
      "Epoch 242/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4905 - tp: 200.0000 - fp: 52.0000 - tn: 392.0000 - fn: 68.0000 - accuracy: 0.8315 - precision: 0.7937 - recall: 0.7463 - auc: 0.8706 - val_loss: 0.4751 - val_tp: 61.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 13.0000 - val_accuracy: 0.8101 - val_precision: 0.7439 - val_recall: 0.8243 - val_auc: 0.8955\n",
      "Epoch 243/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5075 - tp: 210.0000 - fp: 68.0000 - tn: 376.0000 - fn: 58.0000 - accuracy: 0.8230 - precision: 0.7554 - recall: 0.7836 - auc: 0.8560 - val_loss: 0.4756 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8976\n",
      "Epoch 244/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4955 - tp: 196.0000 - fp: 49.0000 - tn: 395.0000 - fn: 72.0000 - accuracy: 0.8301 - precision: 0.8000 - recall: 0.7313 - auc: 0.8659 - val_loss: 0.4834 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8952\n",
      "Epoch 245/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4739 - tp: 206.0000 - fp: 58.0000 - tn: 386.0000 - fn: 62.0000 - accuracy: 0.8315 - precision: 0.7803 - recall: 0.7687 - auc: 0.8757 - val_loss: 0.4762 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8986\n",
      "Epoch 246/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4771 - tp: 207.0000 - fp: 59.0000 - tn: 385.0000 - fn: 61.0000 - accuracy: 0.8315 - precision: 0.7782 - recall: 0.7724 - auc: 0.8783 - val_loss: 0.4737 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8977\n",
      "Epoch 247/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4995 - tp: 202.0000 - fp: 57.0000 - tn: 387.0000 - fn: 66.0000 - accuracy: 0.8272 - precision: 0.7799 - recall: 0.7537 - auc: 0.8620 - val_loss: 0.4819 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8934\n",
      "Epoch 248/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4965 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8631 - val_loss: 0.4774 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8963\n",
      "Epoch 249/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4875 - tp: 201.0000 - fp: 56.0000 - tn: 388.0000 - fn: 67.0000 - accuracy: 0.8272 - precision: 0.7821 - recall: 0.7500 - auc: 0.8709 - val_loss: 0.4714 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8948\n",
      "Epoch 250/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4867 - tp: 200.0000 - fp: 48.0000 - tn: 396.0000 - fn: 68.0000 - accuracy: 0.8371 - precision: 0.8065 - recall: 0.7463 - auc: 0.8737 - val_loss: 0.4766 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8979\n",
      "Epoch 251/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4894 - tp: 202.0000 - fp: 56.0000 - tn: 388.0000 - fn: 66.0000 - accuracy: 0.8287 - precision: 0.7829 - recall: 0.7537 - auc: 0.8692 - val_loss: 0.4803 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8934\n",
      "Epoch 252/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5079 - tp: 202.0000 - fp: 59.0000 - tn: 385.0000 - fn: 66.0000 - accuracy: 0.8244 - precision: 0.7739 - recall: 0.7537 - auc: 0.8588 - val_loss: 0.4808 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8951\n",
      "Epoch 253/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5022 - tp: 195.0000 - fp: 47.0000 - tn: 397.0000 - fn: 73.0000 - accuracy: 0.8315 - precision: 0.8058 - recall: 0.7276 - auc: 0.8607 - val_loss: 0.4746 - val_tp: 61.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 13.0000 - val_accuracy: 0.8436 - val_precision: 0.8026 - val_recall: 0.8243 - val_auc: 0.8961\n",
      "Epoch 254/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4901 - tp: 204.0000 - fp: 67.0000 - tn: 377.0000 - fn: 64.0000 - accuracy: 0.8160 - precision: 0.7528 - recall: 0.7612 - auc: 0.8695 - val_loss: 0.4741 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.9001\n",
      "Epoch 255/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4796 - tp: 207.0000 - fp: 53.0000 - tn: 391.0000 - fn: 61.0000 - accuracy: 0.8399 - precision: 0.7962 - recall: 0.7724 - auc: 0.8727 - val_loss: 0.4765 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8968\n",
      "Epoch 256/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4914 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8664 - val_loss: 0.4782 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8993\n",
      "Epoch 257/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4764 - tp: 196.0000 - fp: 44.0000 - tn: 400.0000 - fn: 72.0000 - accuracy: 0.8371 - precision: 0.8167 - recall: 0.7313 - auc: 0.8805 - val_loss: 0.4874 - val_tp: 62.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 12.0000 - val_accuracy: 0.7933 - val_precision: 0.7126 - val_recall: 0.8378 - val_auc: 0.8947\n",
      "Epoch 258/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4898 - tp: 208.0000 - fp: 60.0000 - tn: 384.0000 - fn: 60.0000 - accuracy: 0.8315 - precision: 0.7761 - recall: 0.7761 - auc: 0.8703 - val_loss: 0.4763 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8999\n",
      "Epoch 259/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4982 - tp: 203.0000 - fp: 55.0000 - tn: 389.0000 - fn: 65.0000 - accuracy: 0.8315 - precision: 0.7868 - recall: 0.7575 - auc: 0.8619 - val_loss: 0.4762 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8969\n",
      "Epoch 260/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4936 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8611 - val_loss: 0.4739 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8989\n",
      "Epoch 261/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4786 - tp: 197.0000 - fp: 50.0000 - tn: 394.0000 - fn: 71.0000 - accuracy: 0.8301 - precision: 0.7976 - recall: 0.7351 - auc: 0.8748 - val_loss: 0.4823 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8965\n",
      "Epoch 262/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4883 - tp: 205.0000 - fp: 60.0000 - tn: 384.0000 - fn: 63.0000 - accuracy: 0.8272 - precision: 0.7736 - recall: 0.7649 - auc: 0.8762 - val_loss: 0.4753 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8976\n",
      "Epoch 263/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4906 - tp: 204.0000 - fp: 54.0000 - tn: 390.0000 - fn: 64.0000 - accuracy: 0.8343 - precision: 0.7907 - recall: 0.7612 - auc: 0.8638 - val_loss: 0.4728 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8980\n",
      "Epoch 264/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4915 - tp: 198.0000 - fp: 45.0000 - tn: 399.0000 - fn: 70.0000 - accuracy: 0.8385 - precision: 0.8148 - recall: 0.7388 - auc: 0.8654 - val_loss: 0.4729 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8960\n",
      "Epoch 265/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4944 - tp: 201.0000 - fp: 54.0000 - tn: 390.0000 - fn: 67.0000 - accuracy: 0.8301 - precision: 0.7882 - recall: 0.7500 - auc: 0.8649 - val_loss: 0.4698 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.9031\n",
      "Epoch 266/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5022 - tp: 199.0000 - fp: 55.0000 - tn: 389.0000 - fn: 69.0000 - accuracy: 0.8258 - precision: 0.7835 - recall: 0.7425 - auc: 0.8610 - val_loss: 0.4769 - val_tp: 62.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 12.0000 - val_accuracy: 0.8212 - val_precision: 0.7561 - val_recall: 0.8378 - val_auc: 0.8953\n",
      "Epoch 267/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4800 - tp: 204.0000 - fp: 51.0000 - tn: 393.0000 - fn: 64.0000 - accuracy: 0.8385 - precision: 0.8000 - recall: 0.7612 - auc: 0.8735 - val_loss: 0.4749 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8953\n",
      "Epoch 268/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4898 - tp: 205.0000 - fp: 65.0000 - tn: 379.0000 - fn: 63.0000 - accuracy: 0.8202 - precision: 0.7593 - recall: 0.7649 - auc: 0.8724 - val_loss: 0.4771 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8967\n",
      "Epoch 269/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4884 - tp: 203.0000 - fp: 52.0000 - tn: 392.0000 - fn: 65.0000 - accuracy: 0.8357 - precision: 0.7961 - recall: 0.7575 - auc: 0.8717 - val_loss: 0.4769 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8965\n",
      "Epoch 270/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4776 - tp: 208.0000 - fp: 55.0000 - tn: 389.0000 - fn: 60.0000 - accuracy: 0.8385 - precision: 0.7909 - recall: 0.7761 - auc: 0.8791 - val_loss: 0.4720 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8961\n",
      "Epoch 271/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4868 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8669 - val_loss: 0.4797 - val_tp: 62.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 12.0000 - val_accuracy: 0.8045 - val_precision: 0.7294 - val_recall: 0.8378 - val_auc: 0.8965\n",
      "Epoch 272/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4806 - tp: 202.0000 - fp: 58.0000 - tn: 386.0000 - fn: 66.0000 - accuracy: 0.8258 - precision: 0.7769 - recall: 0.7537 - auc: 0.8692 - val_loss: 0.4762 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8949\n",
      "Epoch 273/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4847 - tp: 201.0000 - fp: 59.0000 - tn: 385.0000 - fn: 67.0000 - accuracy: 0.8230 - precision: 0.7731 - recall: 0.7500 - auc: 0.8693 - val_loss: 0.4807 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8938\n",
      "Epoch 274/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4869 - tp: 210.0000 - fp: 62.0000 - tn: 382.0000 - fn: 58.0000 - accuracy: 0.8315 - precision: 0.7721 - recall: 0.7836 - auc: 0.8664 - val_loss: 0.4701 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8966\n",
      "Epoch 275/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4879 - tp: 204.0000 - fp: 57.0000 - tn: 387.0000 - fn: 64.0000 - accuracy: 0.8301 - precision: 0.7816 - recall: 0.7612 - auc: 0.8651 - val_loss: 0.4773 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8977\n",
      "Epoch 276/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4792 - tp: 205.0000 - fp: 61.0000 - tn: 383.0000 - fn: 63.0000 - accuracy: 0.8258 - precision: 0.7707 - recall: 0.7649 - auc: 0.8752 - val_loss: 0.4708 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8961\n",
      "Epoch 277/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4856 - tp: 201.0000 - fp: 56.0000 - tn: 388.0000 - fn: 67.0000 - accuracy: 0.8272 - precision: 0.7821 - recall: 0.7500 - auc: 0.8698 - val_loss: 0.4771 - val_tp: 60.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 14.0000 - val_accuracy: 0.8380 - val_precision: 0.8000 - val_recall: 0.8108 - val_auc: 0.8958\n",
      "Epoch 278/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4813 - tp: 200.0000 - fp: 50.0000 - tn: 394.0000 - fn: 68.0000 - accuracy: 0.8343 - precision: 0.8000 - recall: 0.7463 - auc: 0.8700 - val_loss: 0.4761 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8967\n",
      "Epoch 279/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4861 - tp: 205.0000 - fp: 63.0000 - tn: 381.0000 - fn: 63.0000 - accuracy: 0.8230 - precision: 0.7649 - recall: 0.7649 - auc: 0.8623 - val_loss: 0.4825 - val_tp: 54.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 20.0000 - val_accuracy: 0.8212 - val_precision: 0.8182 - val_recall: 0.7297 - val_auc: 0.8931\n",
      "Epoch 280/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4928 - tp: 193.0000 - fp: 45.0000 - tn: 399.0000 - fn: 75.0000 - accuracy: 0.8315 - precision: 0.8109 - recall: 0.7201 - auc: 0.8605 - val_loss: 0.4778 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8965\n",
      "Epoch 281/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4940 - tp: 204.0000 - fp: 63.0000 - tn: 381.0000 - fn: 64.0000 - accuracy: 0.8216 - precision: 0.7640 - recall: 0.7612 - auc: 0.8627 - val_loss: 0.4879 - val_tp: 56.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 18.0000 - val_accuracy: 0.8380 - val_precision: 0.8358 - val_recall: 0.7568 - val_auc: 0.8968\n",
      "Epoch 282/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5044 - tp: 205.0000 - fp: 52.0000 - tn: 392.0000 - fn: 63.0000 - accuracy: 0.8385 - precision: 0.7977 - recall: 0.7649 - auc: 0.8490 - val_loss: 0.4731 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8986\n",
      "Epoch 283/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4963 - tp: 204.0000 - fp: 49.0000 - tn: 395.0000 - fn: 64.0000 - accuracy: 0.8413 - precision: 0.8063 - recall: 0.7612 - auc: 0.8502 - val_loss: 0.4712 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8963\n",
      "Epoch 284/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4868 - tp: 201.0000 - fp: 52.0000 - tn: 392.0000 - fn: 67.0000 - accuracy: 0.8329 - precision: 0.7945 - recall: 0.7500 - auc: 0.8635 - val_loss: 0.4761 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8940\n",
      "Epoch 285/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5141 - tp: 205.0000 - fp: 63.0000 - tn: 381.0000 - fn: 63.0000 - accuracy: 0.8230 - precision: 0.7649 - recall: 0.7649 - auc: 0.8534 - val_loss: 0.4832 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8959\n",
      "Epoch 286/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4829 - tp: 205.0000 - fp: 56.0000 - tn: 388.0000 - fn: 63.0000 - accuracy: 0.8329 - precision: 0.7854 - recall: 0.7649 - auc: 0.8727 - val_loss: 0.4779 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8958\n",
      "Epoch 287/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4922 - tp: 201.0000 - fp: 57.0000 - tn: 387.0000 - fn: 67.0000 - accuracy: 0.8258 - precision: 0.7791 - recall: 0.7500 - auc: 0.8679 - val_loss: 0.4815 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8959\n",
      "Epoch 288/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4832 - tp: 202.0000 - fp: 45.0000 - tn: 399.0000 - fn: 66.0000 - accuracy: 0.8441 - precision: 0.8178 - recall: 0.7537 - auc: 0.8707 - val_loss: 0.4865 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8943\n",
      "Epoch 289/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4892 - tp: 199.0000 - fp: 54.0000 - tn: 390.0000 - fn: 69.0000 - accuracy: 0.8272 - precision: 0.7866 - recall: 0.7425 - auc: 0.8742 - val_loss: 0.4939 - val_tp: 64.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 10.0000 - val_accuracy: 0.7989 - val_precision: 0.7111 - val_recall: 0.8649 - val_auc: 0.8933\n",
      "Epoch 290/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4721 - tp: 202.0000 - fp: 50.0000 - tn: 394.0000 - fn: 66.0000 - accuracy: 0.8371 - precision: 0.8016 - recall: 0.7537 - auc: 0.8804 - val_loss: 0.4721 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8950\n",
      "Epoch 291/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4809 - tp: 206.0000 - fp: 54.0000 - tn: 390.0000 - fn: 62.0000 - accuracy: 0.8371 - precision: 0.7923 - recall: 0.7687 - auc: 0.8724 - val_loss: 0.4703 - val_tp: 61.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 13.0000 - val_accuracy: 0.8101 - val_precision: 0.7439 - val_recall: 0.8243 - val_auc: 0.8953\n",
      "Epoch 292/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.5035 - tp: 197.0000 - fp: 62.0000 - tn: 382.0000 - fn: 71.0000 - accuracy: 0.8132 - precision: 0.7606 - recall: 0.7351 - auc: 0.8566 - val_loss: 0.4683 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8994\n",
      "Epoch 293/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4856 - tp: 204.0000 - fp: 59.0000 - tn: 385.0000 - fn: 64.0000 - accuracy: 0.8272 - precision: 0.7757 - recall: 0.7612 - auc: 0.8688 - val_loss: 0.4727 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8987\n",
      "Epoch 294/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4864 - tp: 208.0000 - fp: 54.0000 - tn: 390.0000 - fn: 60.0000 - accuracy: 0.8399 - precision: 0.7939 - recall: 0.7761 - auc: 0.8634 - val_loss: 0.4744 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8948\n",
      "Epoch 295/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4930 - tp: 203.0000 - fp: 56.0000 - tn: 388.0000 - fn: 65.0000 - accuracy: 0.8301 - precision: 0.7838 - recall: 0.7575 - auc: 0.8606 - val_loss: 0.4827 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8969\n",
      "Epoch 296/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4881 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8668 - val_loss: 0.4815 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8923\n",
      "Epoch 297/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4794 - tp: 197.0000 - fp: 46.0000 - tn: 398.0000 - fn: 71.0000 - accuracy: 0.8357 - precision: 0.8107 - recall: 0.7351 - auc: 0.8757 - val_loss: 0.4783 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8949\n",
      "Epoch 298/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4812 - tp: 208.0000 - fp: 66.0000 - tn: 378.0000 - fn: 60.0000 - accuracy: 0.8230 - precision: 0.7591 - recall: 0.7761 - auc: 0.8720 - val_loss: 0.4747 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8956\n",
      "Epoch 299/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4820 - tp: 202.0000 - fp: 52.0000 - tn: 392.0000 - fn: 66.0000 - accuracy: 0.8343 - precision: 0.7953 - recall: 0.7537 - auc: 0.8676 - val_loss: 0.4738 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8983\n",
      "Epoch 300/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4847 - tp: 202.0000 - fp: 46.0000 - tn: 398.0000 - fn: 66.0000 - accuracy: 0.8427 - precision: 0.8145 - recall: 0.7537 - auc: 0.8664 - val_loss: 0.4792 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8944\n",
      "Epoch 301/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4915 - tp: 207.0000 - fp: 60.0000 - tn: 384.0000 - fn: 61.0000 - accuracy: 0.8301 - precision: 0.7753 - recall: 0.7724 - auc: 0.8677 - val_loss: 0.4745 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8934\n",
      "Epoch 302/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4813 - tp: 201.0000 - fp: 42.0000 - tn: 402.0000 - fn: 67.0000 - accuracy: 0.8469 - precision: 0.8272 - recall: 0.7500 - auc: 0.8736 - val_loss: 0.4776 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8954\n",
      "Epoch 303/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4846 - tp: 193.0000 - fp: 47.0000 - tn: 397.0000 - fn: 75.0000 - accuracy: 0.8287 - precision: 0.8042 - recall: 0.7201 - auc: 0.8725 - val_loss: 0.4694 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8978\n",
      "Epoch 304/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4882 - tp: 198.0000 - fp: 53.0000 - tn: 391.0000 - fn: 70.0000 - accuracy: 0.8272 - precision: 0.7888 - recall: 0.7388 - auc: 0.8726 - val_loss: 0.4748 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8986\n",
      "Epoch 305/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4837 - tp: 205.0000 - fp: 47.0000 - tn: 397.0000 - fn: 63.0000 - accuracy: 0.8455 - precision: 0.8135 - recall: 0.7649 - auc: 0.8684 - val_loss: 0.4728 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8973\n",
      "Epoch 306/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4895 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8713 - val_loss: 0.4698 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8972\n",
      "Epoch 307/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4881 - tp: 197.0000 - fp: 52.0000 - tn: 392.0000 - fn: 71.0000 - accuracy: 0.8272 - precision: 0.7912 - recall: 0.7351 - auc: 0.8666 - val_loss: 0.4821 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8949\n",
      "Epoch 308/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4860 - tp: 204.0000 - fp: 61.0000 - tn: 383.0000 - fn: 64.0000 - accuracy: 0.8244 - precision: 0.7698 - recall: 0.7612 - auc: 0.8630 - val_loss: 0.4729 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8995\n",
      "Epoch 309/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4777 - tp: 207.0000 - fp: 60.0000 - tn: 384.0000 - fn: 61.0000 - accuracy: 0.8301 - precision: 0.7753 - recall: 0.7724 - auc: 0.8810 - val_loss: 0.4834 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8974\n",
      "Epoch 310/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4956 - tp: 198.0000 - fp: 46.0000 - tn: 398.0000 - fn: 70.0000 - accuracy: 0.8371 - precision: 0.8115 - recall: 0.7388 - auc: 0.8642 - val_loss: 0.4689 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8951\n",
      "Epoch 311/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4810 - tp: 207.0000 - fp: 62.0000 - tn: 382.0000 - fn: 61.0000 - accuracy: 0.8272 - precision: 0.7695 - recall: 0.7724 - auc: 0.8690 - val_loss: 0.4722 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8955\n",
      "Epoch 312/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4899 - tp: 197.0000 - fp: 52.0000 - tn: 392.0000 - fn: 71.0000 - accuracy: 0.8272 - precision: 0.7912 - recall: 0.7351 - auc: 0.8675 - val_loss: 0.4744 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8943\n",
      "Epoch 313/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5005 - tp: 193.0000 - fp: 50.0000 - tn: 394.0000 - fn: 75.0000 - accuracy: 0.8244 - precision: 0.7942 - recall: 0.7201 - auc: 0.8535 - val_loss: 0.4809 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8938\n",
      "Epoch 314/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4828 - tp: 202.0000 - fp: 49.0000 - tn: 395.0000 - fn: 66.0000 - accuracy: 0.8385 - precision: 0.8048 - recall: 0.7537 - auc: 0.8685 - val_loss: 0.4770 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8930\n",
      "Epoch 315/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4907 - tp: 202.0000 - fp: 57.0000 - tn: 387.0000 - fn: 66.0000 - accuracy: 0.8272 - precision: 0.7799 - recall: 0.7537 - auc: 0.8638 - val_loss: 0.4898 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8970\n",
      "Epoch 316/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4980 - tp: 199.0000 - fp: 47.0000 - tn: 397.0000 - fn: 69.0000 - accuracy: 0.8371 - precision: 0.8089 - recall: 0.7425 - auc: 0.8579 - val_loss: 0.4738 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8976\n",
      "Epoch 317/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4803 - tp: 203.0000 - fp: 49.0000 - tn: 395.0000 - fn: 65.0000 - accuracy: 0.8399 - precision: 0.8056 - recall: 0.7575 - auc: 0.8755 - val_loss: 0.4753 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8959\n",
      "Epoch 318/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4997 - tp: 205.0000 - fp: 59.0000 - tn: 385.0000 - fn: 63.0000 - accuracy: 0.8287 - precision: 0.7765 - recall: 0.7649 - auc: 0.8530 - val_loss: 0.4804 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8962\n",
      "Epoch 319/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5031 - tp: 186.0000 - fp: 47.0000 - tn: 397.0000 - fn: 82.0000 - accuracy: 0.8188 - precision: 0.7983 - recall: 0.6940 - auc: 0.8681 - val_loss: 0.4720 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8970\n",
      "Epoch 320/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4825 - tp: 207.0000 - fp: 63.0000 - tn: 381.0000 - fn: 61.0000 - accuracy: 0.8258 - precision: 0.7667 - recall: 0.7724 - auc: 0.8680 - val_loss: 0.4690 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8969\n",
      "Epoch 321/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4810 - tp: 200.0000 - fp: 59.0000 - tn: 385.0000 - fn: 68.0000 - accuracy: 0.8216 - precision: 0.7722 - recall: 0.7463 - auc: 0.8719 - val_loss: 0.4723 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.9001\n",
      "Epoch 322/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4862 - tp: 195.0000 - fp: 47.0000 - tn: 397.0000 - fn: 73.0000 - accuracy: 0.8315 - precision: 0.8058 - recall: 0.7276 - auc: 0.8672 - val_loss: 0.4761 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8981\n",
      "Epoch 323/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4812 - tp: 205.0000 - fp: 60.0000 - tn: 384.0000 - fn: 63.0000 - accuracy: 0.8272 - precision: 0.7736 - recall: 0.7649 - auc: 0.8731 - val_loss: 0.4707 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8948\n",
      "Epoch 324/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4868 - tp: 204.0000 - fp: 51.0000 - tn: 393.0000 - fn: 64.0000 - accuracy: 0.8385 - precision: 0.8000 - recall: 0.7612 - auc: 0.8694 - val_loss: 0.4719 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8981\n",
      "Epoch 325/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4868 - tp: 203.0000 - fp: 51.0000 - tn: 393.0000 - fn: 65.0000 - accuracy: 0.8371 - precision: 0.7992 - recall: 0.7575 - auc: 0.8697 - val_loss: 0.4758 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8950\n",
      "Epoch 326/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4715 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8779 - val_loss: 0.4699 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8961\n",
      "Epoch 327/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4741 - tp: 204.0000 - fp: 46.0000 - tn: 398.0000 - fn: 64.0000 - accuracy: 0.8455 - precision: 0.8160 - recall: 0.7612 - auc: 0.8720 - val_loss: 0.4736 - val_tp: 62.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 12.0000 - val_accuracy: 0.8045 - val_precision: 0.7294 - val_recall: 0.8378 - val_auc: 0.8958\n",
      "Epoch 328/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.4866 - tp: 205.0000 - fp: 57.0000 - tn: 387.0000 - fn: 63.0000 - accuracy: 0.8315 - precision: 0.7824 - recall: 0.7649 - auc: 0.8704 - val_loss: 0.4624 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8973\n",
      "Epoch 329/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5043 - tp: 198.0000 - fp: 49.0000 - tn: 395.0000 - fn: 70.0000 - accuracy: 0.8329 - precision: 0.8016 - recall: 0.7388 - auc: 0.8546 - val_loss: 0.4674 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.9001\n",
      "Epoch 330/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4679 - tp: 205.0000 - fp: 57.0000 - tn: 387.0000 - fn: 63.0000 - accuracy: 0.8315 - precision: 0.7824 - recall: 0.7649 - auc: 0.8783 - val_loss: 0.4708 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8961\n",
      "Epoch 331/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4902 - tp: 196.0000 - fp: 56.0000 - tn: 388.0000 - fn: 72.0000 - accuracy: 0.8202 - precision: 0.7778 - recall: 0.7313 - auc: 0.8606 - val_loss: 0.4681 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8974\n",
      "Epoch 332/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4874 - tp: 209.0000 - fp: 55.0000 - tn: 389.0000 - fn: 59.0000 - accuracy: 0.8399 - precision: 0.7917 - recall: 0.7799 - auc: 0.8657 - val_loss: 0.4791 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8960\n",
      "Epoch 333/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4937 - tp: 200.0000 - fp: 58.0000 - tn: 386.0000 - fn: 68.0000 - accuracy: 0.8230 - precision: 0.7752 - recall: 0.7463 - auc: 0.8600 - val_loss: 0.4743 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8983\n",
      "Epoch 334/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4768 - tp: 203.0000 - fp: 50.0000 - tn: 394.0000 - fn: 65.0000 - accuracy: 0.8385 - precision: 0.8024 - recall: 0.7575 - auc: 0.8776 - val_loss: 0.4679 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8987\n",
      "Epoch 335/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4837 - tp: 202.0000 - fp: 49.0000 - tn: 395.0000 - fn: 66.0000 - accuracy: 0.8385 - precision: 0.8048 - recall: 0.7537 - auc: 0.8613 - val_loss: 0.4716 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8961\n",
      "Epoch 336/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4879 - tp: 199.0000 - fp: 51.0000 - tn: 393.0000 - fn: 69.0000 - accuracy: 0.8315 - precision: 0.7960 - recall: 0.7425 - auc: 0.8653 - val_loss: 0.4695 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8981\n",
      "Epoch 337/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4915 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8596 - val_loss: 0.4734 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8958\n",
      "Epoch 338/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4853 - tp: 202.0000 - fp: 56.0000 - tn: 388.0000 - fn: 66.0000 - accuracy: 0.8287 - precision: 0.7829 - recall: 0.7537 - auc: 0.8642 - val_loss: 0.4790 - val_tp: 61.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 13.0000 - val_accuracy: 0.8156 - val_precision: 0.7531 - val_recall: 0.8243 - val_auc: 0.8954\n",
      "Epoch 339/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4869 - tp: 197.0000 - fp: 57.0000 - tn: 387.0000 - fn: 71.0000 - accuracy: 0.8202 - precision: 0.7756 - recall: 0.7351 - auc: 0.8734 - val_loss: 0.4713 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.9044\n",
      "Epoch 340/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5064 - tp: 192.0000 - fp: 51.0000 - tn: 393.0000 - fn: 76.0000 - accuracy: 0.8216 - precision: 0.7901 - recall: 0.7164 - auc: 0.8518 - val_loss: 0.4715 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8950\n",
      "Epoch 341/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4846 - tp: 204.0000 - fp: 47.0000 - tn: 397.0000 - fn: 64.0000 - accuracy: 0.8441 - precision: 0.8127 - recall: 0.7612 - auc: 0.8658 - val_loss: 0.4831 - val_tp: 68.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 6.0000 - val_accuracy: 0.8156 - val_precision: 0.7158 - val_recall: 0.9189 - val_auc: 0.8958\n",
      "Epoch 342/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4874 - tp: 196.0000 - fp: 51.0000 - tn: 393.0000 - fn: 72.0000 - accuracy: 0.8272 - precision: 0.7935 - recall: 0.7313 - auc: 0.8658 - val_loss: 0.4766 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8954\n",
      "Epoch 343/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4835 - tp: 204.0000 - fp: 61.0000 - tn: 383.0000 - fn: 64.0000 - accuracy: 0.8244 - precision: 0.7698 - recall: 0.7612 - auc: 0.8707 - val_loss: 0.4795 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8936\n",
      "Epoch 344/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4841 - tp: 198.0000 - fp: 48.0000 - tn: 396.0000 - fn: 70.0000 - accuracy: 0.8343 - precision: 0.8049 - recall: 0.7388 - auc: 0.8740 - val_loss: 0.4787 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8968\n",
      "Epoch 345/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4864 - tp: 207.0000 - fp: 53.0000 - tn: 391.0000 - fn: 61.0000 - accuracy: 0.8399 - precision: 0.7962 - recall: 0.7724 - auc: 0.8627 - val_loss: 0.4658 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.9003\n",
      "Epoch 346/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4898 - tp: 196.0000 - fp: 47.0000 - tn: 397.0000 - fn: 72.0000 - accuracy: 0.8329 - precision: 0.8066 - recall: 0.7313 - auc: 0.8759 - val_loss: 0.4794 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8955\n",
      "Epoch 347/500\n",
      "712/712 [==============================] - 0s 205us/sample - loss: 0.4825 - tp: 201.0000 - fp: 57.0000 - tn: 387.0000 - fn: 67.0000 - accuracy: 0.8258 - precision: 0.7791 - recall: 0.7500 - auc: 0.8652 - val_loss: 0.4750 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8964\n",
      "Epoch 348/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4914 - tp: 204.0000 - fp: 54.0000 - tn: 390.0000 - fn: 64.0000 - accuracy: 0.8343 - precision: 0.7907 - recall: 0.7612 - auc: 0.8650 - val_loss: 0.4661 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.9000\n",
      "Epoch 349/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4799 - tp: 189.0000 - fp: 36.0000 - tn: 408.0000 - fn: 79.0000 - accuracy: 0.8385 - precision: 0.8400 - recall: 0.7052 - auc: 0.8861 - val_loss: 0.4723 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8949\n",
      "Epoch 350/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4983 - tp: 205.0000 - fp: 64.0000 - tn: 380.0000 - fn: 63.0000 - accuracy: 0.8216 - precision: 0.7621 - recall: 0.7649 - auc: 0.8630 - val_loss: 0.4662 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8974\n",
      "Epoch 351/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4794 - tp: 197.0000 - fp: 41.0000 - tn: 403.0000 - fn: 71.0000 - accuracy: 0.8427 - precision: 0.8277 - recall: 0.7351 - auc: 0.8768 - val_loss: 0.4668 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8974\n",
      "Epoch 352/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4863 - tp: 210.0000 - fp: 71.0000 - tn: 373.0000 - fn: 58.0000 - accuracy: 0.8188 - precision: 0.7473 - recall: 0.7836 - auc: 0.8678 - val_loss: 0.4761 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8964\n",
      "Epoch 353/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4973 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8665 - val_loss: 0.4753 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8958\n",
      "Epoch 354/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.4710 - tp: 205.0000 - fp: 53.0000 - tn: 391.0000 - fn: 63.0000 - accuracy: 0.8371 - precision: 0.7946 - recall: 0.7649 - auc: 0.8836 - val_loss: 0.4753 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8935\n",
      "Epoch 355/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4971 - tp: 200.0000 - fp: 51.0000 - tn: 393.0000 - fn: 68.0000 - accuracy: 0.8329 - precision: 0.7968 - recall: 0.7463 - auc: 0.8604 - val_loss: 0.4838 - val_tp: 61.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 13.0000 - val_accuracy: 0.8156 - val_precision: 0.7531 - val_recall: 0.8243 - val_auc: 0.8936\n",
      "Epoch 356/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4785 - tp: 198.0000 - fp: 63.0000 - tn: 381.0000 - fn: 70.0000 - accuracy: 0.8132 - precision: 0.7586 - recall: 0.7388 - auc: 0.8751 - val_loss: 0.4758 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8949\n",
      "Epoch 357/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4796 - tp: 203.0000 - fp: 50.0000 - tn: 394.0000 - fn: 65.0000 - accuracy: 0.8385 - precision: 0.8024 - recall: 0.7575 - auc: 0.8689 - val_loss: 0.4753 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8954\n",
      "Epoch 358/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4933 - tp: 198.0000 - fp: 48.0000 - tn: 396.0000 - fn: 70.0000 - accuracy: 0.8343 - precision: 0.8049 - recall: 0.7388 - auc: 0.8694 - val_loss: 0.5046 - val_tp: 68.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 6.0000 - val_accuracy: 0.7877 - val_precision: 0.6800 - val_recall: 0.9189 - val_auc: 0.8932\n",
      "Epoch 359/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4887 - tp: 195.0000 - fp: 55.0000 - tn: 389.0000 - fn: 73.0000 - accuracy: 0.8202 - precision: 0.7800 - recall: 0.7276 - auc: 0.8688 - val_loss: 0.4714 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8957\n",
      "Epoch 360/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4874 - tp: 205.0000 - fp: 59.0000 - tn: 385.0000 - fn: 63.0000 - accuracy: 0.8287 - precision: 0.7765 - recall: 0.7649 - auc: 0.8725 - val_loss: 0.4640 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8995\n",
      "Epoch 361/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4922 - tp: 200.0000 - fp: 49.0000 - tn: 395.0000 - fn: 68.0000 - accuracy: 0.8357 - precision: 0.8032 - recall: 0.7463 - auc: 0.8637 - val_loss: 0.4662 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8976\n",
      "Epoch 362/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4947 - tp: 191.0000 - fp: 54.0000 - tn: 390.0000 - fn: 77.0000 - accuracy: 0.8160 - precision: 0.7796 - recall: 0.7127 - auc: 0.8588 - val_loss: 0.4695 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8944\n",
      "Epoch 363/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4841 - tp: 198.0000 - fp: 57.0000 - tn: 387.0000 - fn: 70.0000 - accuracy: 0.8216 - precision: 0.7765 - recall: 0.7388 - auc: 0.8716 - val_loss: 0.4760 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8923\n",
      "Epoch 364/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4829 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8688 - val_loss: 0.4768 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8962\n",
      "Epoch 365/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4771 - tp: 203.0000 - fp: 53.0000 - tn: 391.0000 - fn: 65.0000 - accuracy: 0.8343 - precision: 0.7930 - recall: 0.7575 - auc: 0.8711 - val_loss: 0.4792 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8931\n",
      "Epoch 366/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4777 - tp: 207.0000 - fp: 48.0000 - tn: 396.0000 - fn: 61.0000 - accuracy: 0.8469 - precision: 0.8118 - recall: 0.7724 - auc: 0.8698 - val_loss: 0.4862 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8932\n",
      "Epoch 367/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4684 - tp: 206.0000 - fp: 57.0000 - tn: 387.0000 - fn: 62.0000 - accuracy: 0.8329 - precision: 0.7833 - recall: 0.7687 - auc: 0.8788 - val_loss: 0.4821 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8956\n",
      "Epoch 368/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4924 - tp: 197.0000 - fp: 43.0000 - tn: 401.0000 - fn: 71.0000 - accuracy: 0.8399 - precision: 0.8208 - recall: 0.7351 - auc: 0.8602 - val_loss: 0.4836 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8947\n",
      "Epoch 369/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4794 - tp: 195.0000 - fp: 54.0000 - tn: 390.0000 - fn: 73.0000 - accuracy: 0.8216 - precision: 0.7831 - recall: 0.7276 - auc: 0.8740 - val_loss: 0.4661 - val_tp: 62.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 12.0000 - val_accuracy: 0.8156 - val_precision: 0.7470 - val_recall: 0.8378 - val_auc: 0.8921\n",
      "Epoch 370/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4828 - tp: 210.0000 - fp: 67.0000 - tn: 377.0000 - fn: 58.0000 - accuracy: 0.8244 - precision: 0.7581 - recall: 0.7836 - auc: 0.8676 - val_loss: 0.4669 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8929\n",
      "Epoch 371/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4901 - tp: 198.0000 - fp: 44.0000 - tn: 400.0000 - fn: 70.0000 - accuracy: 0.8399 - precision: 0.8182 - recall: 0.7388 - auc: 0.8635 - val_loss: 0.4945 - val_tp: 65.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 9.0000 - val_accuracy: 0.7877 - val_precision: 0.6915 - val_recall: 0.8784 - val_auc: 0.8918\n",
      "Epoch 372/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4991 - tp: 205.0000 - fp: 64.0000 - tn: 380.0000 - fn: 63.0000 - accuracy: 0.8216 - precision: 0.7621 - recall: 0.7649 - auc: 0.8709 - val_loss: 0.4636 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8909\n",
      "Epoch 373/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4785 - tp: 202.0000 - fp: 56.0000 - tn: 388.0000 - fn: 66.0000 - accuracy: 0.8287 - precision: 0.7829 - recall: 0.7537 - auc: 0.8705 - val_loss: 0.4710 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8976\n",
      "Epoch 374/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4910 - tp: 204.0000 - fp: 54.0000 - tn: 390.0000 - fn: 64.0000 - accuracy: 0.8343 - precision: 0.7907 - recall: 0.7612 - auc: 0.8577 - val_loss: 0.4755 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8976\n",
      "Epoch 375/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4851 - tp: 199.0000 - fp: 45.0000 - tn: 399.0000 - fn: 69.0000 - accuracy: 0.8399 - precision: 0.8156 - recall: 0.7425 - auc: 0.8685 - val_loss: 0.4737 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8956\n",
      "Epoch 376/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4791 - tp: 202.0000 - fp: 54.0000 - tn: 390.0000 - fn: 66.0000 - accuracy: 0.8315 - precision: 0.7891 - recall: 0.7537 - auc: 0.8701 - val_loss: 0.4765 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8977\n",
      "Epoch 377/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4970 - tp: 194.0000 - fp: 50.0000 - tn: 394.0000 - fn: 74.0000 - accuracy: 0.8258 - precision: 0.7951 - recall: 0.7239 - auc: 0.8633 - val_loss: 0.4845 - val_tp: 54.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 20.0000 - val_accuracy: 0.8268 - val_precision: 0.8308 - val_recall: 0.7297 - val_auc: 0.8999\n",
      "Epoch 378/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4972 - tp: 201.0000 - fp: 70.0000 - tn: 374.0000 - fn: 67.0000 - accuracy: 0.8076 - precision: 0.7417 - recall: 0.7500 - auc: 0.8617 - val_loss: 0.4683 - val_tp: 59.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 15.0000 - val_accuracy: 0.8436 - val_precision: 0.8194 - val_recall: 0.7973 - val_auc: 0.8986\n",
      "Epoch 379/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.4840 - tp: 208.0000 - fp: 55.0000 - tn: 389.0000 - fn: 60.0000 - accuracy: 0.8385 - precision: 0.7909 - recall: 0.7761 - auc: 0.8717 - val_loss: 0.4678 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8953\n",
      "Epoch 380/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4775 - tp: 202.0000 - fp: 46.0000 - tn: 398.0000 - fn: 66.0000 - accuracy: 0.8427 - precision: 0.8145 - recall: 0.7537 - auc: 0.8732 - val_loss: 0.4855 - val_tp: 64.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 10.0000 - val_accuracy: 0.7877 - val_precision: 0.6957 - val_recall: 0.8649 - val_auc: 0.8939\n",
      "Epoch 381/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4956 - tp: 196.0000 - fp: 52.0000 - tn: 392.0000 - fn: 72.0000 - accuracy: 0.8258 - precision: 0.7903 - recall: 0.7313 - auc: 0.8640 - val_loss: 0.4829 - val_tp: 64.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 10.0000 - val_accuracy: 0.8045 - val_precision: 0.7191 - val_recall: 0.8649 - val_auc: 0.8966\n",
      "Epoch 382/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4951 - tp: 203.0000 - fp: 62.0000 - tn: 382.0000 - fn: 65.0000 - accuracy: 0.8216 - precision: 0.7660 - recall: 0.7575 - auc: 0.8628 - val_loss: 0.4730 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8976\n",
      "Epoch 383/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5025 - tp: 206.0000 - fp: 53.0000 - tn: 391.0000 - fn: 62.0000 - accuracy: 0.8385 - precision: 0.7954 - recall: 0.7687 - auc: 0.8575 - val_loss: 0.4720 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8968\n",
      "Epoch 384/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4858 - tp: 204.0000 - fp: 57.0000 - tn: 387.0000 - fn: 64.0000 - accuracy: 0.8301 - precision: 0.7816 - recall: 0.7612 - auc: 0.8671 - val_loss: 0.4736 - val_tp: 60.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 14.0000 - val_accuracy: 0.8380 - val_precision: 0.8000 - val_recall: 0.8108 - val_auc: 0.8953\n",
      "Epoch 385/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4835 - tp: 206.0000 - fp: 50.0000 - tn: 394.0000 - fn: 62.0000 - accuracy: 0.8427 - precision: 0.8047 - recall: 0.7687 - auc: 0.8675 - val_loss: 0.4723 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8983\n",
      "Epoch 386/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4762 - tp: 204.0000 - fp: 51.0000 - tn: 393.0000 - fn: 64.0000 - accuracy: 0.8385 - precision: 0.8000 - recall: 0.7612 - auc: 0.8689 - val_loss: 0.4746 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8952\n",
      "Epoch 387/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4664 - tp: 209.0000 - fp: 67.0000 - tn: 377.0000 - fn: 59.0000 - accuracy: 0.8230 - precision: 0.7572 - recall: 0.7799 - auc: 0.8847 - val_loss: 0.4788 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8922\n",
      "Epoch 388/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4701 - tp: 204.0000 - fp: 51.0000 - tn: 393.0000 - fn: 64.0000 - accuracy: 0.8385 - precision: 0.8000 - recall: 0.7612 - auc: 0.8866 - val_loss: 0.4683 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8979\n",
      "Epoch 389/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4868 - tp: 191.0000 - fp: 52.0000 - tn: 392.0000 - fn: 77.0000 - accuracy: 0.8188 - precision: 0.7860 - recall: 0.7127 - auc: 0.8656 - val_loss: 0.4627 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8974\n",
      "Epoch 390/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4800 - tp: 202.0000 - fp: 51.0000 - tn: 393.0000 - fn: 66.0000 - accuracy: 0.8357 - precision: 0.7984 - recall: 0.7537 - auc: 0.8700 - val_loss: 0.4704 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8955\n",
      "Epoch 391/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4839 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8710 - val_loss: 0.4729 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8959\n",
      "Epoch 392/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4856 - tp: 199.0000 - fp: 56.0000 - tn: 388.0000 - fn: 69.0000 - accuracy: 0.8244 - precision: 0.7804 - recall: 0.7425 - auc: 0.8730 - val_loss: 0.4677 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8926\n",
      "Epoch 393/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4927 - tp: 198.0000 - fp: 55.0000 - tn: 389.0000 - fn: 70.0000 - accuracy: 0.8244 - precision: 0.7826 - recall: 0.7388 - auc: 0.8633 - val_loss: 0.4702 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8982\n",
      "Epoch 394/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4762 - tp: 214.0000 - fp: 74.0000 - tn: 370.0000 - fn: 54.0000 - accuracy: 0.8202 - precision: 0.7431 - recall: 0.7985 - auc: 0.8742 - val_loss: 0.4759 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8939\n",
      "Epoch 395/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4875 - tp: 199.0000 - fp: 50.0000 - tn: 394.0000 - fn: 69.0000 - accuracy: 0.8329 - precision: 0.7992 - recall: 0.7425 - auc: 0.8703 - val_loss: 0.4751 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8961\n",
      "Epoch 396/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4875 - tp: 203.0000 - fp: 50.0000 - tn: 394.0000 - fn: 65.0000 - accuracy: 0.8385 - precision: 0.8024 - recall: 0.7575 - auc: 0.8679 - val_loss: 0.4696 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8942\n",
      "Epoch 397/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4805 - tp: 202.0000 - fp: 63.0000 - tn: 381.0000 - fn: 66.0000 - accuracy: 0.8188 - precision: 0.7623 - recall: 0.7537 - auc: 0.8669 - val_loss: 0.4688 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8956\n",
      "Epoch 398/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4812 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8733 - val_loss: 0.4643 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8982\n",
      "Epoch 399/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4810 - tp: 194.0000 - fp: 48.0000 - tn: 396.0000 - fn: 74.0000 - accuracy: 0.8287 - precision: 0.8017 - recall: 0.7239 - auc: 0.8657 - val_loss: 0.4755 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8956\n",
      "Epoch 400/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4935 - tp: 203.0000 - fp: 64.0000 - tn: 380.0000 - fn: 65.0000 - accuracy: 0.8188 - precision: 0.7603 - recall: 0.7575 - auc: 0.8642 - val_loss: 0.4749 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8947\n",
      "Epoch 401/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4858 - tp: 193.0000 - fp: 50.0000 - tn: 394.0000 - fn: 75.0000 - accuracy: 0.8244 - precision: 0.7942 - recall: 0.7201 - auc: 0.8690 - val_loss: 0.4703 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8996\n",
      "Epoch 402/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4665 - tp: 206.0000 - fp: 51.0000 - tn: 393.0000 - fn: 62.0000 - accuracy: 0.8413 - precision: 0.8016 - recall: 0.7687 - auc: 0.8827 - val_loss: 0.4725 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8932\n",
      "Epoch 403/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4918 - tp: 199.0000 - fp: 42.0000 - tn: 402.0000 - fn: 69.0000 - accuracy: 0.8441 - precision: 0.8257 - recall: 0.7425 - auc: 0.8613 - val_loss: 0.4864 - val_tp: 64.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 10.0000 - val_accuracy: 0.7989 - val_precision: 0.7111 - val_recall: 0.8649 - val_auc: 0.8954\n",
      "Epoch 404/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4947 - tp: 201.0000 - fp: 57.0000 - tn: 387.0000 - fn: 67.0000 - accuracy: 0.8258 - precision: 0.7791 - recall: 0.7500 - auc: 0.8632 - val_loss: 0.4661 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8957\n",
      "Epoch 405/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4918 - tp: 200.0000 - fp: 49.0000 - tn: 395.0000 - fn: 68.0000 - accuracy: 0.8357 - precision: 0.8032 - recall: 0.7463 - auc: 0.8574 - val_loss: 0.4745 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8977\n",
      "Epoch 406/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4785 - tp: 212.0000 - fp: 51.0000 - tn: 393.0000 - fn: 56.0000 - accuracy: 0.8497 - precision: 0.8061 - recall: 0.7910 - auc: 0.8707 - val_loss: 0.4876 - val_tp: 54.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 20.0000 - val_accuracy: 0.8212 - val_precision: 0.8182 - val_recall: 0.7297 - val_auc: 0.8909\n",
      "Epoch 407/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4852 - tp: 198.0000 - fp: 46.0000 - tn: 398.0000 - fn: 70.0000 - accuracy: 0.8371 - precision: 0.8115 - recall: 0.7388 - auc: 0.8692 - val_loss: 0.4749 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8940\n",
      "Epoch 408/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4716 - tp: 200.0000 - fp: 54.0000 - tn: 390.0000 - fn: 68.0000 - accuracy: 0.8287 - precision: 0.7874 - recall: 0.7463 - auc: 0.8818 - val_loss: 0.4681 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8993\n",
      "Epoch 409/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4800 - tp: 206.0000 - fp: 52.0000 - tn: 392.0000 - fn: 62.0000 - accuracy: 0.8399 - precision: 0.7984 - recall: 0.7687 - auc: 0.8735 - val_loss: 0.4594 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8961\n",
      "Epoch 410/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4847 - tp: 202.0000 - fp: 53.0000 - tn: 391.0000 - fn: 66.0000 - accuracy: 0.8329 - precision: 0.7922 - recall: 0.7537 - auc: 0.8707 - val_loss: 0.4709 - val_tp: 65.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 9.0000 - val_accuracy: 0.8101 - val_precision: 0.7222 - val_recall: 0.8784 - val_auc: 0.8976\n",
      "Epoch 411/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4888 - tp: 211.0000 - fp: 69.0000 - tn: 375.0000 - fn: 57.0000 - accuracy: 0.8230 - precision: 0.7536 - recall: 0.7873 - auc: 0.8709 - val_loss: 0.4655 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8961\n",
      "Epoch 412/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4951 - tp: 205.0000 - fp: 67.0000 - tn: 377.0000 - fn: 63.0000 - accuracy: 0.8174 - precision: 0.7537 - recall: 0.7649 - auc: 0.8600 - val_loss: 0.4748 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8945\n",
      "Epoch 413/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4937 - tp: 194.0000 - fp: 46.0000 - tn: 398.0000 - fn: 74.0000 - accuracy: 0.8315 - precision: 0.8083 - recall: 0.7239 - auc: 0.8687 - val_loss: 0.4735 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8986\n",
      "Epoch 414/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4754 - tp: 197.0000 - fp: 45.0000 - tn: 399.0000 - fn: 71.0000 - accuracy: 0.8371 - precision: 0.8140 - recall: 0.7351 - auc: 0.8765 - val_loss: 0.4778 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8956\n",
      "Epoch 415/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4898 - tp: 201.0000 - fp: 62.0000 - tn: 382.0000 - fn: 67.0000 - accuracy: 0.8188 - precision: 0.7643 - recall: 0.7500 - auc: 0.8630 - val_loss: 0.4683 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8977\n",
      "Epoch 416/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4781 - tp: 198.0000 - fp: 55.0000 - tn: 389.0000 - fn: 70.0000 - accuracy: 0.8244 - precision: 0.7826 - recall: 0.7388 - auc: 0.8746 - val_loss: 0.4778 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8918\n",
      "Epoch 417/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4900 - tp: 201.0000 - fp: 47.0000 - tn: 397.0000 - fn: 67.0000 - accuracy: 0.8399 - precision: 0.8105 - recall: 0.7500 - auc: 0.8698 - val_loss: 0.4821 - val_tp: 64.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 10.0000 - val_accuracy: 0.8101 - val_precision: 0.7273 - val_recall: 0.8649 - val_auc: 0.8941\n",
      "Epoch 418/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4875 - tp: 194.0000 - fp: 49.0000 - tn: 395.0000 - fn: 74.0000 - accuracy: 0.8272 - precision: 0.7984 - recall: 0.7239 - auc: 0.8710 - val_loss: 0.4705 - val_tp: 64.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 10.0000 - val_accuracy: 0.8045 - val_precision: 0.7191 - val_recall: 0.8649 - val_auc: 0.8988\n",
      "Epoch 419/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4984 - tp: 197.0000 - fp: 50.0000 - tn: 394.0000 - fn: 71.0000 - accuracy: 0.8301 - precision: 0.7976 - recall: 0.7351 - auc: 0.8608 - val_loss: 0.4690 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8974\n",
      "Epoch 420/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4741 - tp: 204.0000 - fp: 56.0000 - tn: 388.0000 - fn: 64.0000 - accuracy: 0.8315 - precision: 0.7846 - recall: 0.7612 - auc: 0.8744 - val_loss: 0.4835 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8947\n",
      "Epoch 421/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4901 - tp: 195.0000 - fp: 51.0000 - tn: 393.0000 - fn: 73.0000 - accuracy: 0.8258 - precision: 0.7927 - recall: 0.7276 - auc: 0.8644 - val_loss: 0.4716 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8981\n",
      "Epoch 422/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4961 - tp: 197.0000 - fp: 55.0000 - tn: 389.0000 - fn: 71.0000 - accuracy: 0.8230 - precision: 0.7817 - recall: 0.7351 - auc: 0.8606 - val_loss: 0.4756 - val_tp: 61.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 13.0000 - val_accuracy: 0.7989 - val_precision: 0.7262 - val_recall: 0.8243 - val_auc: 0.8967\n",
      "Epoch 423/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4807 - tp: 202.0000 - fp: 47.0000 - tn: 397.0000 - fn: 66.0000 - accuracy: 0.8413 - precision: 0.8112 - recall: 0.7537 - auc: 0.8723 - val_loss: 0.4827 - val_tp: 63.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 11.0000 - val_accuracy: 0.7989 - val_precision: 0.7159 - val_recall: 0.8514 - val_auc: 0.8931\n",
      "Epoch 424/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4851 - tp: 210.0000 - fp: 56.0000 - tn: 388.0000 - fn: 58.0000 - accuracy: 0.8399 - precision: 0.7895 - recall: 0.7836 - auc: 0.8688 - val_loss: 0.4658 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8932\n",
      "Epoch 425/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4777 - tp: 207.0000 - fp: 59.0000 - tn: 385.0000 - fn: 61.0000 - accuracy: 0.8315 - precision: 0.7782 - recall: 0.7724 - auc: 0.8773 - val_loss: 0.4617 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8959\n",
      "Epoch 426/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4748 - tp: 203.0000 - fp: 44.0000 - tn: 400.0000 - fn: 65.0000 - accuracy: 0.8469 - precision: 0.8219 - recall: 0.7575 - auc: 0.8703 - val_loss: 0.4804 - val_tp: 68.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 6.0000 - val_accuracy: 0.8101 - val_precision: 0.7083 - val_recall: 0.9189 - val_auc: 0.8969\n",
      "Epoch 427/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4916 - tp: 205.0000 - fp: 75.0000 - tn: 369.0000 - fn: 63.0000 - accuracy: 0.8062 - precision: 0.7321 - recall: 0.7649 - auc: 0.8669 - val_loss: 0.4650 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8988\n",
      "Epoch 428/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4746 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8765 - val_loss: 0.4612 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.9015\n",
      "Epoch 429/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4938 - tp: 203.0000 - fp: 62.0000 - tn: 382.0000 - fn: 65.0000 - accuracy: 0.8216 - precision: 0.7660 - recall: 0.7575 - auc: 0.8613 - val_loss: 0.4606 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8979\n",
      "Epoch 430/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4740 - tp: 200.0000 - fp: 49.0000 - tn: 395.0000 - fn: 68.0000 - accuracy: 0.8357 - precision: 0.8032 - recall: 0.7463 - auc: 0.8711 - val_loss: 0.4650 - val_tp: 63.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 11.0000 - val_accuracy: 0.8212 - val_precision: 0.7500 - val_recall: 0.8514 - val_auc: 0.9005\n",
      "Epoch 431/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4736 - tp: 205.0000 - fp: 56.0000 - tn: 388.0000 - fn: 63.0000 - accuracy: 0.8329 - precision: 0.7854 - recall: 0.7649 - auc: 0.8721 - val_loss: 0.4678 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8976\n",
      "Epoch 432/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4696 - tp: 201.0000 - fp: 61.0000 - tn: 383.0000 - fn: 67.0000 - accuracy: 0.8202 - precision: 0.7672 - recall: 0.7500 - auc: 0.8777 - val_loss: 0.4630 - val_tp: 62.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 12.0000 - val_accuracy: 0.8380 - val_precision: 0.7848 - val_recall: 0.8378 - val_auc: 0.8974\n",
      "Epoch 433/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4821 - tp: 209.0000 - fp: 69.0000 - tn: 375.0000 - fn: 59.0000 - accuracy: 0.8202 - precision: 0.7518 - recall: 0.7799 - auc: 0.8703 - val_loss: 0.4607 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8950\n",
      "Epoch 434/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4701 - tp: 201.0000 - fp: 46.0000 - tn: 398.0000 - fn: 67.0000 - accuracy: 0.8413 - precision: 0.8138 - recall: 0.7500 - auc: 0.8794 - val_loss: 0.4620 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.9005\n",
      "Epoch 435/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4739 - tp: 201.0000 - fp: 62.0000 - tn: 382.0000 - fn: 67.0000 - accuracy: 0.8188 - precision: 0.7643 - recall: 0.7500 - auc: 0.8830 - val_loss: 0.4586 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8941\n",
      "Epoch 436/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4934 - tp: 198.0000 - fp: 50.0000 - tn: 394.0000 - fn: 70.0000 - accuracy: 0.8315 - precision: 0.7984 - recall: 0.7388 - auc: 0.8676 - val_loss: 0.4642 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8983\n",
      "Epoch 437/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4774 - tp: 205.0000 - fp: 56.0000 - tn: 388.0000 - fn: 63.0000 - accuracy: 0.8329 - precision: 0.7854 - recall: 0.7649 - auc: 0.8697 - val_loss: 0.4721 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8992\n",
      "Epoch 438/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4879 - tp: 196.0000 - fp: 44.0000 - tn: 400.0000 - fn: 72.0000 - accuracy: 0.8371 - precision: 0.8167 - recall: 0.7313 - auc: 0.8682 - val_loss: 0.4668 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8976\n",
      "Epoch 439/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4814 - tp: 202.0000 - fp: 56.0000 - tn: 388.0000 - fn: 66.0000 - accuracy: 0.8287 - precision: 0.7829 - recall: 0.7537 - auc: 0.8721 - val_loss: 0.4673 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8965\n",
      "Epoch 440/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4658 - tp: 209.0000 - fp: 56.0000 - tn: 388.0000 - fn: 59.0000 - accuracy: 0.8385 - precision: 0.7887 - recall: 0.7799 - auc: 0.8814 - val_loss: 0.4701 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8974\n",
      "Epoch 441/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4777 - tp: 197.0000 - fp: 44.0000 - tn: 400.0000 - fn: 71.0000 - accuracy: 0.8385 - precision: 0.8174 - recall: 0.7351 - auc: 0.8668 - val_loss: 0.4755 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.9030\n",
      "Epoch 442/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4752 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8718 - val_loss: 0.4658 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8978\n",
      "Epoch 443/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4899 - tp: 193.0000 - fp: 44.0000 - tn: 400.0000 - fn: 75.0000 - accuracy: 0.8329 - precision: 0.8143 - recall: 0.7201 - auc: 0.8642 - val_loss: 0.4653 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.9003\n",
      "Epoch 444/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4891 - tp: 201.0000 - fp: 61.0000 - tn: 383.0000 - fn: 67.0000 - accuracy: 0.8202 - precision: 0.7672 - recall: 0.7500 - auc: 0.8634 - val_loss: 0.4628 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8983\n",
      "Epoch 445/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4824 - tp: 197.0000 - fp: 54.0000 - tn: 390.0000 - fn: 71.0000 - accuracy: 0.8244 - precision: 0.7849 - recall: 0.7351 - auc: 0.8634 - val_loss: 0.4658 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8977\n",
      "Epoch 446/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4663 - tp: 204.0000 - fp: 53.0000 - tn: 391.0000 - fn: 64.0000 - accuracy: 0.8357 - precision: 0.7938 - recall: 0.7612 - auc: 0.8821 - val_loss: 0.4660 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8983\n",
      "Epoch 447/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4819 - tp: 199.0000 - fp: 49.0000 - tn: 395.0000 - fn: 69.0000 - accuracy: 0.8343 - precision: 0.8024 - recall: 0.7425 - auc: 0.8709 - val_loss: 0.4659 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.9037\n",
      "Epoch 448/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4753 - tp: 206.0000 - fp: 50.0000 - tn: 394.0000 - fn: 62.0000 - accuracy: 0.8427 - precision: 0.8047 - recall: 0.7687 - auc: 0.8756 - val_loss: 0.4631 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8978\n",
      "Epoch 449/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4895 - tp: 199.0000 - fp: 52.0000 - tn: 392.0000 - fn: 69.0000 - accuracy: 0.8301 - precision: 0.7928 - recall: 0.7425 - auc: 0.8619 - val_loss: 0.4639 - val_tp: 67.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 7.0000 - val_accuracy: 0.8212 - val_precision: 0.7283 - val_recall: 0.9054 - val_auc: 0.9025\n",
      "Epoch 450/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4910 - tp: 205.0000 - fp: 59.0000 - tn: 385.0000 - fn: 63.0000 - accuracy: 0.8287 - precision: 0.7765 - recall: 0.7649 - auc: 0.8641 - val_loss: 0.4633 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.9015\n",
      "Epoch 451/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4727 - tp: 200.0000 - fp: 56.0000 - tn: 388.0000 - fn: 68.0000 - accuracy: 0.8258 - precision: 0.7812 - recall: 0.7463 - auc: 0.8771 - val_loss: 0.4675 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8989\n",
      "Epoch 452/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4921 - tp: 203.0000 - fp: 59.0000 - tn: 385.0000 - fn: 65.0000 - accuracy: 0.8258 - precision: 0.7748 - recall: 0.7575 - auc: 0.8632 - val_loss: 0.4712 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.9014\n",
      "Epoch 453/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4728 - tp: 205.0000 - fp: 44.0000 - tn: 400.0000 - fn: 63.0000 - accuracy: 0.8497 - precision: 0.8233 - recall: 0.7649 - auc: 0.8724 - val_loss: 0.4647 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.9001\n",
      "Epoch 454/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4815 - tp: 198.0000 - fp: 47.0000 - tn: 397.0000 - fn: 70.0000 - accuracy: 0.8357 - precision: 0.8082 - recall: 0.7388 - auc: 0.8677 - val_loss: 0.4625 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.9040\n",
      "Epoch 455/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4734 - tp: 207.0000 - fp: 58.0000 - tn: 386.0000 - fn: 61.0000 - accuracy: 0.8329 - precision: 0.7811 - recall: 0.7724 - auc: 0.8776 - val_loss: 0.4658 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.9015\n",
      "Epoch 456/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4955 - tp: 198.0000 - fp: 58.0000 - tn: 386.0000 - fn: 70.0000 - accuracy: 0.8202 - precision: 0.7734 - recall: 0.7388 - auc: 0.8649 - val_loss: 0.4613 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.9031\n",
      "Epoch 457/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4689 - tp: 201.0000 - fp: 48.0000 - tn: 396.0000 - fn: 67.0000 - accuracy: 0.8385 - precision: 0.8072 - recall: 0.7500 - auc: 0.8826 - val_loss: 0.4687 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8995\n",
      "Epoch 458/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4797 - tp: 196.0000 - fp: 53.0000 - tn: 391.0000 - fn: 72.0000 - accuracy: 0.8244 - precision: 0.7871 - recall: 0.7313 - auc: 0.8673 - val_loss: 0.4683 - val_tp: 67.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 7.0000 - val_accuracy: 0.8212 - val_precision: 0.7283 - val_recall: 0.9054 - val_auc: 0.8985\n",
      "Epoch 459/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4852 - tp: 202.0000 - fp: 61.0000 - tn: 383.0000 - fn: 66.0000 - accuracy: 0.8216 - precision: 0.7681 - recall: 0.7537 - auc: 0.8694 - val_loss: 0.4664 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.9012\n",
      "Epoch 460/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4793 - tp: 203.0000 - fp: 51.0000 - tn: 393.0000 - fn: 65.0000 - accuracy: 0.8371 - precision: 0.7992 - recall: 0.7575 - auc: 0.8721 - val_loss: 0.4676 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.9014\n",
      "Epoch 461/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4779 - tp: 205.0000 - fp: 61.0000 - tn: 383.0000 - fn: 63.0000 - accuracy: 0.8258 - precision: 0.7707 - recall: 0.7649 - auc: 0.8692 - val_loss: 0.4705 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8946\n",
      "Epoch 462/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4739 - tp: 200.0000 - fp: 55.0000 - tn: 389.0000 - fn: 68.0000 - accuracy: 0.8272 - precision: 0.7843 - recall: 0.7463 - auc: 0.8772 - val_loss: 0.4665 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8959\n",
      "Epoch 463/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4896 - tp: 196.0000 - fp: 62.0000 - tn: 382.0000 - fn: 72.0000 - accuracy: 0.8118 - precision: 0.7597 - recall: 0.7313 - auc: 0.8725 - val_loss: 0.4665 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8998\n",
      "Epoch 464/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4843 - tp: 206.0000 - fp: 65.0000 - tn: 379.0000 - fn: 62.0000 - accuracy: 0.8216 - precision: 0.7601 - recall: 0.7687 - auc: 0.8657 - val_loss: 0.4655 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8994\n",
      "Epoch 465/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4733 - tp: 207.0000 - fp: 46.0000 - tn: 398.0000 - fn: 61.0000 - accuracy: 0.8497 - precision: 0.8182 - recall: 0.7724 - auc: 0.8724 - val_loss: 0.4659 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8938\n",
      "Epoch 466/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4731 - tp: 204.0000 - fp: 57.0000 - tn: 387.0000 - fn: 64.0000 - accuracy: 0.8301 - precision: 0.7816 - recall: 0.7612 - auc: 0.8722 - val_loss: 0.4719 - val_tp: 64.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 10.0000 - val_accuracy: 0.8324 - val_precision: 0.7619 - val_recall: 0.8649 - val_auc: 0.9017\n",
      "Epoch 467/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4868 - tp: 208.0000 - fp: 61.0000 - tn: 383.0000 - fn: 60.0000 - accuracy: 0.8301 - precision: 0.7732 - recall: 0.7761 - auc: 0.8717 - val_loss: 0.4632 - val_tp: 63.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 11.0000 - val_accuracy: 0.8268 - val_precision: 0.7590 - val_recall: 0.8514 - val_auc: 0.8969\n",
      "Epoch 468/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4614 - tp: 208.0000 - fp: 51.0000 - tn: 393.0000 - fn: 60.0000 - accuracy: 0.8441 - precision: 0.8031 - recall: 0.7761 - auc: 0.8826 - val_loss: 0.4657 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.9001\n",
      "Epoch 469/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4878 - tp: 205.0000 - fp: 67.0000 - tn: 377.0000 - fn: 63.0000 - accuracy: 0.8174 - precision: 0.7537 - recall: 0.7649 - auc: 0.8724 - val_loss: 0.4663 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8969\n",
      "Epoch 470/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4698 - tp: 208.0000 - fp: 60.0000 - tn: 384.0000 - fn: 60.0000 - accuracy: 0.8315 - precision: 0.7761 - recall: 0.7761 - auc: 0.8808 - val_loss: 0.4637 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8961\n",
      "Epoch 471/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4763 - tp: 198.0000 - fp: 42.0000 - tn: 402.0000 - fn: 70.0000 - accuracy: 0.8427 - precision: 0.8250 - recall: 0.7388 - auc: 0.8745 - val_loss: 0.4677 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8983\n",
      "Epoch 472/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4851 - tp: 205.0000 - fp: 53.0000 - tn: 391.0000 - fn: 63.0000 - accuracy: 0.8371 - precision: 0.7946 - recall: 0.7649 - auc: 0.8696 - val_loss: 0.4697 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8967\n",
      "Epoch 473/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.4887 - tp: 205.0000 - fp: 58.0000 - tn: 386.0000 - fn: 63.0000 - accuracy: 0.8301 - precision: 0.7795 - recall: 0.7649 - auc: 0.8663 - val_loss: 0.4716 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8971\n",
      "Epoch 474/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4699 - tp: 195.0000 - fp: 46.0000 - tn: 398.0000 - fn: 73.0000 - accuracy: 0.8329 - precision: 0.8091 - recall: 0.7276 - auc: 0.8823 - val_loss: 0.4690 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8997\n",
      "Epoch 475/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4756 - tp: 201.0000 - fp: 52.0000 - tn: 392.0000 - fn: 67.0000 - accuracy: 0.8329 - precision: 0.7945 - recall: 0.7500 - auc: 0.8743 - val_loss: 0.4699 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8943\n",
      "Epoch 476/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4777 - tp: 197.0000 - fp: 49.0000 - tn: 395.0000 - fn: 71.0000 - accuracy: 0.8315 - precision: 0.8008 - recall: 0.7351 - auc: 0.8739 - val_loss: 0.4690 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8987\n",
      "Epoch 477/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4761 - tp: 207.0000 - fp: 60.0000 - tn: 384.0000 - fn: 61.0000 - accuracy: 0.8301 - precision: 0.7753 - recall: 0.7724 - auc: 0.8761 - val_loss: 0.4763 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.9060\n",
      "Epoch 478/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4707 - tp: 196.0000 - fp: 43.0000 - tn: 401.0000 - fn: 72.0000 - accuracy: 0.8385 - precision: 0.8201 - recall: 0.7313 - auc: 0.8748 - val_loss: 0.4682 - val_tp: 62.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 12.0000 - val_accuracy: 0.8268 - val_precision: 0.7654 - val_recall: 0.8378 - val_auc: 0.8979\n",
      "Epoch 479/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4740 - tp: 202.0000 - fp: 45.0000 - tn: 399.0000 - fn: 66.0000 - accuracy: 0.8441 - precision: 0.8178 - recall: 0.7537 - auc: 0.8722 - val_loss: 0.4644 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.9084\n",
      "Epoch 480/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4858 - tp: 207.0000 - fp: 56.0000 - tn: 388.0000 - fn: 61.0000 - accuracy: 0.8357 - precision: 0.7871 - recall: 0.7724 - auc: 0.8662 - val_loss: 0.4613 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.9028\n",
      "Epoch 481/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4817 - tp: 198.0000 - fp: 55.0000 - tn: 389.0000 - fn: 70.0000 - accuracy: 0.8244 - precision: 0.7826 - recall: 0.7388 - auc: 0.8693 - val_loss: 0.4638 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8996\n",
      "Epoch 482/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4746 - tp: 199.0000 - fp: 37.0000 - tn: 407.0000 - fn: 69.0000 - accuracy: 0.8511 - precision: 0.8432 - recall: 0.7425 - auc: 0.8669 - val_loss: 0.4674 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8990\n",
      "Epoch 483/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4757 - tp: 193.0000 - fp: 42.0000 - tn: 402.0000 - fn: 75.0000 - accuracy: 0.8357 - precision: 0.8213 - recall: 0.7201 - auc: 0.8721 - val_loss: 0.4645 - val_tp: 62.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 12.0000 - val_accuracy: 0.8268 - val_precision: 0.7654 - val_recall: 0.8378 - val_auc: 0.8981\n",
      "Epoch 484/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4860 - tp: 210.0000 - fp: 69.0000 - tn: 375.0000 - fn: 58.0000 - accuracy: 0.8216 - precision: 0.7527 - recall: 0.7836 - auc: 0.8710 - val_loss: 0.4772 - val_tp: 55.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 19.0000 - val_accuracy: 0.8380 - val_precision: 0.8462 - val_recall: 0.7432 - val_auc: 0.8994\n",
      "Epoch 485/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4912 - tp: 201.0000 - fp: 55.0000 - tn: 389.0000 - fn: 67.0000 - accuracy: 0.8287 - precision: 0.7852 - recall: 0.7500 - auc: 0.8610 - val_loss: 0.4703 - val_tp: 67.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 7.0000 - val_accuracy: 0.8324 - val_precision: 0.7444 - val_recall: 0.9054 - val_auc: 0.9017\n",
      "Epoch 486/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4760 - tp: 197.0000 - fp: 41.0000 - tn: 403.0000 - fn: 71.0000 - accuracy: 0.8427 - precision: 0.8277 - recall: 0.7351 - auc: 0.8692 - val_loss: 0.4656 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.9029\n",
      "Epoch 487/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4693 - tp: 203.0000 - fp: 52.0000 - tn: 392.0000 - fn: 65.0000 - accuracy: 0.8357 - precision: 0.7961 - recall: 0.7575 - auc: 0.8848 - val_loss: 0.4694 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8981\n",
      "Epoch 488/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4843 - tp: 206.0000 - fp: 62.0000 - tn: 382.0000 - fn: 62.0000 - accuracy: 0.8258 - precision: 0.7687 - recall: 0.7687 - auc: 0.8632 - val_loss: 0.4643 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.9006\n",
      "Epoch 489/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4698 - tp: 207.0000 - fp: 58.0000 - tn: 386.0000 - fn: 61.0000 - accuracy: 0.8329 - precision: 0.7811 - recall: 0.7724 - auc: 0.8778 - val_loss: 0.4658 - val_tp: 57.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 17.0000 - val_accuracy: 0.8380 - val_precision: 0.8261 - val_recall: 0.7703 - val_auc: 0.8956\n",
      "Epoch 490/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4804 - tp: 194.0000 - fp: 45.0000 - tn: 399.0000 - fn: 74.0000 - accuracy: 0.8329 - precision: 0.8117 - recall: 0.7239 - auc: 0.8714 - val_loss: 0.4722 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.9021\n",
      "Epoch 491/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4698 - tp: 199.0000 - fp: 39.0000 - tn: 405.0000 - fn: 69.0000 - accuracy: 0.8483 - precision: 0.8361 - recall: 0.7425 - auc: 0.8779 - val_loss: 0.4672 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8977\n",
      "Epoch 492/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4734 - tp: 209.0000 - fp: 59.0000 - tn: 385.0000 - fn: 59.0000 - accuracy: 0.8343 - precision: 0.7799 - recall: 0.7799 - auc: 0.8724 - val_loss: 0.4686 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8979\n",
      "Epoch 493/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4747 - tp: 209.0000 - fp: 61.0000 - tn: 383.0000 - fn: 59.0000 - accuracy: 0.8315 - precision: 0.7741 - recall: 0.7799 - auc: 0.8696 - val_loss: 0.4633 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8962\n",
      "Epoch 494/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.4748 - tp: 203.0000 - fp: 51.0000 - tn: 393.0000 - fn: 65.0000 - accuracy: 0.8371 - precision: 0.7992 - recall: 0.7575 - auc: 0.8759 - val_loss: 0.4632 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8975\n",
      "Epoch 495/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4699 - tp: 195.0000 - fp: 38.0000 - tn: 406.0000 - fn: 73.0000 - accuracy: 0.8441 - precision: 0.8369 - recall: 0.7276 - auc: 0.8792 - val_loss: 0.4734 - val_tp: 64.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 10.0000 - val_accuracy: 0.8324 - val_precision: 0.7619 - val_recall: 0.8649 - val_auc: 0.9002\n",
      "Epoch 496/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4753 - tp: 208.0000 - fp: 49.0000 - tn: 395.0000 - fn: 60.0000 - accuracy: 0.8469 - precision: 0.8093 - recall: 0.7761 - auc: 0.8725 - val_loss: 0.4622 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8961\n",
      "Epoch 497/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4675 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8805 - val_loss: 0.4701 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.9035\n",
      "Epoch 498/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4714 - tp: 203.0000 - fp: 49.0000 - tn: 395.0000 - fn: 65.0000 - accuracy: 0.8399 - precision: 0.8056 - recall: 0.7575 - auc: 0.8744 - val_loss: 0.4638 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8940\n",
      "Epoch 499/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4963 - tp: 197.0000 - fp: 62.0000 - tn: 382.0000 - fn: 71.0000 - accuracy: 0.8132 - precision: 0.7606 - recall: 0.7351 - auc: 0.8583 - val_loss: 0.4662 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.9010\n",
      "Epoch 500/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4854 - tp: 201.0000 - fp: 57.0000 - tn: 387.0000 - fn: 67.0000 - accuracy: 0.8258 - precision: 0.7791 - recall: 0.7500 - auc: 0.8650 - val_loss: 0.4693 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8947\n"
     ]
    }
   ],
   "source": [
    "# Create a new model each time before running training (otherwise new trainings would just be on already trained model)\n",
    "model = get_model(X_train.shape[1])\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=500, batch_size=32, validation_data=(X_dev, Y_dev), class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Results of the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.plot(history.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'tp', 'fp', 'tn', 'fn', 'accuracy', 'precision', 'recall', 'auc', 'val_loss', 'val_tp', 'val_fp', 'val_tn', 'val_fn', 'val_accuracy', 'val_precision', 'val_recall', 'val_auc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train evaluation:\n",
      "712/712 - 1s - loss: 0.4405 - tp: 200.0000 - fp: 39.0000 - tn: 405.0000 - fn: 68.0000 - accuracy: 0.8497 - precision: 0.8368 - recall: 0.7463 - auc: 0.8798\n"
     ]
    }
   ],
   "source": [
    "print(\"Train evaluation:\")\n",
    "_ = model.evaluate(X_train, Y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev evaluation:\n",
      "179/179 - 0s - loss: 0.4769 - tp: 57.0000 - fp: 15.0000 - tn: 90.0000 - fn: 17.0000 - accuracy: 0.8212 - precision: 0.7917 - recall: 0.7703 - auc: 0.8947\n"
     ]
    }
   ],
   "source": [
    "print(\"Dev evaluation:\")\n",
    "_ = model.evaluate(X_dev, Y_dev, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Tune hyperparameters for the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt\n",
    "\n",
    "# https://www.sicara.ai/blog/hyperparameter-tuning-keras-tuner\n",
    "# https://www.curiousily.com/posts/hackers-guide-to-hyperparameter-tuning/\n",
    "\n",
    "class TitanicHyperModel(kt.HyperModel):\n",
    "    def __init__(self, input_size):\n",
    "        self.input_shape = (input_size, )\n",
    "\n",
    "    def build(self, hp):\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import Dense, Dropout, InputLayer\n",
    "        from tensorflow.keras.regularizers import L1L2\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(input_shape=self.input_shape))\n",
    "        \n",
    "        for layer_n in range(hp.Int(\"num_layers\", min_value=2, max_value=7, step=1, default=3)):\n",
    "            units = hp.Int(\n",
    "                f\"dense_units_{layer_n}\",\n",
    "                min_value=8,\n",
    "                max_value=64,\n",
    "                step=8,\n",
    "                default=64\n",
    "            )\n",
    "            activation = hp.Choice(\n",
    "                f\"dense_activation_{layer_n}\",\n",
    "                values=[\"relu\", \"tanh\", \"sigmoid\"],\n",
    "                default=\"relu\"\n",
    "            )\n",
    "            regularizer_l1 = hp.Choice(\n",
    "                f\"l1_{layer_n}\",\n",
    "                values=[1e-2, 1e-3, 1e-4, 1e-5, 0.0],\n",
    "                default=1e-2\n",
    "            )\n",
    "            regularizer_l2 = hp.Choice(\n",
    "                f\"l2_{layer_n}\",\n",
    "                values=[1e-2, 1e-3, 1e-4, 1e-5, 0.0],\n",
    "                default=1e-2\n",
    "            )\n",
    "\n",
    "            model.add(Dense(\n",
    "                units=units,\n",
    "                activation=activation,\n",
    "                kernel_regularizer=L1L2(l1=regularizer_l1, l2=regularizer_l2),\n",
    "                bias_regularizer=L1L2(l1=regularizer_l1, l2=regularizer_l2)\n",
    "            ))\n",
    "            \n",
    "            droupout_rate = hp.Float(\n",
    "                f\"dropout_{layer_n}\",\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            )\n",
    "            \n",
    "            model.add(Dropout(rate=droupout_rate))\n",
    "        \n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "        \n",
    "        learning_rate = hp.Choice(\n",
    "            \"learning_rate\",\n",
    "            values=[1e-3, 5e-4, 3e-4, 1e-4],\n",
    "            default=1e-3\n",
    "        )\n",
    "        \n",
    "        optimizer = hp.Choice(\n",
    "            \"optimizer\",\n",
    "            values=[\"adam\", \"RMSprop\", \"SGD\"],\n",
    "            default=\"adam\"\n",
    "        )\n",
    "        optimizer_type = {\n",
    "            \"adam\": keras.optimizers.Adam,\n",
    "            \"RMSprop\": keras.optimizers.RMSprop,\n",
    "            \"SGD\": keras.optimizers.SGD\n",
    "        }\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer_type[optimizer](learning_rate=learning_rate),\n",
    "            metrics=[\"accuracy\"],\n",
    "            loss=\"binary_crossentropy\",\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "hypermodel = TitanicHyperModel(input_size=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTuner(kt.Tuner):\n",
    "    def run_trial(self, trial, X_train, Y_train, validation_data):\n",
    "        hp = trial.hyperparameters\n",
    "        \n",
    "        batch_size = hp.Int(\"batch_size\", 16, 128, step=16, default=32)\n",
    "        epoch_number = hp.Int(\"epoch_number\", 400, 700, step=100, default=500)\n",
    "        \n",
    "        model = self.hypermodel.build(hp)\n",
    "        \n",
    "        history = model.fit(X_train, Y_train, epochs=epoch_number, batch_size=batch_size, validation_data=validation_data, class_weight=class_weights)\n",
    "        \n",
    "        self.oracle.update_trial(trial.trial_id, {\"val_accuracy\": history.history[\"val_accuracy\"][-1]})\n",
    "        self.save_model(trial.trial_id, model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dev mode\n",
    "\n",
    "if MODE == \"DEV\":\n",
    "    MAX_TRIALS = 20\n",
    "else:\n",
    "    MAX_TRIALS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ATTEMPT = ATTEMPT + 1\n",
    "except NameError:\n",
    "    ATTEMPT = 0\n",
    "\n",
    "hp = kt.HyperParameters()\n",
    "if MODE == \"DEV\":\n",
    "    hp.Fixed(\"epoch_number\", 50)\n",
    "\n",
    "# Seems like 32 always comes to be the best option...\n",
    "hp.Fixed(\"batch_size\", 32)\n",
    "    \n",
    "tuner = MyTuner(\n",
    "    oracle=kt.oracles.RandomSearch(\n",
    "        objective=\"val_accuracy\",\n",
    "        seed=SEED,\n",
    "        hyperparameters=hp,\n",
    "        tune_new_entries=True,\n",
    "        max_trials=MAX_TRIALS),\n",
    "    hypermodel=hypermodel,\n",
    "    directory=f\"my_search_{ATTEMPT}\",\n",
    "    project_name=\"titanic\"\n",
    ")\n",
    "\n",
    "# tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 1s 2ms/sample - loss: 1.6340 - accuracy: 0.6419 - val_loss: 1.4581 - val_accuracy: 0.7207\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 1.5431 - accuracy: 0.6531 - val_loss: 1.4060 - val_accuracy: 0.7318\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 1.4899 - accuracy: 0.6728 - val_loss: 1.3612 - val_accuracy: 0.7542\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 1.4565 - accuracy: 0.6657 - val_loss: 1.3229 - val_accuracy: 0.7430\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 1.4180 - accuracy: 0.6629 - val_loss: 1.2846 - val_accuracy: 0.7598\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 1.3440 - accuracy: 0.7093 - val_loss: 1.2475 - val_accuracy: 0.7542\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 1.3115 - accuracy: 0.7065 - val_loss: 1.2098 - val_accuracy: 0.7709\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 1.2829 - accuracy: 0.7402 - val_loss: 1.1778 - val_accuracy: 0.7709\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 1.2399 - accuracy: 0.7402 - val_loss: 1.1456 - val_accuracy: 0.7542\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 1.2215 - accuracy: 0.7261 - val_loss: 1.1147 - val_accuracy: 0.7486\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 1.1693 - accuracy: 0.7500 - val_loss: 1.0853 - val_accuracy: 0.7430\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 1.1416 - accuracy: 0.7444 - val_loss: 1.0587 - val_accuracy: 0.7430\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 1.1122 - accuracy: 0.7654 - val_loss: 1.0326 - val_accuracy: 0.7430\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 1.0936 - accuracy: 0.7711 - val_loss: 1.0084 - val_accuracy: 0.7542\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 1.0805 - accuracy: 0.7472 - val_loss: 0.9853 - val_accuracy: 0.7542\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 1.0293 - accuracy: 0.7795 - val_loss: 0.9640 - val_accuracy: 0.7821\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 1.0093 - accuracy: 0.7683 - val_loss: 0.9411 - val_accuracy: 0.7542\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.9851 - accuracy: 0.7444 - val_loss: 0.9202 - val_accuracy: 0.7598\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.9678 - accuracy: 0.7654 - val_loss: 0.8999 - val_accuracy: 0.7598\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.9484 - accuracy: 0.7725 - val_loss: 0.8807 - val_accuracy: 0.7654\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.9195 - accuracy: 0.7654 - val_loss: 0.8616 - val_accuracy: 0.7598\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.9103 - accuracy: 0.7795 - val_loss: 0.8450 - val_accuracy: 0.7598\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.9004 - accuracy: 0.7612 - val_loss: 0.8280 - val_accuracy: 0.7598\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.8749 - accuracy: 0.7711 - val_loss: 0.8116 - val_accuracy: 0.7598\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.8623 - accuracy: 0.7893 - val_loss: 0.7977 - val_accuracy: 0.7598\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8244 - accuracy: 0.7837 - val_loss: 0.7837 - val_accuracy: 0.7598\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.8293 - accuracy: 0.7739 - val_loss: 0.7705 - val_accuracy: 0.7542\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8071 - accuracy: 0.7823 - val_loss: 0.7598 - val_accuracy: 0.7542\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.7886 - accuracy: 0.7767 - val_loss: 0.7475 - val_accuracy: 0.7709\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.7764 - accuracy: 0.7809 - val_loss: 0.7364 - val_accuracy: 0.7542\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7801 - accuracy: 0.7795 - val_loss: 0.7269 - val_accuracy: 0.7542\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7382 - accuracy: 0.7879 - val_loss: 0.7180 - val_accuracy: 0.7709\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7479 - accuracy: 0.7992 - val_loss: 0.7102 - val_accuracy: 0.7765\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7319 - accuracy: 0.7921 - val_loss: 0.7032 - val_accuracy: 0.7598\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7291 - accuracy: 0.7963 - val_loss: 0.6949 - val_accuracy: 0.7709\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7281 - accuracy: 0.7907 - val_loss: 0.6898 - val_accuracy: 0.7765\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.7192 - accuracy: 0.7865 - val_loss: 0.6853 - val_accuracy: 0.7765\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.7028 - accuracy: 0.7992 - val_loss: 0.6780 - val_accuracy: 0.7709\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.7130 - accuracy: 0.7865 - val_loss: 0.6738 - val_accuracy: 0.7598\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.7094 - accuracy: 0.7837 - val_loss: 0.6674 - val_accuracy: 0.7709\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.6899 - accuracy: 0.7921 - val_loss: 0.6624 - val_accuracy: 0.7654\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.6970 - accuracy: 0.7935 - val_loss: 0.6570 - val_accuracy: 0.7709\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.6781 - accuracy: 0.7893 - val_loss: 0.6540 - val_accuracy: 0.7821\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.6947 - accuracy: 0.7978 - val_loss: 0.6490 - val_accuracy: 0.7765\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.6772 - accuracy: 0.7921 - val_loss: 0.6460 - val_accuracy: 0.7654\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.6846 - accuracy: 0.7809 - val_loss: 0.6417 - val_accuracy: 0.7542\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.6741 - accuracy: 0.7907 - val_loss: 0.6391 - val_accuracy: 0.7654\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.6689 - accuracy: 0.7949 - val_loss: 0.6341 - val_accuracy: 0.7654\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.6720 - accuracy: 0.7893 - val_loss: 0.6299 - val_accuracy: 0.7709\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.6591 - accuracy: 0.7935 - val_loss: 0.6300 - val_accuracy: 0.7542\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.6525 - accuracy: 0.7907 - val_loss: 0.6258 - val_accuracy: 0.7598\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.6571 - accuracy: 0.7795 - val_loss: 0.6221 - val_accuracy: 0.7654\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.6606 - accuracy: 0.7865 - val_loss: 0.6202 - val_accuracy: 0.7654\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.6387 - accuracy: 0.7879 - val_loss: 0.6169 - val_accuracy: 0.7709\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.6459 - accuracy: 0.7921 - val_loss: 0.6131 - val_accuracy: 0.7709\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6396 - accuracy: 0.7893 - val_loss: 0.6136 - val_accuracy: 0.7654\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.6421 - accuracy: 0.7893 - val_loss: 0.6086 - val_accuracy: 0.7709\n",
      "Epoch 58/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6429 - accuracy: 0.7907 - val_loss: 0.6086 - val_accuracy: 0.7654\n",
      "Epoch 59/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.6274 - accuracy: 0.7921 - val_loss: 0.6038 - val_accuracy: 0.7765\n",
      "Epoch 60/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.6387 - accuracy: 0.7978 - val_loss: 0.6012 - val_accuracy: 0.7709\n",
      "Epoch 61/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.6338 - accuracy: 0.8020 - val_loss: 0.5990 - val_accuracy: 0.7709\n",
      "Epoch 62/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6374 - accuracy: 0.7921 - val_loss: 0.5971 - val_accuracy: 0.7709\n",
      "Epoch 63/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.6324 - accuracy: 0.8076 - val_loss: 0.5938 - val_accuracy: 0.7765\n",
      "Epoch 64/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6338 - accuracy: 0.7851 - val_loss: 0.5933 - val_accuracy: 0.7821\n",
      "Epoch 65/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6254 - accuracy: 0.7935 - val_loss: 0.5881 - val_accuracy: 0.7765\n",
      "Epoch 66/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6305 - accuracy: 0.7921 - val_loss: 0.5855 - val_accuracy: 0.7765\n",
      "Epoch 67/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6095 - accuracy: 0.7935 - val_loss: 0.5849 - val_accuracy: 0.7933\n",
      "Epoch 68/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6137 - accuracy: 0.7907 - val_loss: 0.5822 - val_accuracy: 0.7821\n",
      "Epoch 69/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.6123 - accuracy: 0.8006 - val_loss: 0.5789 - val_accuracy: 0.7821\n",
      "Epoch 70/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.6064 - accuracy: 0.7893 - val_loss: 0.5762 - val_accuracy: 0.7821\n",
      "Epoch 71/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.6139 - accuracy: 0.7893 - val_loss: 0.5742 - val_accuracy: 0.7821\n",
      "Epoch 72/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.6169 - accuracy: 0.7921 - val_loss: 0.5726 - val_accuracy: 0.7877\n",
      "Epoch 73/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.6010 - accuracy: 0.8048 - val_loss: 0.5707 - val_accuracy: 0.7821\n",
      "Epoch 74/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5921 - accuracy: 0.8132 - val_loss: 0.5687 - val_accuracy: 0.7821\n",
      "Epoch 75/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5951 - accuracy: 0.8118 - val_loss: 0.5647 - val_accuracy: 0.7821\n",
      "Epoch 76/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5989 - accuracy: 0.8006 - val_loss: 0.5635 - val_accuracy: 0.7821\n",
      "Epoch 77/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5986 - accuracy: 0.8034 - val_loss: 0.5615 - val_accuracy: 0.7877\n",
      "Epoch 78/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5940 - accuracy: 0.8006 - val_loss: 0.5600 - val_accuracy: 0.7877\n",
      "Epoch 79/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5948 - accuracy: 0.7992 - val_loss: 0.5591 - val_accuracy: 0.7765\n",
      "Epoch 80/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5783 - accuracy: 0.8090 - val_loss: 0.5569 - val_accuracy: 0.7821\n",
      "Epoch 81/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.6016 - accuracy: 0.7978 - val_loss: 0.5550 - val_accuracy: 0.7821\n",
      "Epoch 82/500\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5930 - accuracy: 0.8034 - val_loss: 0.5539 - val_accuracy: 0.7989\n",
      "Epoch 83/500\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5806 - accuracy: 0.8048 - val_loss: 0.5523 - val_accuracy: 0.7989\n",
      "Epoch 84/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5694 - accuracy: 0.8090 - val_loss: 0.5495 - val_accuracy: 0.7933\n",
      "Epoch 85/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5757 - accuracy: 0.7978 - val_loss: 0.5489 - val_accuracy: 0.7877\n",
      "Epoch 86/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5645 - accuracy: 0.8104 - val_loss: 0.5485 - val_accuracy: 0.8045\n",
      "Epoch 87/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5832 - accuracy: 0.7907 - val_loss: 0.5458 - val_accuracy: 0.7989\n",
      "Epoch 88/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5628 - accuracy: 0.7978 - val_loss: 0.5444 - val_accuracy: 0.7989\n",
      "Epoch 89/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5710 - accuracy: 0.7963 - val_loss: 0.5420 - val_accuracy: 0.7933\n",
      "Epoch 90/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5631 - accuracy: 0.8062 - val_loss: 0.5410 - val_accuracy: 0.7933\n",
      "Epoch 91/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5673 - accuracy: 0.7992 - val_loss: 0.5385 - val_accuracy: 0.7989\n",
      "Epoch 92/500\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5600 - accuracy: 0.8118 - val_loss: 0.5367 - val_accuracy: 0.7989\n",
      "Epoch 93/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5543 - accuracy: 0.8034 - val_loss: 0.5361 - val_accuracy: 0.7933\n",
      "Epoch 94/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5627 - accuracy: 0.8006 - val_loss: 0.5347 - val_accuracy: 0.7989\n",
      "Epoch 95/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5635 - accuracy: 0.8062 - val_loss: 0.5338 - val_accuracy: 0.7933\n",
      "Epoch 96/500\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5536 - accuracy: 0.8076 - val_loss: 0.5324 - val_accuracy: 0.7933\n",
      "Epoch 97/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5575 - accuracy: 0.8132 - val_loss: 0.5322 - val_accuracy: 0.7989\n",
      "Epoch 98/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5733 - accuracy: 0.7992 - val_loss: 0.5305 - val_accuracy: 0.7989\n",
      "Epoch 99/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5535 - accuracy: 0.8076 - val_loss: 0.5296 - val_accuracy: 0.7989\n",
      "Epoch 100/500\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5613 - accuracy: 0.8006 - val_loss: 0.5289 - val_accuracy: 0.7933\n",
      "Epoch 101/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5635 - accuracy: 0.7992 - val_loss: 0.5282 - val_accuracy: 0.7989\n",
      "Epoch 102/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5400 - accuracy: 0.8118 - val_loss: 0.5267 - val_accuracy: 0.7933\n",
      "Epoch 103/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5627 - accuracy: 0.8034 - val_loss: 0.5266 - val_accuracy: 0.7989\n",
      "Epoch 104/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5477 - accuracy: 0.8202 - val_loss: 0.5265 - val_accuracy: 0.7989\n",
      "Epoch 105/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5443 - accuracy: 0.8132 - val_loss: 0.5242 - val_accuracy: 0.7933\n",
      "Epoch 106/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5415 - accuracy: 0.8020 - val_loss: 0.5222 - val_accuracy: 0.7989\n",
      "Epoch 107/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5430 - accuracy: 0.8160 - val_loss: 0.5213 - val_accuracy: 0.7989\n",
      "Epoch 108/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5497 - accuracy: 0.8062 - val_loss: 0.5217 - val_accuracy: 0.7989\n",
      "Epoch 109/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5494 - accuracy: 0.7992 - val_loss: 0.5202 - val_accuracy: 0.7989\n",
      "Epoch 110/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5481 - accuracy: 0.8076 - val_loss: 0.5203 - val_accuracy: 0.8045\n",
      "Epoch 111/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5510 - accuracy: 0.8076 - val_loss: 0.5205 - val_accuracy: 0.7989\n",
      "Epoch 112/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5444 - accuracy: 0.8118 - val_loss: 0.5185 - val_accuracy: 0.7989\n",
      "Epoch 113/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5427 - accuracy: 0.8160 - val_loss: 0.5170 - val_accuracy: 0.7989\n",
      "Epoch 114/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5432 - accuracy: 0.8090 - val_loss: 0.5176 - val_accuracy: 0.8045\n",
      "Epoch 115/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5449 - accuracy: 0.8034 - val_loss: 0.5177 - val_accuracy: 0.8045\n",
      "Epoch 116/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5546 - accuracy: 0.8020 - val_loss: 0.5152 - val_accuracy: 0.7933\n",
      "Epoch 117/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5486 - accuracy: 0.7963 - val_loss: 0.5157 - val_accuracy: 0.7989\n",
      "Epoch 118/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5462 - accuracy: 0.8132 - val_loss: 0.5200 - val_accuracy: 0.7877\n",
      "Epoch 119/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5448 - accuracy: 0.8048 - val_loss: 0.5157 - val_accuracy: 0.7989\n",
      "Epoch 120/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5444 - accuracy: 0.8006 - val_loss: 0.5137 - val_accuracy: 0.7989\n",
      "Epoch 121/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5377 - accuracy: 0.8146 - val_loss: 0.5137 - val_accuracy: 0.7933\n",
      "Epoch 122/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5323 - accuracy: 0.8118 - val_loss: 0.5147 - val_accuracy: 0.7989\n",
      "Epoch 123/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5457 - accuracy: 0.8132 - val_loss: 0.5126 - val_accuracy: 0.7989\n",
      "Epoch 124/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5311 - accuracy: 0.8118 - val_loss: 0.5112 - val_accuracy: 0.7989\n",
      "Epoch 125/500\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5363 - accuracy: 0.8104 - val_loss: 0.5124 - val_accuracy: 0.8045\n",
      "Epoch 126/500\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5367 - accuracy: 0.8132 - val_loss: 0.5110 - val_accuracy: 0.8045\n",
      "Epoch 127/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5405 - accuracy: 0.8076 - val_loss: 0.5095 - val_accuracy: 0.7933\n",
      "Epoch 128/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5407 - accuracy: 0.8146 - val_loss: 0.5095 - val_accuracy: 0.8045\n",
      "Epoch 129/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5330 - accuracy: 0.8104 - val_loss: 0.5069 - val_accuracy: 0.7933\n",
      "Epoch 130/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5387 - accuracy: 0.8020 - val_loss: 0.5069 - val_accuracy: 0.7989\n",
      "Epoch 131/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5207 - accuracy: 0.8062 - val_loss: 0.5089 - val_accuracy: 0.7989\n",
      "Epoch 132/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5455 - accuracy: 0.8020 - val_loss: 0.5058 - val_accuracy: 0.7989\n",
      "Epoch 133/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5278 - accuracy: 0.8034 - val_loss: 0.5072 - val_accuracy: 0.8045\n",
      "Epoch 134/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5336 - accuracy: 0.8202 - val_loss: 0.5062 - val_accuracy: 0.7933\n",
      "Epoch 135/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5380 - accuracy: 0.7992 - val_loss: 0.5057 - val_accuracy: 0.7989\n",
      "Epoch 136/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5230 - accuracy: 0.8020 - val_loss: 0.5055 - val_accuracy: 0.8045\n",
      "Epoch 137/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5155 - accuracy: 0.8048 - val_loss: 0.5040 - val_accuracy: 0.7933\n",
      "Epoch 138/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5173 - accuracy: 0.8132 - val_loss: 0.5029 - val_accuracy: 0.7933\n",
      "Epoch 139/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5253 - accuracy: 0.8020 - val_loss: 0.5042 - val_accuracy: 0.8045\n",
      "Epoch 140/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5195 - accuracy: 0.8160 - val_loss: 0.5021 - val_accuracy: 0.7989\n",
      "Epoch 141/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5222 - accuracy: 0.8132 - val_loss: 0.5018 - val_accuracy: 0.7989\n",
      "Epoch 142/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5342 - accuracy: 0.8174 - val_loss: 0.5016 - val_accuracy: 0.7933\n",
      "Epoch 143/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5276 - accuracy: 0.8132 - val_loss: 0.5039 - val_accuracy: 0.8045\n",
      "Epoch 144/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5337 - accuracy: 0.8076 - val_loss: 0.5021 - val_accuracy: 0.7989\n",
      "Epoch 145/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5345 - accuracy: 0.8034 - val_loss: 0.5017 - val_accuracy: 0.7989\n",
      "Epoch 146/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5361 - accuracy: 0.8034 - val_loss: 0.5006 - val_accuracy: 0.7989\n",
      "Epoch 147/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5244 - accuracy: 0.8188 - val_loss: 0.5006 - val_accuracy: 0.7933\n",
      "Epoch 148/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5245 - accuracy: 0.8020 - val_loss: 0.5004 - val_accuracy: 0.7933\n",
      "Epoch 149/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5264 - accuracy: 0.8174 - val_loss: 0.5030 - val_accuracy: 0.7989\n",
      "Epoch 150/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5176 - accuracy: 0.8062 - val_loss: 0.5004 - val_accuracy: 0.7989\n",
      "Epoch 151/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5236 - accuracy: 0.8146 - val_loss: 0.4998 - val_accuracy: 0.7989\n",
      "Epoch 152/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5213 - accuracy: 0.8132 - val_loss: 0.4999 - val_accuracy: 0.7933\n",
      "Epoch 153/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5284 - accuracy: 0.8006 - val_loss: 0.4986 - val_accuracy: 0.7989\n",
      "Epoch 154/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5230 - accuracy: 0.8188 - val_loss: 0.4989 - val_accuracy: 0.7989\n",
      "Epoch 155/500\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5075 - accuracy: 0.8188 - val_loss: 0.5010 - val_accuracy: 0.8045\n",
      "Epoch 156/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5225 - accuracy: 0.8216 - val_loss: 0.5008 - val_accuracy: 0.7821\n",
      "Epoch 157/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.5282 - accuracy: 0.8062 - val_loss: 0.4990 - val_accuracy: 0.7989\n",
      "Epoch 158/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5293 - accuracy: 0.8034 - val_loss: 0.4990 - val_accuracy: 0.8045\n",
      "Epoch 159/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5207 - accuracy: 0.8146 - val_loss: 0.4980 - val_accuracy: 0.8045\n",
      "Epoch 160/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5333 - accuracy: 0.8048 - val_loss: 0.4967 - val_accuracy: 0.8045\n",
      "Epoch 161/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5108 - accuracy: 0.8104 - val_loss: 0.4974 - val_accuracy: 0.7877\n",
      "Epoch 162/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5300 - accuracy: 0.8062 - val_loss: 0.4947 - val_accuracy: 0.8045\n",
      "Epoch 163/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5323 - accuracy: 0.8118 - val_loss: 0.4979 - val_accuracy: 0.7765\n",
      "Epoch 164/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5332 - accuracy: 0.8006 - val_loss: 0.4945 - val_accuracy: 0.7989\n",
      "Epoch 165/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5150 - accuracy: 0.8146 - val_loss: 0.4947 - val_accuracy: 0.7933\n",
      "Epoch 166/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5187 - accuracy: 0.7992 - val_loss: 0.4937 - val_accuracy: 0.7933\n",
      "Epoch 167/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5167 - accuracy: 0.8062 - val_loss: 0.4935 - val_accuracy: 0.7933\n",
      "Epoch 168/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5219 - accuracy: 0.7978 - val_loss: 0.4949 - val_accuracy: 0.8045\n",
      "Epoch 169/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5180 - accuracy: 0.8090 - val_loss: 0.4939 - val_accuracy: 0.8045\n",
      "Epoch 170/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5140 - accuracy: 0.8104 - val_loss: 0.4932 - val_accuracy: 0.7933\n",
      "Epoch 171/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5124 - accuracy: 0.8244 - val_loss: 0.4938 - val_accuracy: 0.7989\n",
      "Epoch 172/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5280 - accuracy: 0.8062 - val_loss: 0.4930 - val_accuracy: 0.7933\n",
      "Epoch 173/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5193 - accuracy: 0.8118 - val_loss: 0.4937 - val_accuracy: 0.8045\n",
      "Epoch 174/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5101 - accuracy: 0.8118 - val_loss: 0.4921 - val_accuracy: 0.7933\n",
      "Epoch 175/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5174 - accuracy: 0.8048 - val_loss: 0.4921 - val_accuracy: 0.8045\n",
      "Epoch 176/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5293 - accuracy: 0.8062 - val_loss: 0.4925 - val_accuracy: 0.8045\n",
      "Epoch 177/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5266 - accuracy: 0.8104 - val_loss: 0.4921 - val_accuracy: 0.7933\n",
      "Epoch 178/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5244 - accuracy: 0.8188 - val_loss: 0.4926 - val_accuracy: 0.8045\n",
      "Epoch 179/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5173 - accuracy: 0.8104 - val_loss: 0.4921 - val_accuracy: 0.8045\n",
      "Epoch 180/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5189 - accuracy: 0.8118 - val_loss: 0.4919 - val_accuracy: 0.8045\n",
      "Epoch 181/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5177 - accuracy: 0.8146 - val_loss: 0.4907 - val_accuracy: 0.8045\n",
      "Epoch 182/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5217 - accuracy: 0.8132 - val_loss: 0.4907 - val_accuracy: 0.8045\n",
      "Epoch 183/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5086 - accuracy: 0.8104 - val_loss: 0.4902 - val_accuracy: 0.8045\n",
      "Epoch 184/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5105 - accuracy: 0.8118 - val_loss: 0.4902 - val_accuracy: 0.7989\n",
      "Epoch 185/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5169 - accuracy: 0.8174 - val_loss: 0.4907 - val_accuracy: 0.7989\n",
      "Epoch 186/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5187 - accuracy: 0.8104 - val_loss: 0.4901 - val_accuracy: 0.7989\n",
      "Epoch 187/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5267 - accuracy: 0.8048 - val_loss: 0.4900 - val_accuracy: 0.7989\n",
      "Epoch 188/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5216 - accuracy: 0.8174 - val_loss: 0.4916 - val_accuracy: 0.7989\n",
      "Epoch 189/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5140 - accuracy: 0.8076 - val_loss: 0.4901 - val_accuracy: 0.7989\n",
      "Epoch 190/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5264 - accuracy: 0.8006 - val_loss: 0.4913 - val_accuracy: 0.8045\n",
      "Epoch 191/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5296 - accuracy: 0.8020 - val_loss: 0.4904 - val_accuracy: 0.7933\n",
      "Epoch 192/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5079 - accuracy: 0.8118 - val_loss: 0.4890 - val_accuracy: 0.7933\n",
      "Epoch 193/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5188 - accuracy: 0.8188 - val_loss: 0.4885 - val_accuracy: 0.7989\n",
      "Epoch 194/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5082 - accuracy: 0.8048 - val_loss: 0.4882 - val_accuracy: 0.7933\n",
      "Epoch 195/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5208 - accuracy: 0.8048 - val_loss: 0.4890 - val_accuracy: 0.8045\n",
      "Epoch 196/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5190 - accuracy: 0.8034 - val_loss: 0.4880 - val_accuracy: 0.7989\n",
      "Epoch 197/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5084 - accuracy: 0.8230 - val_loss: 0.4876 - val_accuracy: 0.8045\n",
      "Epoch 198/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5191 - accuracy: 0.7992 - val_loss: 0.4877 - val_accuracy: 0.7877\n",
      "Epoch 199/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5169 - accuracy: 0.8076 - val_loss: 0.4881 - val_accuracy: 0.8045\n",
      "Epoch 200/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5062 - accuracy: 0.8076 - val_loss: 0.4878 - val_accuracy: 0.7989\n",
      "Epoch 201/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5186 - accuracy: 0.8230 - val_loss: 0.4880 - val_accuracy: 0.7877\n",
      "Epoch 202/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5082 - accuracy: 0.8062 - val_loss: 0.4870 - val_accuracy: 0.8045\n",
      "Epoch 203/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5148 - accuracy: 0.8048 - val_loss: 0.4868 - val_accuracy: 0.8045\n",
      "Epoch 204/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5158 - accuracy: 0.8160 - val_loss: 0.4902 - val_accuracy: 0.7709\n",
      "Epoch 205/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5106 - accuracy: 0.8160 - val_loss: 0.4884 - val_accuracy: 0.8045\n",
      "Epoch 206/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5086 - accuracy: 0.8188 - val_loss: 0.4874 - val_accuracy: 0.8045\n",
      "Epoch 207/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5110 - accuracy: 0.8048 - val_loss: 0.4857 - val_accuracy: 0.8045\n",
      "Epoch 208/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5071 - accuracy: 0.8174 - val_loss: 0.4849 - val_accuracy: 0.7933\n",
      "Epoch 209/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5059 - accuracy: 0.8146 - val_loss: 0.4863 - val_accuracy: 0.7877\n",
      "Epoch 210/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5229 - accuracy: 0.8104 - val_loss: 0.4873 - val_accuracy: 0.7933\n",
      "Epoch 211/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5160 - accuracy: 0.8076 - val_loss: 0.4871 - val_accuracy: 0.7877\n",
      "Epoch 212/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5057 - accuracy: 0.8104 - val_loss: 0.4848 - val_accuracy: 0.7989\n",
      "Epoch 213/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5082 - accuracy: 0.8146 - val_loss: 0.4848 - val_accuracy: 0.8045\n",
      "Epoch 214/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5051 - accuracy: 0.8146 - val_loss: 0.4841 - val_accuracy: 0.7989\n",
      "Epoch 215/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5221 - accuracy: 0.8132 - val_loss: 0.4875 - val_accuracy: 0.7821\n",
      "Epoch 216/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5113 - accuracy: 0.8132 - val_loss: 0.4850 - val_accuracy: 0.8045\n",
      "Epoch 217/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5037 - accuracy: 0.8076 - val_loss: 0.4843 - val_accuracy: 0.7933\n",
      "Epoch 218/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5153 - accuracy: 0.8048 - val_loss: 0.4847 - val_accuracy: 0.7989\n",
      "Epoch 219/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.5148 - accuracy: 0.8048 - val_loss: 0.4839 - val_accuracy: 0.7989\n",
      "Epoch 220/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5178 - accuracy: 0.8104 - val_loss: 0.4836 - val_accuracy: 0.8045\n",
      "Epoch 221/500\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5059 - accuracy: 0.8202 - val_loss: 0.4832 - val_accuracy: 0.8045\n",
      "Epoch 222/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5113 - accuracy: 0.8090 - val_loss: 0.4835 - val_accuracy: 0.8045\n",
      "Epoch 223/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.4959 - accuracy: 0.8230 - val_loss: 0.4824 - val_accuracy: 0.8045\n",
      "Epoch 224/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.5252 - accuracy: 0.8104 - val_loss: 0.4868 - val_accuracy: 0.7821\n",
      "Epoch 225/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.5090 - accuracy: 0.8090 - val_loss: 0.4840 - val_accuracy: 0.7877\n",
      "Epoch 226/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.4916 - accuracy: 0.8174 - val_loss: 0.4824 - val_accuracy: 0.8045\n",
      "Epoch 227/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5086 - accuracy: 0.8104 - val_loss: 0.4839 - val_accuracy: 0.7877\n",
      "Epoch 228/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5152 - accuracy: 0.8062 - val_loss: 0.4825 - val_accuracy: 0.7989\n",
      "Epoch 229/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5025 - accuracy: 0.8090 - val_loss: 0.4816 - val_accuracy: 0.8045\n",
      "Epoch 230/500\n",
      "712/712 [==============================] - 0s 101us/sample - loss: 0.5064 - accuracy: 0.8104 - val_loss: 0.4819 - val_accuracy: 0.7989\n",
      "Epoch 231/500\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5142 - accuracy: 0.8160 - val_loss: 0.4825 - val_accuracy: 0.7877\n",
      "Epoch 232/500\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5103 - accuracy: 0.8076 - val_loss: 0.4818 - val_accuracy: 0.8045\n",
      "Epoch 233/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4997 - accuracy: 0.8132 - val_loss: 0.4816 - val_accuracy: 0.8045\n",
      "Epoch 234/500\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5063 - accuracy: 0.8230 - val_loss: 0.4807 - val_accuracy: 0.8045\n",
      "Epoch 235/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5013 - accuracy: 0.8090 - val_loss: 0.4827 - val_accuracy: 0.7877\n",
      "Epoch 236/500\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5028 - accuracy: 0.8034 - val_loss: 0.4804 - val_accuracy: 0.8045\n",
      "Epoch 237/500\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5011 - accuracy: 0.8104 - val_loss: 0.4798 - val_accuracy: 0.8045\n",
      "Epoch 238/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5104 - accuracy: 0.8216 - val_loss: 0.4831 - val_accuracy: 0.7821\n",
      "Epoch 239/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5003 - accuracy: 0.8062 - val_loss: 0.4802 - val_accuracy: 0.8045\n",
      "Epoch 240/500\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5155 - accuracy: 0.7992 - val_loss: 0.4803 - val_accuracy: 0.7877\n",
      "Epoch 241/500\n",
      "712/712 [==============================] - 0s 102us/sample - loss: 0.5155 - accuracy: 0.8006 - val_loss: 0.4798 - val_accuracy: 0.7877\n",
      "Epoch 242/500\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.5061 - accuracy: 0.8160 - val_loss: 0.4815 - val_accuracy: 0.7821\n",
      "Epoch 243/500\n",
      "712/712 [==============================] - 0s 104us/sample - loss: 0.5103 - accuracy: 0.8104 - val_loss: 0.4796 - val_accuracy: 0.8045\n",
      "Epoch 244/500\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5083 - accuracy: 0.8230 - val_loss: 0.4821 - val_accuracy: 0.7821\n",
      "Epoch 245/500\n",
      "712/712 [==============================] - 0s 102us/sample - loss: 0.5013 - accuracy: 0.8160 - val_loss: 0.4791 - val_accuracy: 0.8045\n",
      "Epoch 246/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5183 - accuracy: 0.8160 - val_loss: 0.4804 - val_accuracy: 0.7821\n",
      "Epoch 247/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.5038 - accuracy: 0.8118 - val_loss: 0.4831 - val_accuracy: 0.7821\n",
      "Epoch 248/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5001 - accuracy: 0.8034 - val_loss: 0.4790 - val_accuracy: 0.8045\n",
      "Epoch 249/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5091 - accuracy: 0.8118 - val_loss: 0.4804 - val_accuracy: 0.7821\n",
      "Epoch 250/500\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.5168 - accuracy: 0.8048 - val_loss: 0.4797 - val_accuracy: 0.7821\n",
      "Epoch 251/500\n",
      "712/712 [==============================] - 0s 100us/sample - loss: 0.5201 - accuracy: 0.8090 - val_loss: 0.4793 - val_accuracy: 0.8045\n",
      "Epoch 252/500\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5105 - accuracy: 0.8118 - val_loss: 0.4841 - val_accuracy: 0.7821\n",
      "Epoch 253/500\n",
      "712/712 [==============================] - 0s 101us/sample - loss: 0.4905 - accuracy: 0.8132 - val_loss: 0.4799 - val_accuracy: 0.7821\n",
      "Epoch 254/500\n",
      "712/712 [==============================] - 0s 100us/sample - loss: 0.5092 - accuracy: 0.8090 - val_loss: 0.4791 - val_accuracy: 0.7877\n",
      "Epoch 255/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5009 - accuracy: 0.8118 - val_loss: 0.4783 - val_accuracy: 0.8045\n",
      "Epoch 256/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.5099 - accuracy: 0.8174 - val_loss: 0.4813 - val_accuracy: 0.7821\n",
      "Epoch 257/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5114 - accuracy: 0.8076 - val_loss: 0.4817 - val_accuracy: 0.7821\n",
      "Epoch 258/500\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.4962 - accuracy: 0.8062 - val_loss: 0.4801 - val_accuracy: 0.7877\n",
      "Epoch 259/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5083 - accuracy: 0.8090 - val_loss: 0.4784 - val_accuracy: 0.7989\n",
      "Epoch 260/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5133 - accuracy: 0.8244 - val_loss: 0.4786 - val_accuracy: 0.8045\n",
      "Epoch 261/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.4990 - accuracy: 0.8146 - val_loss: 0.4830 - val_accuracy: 0.7765\n",
      "Epoch 262/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5082 - accuracy: 0.8202 - val_loss: 0.4801 - val_accuracy: 0.7877\n",
      "Epoch 263/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5037 - accuracy: 0.8202 - val_loss: 0.4804 - val_accuracy: 0.7877\n",
      "Epoch 264/500\n",
      "712/712 [==============================] - 0s 101us/sample - loss: 0.5010 - accuracy: 0.8132 - val_loss: 0.4797 - val_accuracy: 0.7933\n",
      "Epoch 265/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5184 - accuracy: 0.8034 - val_loss: 0.4786 - val_accuracy: 0.8045\n",
      "Epoch 266/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.4972 - accuracy: 0.8258 - val_loss: 0.4780 - val_accuracy: 0.7989\n",
      "Epoch 267/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.4941 - accuracy: 0.8146 - val_loss: 0.4783 - val_accuracy: 0.8045\n",
      "Epoch 268/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5097 - accuracy: 0.8160 - val_loss: 0.4779 - val_accuracy: 0.8045\n",
      "Epoch 269/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.5099 - accuracy: 0.8132 - val_loss: 0.4794 - val_accuracy: 0.7877\n",
      "Epoch 270/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5065 - accuracy: 0.8118 - val_loss: 0.4809 - val_accuracy: 0.7877\n",
      "Epoch 271/500\n",
      "712/712 [==============================] - 0s 101us/sample - loss: 0.5120 - accuracy: 0.8090 - val_loss: 0.4780 - val_accuracy: 0.8045\n",
      "Epoch 272/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.4787 - accuracy: 0.8174 - val_loss: 0.4764 - val_accuracy: 0.8045\n",
      "Epoch 273/500\n",
      "712/712 [==============================] - 0s 100us/sample - loss: 0.5037 - accuracy: 0.8160 - val_loss: 0.4770 - val_accuracy: 0.8045\n",
      "Epoch 274/500\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5025 - accuracy: 0.8216 - val_loss: 0.4772 - val_accuracy: 0.8101\n",
      "Epoch 275/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5156 - accuracy: 0.8132 - val_loss: 0.4770 - val_accuracy: 0.8045\n",
      "Epoch 276/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5040 - accuracy: 0.8216 - val_loss: 0.4784 - val_accuracy: 0.8101\n",
      "Epoch 277/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.4983 - accuracy: 0.8062 - val_loss: 0.4760 - val_accuracy: 0.7989\n",
      "Epoch 278/500\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.4893 - accuracy: 0.8230 - val_loss: 0.4757 - val_accuracy: 0.8045\n",
      "Epoch 279/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.4923 - accuracy: 0.8132 - val_loss: 0.4761 - val_accuracy: 0.8101\n",
      "Epoch 280/500\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.4987 - accuracy: 0.8216 - val_loss: 0.4777 - val_accuracy: 0.7933\n",
      "Epoch 281/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5032 - accuracy: 0.8020 - val_loss: 0.4764 - val_accuracy: 0.8045\n",
      "Epoch 282/500\n",
      "712/712 [==============================] - 0s 101us/sample - loss: 0.4940 - accuracy: 0.8174 - val_loss: 0.4771 - val_accuracy: 0.7933\n",
      "Epoch 283/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5064 - accuracy: 0.8076 - val_loss: 0.4768 - val_accuracy: 0.7933\n",
      "Epoch 284/500\n",
      "712/712 [==============================] - 0s 101us/sample - loss: 0.4995 - accuracy: 0.8174 - val_loss: 0.4782 - val_accuracy: 0.7877\n",
      "Epoch 285/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5019 - accuracy: 0.8258 - val_loss: 0.4773 - val_accuracy: 0.7933\n",
      "Epoch 286/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.5011 - accuracy: 0.8090 - val_loss: 0.4777 - val_accuracy: 0.7933\n",
      "Epoch 287/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.4992 - accuracy: 0.8118 - val_loss: 0.4764 - val_accuracy: 0.8045\n",
      "Epoch 288/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5056 - accuracy: 0.8202 - val_loss: 0.4761 - val_accuracy: 0.8101\n",
      "Epoch 289/500\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.4862 - accuracy: 0.8188 - val_loss: 0.4759 - val_accuracy: 0.8045\n",
      "Epoch 290/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.4898 - accuracy: 0.8258 - val_loss: 0.4787 - val_accuracy: 0.7933\n",
      "Epoch 291/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.4982 - accuracy: 0.8188 - val_loss: 0.4762 - val_accuracy: 0.8045\n",
      "Epoch 292/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4830 - accuracy: 0.8174 - val_loss: 0.4748 - val_accuracy: 0.8045\n",
      "Epoch 293/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4978 - accuracy: 0.8118 - val_loss: 0.4748 - val_accuracy: 0.8045\n",
      "Epoch 294/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5009 - accuracy: 0.8104 - val_loss: 0.4752 - val_accuracy: 0.8101\n",
      "Epoch 295/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4981 - accuracy: 0.8160 - val_loss: 0.4758 - val_accuracy: 0.8045\n",
      "Epoch 296/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5062 - accuracy: 0.8230 - val_loss: 0.4753 - val_accuracy: 0.8045\n",
      "Epoch 297/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5113 - accuracy: 0.8104 - val_loss: 0.4758 - val_accuracy: 0.8045\n",
      "Epoch 298/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5058 - accuracy: 0.8104 - val_loss: 0.4749 - val_accuracy: 0.7989\n",
      "Epoch 299/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5154 - accuracy: 0.8090 - val_loss: 0.4748 - val_accuracy: 0.8045\n",
      "Epoch 300/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5098 - accuracy: 0.8160 - val_loss: 0.4750 - val_accuracy: 0.8045\n",
      "Epoch 301/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5059 - accuracy: 0.8104 - val_loss: 0.4756 - val_accuracy: 0.8045\n",
      "Epoch 302/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4985 - accuracy: 0.8216 - val_loss: 0.4751 - val_accuracy: 0.8045\n",
      "Epoch 303/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.4980 - accuracy: 0.8174 - val_loss: 0.4764 - val_accuracy: 0.7877\n",
      "Epoch 304/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5175 - accuracy: 0.8020 - val_loss: 0.4757 - val_accuracy: 0.8101\n",
      "Epoch 305/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5018 - accuracy: 0.8174 - val_loss: 0.4764 - val_accuracy: 0.8045\n",
      "Epoch 306/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5144 - accuracy: 0.8104 - val_loss: 0.4798 - val_accuracy: 0.7877\n",
      "Epoch 307/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5199 - accuracy: 0.8076 - val_loss: 0.4802 - val_accuracy: 0.7877\n",
      "Epoch 308/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5027 - accuracy: 0.8174 - val_loss: 0.4776 - val_accuracy: 0.7877\n",
      "Epoch 309/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5144 - accuracy: 0.8020 - val_loss: 0.4770 - val_accuracy: 0.8101\n",
      "Epoch 310/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5043 - accuracy: 0.8160 - val_loss: 0.4802 - val_accuracy: 0.7877\n",
      "Epoch 311/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5005 - accuracy: 0.8188 - val_loss: 0.4767 - val_accuracy: 0.8101\n",
      "Epoch 312/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5019 - accuracy: 0.8160 - val_loss: 0.4763 - val_accuracy: 0.8101\n",
      "Epoch 313/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5078 - accuracy: 0.8202 - val_loss: 0.4756 - val_accuracy: 0.8045\n",
      "Epoch 314/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5039 - accuracy: 0.8104 - val_loss: 0.4773 - val_accuracy: 0.7877\n",
      "Epoch 315/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5037 - accuracy: 0.8174 - val_loss: 0.4760 - val_accuracy: 0.8101\n",
      "Epoch 316/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5042 - accuracy: 0.8132 - val_loss: 0.4746 - val_accuracy: 0.8101\n",
      "Epoch 317/500\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5019 - accuracy: 0.8132 - val_loss: 0.4750 - val_accuracy: 0.8045\n",
      "Epoch 318/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5043 - accuracy: 0.8202 - val_loss: 0.4780 - val_accuracy: 0.8101\n",
      "Epoch 319/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4961 - accuracy: 0.8216 - val_loss: 0.4758 - val_accuracy: 0.8045\n",
      "Epoch 320/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4971 - accuracy: 0.8216 - val_loss: 0.4757 - val_accuracy: 0.8101\n",
      "Epoch 321/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5032 - accuracy: 0.8287 - val_loss: 0.4748 - val_accuracy: 0.8045\n",
      "Epoch 322/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4948 - accuracy: 0.8188 - val_loss: 0.4778 - val_accuracy: 0.7821\n",
      "Epoch 323/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5070 - accuracy: 0.8104 - val_loss: 0.4765 - val_accuracy: 0.7821\n",
      "Epoch 324/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4986 - accuracy: 0.8216 - val_loss: 0.4747 - val_accuracy: 0.8045\n",
      "Epoch 325/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4800 - accuracy: 0.8258 - val_loss: 0.4740 - val_accuracy: 0.8045\n",
      "Epoch 326/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5127 - accuracy: 0.8174 - val_loss: 0.4741 - val_accuracy: 0.8045\n",
      "Epoch 327/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5021 - accuracy: 0.8230 - val_loss: 0.4733 - val_accuracy: 0.8045\n",
      "Epoch 328/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.4975 - accuracy: 0.8216 - val_loss: 0.4735 - val_accuracy: 0.7821\n",
      "Epoch 329/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.4964 - accuracy: 0.8174 - val_loss: 0.4746 - val_accuracy: 0.7821\n",
      "Epoch 330/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5033 - accuracy: 0.8146 - val_loss: 0.4747 - val_accuracy: 0.7821\n",
      "Epoch 331/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4941 - accuracy: 0.8090 - val_loss: 0.4726 - val_accuracy: 0.8045\n",
      "Epoch 332/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4889 - accuracy: 0.8216 - val_loss: 0.4733 - val_accuracy: 0.8101\n",
      "Epoch 333/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5081 - accuracy: 0.8244 - val_loss: 0.4742 - val_accuracy: 0.7877\n",
      "Epoch 334/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5111 - accuracy: 0.8146 - val_loss: 0.4739 - val_accuracy: 0.7821\n",
      "Epoch 335/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4958 - accuracy: 0.8160 - val_loss: 0.4745 - val_accuracy: 0.7877\n",
      "Epoch 336/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5173 - accuracy: 0.8090 - val_loss: 0.4733 - val_accuracy: 0.8045\n",
      "Epoch 337/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5047 - accuracy: 0.8258 - val_loss: 0.4738 - val_accuracy: 0.8045\n",
      "Epoch 338/500\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5039 - accuracy: 0.8202 - val_loss: 0.4733 - val_accuracy: 0.8101\n",
      "Epoch 339/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5004 - accuracy: 0.8160 - val_loss: 0.4741 - val_accuracy: 0.8045\n",
      "Epoch 340/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4993 - accuracy: 0.8174 - val_loss: 0.4734 - val_accuracy: 0.8045\n",
      "Epoch 341/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5013 - accuracy: 0.8076 - val_loss: 0.4751 - val_accuracy: 0.7933\n",
      "Epoch 342/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5040 - accuracy: 0.8188 - val_loss: 0.4737 - val_accuracy: 0.8045\n",
      "Epoch 343/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4928 - accuracy: 0.8188 - val_loss: 0.4739 - val_accuracy: 0.8101\n",
      "Epoch 344/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5022 - accuracy: 0.8090 - val_loss: 0.4771 - val_accuracy: 0.7877\n",
      "Epoch 345/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5152 - accuracy: 0.8062 - val_loss: 0.4752 - val_accuracy: 0.7877\n",
      "Epoch 346/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5034 - accuracy: 0.8188 - val_loss: 0.4761 - val_accuracy: 0.7877\n",
      "Epoch 347/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4969 - accuracy: 0.8174 - val_loss: 0.4731 - val_accuracy: 0.8045\n",
      "Epoch 348/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5010 - accuracy: 0.8076 - val_loss: 0.4729 - val_accuracy: 0.8101\n",
      "Epoch 349/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4997 - accuracy: 0.8244 - val_loss: 0.4758 - val_accuracy: 0.7877\n",
      "Epoch 350/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5135 - accuracy: 0.8062 - val_loss: 0.4736 - val_accuracy: 0.8045\n",
      "Epoch 351/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.4992 - accuracy: 0.8132 - val_loss: 0.4740 - val_accuracy: 0.7877\n",
      "Epoch 352/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5079 - accuracy: 0.8258 - val_loss: 0.4743 - val_accuracy: 0.8045\n",
      "Epoch 353/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4901 - accuracy: 0.8202 - val_loss: 0.4735 - val_accuracy: 0.8156\n",
      "Epoch 354/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5041 - accuracy: 0.8230 - val_loss: 0.4717 - val_accuracy: 0.8045\n",
      "Epoch 355/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5121 - accuracy: 0.8258 - val_loss: 0.4741 - val_accuracy: 0.7877\n",
      "Epoch 356/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4916 - accuracy: 0.8146 - val_loss: 0.4716 - val_accuracy: 0.8045\n",
      "Epoch 357/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4991 - accuracy: 0.8160 - val_loss: 0.4715 - val_accuracy: 0.8101\n",
      "Epoch 358/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4990 - accuracy: 0.8188 - val_loss: 0.4729 - val_accuracy: 0.7933\n",
      "Epoch 359/500\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5024 - accuracy: 0.8174 - val_loss: 0.4734 - val_accuracy: 0.7877\n",
      "Epoch 360/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4959 - accuracy: 0.8188 - val_loss: 0.4716 - val_accuracy: 0.8101\n",
      "Epoch 361/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.4923 - accuracy: 0.8090 - val_loss: 0.4719 - val_accuracy: 0.8101\n",
      "Epoch 362/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5039 - accuracy: 0.8244 - val_loss: 0.4736 - val_accuracy: 0.7933\n",
      "Epoch 363/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5059 - accuracy: 0.8132 - val_loss: 0.4721 - val_accuracy: 0.8045\n",
      "Epoch 364/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4993 - accuracy: 0.8188 - val_loss: 0.4730 - val_accuracy: 0.7877\n",
      "Epoch 365/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4820 - accuracy: 0.8244 - val_loss: 0.4719 - val_accuracy: 0.8101\n",
      "Epoch 366/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5058 - accuracy: 0.8188 - val_loss: 0.4735 - val_accuracy: 0.7877\n",
      "Epoch 367/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5003 - accuracy: 0.8048 - val_loss: 0.4735 - val_accuracy: 0.8045\n",
      "Epoch 368/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5010 - accuracy: 0.8258 - val_loss: 0.4737 - val_accuracy: 0.7989\n",
      "Epoch 369/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4947 - accuracy: 0.8160 - val_loss: 0.4726 - val_accuracy: 0.8045\n",
      "Epoch 370/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4922 - accuracy: 0.8132 - val_loss: 0.4724 - val_accuracy: 0.8045\n",
      "Epoch 371/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4899 - accuracy: 0.8287 - val_loss: 0.4841 - val_accuracy: 0.7821\n",
      "Epoch 372/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4932 - accuracy: 0.8146 - val_loss: 0.4732 - val_accuracy: 0.8045\n",
      "Epoch 373/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.4867 - accuracy: 0.8216 - val_loss: 0.4776 - val_accuracy: 0.7821\n",
      "Epoch 374/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5086 - accuracy: 0.8020 - val_loss: 0.4740 - val_accuracy: 0.8045\n",
      "Epoch 375/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4979 - accuracy: 0.8244 - val_loss: 0.4826 - val_accuracy: 0.7821\n",
      "Epoch 376/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5016 - accuracy: 0.8188 - val_loss: 0.4760 - val_accuracy: 0.7933\n",
      "Epoch 377/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5020 - accuracy: 0.8090 - val_loss: 0.4751 - val_accuracy: 0.7933\n",
      "Epoch 378/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4960 - accuracy: 0.8202 - val_loss: 0.4773 - val_accuracy: 0.7821\n",
      "Epoch 379/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5008 - accuracy: 0.8118 - val_loss: 0.4736 - val_accuracy: 0.7933\n",
      "Epoch 380/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5057 - accuracy: 0.8132 - val_loss: 0.4726 - val_accuracy: 0.7877\n",
      "Epoch 381/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.4823 - accuracy: 0.8090 - val_loss: 0.4745 - val_accuracy: 0.7821\n",
      "Epoch 382/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5070 - accuracy: 0.8076 - val_loss: 0.4734 - val_accuracy: 0.7821\n",
      "Epoch 383/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5009 - accuracy: 0.8118 - val_loss: 0.4732 - val_accuracy: 0.7933\n",
      "Epoch 384/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4997 - accuracy: 0.8244 - val_loss: 0.4726 - val_accuracy: 0.7933\n",
      "Epoch 385/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5014 - accuracy: 0.8076 - val_loss: 0.4714 - val_accuracy: 0.7933\n",
      "Epoch 386/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4973 - accuracy: 0.8146 - val_loss: 0.4730 - val_accuracy: 0.7877\n",
      "Epoch 387/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5114 - accuracy: 0.8132 - val_loss: 0.4709 - val_accuracy: 0.8101\n",
      "Epoch 388/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.4977 - accuracy: 0.8315 - val_loss: 0.4711 - val_accuracy: 0.7989\n",
      "Epoch 389/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5152 - accuracy: 0.8146 - val_loss: 0.4716 - val_accuracy: 0.7933\n",
      "Epoch 390/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.4966 - accuracy: 0.8062 - val_loss: 0.4709 - val_accuracy: 0.7933\n",
      "Epoch 391/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4957 - accuracy: 0.8146 - val_loss: 0.4701 - val_accuracy: 0.8101\n",
      "Epoch 392/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5002 - accuracy: 0.8188 - val_loss: 0.4736 - val_accuracy: 0.7821\n",
      "Epoch 393/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5055 - accuracy: 0.8146 - val_loss: 0.4781 - val_accuracy: 0.7821\n",
      "Epoch 394/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5003 - accuracy: 0.8062 - val_loss: 0.4700 - val_accuracy: 0.8045\n",
      "Epoch 395/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4958 - accuracy: 0.8230 - val_loss: 0.4701 - val_accuracy: 0.8045\n",
      "Epoch 396/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5029 - accuracy: 0.8230 - val_loss: 0.4695 - val_accuracy: 0.8045\n",
      "Epoch 397/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4934 - accuracy: 0.8146 - val_loss: 0.4726 - val_accuracy: 0.7877\n",
      "Epoch 398/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.4869 - accuracy: 0.8188 - val_loss: 0.4701 - val_accuracy: 0.8101\n",
      "Epoch 399/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5068 - accuracy: 0.8216 - val_loss: 0.4732 - val_accuracy: 0.7877\n",
      "Epoch 400/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5003 - accuracy: 0.8118 - val_loss: 0.4704 - val_accuracy: 0.8045\n",
      "Epoch 401/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4987 - accuracy: 0.8188 - val_loss: 0.4706 - val_accuracy: 0.8045\n",
      "Epoch 402/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5031 - accuracy: 0.8146 - val_loss: 0.4707 - val_accuracy: 0.8101\n",
      "Epoch 403/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5039 - accuracy: 0.8287 - val_loss: 0.4746 - val_accuracy: 0.7877\n",
      "Epoch 404/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4954 - accuracy: 0.8188 - val_loss: 0.4729 - val_accuracy: 0.7877\n",
      "Epoch 405/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5046 - accuracy: 0.8174 - val_loss: 0.4717 - val_accuracy: 0.8101\n",
      "Epoch 406/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.4967 - accuracy: 0.8160 - val_loss: 0.4707 - val_accuracy: 0.8045\n",
      "Epoch 407/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4898 - accuracy: 0.8244 - val_loss: 0.4717 - val_accuracy: 0.7877\n",
      "Epoch 408/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.4864 - accuracy: 0.8188 - val_loss: 0.4706 - val_accuracy: 0.8101\n",
      "Epoch 409/500\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5117 - accuracy: 0.8076 - val_loss: 0.4729 - val_accuracy: 0.7877\n",
      "Epoch 410/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5128 - accuracy: 0.8090 - val_loss: 0.4807 - val_accuracy: 0.7821\n",
      "Epoch 411/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4928 - accuracy: 0.8160 - val_loss: 0.4705 - val_accuracy: 0.7877\n",
      "Epoch 412/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5056 - accuracy: 0.8188 - val_loss: 0.4688 - val_accuracy: 0.8101\n",
      "Epoch 413/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4799 - accuracy: 0.8258 - val_loss: 0.4696 - val_accuracy: 0.8101\n",
      "Epoch 414/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4931 - accuracy: 0.8202 - val_loss: 0.4707 - val_accuracy: 0.7877\n",
      "Epoch 415/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.4938 - accuracy: 0.8118 - val_loss: 0.4706 - val_accuracy: 0.7877\n",
      "Epoch 416/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.4967 - accuracy: 0.8076 - val_loss: 0.4709 - val_accuracy: 0.7877\n",
      "Epoch 417/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.4894 - accuracy: 0.8132 - val_loss: 0.4694 - val_accuracy: 0.7877\n",
      "Epoch 418/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4951 - accuracy: 0.8174 - val_loss: 0.4708 - val_accuracy: 0.7877\n",
      "Epoch 419/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4987 - accuracy: 0.8244 - val_loss: 0.4735 - val_accuracy: 0.7877\n",
      "Epoch 420/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4910 - accuracy: 0.8174 - val_loss: 0.4700 - val_accuracy: 0.8101\n",
      "Epoch 421/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4941 - accuracy: 0.8188 - val_loss: 0.4701 - val_accuracy: 0.7821\n",
      "Epoch 422/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4995 - accuracy: 0.8216 - val_loss: 0.4707 - val_accuracy: 0.8101\n",
      "Epoch 423/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.4889 - accuracy: 0.8132 - val_loss: 0.4688 - val_accuracy: 0.7877\n",
      "Epoch 424/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4868 - accuracy: 0.8202 - val_loss: 0.4692 - val_accuracy: 0.7877\n",
      "Epoch 425/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4882 - accuracy: 0.8160 - val_loss: 0.4704 - val_accuracy: 0.7821\n",
      "Epoch 426/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5022 - accuracy: 0.8188 - val_loss: 0.4801 - val_accuracy: 0.7821\n",
      "Epoch 427/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4952 - accuracy: 0.8104 - val_loss: 0.4693 - val_accuracy: 0.7877\n",
      "Epoch 428/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5105 - accuracy: 0.8048 - val_loss: 0.4729 - val_accuracy: 0.7821\n",
      "Epoch 429/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4946 - accuracy: 0.8202 - val_loss: 0.4688 - val_accuracy: 0.8045\n",
      "Epoch 430/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4880 - accuracy: 0.8258 - val_loss: 0.4719 - val_accuracy: 0.7821\n",
      "Epoch 431/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4983 - accuracy: 0.8020 - val_loss: 0.4688 - val_accuracy: 0.7821\n",
      "Epoch 432/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5015 - accuracy: 0.8174 - val_loss: 0.4719 - val_accuracy: 0.7765\n",
      "Epoch 433/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4973 - accuracy: 0.8160 - val_loss: 0.4707 - val_accuracy: 0.7877\n",
      "Epoch 434/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4934 - accuracy: 0.8188 - val_loss: 0.4690 - val_accuracy: 0.8045\n",
      "Epoch 435/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4937 - accuracy: 0.8118 - val_loss: 0.4687 - val_accuracy: 0.8101\n",
      "Epoch 436/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.4987 - accuracy: 0.8174 - val_loss: 0.4695 - val_accuracy: 0.7877\n",
      "Epoch 437/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4985 - accuracy: 0.8132 - val_loss: 0.4687 - val_accuracy: 0.7877\n",
      "Epoch 438/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5013 - accuracy: 0.8076 - val_loss: 0.4702 - val_accuracy: 0.7933\n",
      "Epoch 439/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4907 - accuracy: 0.8216 - val_loss: 0.4766 - val_accuracy: 0.7765\n",
      "Epoch 440/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4861 - accuracy: 0.8132 - val_loss: 0.4705 - val_accuracy: 0.8101\n",
      "Epoch 441/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5136 - accuracy: 0.8244 - val_loss: 0.4725 - val_accuracy: 0.7933\n",
      "Epoch 442/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.4889 - accuracy: 0.8202 - val_loss: 0.4708 - val_accuracy: 0.8101\n",
      "Epoch 443/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5054 - accuracy: 0.8104 - val_loss: 0.4713 - val_accuracy: 0.7877\n",
      "Epoch 444/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4901 - accuracy: 0.8174 - val_loss: 0.4699 - val_accuracy: 0.8101\n",
      "Epoch 445/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5014 - accuracy: 0.8160 - val_loss: 0.4698 - val_accuracy: 0.8101\n",
      "Epoch 446/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4970 - accuracy: 0.8104 - val_loss: 0.4699 - val_accuracy: 0.8101\n",
      "Epoch 447/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4971 - accuracy: 0.8188 - val_loss: 0.4700 - val_accuracy: 0.7877\n",
      "Epoch 448/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.4935 - accuracy: 0.8160 - val_loss: 0.4702 - val_accuracy: 0.7877\n",
      "Epoch 449/500\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5057 - accuracy: 0.8146 - val_loss: 0.4717 - val_accuracy: 0.7877\n",
      "Epoch 450/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5035 - accuracy: 0.8062 - val_loss: 0.4716 - val_accuracy: 0.7877\n",
      "Epoch 451/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4971 - accuracy: 0.8160 - val_loss: 0.4699 - val_accuracy: 0.8045\n",
      "Epoch 452/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.4876 - accuracy: 0.8174 - val_loss: 0.4690 - val_accuracy: 0.8045\n",
      "Epoch 453/500\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.4868 - accuracy: 0.8230 - val_loss: 0.4688 - val_accuracy: 0.8045\n",
      "Epoch 454/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5079 - accuracy: 0.8118 - val_loss: 0.4690 - val_accuracy: 0.8101\n",
      "Epoch 455/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4916 - accuracy: 0.8216 - val_loss: 0.4691 - val_accuracy: 0.8045\n",
      "Epoch 456/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5074 - accuracy: 0.8216 - val_loss: 0.4683 - val_accuracy: 0.8101\n",
      "Epoch 457/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4812 - accuracy: 0.8202 - val_loss: 0.4686 - val_accuracy: 0.7821\n",
      "Epoch 458/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4994 - accuracy: 0.8118 - val_loss: 0.4698 - val_accuracy: 0.7877\n",
      "Epoch 459/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4904 - accuracy: 0.8132 - val_loss: 0.4692 - val_accuracy: 0.8156\n",
      "Epoch 460/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5030 - accuracy: 0.8216 - val_loss: 0.4738 - val_accuracy: 0.7765\n",
      "Epoch 461/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5031 - accuracy: 0.8174 - val_loss: 0.4709 - val_accuracy: 0.7821\n",
      "Epoch 462/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4977 - accuracy: 0.8118 - val_loss: 0.4689 - val_accuracy: 0.7821\n",
      "Epoch 463/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5142 - accuracy: 0.8146 - val_loss: 0.4748 - val_accuracy: 0.7877\n",
      "Epoch 464/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.4957 - accuracy: 0.8104 - val_loss: 0.4700 - val_accuracy: 0.7877\n",
      "Epoch 465/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5021 - accuracy: 0.8090 - val_loss: 0.4679 - val_accuracy: 0.8101\n",
      "Epoch 466/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4907 - accuracy: 0.8258 - val_loss: 0.4680 - val_accuracy: 0.7821\n",
      "Epoch 467/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5069 - accuracy: 0.8174 - val_loss: 0.4696 - val_accuracy: 0.7877\n",
      "Epoch 468/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4901 - accuracy: 0.8160 - val_loss: 0.4780 - val_accuracy: 0.7821\n",
      "Epoch 469/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4855 - accuracy: 0.8132 - val_loss: 0.4686 - val_accuracy: 0.7877\n",
      "Epoch 470/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4888 - accuracy: 0.8258 - val_loss: 0.4686 - val_accuracy: 0.8101\n",
      "Epoch 471/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4960 - accuracy: 0.8174 - val_loss: 0.4685 - val_accuracy: 0.7877\n",
      "Epoch 472/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4956 - accuracy: 0.8174 - val_loss: 0.4679 - val_accuracy: 0.7821\n",
      "Epoch 473/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4971 - accuracy: 0.8132 - val_loss: 0.4673 - val_accuracy: 0.7877\n",
      "Epoch 474/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4892 - accuracy: 0.8146 - val_loss: 0.4700 - val_accuracy: 0.7877\n",
      "Epoch 475/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4886 - accuracy: 0.8146 - val_loss: 0.4692 - val_accuracy: 0.8101\n",
      "Epoch 476/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4935 - accuracy: 0.8230 - val_loss: 0.4739 - val_accuracy: 0.7821\n",
      "Epoch 477/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4859 - accuracy: 0.8104 - val_loss: 0.4689 - val_accuracy: 0.7877\n",
      "Epoch 478/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4979 - accuracy: 0.8160 - val_loss: 0.4746 - val_accuracy: 0.7821\n",
      "Epoch 479/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5065 - accuracy: 0.8062 - val_loss: 0.4752 - val_accuracy: 0.7821\n",
      "Epoch 480/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.4940 - accuracy: 0.8118 - val_loss: 0.4686 - val_accuracy: 0.7877\n",
      "Epoch 481/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4819 - accuracy: 0.8230 - val_loss: 0.4676 - val_accuracy: 0.8045\n",
      "Epoch 482/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5109 - accuracy: 0.8244 - val_loss: 0.4682 - val_accuracy: 0.8045\n",
      "Epoch 483/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4987 - accuracy: 0.8230 - val_loss: 0.4734 - val_accuracy: 0.7821\n",
      "Epoch 484/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.4880 - accuracy: 0.8188 - val_loss: 0.4701 - val_accuracy: 0.8101\n",
      "Epoch 485/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.4969 - accuracy: 0.8216 - val_loss: 0.4687 - val_accuracy: 0.7877\n",
      "Epoch 486/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.4825 - accuracy: 0.8188 - val_loss: 0.4703 - val_accuracy: 0.7877\n",
      "Epoch 487/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4900 - accuracy: 0.8230 - val_loss: 0.4689 - val_accuracy: 0.7877\n",
      "Epoch 488/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5071 - accuracy: 0.8118 - val_loss: 0.4685 - val_accuracy: 0.7877\n",
      "Epoch 489/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.4966 - accuracy: 0.8118 - val_loss: 0.4685 - val_accuracy: 0.8045\n",
      "Epoch 490/500\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.4952 - accuracy: 0.8244 - val_loss: 0.4684 - val_accuracy: 0.7877\n",
      "Epoch 491/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5025 - accuracy: 0.8202 - val_loss: 0.4730 - val_accuracy: 0.7765\n",
      "Epoch 492/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.4939 - accuracy: 0.8174 - val_loss: 0.4679 - val_accuracy: 0.7933\n",
      "Epoch 493/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.4981 - accuracy: 0.8188 - val_loss: 0.4684 - val_accuracy: 0.8045\n",
      "Epoch 494/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5015 - accuracy: 0.8230 - val_loss: 0.4684 - val_accuracy: 0.8101\n",
      "Epoch 495/500\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5101 - accuracy: 0.8132 - val_loss: 0.4701 - val_accuracy: 0.7877\n",
      "Epoch 496/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5005 - accuracy: 0.8146 - val_loss: 0.4755 - val_accuracy: 0.7821\n",
      "Epoch 497/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.4911 - accuracy: 0.8188 - val_loss: 0.4694 - val_accuracy: 0.8101\n",
      "Epoch 498/500\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5073 - accuracy: 0.8244 - val_loss: 0.4696 - val_accuracy: 0.8101\n",
      "Epoch 499/500\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5026 - accuracy: 0.8202 - val_loss: 0.4696 - val_accuracy: 0.7877\n",
      "Epoch 500/500\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5003 - accuracy: 0.8118 - val_loss: 0.4686 - val_accuracy: 0.7989\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 953921b5d515a235d5721999d125190b</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7988826632499695</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-batch_size: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_0: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_1: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_2: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_1: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_2: 56</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_0: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_1: 0.30000000000000004</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_2: 0.30000000000000004</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-epoch_number: 500</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_0: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_1: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_2: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_0: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_1: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_2: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-learning_rate: 0.0005</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: RMSprop</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 2s 3ms/sample - loss: 19.7631 - accuracy: 0.4494 - val_loss: 18.6924 - val_accuracy: 0.4134\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 17.7981 - accuracy: 0.4382 - val_loss: 16.7914 - val_accuracy: 0.4134\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 15.9474 - accuracy: 0.4733 - val_loss: 15.0093 - val_accuracy: 0.4134\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 14.2210 - accuracy: 0.4874 - val_loss: 13.3502 - val_accuracy: 0.4134\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 12.6165 - accuracy: 0.4916 - val_loss: 11.8083 - val_accuracy: 0.5866\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 11.1298 - accuracy: 0.4719 - val_loss: 10.3861 - val_accuracy: 0.5866\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 9.7597 - accuracy: 0.5379 - val_loss: 9.0798 - val_accuracy: 0.5866\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 8.5058 - accuracy: 0.5492 - val_loss: 7.8855 - val_accuracy: 0.5866\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 7.3606 - accuracy: 0.5772 - val_loss: 6.7967 - val_accuracy: 0.5866\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 6.3191 - accuracy: 0.6067 - val_loss: 5.8096 - val_accuracy: 0.5866\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 5.3792 - accuracy: 0.6194 - val_loss: 4.9240 - val_accuracy: 0.5866\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 4.5374 - accuracy: 0.6236 - val_loss: 4.1332 - val_accuracy: 0.5866\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 3.7899 - accuracy: 0.6236 - val_loss: 3.4356 - val_accuracy: 0.5866\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 3.1338 - accuracy: 0.6236 - val_loss: 2.8277 - val_accuracy: 0.5866\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 2.5661 - accuracy: 0.6236 - val_loss: 2.3051 - val_accuracy: 0.5866\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.0824 - accuracy: 0.6236 - val_loss: 1.8672 - val_accuracy: 0.5866\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.6818 - accuracy: 0.6236 - val_loss: 1.5092 - val_accuracy: 0.5866\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3593 - accuracy: 0.6236 - val_loss: 1.2276 - val_accuracy: 0.5866\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.1139 - accuracy: 0.6236 - val_loss: 1.0245 - val_accuracy: 0.5866\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.9448 - accuracy: 0.6236 - val_loss: 0.8942 - val_accuracy: 0.5866\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.8453 - accuracy: 0.6236 - val_loss: 0.8230 - val_accuracy: 0.5866\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7871 - accuracy: 0.6236 - val_loss: 0.7777 - val_accuracy: 0.5866\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.7500 - accuracy: 0.6236 - val_loss: 0.7494 - val_accuracy: 0.5866\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7283 - accuracy: 0.6236 - val_loss: 0.7350 - val_accuracy: 0.5866\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7184 - accuracy: 0.6236 - val_loss: 0.7293 - val_accuracy: 0.5866\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7146 - accuracy: 0.6236 - val_loss: 0.7269 - val_accuracy: 0.5866\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7127 - accuracy: 0.6236 - val_loss: 0.7255 - val_accuracy: 0.5866\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7115 - accuracy: 0.6236 - val_loss: 0.7243 - val_accuracy: 0.5866\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7103 - accuracy: 0.6236 - val_loss: 0.7232 - val_accuracy: 0.5866\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7094 - accuracy: 0.6236 - val_loss: 0.7224 - val_accuracy: 0.5866\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.7084 - accuracy: 0.6236 - val_loss: 0.7214 - val_accuracy: 0.5866\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7078 - accuracy: 0.6236 - val_loss: 0.7207 - val_accuracy: 0.5866\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7070 - accuracy: 0.6236 - val_loss: 0.7201 - val_accuracy: 0.5866\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7064 - accuracy: 0.6236 - val_loss: 0.7195 - val_accuracy: 0.5866\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7059 - accuracy: 0.6236 - val_loss: 0.7191 - val_accuracy: 0.5866\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7054 - accuracy: 0.6236 - val_loss: 0.7187 - val_accuracy: 0.5866\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7050 - accuracy: 0.6236 - val_loss: 0.7183 - val_accuracy: 0.5866\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7046 - accuracy: 0.6236 - val_loss: 0.7179 - val_accuracy: 0.5866\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7042 - accuracy: 0.6236 - val_loss: 0.7174 - val_accuracy: 0.5866\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7038 - accuracy: 0.6236 - val_loss: 0.7172 - val_accuracy: 0.5866\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 201us/sample - loss: 0.7035 - accuracy: 0.6236 - val_loss: 0.7169 - val_accuracy: 0.5866\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.7034 - accuracy: 0.6236 - val_loss: 0.7167 - val_accuracy: 0.5866\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7031 - accuracy: 0.6236 - val_loss: 0.7167 - val_accuracy: 0.5866\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7029 - accuracy: 0.6236 - val_loss: 0.7164 - val_accuracy: 0.5866\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7027 - accuracy: 0.6236 - val_loss: 0.7162 - val_accuracy: 0.5866\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7026 - accuracy: 0.6236 - val_loss: 0.7160 - val_accuracy: 0.5866\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.7024 - accuracy: 0.6236 - val_loss: 0.7159 - val_accuracy: 0.5866\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.7023 - accuracy: 0.6236 - val_loss: 0.7158 - val_accuracy: 0.5866\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7021 - accuracy: 0.6236 - val_loss: 0.7156 - val_accuracy: 0.5866\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.7021 - accuracy: 0.6236 - val_loss: 0.7156 - val_accuracy: 0.5866\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7021 - accuracy: 0.6236 - val_loss: 0.7155 - val_accuracy: 0.5866\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7019 - accuracy: 0.6236 - val_loss: 0.7153 - val_accuracy: 0.5866\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7017 - accuracy: 0.6236 - val_loss: 0.7153 - val_accuracy: 0.5866\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7017 - accuracy: 0.6236 - val_loss: 0.7151 - val_accuracy: 0.5866\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7016 - accuracy: 0.6236 - val_loss: 0.7151 - val_accuracy: 0.5866\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7015 - accuracy: 0.6236 - val_loss: 0.7149 - val_accuracy: 0.5866\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7014 - accuracy: 0.6236 - val_loss: 0.7149 - val_accuracy: 0.5866\n",
      "Epoch 58/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7013 - accuracy: 0.6236 - val_loss: 0.7148 - val_accuracy: 0.5866\n",
      "Epoch 59/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7014 - accuracy: 0.6236 - val_loss: 0.7147 - val_accuracy: 0.5866\n",
      "Epoch 60/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.7012 - accuracy: 0.6236 - val_loss: 0.7148 - val_accuracy: 0.5866\n",
      "Epoch 61/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7012 - accuracy: 0.6236 - val_loss: 0.7147 - val_accuracy: 0.5866\n",
      "Epoch 62/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7011 - accuracy: 0.6236 - val_loss: 0.7146 - val_accuracy: 0.5866\n",
      "Epoch 63/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.7011 - accuracy: 0.6236 - val_loss: 0.7147 - val_accuracy: 0.5866\n",
      "Epoch 64/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.7011 - accuracy: 0.6236 - val_loss: 0.7146 - val_accuracy: 0.5866\n",
      "Epoch 65/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7010 - accuracy: 0.6236 - val_loss: 0.7146 - val_accuracy: 0.5866\n",
      "Epoch 66/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7009 - accuracy: 0.6236 - val_loss: 0.7145 - val_accuracy: 0.5866\n",
      "Epoch 67/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7009 - accuracy: 0.6236 - val_loss: 0.7144 - val_accuracy: 0.5866\n",
      "Epoch 68/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.7009 - accuracy: 0.6236 - val_loss: 0.7144 - val_accuracy: 0.5866\n",
      "Epoch 69/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.7008 - accuracy: 0.6236 - val_loss: 0.7143 - val_accuracy: 0.5866\n",
      "Epoch 70/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7007 - accuracy: 0.6236 - val_loss: 0.7143 - val_accuracy: 0.5866\n",
      "Epoch 71/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7007 - accuracy: 0.6236 - val_loss: 0.7142 - val_accuracy: 0.5866\n",
      "Epoch 72/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7007 - accuracy: 0.6236 - val_loss: 0.7142 - val_accuracy: 0.5866\n",
      "Epoch 73/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7006 - accuracy: 0.6236 - val_loss: 0.7142 - val_accuracy: 0.5866\n",
      "Epoch 74/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7007 - accuracy: 0.6236 - val_loss: 0.7144 - val_accuracy: 0.5866\n",
      "Epoch 75/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7007 - accuracy: 0.6236 - val_loss: 0.7143 - val_accuracy: 0.5866\n",
      "Epoch 76/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7006 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 77/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7005 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 78/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7004 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 79/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7005 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 80/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7003 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 81/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7003 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 82/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.7003 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 83/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 84/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 85/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 86/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 87/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 88/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 89/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 90/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 91/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 92/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 93/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 94/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 95/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 96/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 97/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 98/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 99/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 100/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 101/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 102/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 103/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 104/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 105/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 106/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 107/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 108/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 109/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7133 - val_accuracy: 0.5866\n",
      "Epoch 110/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7133 - val_accuracy: 0.5866\n",
      "Epoch 111/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7133 - val_accuracy: 0.5866\n",
      "Epoch 112/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 113/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 114/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 115/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 116/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 117/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 118/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 119/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 120/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 121/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 122/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 123/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 124/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 125/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 126/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 127/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 128/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 129/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 130/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 131/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 132/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 133/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 134/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 135/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 136/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 137/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 138/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 139/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7134 - val_accuracy: 0.5866\n",
      "Epoch 140/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 141/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 142/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 143/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 144/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 145/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 146/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 147/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 148/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 149/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 150/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 151/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 152/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 153/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 154/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 155/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 156/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 157/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 158/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 159/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 160/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 161/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 162/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 163/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 164/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7135 - val_accuracy: 0.5866\n",
      "Epoch 165/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 166/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 167/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 168/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 169/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 170/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 171/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 172/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 173/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6998 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 174/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 175/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 176/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 177/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 178/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 179/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 180/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 181/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 182/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 183/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 184/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 185/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 186/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 187/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 188/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 189/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 190/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 191/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 192/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 193/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 194/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 195/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 196/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 197/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 198/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 199/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 200/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6999 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 201/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 202/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 203/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 204/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 205/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 206/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 207/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 208/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 209/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 210/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 211/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 212/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 213/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 214/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 215/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 216/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 217/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 218/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 219/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 220/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 221/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 222/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 223/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 224/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 225/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 226/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 227/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 228/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 229/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 230/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 231/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 232/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 233/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 234/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 235/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 236/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 237/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 238/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 239/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 240/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7004 - accuracy: 0.6236 - val_loss: 0.7142 - val_accuracy: 0.5866\n",
      "Epoch 241/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 242/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 243/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 244/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 245/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 246/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 247/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 248/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 249/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 250/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 251/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 252/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 253/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 254/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 255/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 256/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 257/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 258/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7142 - val_accuracy: 0.5866\n",
      "Epoch 259/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 260/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 261/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 262/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 263/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 264/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 265/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 266/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 267/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 268/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 269/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 270/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 271/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 272/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 273/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 274/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 275/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 276/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 277/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 278/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 279/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7142 - val_accuracy: 0.5866\n",
      "Epoch 280/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7003 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 281/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 282/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 283/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 284/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 285/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 286/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 287/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 288/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 289/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 290/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 291/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 292/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 293/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 294/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 295/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 296/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 297/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 298/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 299/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7003 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 300/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 301/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 302/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 303/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 304/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 305/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 306/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 307/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 308/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 309/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 310/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 311/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 312/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 313/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 314/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 315/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 316/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 317/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 318/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 319/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 320/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 321/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 322/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 323/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 324/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 325/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 326/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 327/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 328/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 329/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 330/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 331/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 332/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 333/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 334/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 335/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 336/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 337/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 338/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 339/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 340/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 341/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 342/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 343/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 344/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 345/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 346/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 347/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 348/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 349/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 350/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 351/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 352/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 353/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 354/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 355/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 356/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 357/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 358/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7003 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 359/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 360/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 361/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 362/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 363/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7142 - val_accuracy: 0.5866\n",
      "Epoch 364/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 365/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7142 - val_accuracy: 0.5866\n",
      "Epoch 366/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 367/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 368/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 369/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 370/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 371/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7141 - val_accuracy: 0.5866\n",
      "Epoch 372/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 373/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 374/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 375/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 376/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 377/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 378/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 379/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 380/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 381/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 382/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 383/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 384/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 385/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 386/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 387/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 388/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 389/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 390/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 391/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 392/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 393/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 394/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 395/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 396/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 397/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 398/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 399/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 400/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 401/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 402/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 403/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 404/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 405/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 406/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 407/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 408/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 409/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 410/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 411/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 412/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 413/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 414/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 415/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 416/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 417/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 418/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 419/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 420/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 421/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 422/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 423/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 424/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 425/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 426/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 427/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 428/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 429/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 430/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 431/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 432/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 433/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 434/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7136 - val_accuracy: 0.5866\n",
      "Epoch 435/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 436/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 437/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 438/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 439/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 440/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 441/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 442/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 443/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 444/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 445/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 446/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 447/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 448/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 449/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 450/500\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 451/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 452/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7002 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 453/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 454/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 455/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 456/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 457/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 458/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 459/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 460/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 461/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 462/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 463/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 464/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 465/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 466/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 467/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 468/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 469/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 470/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 471/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 472/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 473/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 474/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 475/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 476/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 477/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 478/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 479/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7137 - val_accuracy: 0.5866\n",
      "Epoch 480/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 481/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 482/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 483/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 484/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 485/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 486/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 487/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 488/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 489/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7138 - val_accuracy: 0.5866\n",
      "Epoch 490/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 491/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 492/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 493/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 494/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 495/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 496/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 497/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7001 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 498/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7140 - val_accuracy: 0.5866\n",
      "Epoch 499/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n",
      "Epoch 500/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7000 - accuracy: 0.6236 - val_loss: 0.7139 - val_accuracy: 0.5866\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 1dcc67aaca314d0b10e48a93d51ff363</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.5865921974182129</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-batch_size: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_0: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_1: sigmoid</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_2: sigmoid</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_3: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_4: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_5: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_6: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_1: 48</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_2: 24</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_3: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_4: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_5: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_6: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_0: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_1: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_2: 0.4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_3: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_4: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_5: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_6: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-epoch_number: 500</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_0: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_1: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_2: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_3: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_4: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_5: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_6: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_0: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_1: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_2: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_3: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_4: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_5: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_6: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-learning_rate: 0.0005</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_layers: 7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/400\n",
      "712/712 [==============================] - 1s 2ms/sample - loss: 1.4763 - accuracy: 0.6194 - val_loss: 1.4543 - val_accuracy: 0.5866\n",
      "Epoch 2/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 1.4001 - accuracy: 0.5955 - val_loss: 1.3943 - val_accuracy: 0.5866\n",
      "Epoch 3/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 1.3581 - accuracy: 0.5758 - val_loss: 1.3460 - val_accuracy: 0.5866\n",
      "Epoch 4/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 1.3208 - accuracy: 0.5351 - val_loss: 1.3091 - val_accuracy: 0.5866\n",
      "Epoch 5/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 1.2772 - accuracy: 0.5801 - val_loss: 1.2715 - val_accuracy: 0.6648\n",
      "Epoch 6/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 1.2504 - accuracy: 0.5590 - val_loss: 1.2411 - val_accuracy: 0.6480\n",
      "Epoch 7/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 1.2158 - accuracy: 0.5590 - val_loss: 1.2072 - val_accuracy: 0.6704\n",
      "Epoch 8/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 1.1896 - accuracy: 0.5323 - val_loss: 1.1788 - val_accuracy: 0.6816\n",
      "Epoch 9/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 1.1698 - accuracy: 0.5337 - val_loss: 1.1493 - val_accuracy: 0.6927\n",
      "Epoch 10/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 1.1272 - accuracy: 0.5815 - val_loss: 1.1215 - val_accuracy: 0.7039\n",
      "Epoch 11/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 1.1082 - accuracy: 0.5407 - val_loss: 1.0944 - val_accuracy: 0.6983\n",
      "Epoch 12/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 1.0732 - accuracy: 0.5758 - val_loss: 1.0691 - val_accuracy: 0.6816\n",
      "Epoch 13/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 1.0602 - accuracy: 0.5520 - val_loss: 1.0455 - val_accuracy: 0.6872\n",
      "Epoch 14/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 1.0305 - accuracy: 0.5604 - val_loss: 1.0237 - val_accuracy: 0.7039\n",
      "Epoch 15/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 1.0107 - accuracy: 0.5787 - val_loss: 1.0015 - val_accuracy: 0.6927\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.9985 - accuracy: 0.5393 - val_loss: 0.9839 - val_accuracy: 0.7095\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.9749 - accuracy: 0.6081 - val_loss: 0.9627 - val_accuracy: 0.7095\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.9599 - accuracy: 0.5604 - val_loss: 0.9446 - val_accuracy: 0.7095\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.9404 - accuracy: 0.5983 - val_loss: 0.9255 - val_accuracy: 0.6983\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.9120 - accuracy: 0.6306 - val_loss: 0.9115 - val_accuracy: 0.7095\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.9106 - accuracy: 0.6166 - val_loss: 0.8942 - val_accuracy: 0.6983\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.8897 - accuracy: 0.6362 - val_loss: 0.8787 - val_accuracy: 0.7039\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.8680 - accuracy: 0.6489 - val_loss: 0.8644 - val_accuracy: 0.7207\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.8615 - accuracy: 0.6348 - val_loss: 0.8492 - val_accuracy: 0.7207\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.8544 - accuracy: 0.6376 - val_loss: 0.8343 - val_accuracy: 0.6927\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.8397 - accuracy: 0.6376 - val_loss: 0.8207 - val_accuracy: 0.6983\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.8282 - accuracy: 0.6433 - val_loss: 0.8066 - val_accuracy: 0.6983\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.8027 - accuracy: 0.6742 - val_loss: 0.7949 - val_accuracy: 0.7318\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.8008 - accuracy: 0.6615 - val_loss: 0.7879 - val_accuracy: 0.7151\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.7922 - accuracy: 0.6742 - val_loss: 0.7742 - val_accuracy: 0.7039\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.7843 - accuracy: 0.6699 - val_loss: 0.7616 - val_accuracy: 0.7207\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.7674 - accuracy: 0.6742 - val_loss: 0.7524 - val_accuracy: 0.7151\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.7697 - accuracy: 0.6840 - val_loss: 0.7471 - val_accuracy: 0.7263\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.7614 - accuracy: 0.6896 - val_loss: 0.7326 - val_accuracy: 0.7430\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.7475 - accuracy: 0.6882 - val_loss: 0.7236 - val_accuracy: 0.7430\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.7371 - accuracy: 0.6952 - val_loss: 0.7204 - val_accuracy: 0.7318\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.7248 - accuracy: 0.7261 - val_loss: 0.7143 - val_accuracy: 0.7318\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.7231 - accuracy: 0.7065 - val_loss: 0.7025 - val_accuracy: 0.7374\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.7116 - accuracy: 0.7247 - val_loss: 0.6924 - val_accuracy: 0.7486\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.7183 - accuracy: 0.7065 - val_loss: 0.6837 - val_accuracy: 0.7430\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.7093 - accuracy: 0.7163 - val_loss: 0.6758 - val_accuracy: 0.7430\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6982 - accuracy: 0.7374 - val_loss: 0.6726 - val_accuracy: 0.7654\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6859 - accuracy: 0.7472 - val_loss: 0.6695 - val_accuracy: 0.7374\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6943 - accuracy: 0.7486 - val_loss: 0.6592 - val_accuracy: 0.7598\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6768 - accuracy: 0.7402 - val_loss: 0.6523 - val_accuracy: 0.7430\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6809 - accuracy: 0.7416 - val_loss: 0.6486 - val_accuracy: 0.7654\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6793 - accuracy: 0.7430 - val_loss: 0.6433 - val_accuracy: 0.7374\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6834 - accuracy: 0.7374 - val_loss: 0.6387 - val_accuracy: 0.7486\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6753 - accuracy: 0.7486 - val_loss: 0.6342 - val_accuracy: 0.7654\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6553 - accuracy: 0.7556 - val_loss: 0.6322 - val_accuracy: 0.7486\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6531 - accuracy: 0.7444 - val_loss: 0.6266 - val_accuracy: 0.7374\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6514 - accuracy: 0.7542 - val_loss: 0.6233 - val_accuracy: 0.7430\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6505 - accuracy: 0.7711 - val_loss: 0.6196 - val_accuracy: 0.7374\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.6660 - accuracy: 0.7458 - val_loss: 0.6159 - val_accuracy: 0.7430\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6490 - accuracy: 0.7612 - val_loss: 0.6131 - val_accuracy: 0.7598\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.6475 - accuracy: 0.7781 - val_loss: 0.6115 - val_accuracy: 0.7374\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6408 - accuracy: 0.7542 - val_loss: 0.6076 - val_accuracy: 0.7598\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6345 - accuracy: 0.7739 - val_loss: 0.6046 - val_accuracy: 0.7430\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6288 - accuracy: 0.7683 - val_loss: 0.6026 - val_accuracy: 0.7598\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.6358 - accuracy: 0.7683 - val_loss: 0.6002 - val_accuracy: 0.7430\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6482 - accuracy: 0.7500 - val_loss: 0.6006 - val_accuracy: 0.7598\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6384 - accuracy: 0.7598 - val_loss: 0.5978 - val_accuracy: 0.7598\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6336 - accuracy: 0.7683 - val_loss: 0.5949 - val_accuracy: 0.7598\n",
      "Epoch 64/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.6273 - accuracy: 0.7683 - val_loss: 0.5934 - val_accuracy: 0.7430\n",
      "Epoch 65/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6271 - accuracy: 0.7640 - val_loss: 0.5905 - val_accuracy: 0.7654\n",
      "Epoch 66/400\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.6230 - accuracy: 0.7795 - val_loss: 0.5900 - val_accuracy: 0.7654\n",
      "Epoch 67/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6383 - accuracy: 0.7669 - val_loss: 0.5878 - val_accuracy: 0.7654\n",
      "Epoch 68/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6350 - accuracy: 0.7626 - val_loss: 0.5874 - val_accuracy: 0.7598\n",
      "Epoch 69/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6288 - accuracy: 0.7626 - val_loss: 0.5850 - val_accuracy: 0.7654\n",
      "Epoch 70/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6258 - accuracy: 0.7626 - val_loss: 0.5849 - val_accuracy: 0.7598\n",
      "Epoch 71/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6350 - accuracy: 0.7626 - val_loss: 0.5831 - val_accuracy: 0.7598\n",
      "Epoch 72/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6215 - accuracy: 0.7640 - val_loss: 0.5812 - val_accuracy: 0.7654\n",
      "Epoch 73/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.6144 - accuracy: 0.7556 - val_loss: 0.5841 - val_accuracy: 0.7654\n",
      "Epoch 74/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6300 - accuracy: 0.7528 - val_loss: 0.5845 - val_accuracy: 0.7654\n",
      "Epoch 75/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6146 - accuracy: 0.7767 - val_loss: 0.5785 - val_accuracy: 0.7598\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6088 - accuracy: 0.7683 - val_loss: 0.5777 - val_accuracy: 0.7654\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6145 - accuracy: 0.7739 - val_loss: 0.5768 - val_accuracy: 0.7598\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6283 - accuracy: 0.7640 - val_loss: 0.5758 - val_accuracy: 0.7709\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6151 - accuracy: 0.7697 - val_loss: 0.5834 - val_accuracy: 0.7765\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.6201 - accuracy: 0.7725 - val_loss: 0.5742 - val_accuracy: 0.7654\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6294 - accuracy: 0.7598 - val_loss: 0.5730 - val_accuracy: 0.7598\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6220 - accuracy: 0.7683 - val_loss: 0.5732 - val_accuracy: 0.7654\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6099 - accuracy: 0.7697 - val_loss: 0.5725 - val_accuracy: 0.7654\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6145 - accuracy: 0.7584 - val_loss: 0.5725 - val_accuracy: 0.7654\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.6174 - accuracy: 0.7640 - val_loss: 0.5701 - val_accuracy: 0.7654\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6302 - accuracy: 0.7598 - val_loss: 0.5708 - val_accuracy: 0.7654\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6001 - accuracy: 0.7767 - val_loss: 0.5689 - val_accuracy: 0.7654\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6084 - accuracy: 0.7640 - val_loss: 0.5681 - val_accuracy: 0.7654\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6022 - accuracy: 0.7640 - val_loss: 0.5667 - val_accuracy: 0.7654\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.6069 - accuracy: 0.7949 - val_loss: 0.5655 - val_accuracy: 0.7709\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6106 - accuracy: 0.7739 - val_loss: 0.5650 - val_accuracy: 0.7654\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6100 - accuracy: 0.7683 - val_loss: 0.5644 - val_accuracy: 0.7654\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6019 - accuracy: 0.7781 - val_loss: 0.5655 - val_accuracy: 0.7654\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6166 - accuracy: 0.7697 - val_loss: 0.5659 - val_accuracy: 0.7654\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6077 - accuracy: 0.7949 - val_loss: 0.5630 - val_accuracy: 0.7654\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6003 - accuracy: 0.7711 - val_loss: 0.5621 - val_accuracy: 0.7654\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6051 - accuracy: 0.7697 - val_loss: 0.5613 - val_accuracy: 0.7709\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5936 - accuracy: 0.7837 - val_loss: 0.5632 - val_accuracy: 0.7765\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5907 - accuracy: 0.8048 - val_loss: 0.5616 - val_accuracy: 0.7709\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6049 - accuracy: 0.7781 - val_loss: 0.5618 - val_accuracy: 0.7709\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5969 - accuracy: 0.7781 - val_loss: 0.5590 - val_accuracy: 0.7654\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.6112 - accuracy: 0.7711 - val_loss: 0.5607 - val_accuracy: 0.7709\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5960 - accuracy: 0.7767 - val_loss: 0.5583 - val_accuracy: 0.7654\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5982 - accuracy: 0.7893 - val_loss: 0.5576 - val_accuracy: 0.7598\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6041 - accuracy: 0.7823 - val_loss: 0.5573 - val_accuracy: 0.7765\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5968 - accuracy: 0.7669 - val_loss: 0.5576 - val_accuracy: 0.7709\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5845 - accuracy: 0.8020 - val_loss: 0.5555 - val_accuracy: 0.7654\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5894 - accuracy: 0.7767 - val_loss: 0.5578 - val_accuracy: 0.7374\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5827 - accuracy: 0.7865 - val_loss: 0.5538 - val_accuracy: 0.7598\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5970 - accuracy: 0.7767 - val_loss: 0.5533 - val_accuracy: 0.7654\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5849 - accuracy: 0.7809 - val_loss: 0.5532 - val_accuracy: 0.7654\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6071 - accuracy: 0.7781 - val_loss: 0.5538 - val_accuracy: 0.7765\n",
      "Epoch 113/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5944 - accuracy: 0.7795 - val_loss: 0.5557 - val_accuracy: 0.7821\n",
      "Epoch 114/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5931 - accuracy: 0.7781 - val_loss: 0.5542 - val_accuracy: 0.7709\n",
      "Epoch 115/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5859 - accuracy: 0.7823 - val_loss: 0.5615 - val_accuracy: 0.7877\n",
      "Epoch 116/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5882 - accuracy: 0.7879 - val_loss: 0.5564 - val_accuracy: 0.7765\n",
      "Epoch 117/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5788 - accuracy: 0.7907 - val_loss: 0.5517 - val_accuracy: 0.7821\n",
      "Epoch 118/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5773 - accuracy: 0.7893 - val_loss: 0.5638 - val_accuracy: 0.7542\n",
      "Epoch 119/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6016 - accuracy: 0.7851 - val_loss: 0.5502 - val_accuracy: 0.7765\n",
      "Epoch 120/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5816 - accuracy: 0.7907 - val_loss: 0.5506 - val_accuracy: 0.7821\n",
      "Epoch 121/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5969 - accuracy: 0.7809 - val_loss: 0.5506 - val_accuracy: 0.7765\n",
      "Epoch 122/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5910 - accuracy: 0.7963 - val_loss: 0.5515 - val_accuracy: 0.7598\n",
      "Epoch 123/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5901 - accuracy: 0.7837 - val_loss: 0.5539 - val_accuracy: 0.7765\n",
      "Epoch 124/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5984 - accuracy: 0.7823 - val_loss: 0.5550 - val_accuracy: 0.7821\n",
      "Epoch 125/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5854 - accuracy: 0.7809 - val_loss: 0.5557 - val_accuracy: 0.7821\n",
      "Epoch 126/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5961 - accuracy: 0.7697 - val_loss: 0.5479 - val_accuracy: 0.7765\n",
      "Epoch 127/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5901 - accuracy: 0.7781 - val_loss: 0.5471 - val_accuracy: 0.7709\n",
      "Epoch 128/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.6055 - accuracy: 0.7711 - val_loss: 0.5480 - val_accuracy: 0.7765\n",
      "Epoch 129/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5845 - accuracy: 0.7907 - val_loss: 0.5482 - val_accuracy: 0.7765\n",
      "Epoch 130/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5963 - accuracy: 0.7809 - val_loss: 0.5495 - val_accuracy: 0.7821\n",
      "Epoch 131/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5899 - accuracy: 0.7879 - val_loss: 0.5498 - val_accuracy: 0.7430\n",
      "Epoch 132/400\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5883 - accuracy: 0.7683 - val_loss: 0.5452 - val_accuracy: 0.7765\n",
      "Epoch 133/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5959 - accuracy: 0.7781 - val_loss: 0.5528 - val_accuracy: 0.7821\n",
      "Epoch 134/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5897 - accuracy: 0.7935 - val_loss: 0.5460 - val_accuracy: 0.7765\n",
      "Epoch 135/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5824 - accuracy: 0.7823 - val_loss: 0.5467 - val_accuracy: 0.7654\n",
      "Epoch 136/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5809 - accuracy: 0.7865 - val_loss: 0.5458 - val_accuracy: 0.7542\n",
      "Epoch 137/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5940 - accuracy: 0.7640 - val_loss: 0.5451 - val_accuracy: 0.7765\n",
      "Epoch 138/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5772 - accuracy: 0.7893 - val_loss: 0.5456 - val_accuracy: 0.7821\n",
      "Epoch 139/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5929 - accuracy: 0.7865 - val_loss: 0.5562 - val_accuracy: 0.7877\n",
      "Epoch 140/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5787 - accuracy: 0.7851 - val_loss: 0.5427 - val_accuracy: 0.7709\n",
      "Epoch 141/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5785 - accuracy: 0.8048 - val_loss: 0.5459 - val_accuracy: 0.7821\n",
      "Epoch 142/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5777 - accuracy: 0.7978 - val_loss: 0.5503 - val_accuracy: 0.7877\n",
      "Epoch 143/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5915 - accuracy: 0.7753 - val_loss: 0.5417 - val_accuracy: 0.7709\n",
      "Epoch 144/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5795 - accuracy: 0.7865 - val_loss: 0.5415 - val_accuracy: 0.7765\n",
      "Epoch 145/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5601 - accuracy: 0.7978 - val_loss: 0.5525 - val_accuracy: 0.7877\n",
      "Epoch 146/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5877 - accuracy: 0.7865 - val_loss: 0.5425 - val_accuracy: 0.7821\n",
      "Epoch 147/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5991 - accuracy: 0.7851 - val_loss: 0.5402 - val_accuracy: 0.7765\n",
      "Epoch 148/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5854 - accuracy: 0.7907 - val_loss: 0.5410 - val_accuracy: 0.7709\n",
      "Epoch 149/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5754 - accuracy: 0.7949 - val_loss: 0.5434 - val_accuracy: 0.7654\n",
      "Epoch 150/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5874 - accuracy: 0.7907 - val_loss: 0.5400 - val_accuracy: 0.7765\n",
      "Epoch 151/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5878 - accuracy: 0.7753 - val_loss: 0.5401 - val_accuracy: 0.7765\n",
      "Epoch 152/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5878 - accuracy: 0.7640 - val_loss: 0.5395 - val_accuracy: 0.7709\n",
      "Epoch 153/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5777 - accuracy: 0.7851 - val_loss: 0.5432 - val_accuracy: 0.7933\n",
      "Epoch 154/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5836 - accuracy: 0.7739 - val_loss: 0.5419 - val_accuracy: 0.7933\n",
      "Epoch 155/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5794 - accuracy: 0.7879 - val_loss: 0.5521 - val_accuracy: 0.7877\n",
      "Epoch 156/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5792 - accuracy: 0.7851 - val_loss: 0.5421 - val_accuracy: 0.7486\n",
      "Epoch 157/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5919 - accuracy: 0.7697 - val_loss: 0.5382 - val_accuracy: 0.7765\n",
      "Epoch 158/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.5812 - accuracy: 0.7879 - val_loss: 0.5380 - val_accuracy: 0.7765\n",
      "Epoch 159/400\n",
      "712/712 [==============================] - 0s 101us/sample - loss: 0.5650 - accuracy: 0.7992 - val_loss: 0.5384 - val_accuracy: 0.7598\n",
      "Epoch 160/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5822 - accuracy: 0.7935 - val_loss: 0.5404 - val_accuracy: 0.7933\n",
      "Epoch 161/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5737 - accuracy: 0.7865 - val_loss: 0.5366 - val_accuracy: 0.7709\n",
      "Epoch 162/400\n",
      "712/712 [==============================] - 0s 100us/sample - loss: 0.5795 - accuracy: 0.8006 - val_loss: 0.5383 - val_accuracy: 0.7877\n",
      "Epoch 163/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5687 - accuracy: 0.7879 - val_loss: 0.5369 - val_accuracy: 0.7765\n",
      "Epoch 164/400\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5880 - accuracy: 0.7795 - val_loss: 0.5389 - val_accuracy: 0.7933\n",
      "Epoch 165/400\n",
      "712/712 [==============================] - 0s 100us/sample - loss: 0.5834 - accuracy: 0.7949 - val_loss: 0.5366 - val_accuracy: 0.7765\n",
      "Epoch 166/400\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5898 - accuracy: 0.7795 - val_loss: 0.5365 - val_accuracy: 0.7765\n",
      "Epoch 167/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5829 - accuracy: 0.7865 - val_loss: 0.5393 - val_accuracy: 0.7933\n",
      "Epoch 168/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5836 - accuracy: 0.7795 - val_loss: 0.5507 - val_accuracy: 0.7877\n",
      "Epoch 169/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5811 - accuracy: 0.7907 - val_loss: 0.5369 - val_accuracy: 0.7877\n",
      "Epoch 170/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5743 - accuracy: 0.7837 - val_loss: 0.5345 - val_accuracy: 0.7765\n",
      "Epoch 171/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5681 - accuracy: 0.7921 - val_loss: 0.5369 - val_accuracy: 0.7933\n",
      "Epoch 172/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6048 - accuracy: 0.7669 - val_loss: 0.5384 - val_accuracy: 0.7933\n",
      "Epoch 173/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6000 - accuracy: 0.7711 - val_loss: 0.5349 - val_accuracy: 0.7709\n",
      "Epoch 174/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5804 - accuracy: 0.7921 - val_loss: 0.5419 - val_accuracy: 0.7877\n",
      "Epoch 175/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5800 - accuracy: 0.7851 - val_loss: 0.5341 - val_accuracy: 0.7765\n",
      "Epoch 176/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5734 - accuracy: 0.7949 - val_loss: 0.5342 - val_accuracy: 0.7877\n",
      "Epoch 177/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5730 - accuracy: 0.7879 - val_loss: 0.5371 - val_accuracy: 0.7933\n",
      "Epoch 178/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5614 - accuracy: 0.7978 - val_loss: 0.5331 - val_accuracy: 0.7821\n",
      "Epoch 179/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5687 - accuracy: 0.7949 - val_loss: 0.5336 - val_accuracy: 0.7765\n",
      "Epoch 180/400\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.5713 - accuracy: 0.7809 - val_loss: 0.5334 - val_accuracy: 0.7654\n",
      "Epoch 181/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5829 - accuracy: 0.7753 - val_loss: 0.5339 - val_accuracy: 0.7765\n",
      "Epoch 182/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5865 - accuracy: 0.7837 - val_loss: 0.5390 - val_accuracy: 0.7933\n",
      "Epoch 183/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5953 - accuracy: 0.7879 - val_loss: 0.5346 - val_accuracy: 0.7765\n",
      "Epoch 184/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5784 - accuracy: 0.7781 - val_loss: 0.5346 - val_accuracy: 0.7765\n",
      "Epoch 185/400\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5937 - accuracy: 0.7781 - val_loss: 0.5355 - val_accuracy: 0.7765\n",
      "Epoch 186/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5819 - accuracy: 0.7921 - val_loss: 0.5369 - val_accuracy: 0.7933\n",
      "Epoch 187/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5715 - accuracy: 0.7935 - val_loss: 0.5384 - val_accuracy: 0.7933\n",
      "Epoch 188/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5846 - accuracy: 0.7809 - val_loss: 0.5363 - val_accuracy: 0.7709\n",
      "Epoch 189/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5698 - accuracy: 0.7865 - val_loss: 0.5360 - val_accuracy: 0.7933\n",
      "Epoch 190/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5783 - accuracy: 0.7865 - val_loss: 0.5328 - val_accuracy: 0.7709\n",
      "Epoch 191/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5614 - accuracy: 0.7893 - val_loss: 0.5334 - val_accuracy: 0.7821\n",
      "Epoch 192/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5798 - accuracy: 0.7851 - val_loss: 0.5308 - val_accuracy: 0.7709\n",
      "Epoch 193/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5594 - accuracy: 0.7935 - val_loss: 0.5347 - val_accuracy: 0.7989\n",
      "Epoch 194/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5677 - accuracy: 0.7893 - val_loss: 0.5322 - val_accuracy: 0.7821\n",
      "Epoch 195/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5607 - accuracy: 0.8048 - val_loss: 0.5335 - val_accuracy: 0.7933\n",
      "Epoch 196/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5564 - accuracy: 0.7978 - val_loss: 0.5377 - val_accuracy: 0.7877\n",
      "Epoch 197/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5829 - accuracy: 0.8048 - val_loss: 0.5297 - val_accuracy: 0.7765\n",
      "Epoch 198/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5665 - accuracy: 0.7949 - val_loss: 0.5289 - val_accuracy: 0.7821\n",
      "Epoch 199/400\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5715 - accuracy: 0.8020 - val_loss: 0.5352 - val_accuracy: 0.7933\n",
      "Epoch 200/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5632 - accuracy: 0.7921 - val_loss: 0.5455 - val_accuracy: 0.7877\n",
      "Epoch 201/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5681 - accuracy: 0.7963 - val_loss: 0.5302 - val_accuracy: 0.7709\n",
      "Epoch 202/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5685 - accuracy: 0.7949 - val_loss: 0.5290 - val_accuracy: 0.7765\n",
      "Epoch 203/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5835 - accuracy: 0.7753 - val_loss: 0.5316 - val_accuracy: 0.7877\n",
      "Epoch 204/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5656 - accuracy: 0.7963 - val_loss: 0.5346 - val_accuracy: 0.7598\n",
      "Epoch 205/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5823 - accuracy: 0.7626 - val_loss: 0.5307 - val_accuracy: 0.7709\n",
      "Epoch 206/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5736 - accuracy: 0.7963 - val_loss: 0.5292 - val_accuracy: 0.7709\n",
      "Epoch 207/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5780 - accuracy: 0.7767 - val_loss: 0.5318 - val_accuracy: 0.7877\n",
      "Epoch 208/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5896 - accuracy: 0.7781 - val_loss: 0.5371 - val_accuracy: 0.7933\n",
      "Epoch 209/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5807 - accuracy: 0.7963 - val_loss: 0.5292 - val_accuracy: 0.7709\n",
      "Epoch 210/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5936 - accuracy: 0.7739 - val_loss: 0.5314 - val_accuracy: 0.7709\n",
      "Epoch 211/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5613 - accuracy: 0.7851 - val_loss: 0.5286 - val_accuracy: 0.7709\n",
      "Epoch 212/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5656 - accuracy: 0.7879 - val_loss: 0.5300 - val_accuracy: 0.7877\n",
      "Epoch 213/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5741 - accuracy: 0.7837 - val_loss: 0.5269 - val_accuracy: 0.7765\n",
      "Epoch 214/400\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5707 - accuracy: 0.7795 - val_loss: 0.5304 - val_accuracy: 0.7989\n",
      "Epoch 215/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5941 - accuracy: 0.7711 - val_loss: 0.5280 - val_accuracy: 0.7709\n",
      "Epoch 216/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5890 - accuracy: 0.7795 - val_loss: 0.5286 - val_accuracy: 0.7877\n",
      "Epoch 217/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5685 - accuracy: 0.7851 - val_loss: 0.5298 - val_accuracy: 0.7877\n",
      "Epoch 218/400\n",
      "712/712 [==============================] - 0s 102us/sample - loss: 0.5643 - accuracy: 0.7949 - val_loss: 0.5354 - val_accuracy: 0.7933\n",
      "Epoch 219/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5640 - accuracy: 0.7978 - val_loss: 0.5336 - val_accuracy: 0.7933\n",
      "Epoch 220/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5682 - accuracy: 0.7921 - val_loss: 0.5301 - val_accuracy: 0.7933\n",
      "Epoch 221/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5717 - accuracy: 0.7851 - val_loss: 0.5277 - val_accuracy: 0.7654\n",
      "Epoch 222/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5671 - accuracy: 0.7893 - val_loss: 0.5313 - val_accuracy: 0.7933\n",
      "Epoch 223/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5747 - accuracy: 0.7851 - val_loss: 0.5297 - val_accuracy: 0.7989\n",
      "Epoch 224/400\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5518 - accuracy: 0.7935 - val_loss: 0.5277 - val_accuracy: 0.7765\n",
      "Epoch 225/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5846 - accuracy: 0.7612 - val_loss: 0.5272 - val_accuracy: 0.7765\n",
      "Epoch 226/400\n",
      "712/712 [==============================] - 0s 100us/sample - loss: 0.5595 - accuracy: 0.7921 - val_loss: 0.5264 - val_accuracy: 0.7877\n",
      "Epoch 227/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5684 - accuracy: 0.8020 - val_loss: 0.5274 - val_accuracy: 0.7709\n",
      "Epoch 228/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5649 - accuracy: 0.7921 - val_loss: 0.5343 - val_accuracy: 0.7933\n",
      "Epoch 229/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5862 - accuracy: 0.7865 - val_loss: 0.5263 - val_accuracy: 0.7765\n",
      "Epoch 230/400\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.5667 - accuracy: 0.7879 - val_loss: 0.5285 - val_accuracy: 0.7877\n",
      "Epoch 231/400\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5713 - accuracy: 0.7879 - val_loss: 0.5272 - val_accuracy: 0.7709\n",
      "Epoch 232/400\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.5714 - accuracy: 0.7921 - val_loss: 0.5324 - val_accuracy: 0.7933\n",
      "Epoch 233/400\n",
      "712/712 [==============================] - 0s 102us/sample - loss: 0.5671 - accuracy: 0.7949 - val_loss: 0.5266 - val_accuracy: 0.7877\n",
      "Epoch 234/400\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5672 - accuracy: 0.7978 - val_loss: 0.5271 - val_accuracy: 0.7877\n",
      "Epoch 235/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5623 - accuracy: 0.7851 - val_loss: 0.5253 - val_accuracy: 0.7709\n",
      "Epoch 236/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5651 - accuracy: 0.7809 - val_loss: 0.5261 - val_accuracy: 0.7877\n",
      "Epoch 237/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5669 - accuracy: 0.7851 - val_loss: 0.5295 - val_accuracy: 0.7933\n",
      "Epoch 238/400\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5724 - accuracy: 0.7865 - val_loss: 0.5267 - val_accuracy: 0.7765\n",
      "Epoch 239/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5704 - accuracy: 0.7893 - val_loss: 0.5372 - val_accuracy: 0.7933\n",
      "Epoch 240/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5732 - accuracy: 0.7809 - val_loss: 0.5286 - val_accuracy: 0.7933\n",
      "Epoch 241/400\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5688 - accuracy: 0.7893 - val_loss: 0.5257 - val_accuracy: 0.7709\n",
      "Epoch 242/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5553 - accuracy: 0.7949 - val_loss: 0.5259 - val_accuracy: 0.7709\n",
      "Epoch 243/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5573 - accuracy: 0.7921 - val_loss: 0.5316 - val_accuracy: 0.7933\n",
      "Epoch 244/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5681 - accuracy: 0.7879 - val_loss: 0.5297 - val_accuracy: 0.7598\n",
      "Epoch 245/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5843 - accuracy: 0.7725 - val_loss: 0.5236 - val_accuracy: 0.7765\n",
      "Epoch 246/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5736 - accuracy: 0.7753 - val_loss: 0.5249 - val_accuracy: 0.7709\n",
      "Epoch 247/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5456 - accuracy: 0.7992 - val_loss: 0.5258 - val_accuracy: 0.7709\n",
      "Epoch 248/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5544 - accuracy: 0.8090 - val_loss: 0.5296 - val_accuracy: 0.7933\n",
      "Epoch 249/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5609 - accuracy: 0.8076 - val_loss: 0.5237 - val_accuracy: 0.7821\n",
      "Epoch 250/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5724 - accuracy: 0.7879 - val_loss: 0.5239 - val_accuracy: 0.7765\n",
      "Epoch 251/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5493 - accuracy: 0.7893 - val_loss: 0.5229 - val_accuracy: 0.7877\n",
      "Epoch 252/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5606 - accuracy: 0.8034 - val_loss: 0.5267 - val_accuracy: 0.7598\n",
      "Epoch 253/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5521 - accuracy: 0.7907 - val_loss: 0.5223 - val_accuracy: 0.7877\n",
      "Epoch 254/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5456 - accuracy: 0.8076 - val_loss: 0.5213 - val_accuracy: 0.7765\n",
      "Epoch 255/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5727 - accuracy: 0.7851 - val_loss: 0.5219 - val_accuracy: 0.7821\n",
      "Epoch 256/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5732 - accuracy: 0.7823 - val_loss: 0.5236 - val_accuracy: 0.7821\n",
      "Epoch 257/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5633 - accuracy: 0.8020 - val_loss: 0.5257 - val_accuracy: 0.7709\n",
      "Epoch 258/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5718 - accuracy: 0.7823 - val_loss: 0.5237 - val_accuracy: 0.7877\n",
      "Epoch 259/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5627 - accuracy: 0.7907 - val_loss: 0.5275 - val_accuracy: 0.7989\n",
      "Epoch 260/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5660 - accuracy: 0.7907 - val_loss: 0.5233 - val_accuracy: 0.7765\n",
      "Epoch 261/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5645 - accuracy: 0.8034 - val_loss: 0.5258 - val_accuracy: 0.7821\n",
      "Epoch 262/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5735 - accuracy: 0.7725 - val_loss: 0.5247 - val_accuracy: 0.7709\n",
      "Epoch 263/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5699 - accuracy: 0.7893 - val_loss: 0.5237 - val_accuracy: 0.7765\n",
      "Epoch 264/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5527 - accuracy: 0.7865 - val_loss: 0.5222 - val_accuracy: 0.7821\n",
      "Epoch 265/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5649 - accuracy: 0.7907 - val_loss: 0.5263 - val_accuracy: 0.7989\n",
      "Epoch 266/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5680 - accuracy: 0.7837 - val_loss: 0.5251 - val_accuracy: 0.7989\n",
      "Epoch 267/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5785 - accuracy: 0.7907 - val_loss: 0.5231 - val_accuracy: 0.7821\n",
      "Epoch 268/400\n",
      "712/712 [==============================] - 0s 104us/sample - loss: 0.5639 - accuracy: 0.7879 - val_loss: 0.5233 - val_accuracy: 0.7877\n",
      "Epoch 269/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5664 - accuracy: 0.7893 - val_loss: 0.5224 - val_accuracy: 0.7821\n",
      "Epoch 270/400\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5682 - accuracy: 0.7907 - val_loss: 0.5220 - val_accuracy: 0.7709\n",
      "Epoch 271/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5566 - accuracy: 0.8062 - val_loss: 0.5222 - val_accuracy: 0.7877\n",
      "Epoch 272/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5575 - accuracy: 0.7851 - val_loss: 0.5204 - val_accuracy: 0.7709\n",
      "Epoch 273/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5744 - accuracy: 0.7949 - val_loss: 0.5213 - val_accuracy: 0.7709\n",
      "Epoch 274/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5741 - accuracy: 0.7893 - val_loss: 0.5199 - val_accuracy: 0.7765\n",
      "Epoch 275/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5631 - accuracy: 0.8076 - val_loss: 0.5204 - val_accuracy: 0.7821\n",
      "Epoch 276/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5739 - accuracy: 0.7753 - val_loss: 0.5209 - val_accuracy: 0.7821\n",
      "Epoch 277/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5686 - accuracy: 0.7837 - val_loss: 0.5225 - val_accuracy: 0.7877\n",
      "Epoch 278/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5575 - accuracy: 0.7949 - val_loss: 0.5201 - val_accuracy: 0.7709\n",
      "Epoch 279/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5686 - accuracy: 0.7809 - val_loss: 0.5297 - val_accuracy: 0.7933\n",
      "Epoch 280/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5607 - accuracy: 0.7893 - val_loss: 0.5225 - val_accuracy: 0.7709\n",
      "Epoch 281/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5559 - accuracy: 0.7851 - val_loss: 0.5191 - val_accuracy: 0.7765\n",
      "Epoch 282/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5650 - accuracy: 0.7907 - val_loss: 0.5223 - val_accuracy: 0.7821\n",
      "Epoch 283/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5472 - accuracy: 0.7949 - val_loss: 0.5246 - val_accuracy: 0.7989\n",
      "Epoch 284/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5578 - accuracy: 0.7935 - val_loss: 0.5198 - val_accuracy: 0.7821\n",
      "Epoch 285/400\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5683 - accuracy: 0.8034 - val_loss: 0.5217 - val_accuracy: 0.7877\n",
      "Epoch 286/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5577 - accuracy: 0.7921 - val_loss: 0.5206 - val_accuracy: 0.7821\n",
      "Epoch 287/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5517 - accuracy: 0.7963 - val_loss: 0.5250 - val_accuracy: 0.7933\n",
      "Epoch 288/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5716 - accuracy: 0.7851 - val_loss: 0.5187 - val_accuracy: 0.7821\n",
      "Epoch 289/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5639 - accuracy: 0.7879 - val_loss: 0.5182 - val_accuracy: 0.7821\n",
      "Epoch 290/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5664 - accuracy: 0.7921 - val_loss: 0.5217 - val_accuracy: 0.7821\n",
      "Epoch 291/400\n",
      "712/712 [==============================] - 0s 100us/sample - loss: 0.5657 - accuracy: 0.7879 - val_loss: 0.5199 - val_accuracy: 0.7877\n",
      "Epoch 292/400\n",
      "712/712 [==============================] - 0s 104us/sample - loss: 0.5593 - accuracy: 0.8020 - val_loss: 0.5225 - val_accuracy: 0.7989\n",
      "Epoch 293/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5640 - accuracy: 0.8090 - val_loss: 0.5265 - val_accuracy: 0.7933\n",
      "Epoch 294/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5719 - accuracy: 0.7851 - val_loss: 0.5204 - val_accuracy: 0.7877\n",
      "Epoch 295/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5582 - accuracy: 0.7921 - val_loss: 0.5207 - val_accuracy: 0.7877\n",
      "Epoch 296/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5596 - accuracy: 0.7992 - val_loss: 0.5205 - val_accuracy: 0.7933\n",
      "Epoch 297/400\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5655 - accuracy: 0.8020 - val_loss: 0.5196 - val_accuracy: 0.7765\n",
      "Epoch 298/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5637 - accuracy: 0.7893 - val_loss: 0.5311 - val_accuracy: 0.7933\n",
      "Epoch 299/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5742 - accuracy: 0.7753 - val_loss: 0.5199 - val_accuracy: 0.7877\n",
      "Epoch 300/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5701 - accuracy: 0.7851 - val_loss: 0.5205 - val_accuracy: 0.7877\n",
      "Epoch 301/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5571 - accuracy: 0.7809 - val_loss: 0.5273 - val_accuracy: 0.7933\n",
      "Epoch 302/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5671 - accuracy: 0.7921 - val_loss: 0.5228 - val_accuracy: 0.7933\n",
      "Epoch 303/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5530 - accuracy: 0.7949 - val_loss: 0.5174 - val_accuracy: 0.7821\n",
      "Epoch 304/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5487 - accuracy: 0.8132 - val_loss: 0.5171 - val_accuracy: 0.7877\n",
      "Epoch 305/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5596 - accuracy: 0.7907 - val_loss: 0.5203 - val_accuracy: 0.7933\n",
      "Epoch 306/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5667 - accuracy: 0.7963 - val_loss: 0.5189 - val_accuracy: 0.7765\n",
      "Epoch 307/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5717 - accuracy: 0.7837 - val_loss: 0.5185 - val_accuracy: 0.7765\n",
      "Epoch 308/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5570 - accuracy: 0.7809 - val_loss: 0.5190 - val_accuracy: 0.7877\n",
      "Epoch 309/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5597 - accuracy: 0.7949 - val_loss: 0.5193 - val_accuracy: 0.7877\n",
      "Epoch 310/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5497 - accuracy: 0.7992 - val_loss: 0.5231 - val_accuracy: 0.7598\n",
      "Epoch 311/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5635 - accuracy: 0.7935 - val_loss: 0.5177 - val_accuracy: 0.7877\n",
      "Epoch 312/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5583 - accuracy: 0.7809 - val_loss: 0.5179 - val_accuracy: 0.7877\n",
      "Epoch 313/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5558 - accuracy: 0.7949 - val_loss: 0.5173 - val_accuracy: 0.7821\n",
      "Epoch 314/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5454 - accuracy: 0.8006 - val_loss: 0.5163 - val_accuracy: 0.7933\n",
      "Epoch 315/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5640 - accuracy: 0.7851 - val_loss: 0.5177 - val_accuracy: 0.7933\n",
      "Epoch 316/400\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5604 - accuracy: 0.8006 - val_loss: 0.5172 - val_accuracy: 0.7877\n",
      "Epoch 317/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5656 - accuracy: 0.7949 - val_loss: 0.5186 - val_accuracy: 0.7765\n",
      "Epoch 318/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5486 - accuracy: 0.7851 - val_loss: 0.5209 - val_accuracy: 0.7933\n",
      "Epoch 319/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5374 - accuracy: 0.8132 - val_loss: 0.5164 - val_accuracy: 0.7765\n",
      "Epoch 320/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5662 - accuracy: 0.7921 - val_loss: 0.5255 - val_accuracy: 0.7933\n",
      "Epoch 321/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5626 - accuracy: 0.7921 - val_loss: 0.5229 - val_accuracy: 0.7933\n",
      "Epoch 322/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5631 - accuracy: 0.7978 - val_loss: 0.5159 - val_accuracy: 0.7765\n",
      "Epoch 323/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5420 - accuracy: 0.8020 - val_loss: 0.5154 - val_accuracy: 0.7821\n",
      "Epoch 324/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5553 - accuracy: 0.7865 - val_loss: 0.5153 - val_accuracy: 0.7877\n",
      "Epoch 325/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5722 - accuracy: 0.7893 - val_loss: 0.5171 - val_accuracy: 0.7933\n",
      "Epoch 326/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5508 - accuracy: 0.7851 - val_loss: 0.5206 - val_accuracy: 0.7933\n",
      "Epoch 327/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5525 - accuracy: 0.7893 - val_loss: 0.5181 - val_accuracy: 0.7933\n",
      "Epoch 328/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5660 - accuracy: 0.7893 - val_loss: 0.5145 - val_accuracy: 0.7821\n",
      "Epoch 329/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5656 - accuracy: 0.7949 - val_loss: 0.5169 - val_accuracy: 0.7765\n",
      "Epoch 330/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5624 - accuracy: 0.7879 - val_loss: 0.5158 - val_accuracy: 0.7709\n",
      "Epoch 331/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5534 - accuracy: 0.8006 - val_loss: 0.5139 - val_accuracy: 0.7933\n",
      "Epoch 332/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5431 - accuracy: 0.7949 - val_loss: 0.5215 - val_accuracy: 0.7933\n",
      "Epoch 333/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5688 - accuracy: 0.7907 - val_loss: 0.5205 - val_accuracy: 0.7821\n",
      "Epoch 334/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5647 - accuracy: 0.7809 - val_loss: 0.5176 - val_accuracy: 0.7933\n",
      "Epoch 335/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5507 - accuracy: 0.7921 - val_loss: 0.5166 - val_accuracy: 0.7765\n",
      "Epoch 336/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5535 - accuracy: 0.7837 - val_loss: 0.5172 - val_accuracy: 0.7933\n",
      "Epoch 337/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5494 - accuracy: 0.8076 - val_loss: 0.5160 - val_accuracy: 0.7821\n",
      "Epoch 338/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5490 - accuracy: 0.7935 - val_loss: 0.5173 - val_accuracy: 0.7933\n",
      "Epoch 339/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5596 - accuracy: 0.8006 - val_loss: 0.5239 - val_accuracy: 0.7933\n",
      "Epoch 340/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5576 - accuracy: 0.8062 - val_loss: 0.5166 - val_accuracy: 0.7877\n",
      "Epoch 341/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5764 - accuracy: 0.7739 - val_loss: 0.5152 - val_accuracy: 0.7821\n",
      "Epoch 342/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5510 - accuracy: 0.7935 - val_loss: 0.5145 - val_accuracy: 0.7765\n",
      "Epoch 343/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5540 - accuracy: 0.7767 - val_loss: 0.5220 - val_accuracy: 0.7933\n",
      "Epoch 344/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5370 - accuracy: 0.8146 - val_loss: 0.5173 - val_accuracy: 0.7821\n",
      "Epoch 345/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5610 - accuracy: 0.7795 - val_loss: 0.5168 - val_accuracy: 0.7933\n",
      "Epoch 346/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5547 - accuracy: 0.8006 - val_loss: 0.5203 - val_accuracy: 0.7654\n",
      "Epoch 347/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5590 - accuracy: 0.7697 - val_loss: 0.5135 - val_accuracy: 0.7821\n",
      "Epoch 348/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5585 - accuracy: 0.7879 - val_loss: 0.5302 - val_accuracy: 0.7933\n",
      "Epoch 349/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5582 - accuracy: 0.7851 - val_loss: 0.5140 - val_accuracy: 0.7821\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5566 - accuracy: 0.7879 - val_loss: 0.5133 - val_accuracy: 0.7877\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5550 - accuracy: 0.7992 - val_loss: 0.5132 - val_accuracy: 0.7765\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5461 - accuracy: 0.7893 - val_loss: 0.5216 - val_accuracy: 0.7933\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5596 - accuracy: 0.7851 - val_loss: 0.5261 - val_accuracy: 0.7933\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5654 - accuracy: 0.7865 - val_loss: 0.5138 - val_accuracy: 0.7989\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5536 - accuracy: 0.7963 - val_loss: 0.5148 - val_accuracy: 0.7821\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5519 - accuracy: 0.7963 - val_loss: 0.5152 - val_accuracy: 0.7821\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5449 - accuracy: 0.8034 - val_loss: 0.5143 - val_accuracy: 0.7933\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5606 - accuracy: 0.7837 - val_loss: 0.5152 - val_accuracy: 0.7877\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5402 - accuracy: 0.8062 - val_loss: 0.5154 - val_accuracy: 0.7765\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5507 - accuracy: 0.8062 - val_loss: 0.5153 - val_accuracy: 0.7933\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5467 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7989\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5647 - accuracy: 0.7823 - val_loss: 0.5130 - val_accuracy: 0.7765\n",
      "Epoch 363/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5620 - accuracy: 0.7907 - val_loss: 0.5174 - val_accuracy: 0.7933\n",
      "Epoch 364/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5605 - accuracy: 0.7935 - val_loss: 0.5139 - val_accuracy: 0.7821\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5546 - accuracy: 0.7963 - val_loss: 0.5154 - val_accuracy: 0.7877\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5538 - accuracy: 0.7921 - val_loss: 0.5139 - val_accuracy: 0.7821\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5677 - accuracy: 0.7795 - val_loss: 0.5249 - val_accuracy: 0.7933\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5496 - accuracy: 0.8104 - val_loss: 0.5135 - val_accuracy: 0.7765\n",
      "Epoch 369/400\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5682 - accuracy: 0.7795 - val_loss: 0.5141 - val_accuracy: 0.7765\n",
      "Epoch 370/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5470 - accuracy: 0.7935 - val_loss: 0.5156 - val_accuracy: 0.7933\n",
      "Epoch 371/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5466 - accuracy: 0.8048 - val_loss: 0.5175 - val_accuracy: 0.7821\n",
      "Epoch 372/400\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.5587 - accuracy: 0.7921 - val_loss: 0.5137 - val_accuracy: 0.7821\n",
      "Epoch 373/400\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5454 - accuracy: 0.7978 - val_loss: 0.5138 - val_accuracy: 0.7877\n",
      "Epoch 374/400\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5776 - accuracy: 0.7851 - val_loss: 0.5169 - val_accuracy: 0.7933\n",
      "Epoch 375/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5495 - accuracy: 0.7992 - val_loss: 0.5151 - val_accuracy: 0.7765\n",
      "Epoch 376/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5561 - accuracy: 0.7935 - val_loss: 0.5157 - val_accuracy: 0.7877\n",
      "Epoch 377/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5541 - accuracy: 0.7978 - val_loss: 0.5168 - val_accuracy: 0.7821\n",
      "Epoch 378/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5458 - accuracy: 0.8006 - val_loss: 0.5124 - val_accuracy: 0.7765\n",
      "Epoch 379/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5512 - accuracy: 0.7907 - val_loss: 0.5152 - val_accuracy: 0.7933\n",
      "Epoch 380/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5611 - accuracy: 0.7851 - val_loss: 0.5125 - val_accuracy: 0.7821\n",
      "Epoch 381/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5527 - accuracy: 0.8006 - val_loss: 0.5260 - val_accuracy: 0.7654\n",
      "Epoch 382/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5615 - accuracy: 0.7935 - val_loss: 0.5150 - val_accuracy: 0.7821\n",
      "Epoch 383/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5569 - accuracy: 0.7907 - val_loss: 0.5119 - val_accuracy: 0.7765\n",
      "Epoch 384/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5538 - accuracy: 0.7851 - val_loss: 0.5112 - val_accuracy: 0.7821\n",
      "Epoch 385/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5448 - accuracy: 0.8104 - val_loss: 0.5113 - val_accuracy: 0.7933\n",
      "Epoch 386/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5641 - accuracy: 0.7851 - val_loss: 0.5144 - val_accuracy: 0.7821\n",
      "Epoch 387/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5539 - accuracy: 0.7907 - val_loss: 0.5113 - val_accuracy: 0.7821\n",
      "Epoch 388/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5568 - accuracy: 0.7809 - val_loss: 0.5130 - val_accuracy: 0.7933\n",
      "Epoch 389/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5373 - accuracy: 0.8034 - val_loss: 0.5111 - val_accuracy: 0.7821\n",
      "Epoch 390/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5534 - accuracy: 0.7963 - val_loss: 0.5107 - val_accuracy: 0.7933\n",
      "Epoch 391/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5656 - accuracy: 0.7935 - val_loss: 0.5115 - val_accuracy: 0.7877\n",
      "Epoch 392/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5454 - accuracy: 0.7992 - val_loss: 0.5123 - val_accuracy: 0.7821\n",
      "Epoch 393/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5634 - accuracy: 0.7725 - val_loss: 0.5192 - val_accuracy: 0.7654\n",
      "Epoch 394/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5611 - accuracy: 0.7823 - val_loss: 0.5139 - val_accuracy: 0.7877\n",
      "Epoch 395/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5524 - accuracy: 0.8034 - val_loss: 0.5119 - val_accuracy: 0.7877\n",
      "Epoch 396/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5588 - accuracy: 0.7992 - val_loss: 0.5123 - val_accuracy: 0.7877\n",
      "Epoch 397/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5331 - accuracy: 0.7935 - val_loss: 0.5149 - val_accuracy: 0.7821\n",
      "Epoch 398/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5461 - accuracy: 0.7978 - val_loss: 0.5157 - val_accuracy: 0.7933\n",
      "Epoch 399/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5436 - accuracy: 0.8048 - val_loss: 0.5203 - val_accuracy: 0.7654\n",
      "Epoch 400/400\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5722 - accuracy: 0.7767 - val_loss: 0.5136 - val_accuracy: 0.7933\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 51f3b67c2fc128988d9d001e778de0ec</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7932960987091064</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-batch_size: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_0: sigmoid</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_1: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_2: sigmoid</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_3: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_4: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_5: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_6: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_1: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_2: 56</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_3: 40</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_4: 48</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_5: 56</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_6: 56</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_0: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_1: 0.2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_2: 0.1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_3: 0.45</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_4: 0.45</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_5: 0.45</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_6: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-epoch_number: 400</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_0: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_1: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_2: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_3: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_4: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_5: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_6: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_0: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_1: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_2: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_3: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_4: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_5: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_6: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-learning_rate: 0.0003</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: RMSprop</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/600\n",
      "712/712 [==============================] - 1s 2ms/sample - loss: 1.2221 - accuracy: 0.5590 - val_loss: 1.1809 - val_accuracy: 0.5866\n",
      "Epoch 2/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.1786 - accuracy: 0.5281 - val_loss: 1.1418 - val_accuracy: 0.5866\n",
      "Epoch 3/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1470 - accuracy: 0.5295 - val_loss: 1.1128 - val_accuracy: 0.5866\n",
      "Epoch 4/600\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 1.1075 - accuracy: 0.5295 - val_loss: 1.0866 - val_accuracy: 0.5866\n",
      "Epoch 5/600\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 1.0857 - accuracy: 0.5351 - val_loss: 1.0629 - val_accuracy: 0.5866\n",
      "Epoch 6/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.0681 - accuracy: 0.5126 - val_loss: 1.0401 - val_accuracy: 0.5866\n",
      "Epoch 7/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.0281 - accuracy: 0.5435 - val_loss: 1.0207 - val_accuracy: 0.5866\n",
      "Epoch 8/600\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 1.0169 - accuracy: 0.5365 - val_loss: 1.0009 - val_accuracy: 0.5866\n",
      "Epoch 9/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.0157 - accuracy: 0.4789 - val_loss: 0.9834 - val_accuracy: 0.5866\n",
      "Epoch 10/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.9772 - accuracy: 0.5393 - val_loss: 0.9660 - val_accuracy: 0.5866\n",
      "Epoch 11/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.9625 - accuracy: 0.5197 - val_loss: 0.9489 - val_accuracy: 0.5866\n",
      "Epoch 12/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.9468 - accuracy: 0.4986 - val_loss: 0.9330 - val_accuracy: 0.5866\n",
      "Epoch 13/600\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.9386 - accuracy: 0.5042 - val_loss: 0.9176 - val_accuracy: 0.5866\n",
      "Epoch 14/600\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.9196 - accuracy: 0.5098 - val_loss: 0.9033 - val_accuracy: 0.5866\n",
      "Epoch 15/600\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.8941 - accuracy: 0.5281 - val_loss: 0.8898 - val_accuracy: 0.5866\n",
      "Epoch 16/600\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.8908 - accuracy: 0.4888 - val_loss: 0.8767 - val_accuracy: 0.7598\n",
      "Epoch 17/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.8811 - accuracy: 0.4874 - val_loss: 0.8652 - val_accuracy: 0.5866\n",
      "Epoch 18/600\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.8665 - accuracy: 0.5070 - val_loss: 0.8541 - val_accuracy: 0.5866\n",
      "Epoch 19/600\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.8478 - accuracy: 0.5323 - val_loss: 0.8440 - val_accuracy: 0.5866\n",
      "Epoch 20/600\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.8459 - accuracy: 0.4958 - val_loss: 0.8336 - val_accuracy: 0.5866\n",
      "Epoch 21/600\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.8292 - accuracy: 0.5056 - val_loss: 0.8248 - val_accuracy: 0.5866\n",
      "Epoch 22/600\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.8172 - accuracy: 0.5211 - val_loss: 0.8155 - val_accuracy: 0.5866\n",
      "Epoch 23/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.8112 - accuracy: 0.5154 - val_loss: 0.8075 - val_accuracy: 0.5866\n",
      "Epoch 24/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.8027 - accuracy: 0.5253 - val_loss: 0.8004 - val_accuracy: 0.5866\n",
      "Epoch 25/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.8067 - accuracy: 0.4874 - val_loss: 0.7934 - val_accuracy: 0.5866\n",
      "Epoch 26/600\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7967 - accuracy: 0.5098 - val_loss: 0.7875 - val_accuracy: 0.5866\n",
      "Epoch 27/600\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.7885 - accuracy: 0.5084 - val_loss: 0.7817 - val_accuracy: 0.5866\n",
      "Epoch 28/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.7795 - accuracy: 0.4972 - val_loss: 0.7766 - val_accuracy: 0.5866\n",
      "Epoch 29/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7707 - accuracy: 0.5197 - val_loss: 0.7714 - val_accuracy: 0.5866\n",
      "Epoch 30/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.7622 - accuracy: 0.5211 - val_loss: 0.7682 - val_accuracy: 0.5866\n",
      "Epoch 31/600\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.7804 - accuracy: 0.4649 - val_loss: 0.7639 - val_accuracy: 0.5866\n",
      "Epoch 32/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7574 - accuracy: 0.5028 - val_loss: 0.7594 - val_accuracy: 0.5866\n",
      "Epoch 33/600\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7632 - accuracy: 0.5098 - val_loss: 0.7561 - val_accuracy: 0.5866\n",
      "Epoch 34/600\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7464 - accuracy: 0.5239 - val_loss: 0.7541 - val_accuracy: 0.5866\n",
      "Epoch 35/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7566 - accuracy: 0.5169 - val_loss: 0.7506 - val_accuracy: 0.5866\n",
      "Epoch 36/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7302 - accuracy: 0.5379 - val_loss: 0.7460 - val_accuracy: 0.5866\n",
      "Epoch 37/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6936 - accuracy: 0.5716 - val_loss: 0.7066 - val_accuracy: 0.5866\n",
      "Epoch 515/600\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6966 - accuracy: 0.5548 - val_loss: 0.7066 - val_accuracy: 0.5866\n",
      "Epoch 516/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6955 - accuracy: 0.5435 - val_loss: 0.7067 - val_accuracy: 0.5866\n",
      "Epoch 517/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6973 - accuracy: 0.5506 - val_loss: 0.7065 - val_accuracy: 0.5866\n",
      "Epoch 518/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6937 - accuracy: 0.5772 - val_loss: 0.7066 - val_accuracy: 0.5866\n",
      "Epoch 519/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.6941 - accuracy: 0.5632 - val_loss: 0.7066 - val_accuracy: 0.5866\n",
      "Epoch 520/600\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.6964 - accuracy: 0.5534 - val_loss: 0.7066 - val_accuracy: 0.5866\n",
      "Epoch 521/600\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6941 - accuracy: 0.5449 - val_loss: 0.7065 - val_accuracy: 0.5866\n",
      "Epoch 522/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7009 - accuracy: 0.5604 - val_loss: 0.7065 - val_accuracy: 0.5866\n",
      "Epoch 523/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6961 - accuracy: 0.5435 - val_loss: 0.7064 - val_accuracy: 0.5866\n",
      "Epoch 524/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6990 - accuracy: 0.5449 - val_loss: 0.7064 - val_accuracy: 0.5866\n",
      "Epoch 525/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6893 - accuracy: 0.5772 - val_loss: 0.7064 - val_accuracy: 0.5866\n",
      "Epoch 526/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6974 - accuracy: 0.5449 - val_loss: 0.7066 - val_accuracy: 0.5866\n",
      "Epoch 527/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6891 - accuracy: 0.5843 - val_loss: 0.7065 - val_accuracy: 0.5866\n",
      "Epoch 528/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6945 - accuracy: 0.5618 - val_loss: 0.7065 - val_accuracy: 0.5866\n",
      "Epoch 529/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.6972 - accuracy: 0.5365 - val_loss: 0.7063 - val_accuracy: 0.5866\n",
      "Epoch 530/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.6948 - accuracy: 0.5576 - val_loss: 0.7063 - val_accuracy: 0.5866\n",
      "Epoch 531/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.6947 - accuracy: 0.5590 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 532/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6980 - accuracy: 0.5463 - val_loss: 0.7063 - val_accuracy: 0.5866\n",
      "Epoch 533/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6923 - accuracy: 0.5730 - val_loss: 0.7061 - val_accuracy: 0.5866\n",
      "Epoch 534/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6974 - accuracy: 0.5140 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 535/600\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6923 - accuracy: 0.5646 - val_loss: 0.7061 - val_accuracy: 0.5866\n",
      "Epoch 536/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6924 - accuracy: 0.5365 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 537/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6981 - accuracy: 0.5337 - val_loss: 0.7061 - val_accuracy: 0.5866\n",
      "Epoch 538/600\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.6910 - accuracy: 0.5871 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 539/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6971 - accuracy: 0.5365 - val_loss: 0.7061 - val_accuracy: 0.5866\n",
      "Epoch 540/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6976 - accuracy: 0.5407 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 541/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6947 - accuracy: 0.5815 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 542/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6956 - accuracy: 0.5534 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 543/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6933 - accuracy: 0.5576 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 544/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6995 - accuracy: 0.5323 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 545/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6991 - accuracy: 0.5534 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 546/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6933 - accuracy: 0.5646 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 547/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6980 - accuracy: 0.5351 - val_loss: 0.7061 - val_accuracy: 0.5866\n",
      "Epoch 548/600\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.7040 - accuracy: 0.5225 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 549/600\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.6974 - accuracy: 0.5421 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 550/600\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7025 - accuracy: 0.5435 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 551/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6925 - accuracy: 0.5604 - val_loss: 0.7062 - val_accuracy: 0.5866\n",
      "Epoch 552/600\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.8313 - accuracy: 0.5787 - val_loss: 0.8354 - val_accuracy: 0.7151\n",
      "Epoch 344/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.8531 - accuracy: 0.5323 - val_loss: 0.8353 - val_accuracy: 0.7151\n",
      "Epoch 345/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.8544 - accuracy: 0.5506 - val_loss: 0.8352 - val_accuracy: 0.7151\n",
      "Epoch 346/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8506 - accuracy: 0.5576 - val_loss: 0.8352 - val_accuracy: 0.7207\n",
      "Epoch 347/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.8418 - accuracy: 0.5983 - val_loss: 0.8351 - val_accuracy: 0.7151\n",
      "Epoch 348/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.8408 - accuracy: 0.5716 - val_loss: 0.8351 - val_accuracy: 0.7207\n",
      "Epoch 349/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8409 - accuracy: 0.5871 - val_loss: 0.8350 - val_accuracy: 0.7207\n",
      "Epoch 350/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.8520 - accuracy: 0.5618 - val_loss: 0.8349 - val_accuracy: 0.7207\n",
      "Epoch 351/600\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.8541 - accuracy: 0.5492 - val_loss: 0.8348 - val_accuracy: 0.7207\n",
      "Epoch 352/600\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.8566 - accuracy: 0.5534 - val_loss: 0.8347 - val_accuracy: 0.7207\n",
      "Epoch 353/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.8227 - accuracy: 0.6320 - val_loss: 0.8346 - val_accuracy: 0.7207\n",
      "Epoch 354/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.8453 - accuracy: 0.5885 - val_loss: 0.8346 - val_accuracy: 0.7207\n",
      "Epoch 355/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8557 - accuracy: 0.5534 - val_loss: 0.8345 - val_accuracy: 0.7207\n",
      "Epoch 356/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8615 - accuracy: 0.5154 - val_loss: 0.8344 - val_accuracy: 0.7207\n",
      "Epoch 357/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8502 - accuracy: 0.5632 - val_loss: 0.8343 - val_accuracy: 0.7207\n",
      "Epoch 358/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.8494 - accuracy: 0.5618 - val_loss: 0.8343 - val_accuracy: 0.7207\n",
      "Epoch 359/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.8484 - accuracy: 0.5449 - val_loss: 0.8342 - val_accuracy: 0.7207\n",
      "Epoch 360/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.8454 - accuracy: 0.5927 - val_loss: 0.8342 - val_accuracy: 0.7207\n",
      "Epoch 361/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.8497 - accuracy: 0.5632 - val_loss: 0.8341 - val_accuracy: 0.7207\n",
      "Epoch 362/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.8483 - accuracy: 0.5688 - val_loss: 0.8340 - val_accuracy: 0.7207\n",
      "Epoch 363/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.8516 - accuracy: 0.5801 - val_loss: 0.8339 - val_accuracy: 0.7207\n",
      "Epoch 364/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.8458 - accuracy: 0.5702 - val_loss: 0.8338 - val_accuracy: 0.7207\n",
      "Epoch 365/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.8440 - accuracy: 0.5730 - val_loss: 0.8338 - val_accuracy: 0.7207\n",
      "Epoch 366/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8512 - accuracy: 0.5702 - val_loss: 0.8336 - val_accuracy: 0.7207\n",
      "Epoch 367/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.8525 - accuracy: 0.5829 - val_loss: 0.8336 - val_accuracy: 0.7207\n",
      "Epoch 368/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8522 - accuracy: 0.5562 - val_loss: 0.8335 - val_accuracy: 0.7207\n",
      "Epoch 369/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.8505 - accuracy: 0.5857 - val_loss: 0.8334 - val_accuracy: 0.7207\n",
      "Epoch 370/600\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.8384 - accuracy: 0.5829 - val_loss: 0.8333 - val_accuracy: 0.7207\n",
      "Epoch 371/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.8484 - accuracy: 0.5660 - val_loss: 0.8332 - val_accuracy: 0.7207\n",
      "Epoch 372/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.8449 - accuracy: 0.5604 - val_loss: 0.8331 - val_accuracy: 0.7207\n",
      "Epoch 373/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.8506 - accuracy: 0.5576 - val_loss: 0.8330 - val_accuracy: 0.7207\n",
      "Epoch 374/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.8503 - accuracy: 0.5618 - val_loss: 0.8330 - val_accuracy: 0.7207\n",
      "Epoch 375/600\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.8471 - accuracy: 0.5618 - val_loss: 0.8329 - val_accuracy: 0.7207\n",
      "Epoch 376/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.8451 - accuracy: 0.5730 - val_loss: 0.8328 - val_accuracy: 0.7207\n",
      "Epoch 377/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.8362 - accuracy: 0.5969 - val_loss: 0.8327 - val_accuracy: 0.7207\n",
      "Epoch 378/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8400 - accuracy: 0.5941 - val_loss: 0.8326 - val_accuracy: 0.7207\n",
      "Epoch 379/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8329 - accuracy: 0.5829 - val_loss: 0.8325 - val_accuracy: 0.7207\n",
      "Epoch 380/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8455 - accuracy: 0.5927 - val_loss: 0.8324 - val_accuracy: 0.7207\n",
      "Epoch 381/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8488 - accuracy: 0.5660 - val_loss: 0.8323 - val_accuracy: 0.7207\n",
      "Epoch 382/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8509 - accuracy: 0.5562 - val_loss: 0.8322 - val_accuracy: 0.7207\n",
      "Epoch 383/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8484 - accuracy: 0.5646 - val_loss: 0.8322 - val_accuracy: 0.7207\n",
      "Epoch 384/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8440 - accuracy: 0.5843 - val_loss: 0.8321 - val_accuracy: 0.7207\n",
      "Epoch 385/600\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.8490 - accuracy: 0.5534 - val_loss: 0.8320 - val_accuracy: 0.7207\n",
      "Epoch 386/600\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.8483 - accuracy: 0.5674 - val_loss: 0.8319 - val_accuracy: 0.7207\n",
      "Epoch 387/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.8512 - accuracy: 0.5562 - val_loss: 0.8319 - val_accuracy: 0.7207\n",
      "Epoch 388/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8366 - accuracy: 0.5758 - val_loss: 0.8318 - val_accuracy: 0.7207\n",
      "Epoch 389/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.8364 - accuracy: 0.6096 - val_loss: 0.8317 - val_accuracy: 0.7207\n",
      "Epoch 390/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.8345 - accuracy: 0.5997 - val_loss: 0.8316 - val_accuracy: 0.7207\n",
      "Epoch 391/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.8404 - accuracy: 0.5744 - val_loss: 0.8315 - val_accuracy: 0.7207\n",
      "Epoch 392/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.8562 - accuracy: 0.5506 - val_loss: 0.8314 - val_accuracy: 0.7151\n",
      "Epoch 393/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.8463 - accuracy: 0.5632 - val_loss: 0.8313 - val_accuracy: 0.7207\n",
      "Epoch 394/600\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.8363 - accuracy: 0.5843 - val_loss: 0.8312 - val_accuracy: 0.7151\n",
      "Epoch 395/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.8471 - accuracy: 0.5562 - val_loss: 0.8311 - val_accuracy: 0.7151\n",
      "Epoch 396/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.8393 - accuracy: 0.5674 - val_loss: 0.8310 - val_accuracy: 0.7151\n",
      "Epoch 397/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.8453 - accuracy: 0.5548 - val_loss: 0.8310 - val_accuracy: 0.7151\n",
      "Epoch 398/600\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 1.5049 - accuracy: 0.5126 - val_loss: 1.4871 - val_accuracy: 0.5866\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 1.4948 - accuracy: 0.5548 - val_loss: 1.4860 - val_accuracy: 0.5866\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 1.5029 - accuracy: 0.5183 - val_loss: 1.4846 - val_accuracy: 0.5866\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 1.5118 - accuracy: 0.5267 - val_loss: 1.4840 - val_accuracy: 0.5866\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4961 - accuracy: 0.5435 - val_loss: 1.4834 - val_accuracy: 0.5866\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4912 - accuracy: 0.5309 - val_loss: 1.4827 - val_accuracy: 0.5866\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 1.5166 - accuracy: 0.4860 - val_loss: 1.4820 - val_accuracy: 0.5866\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 1.4717 - accuracy: 0.5534 - val_loss: 1.4816 - val_accuracy: 0.5866\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 1.4864 - accuracy: 0.5435 - val_loss: 1.4811 - val_accuracy: 0.5866\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 1.4818 - accuracy: 0.5506 - val_loss: 1.4807 - val_accuracy: 0.5866\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 1.4906 - accuracy: 0.5295 - val_loss: 1.4799 - val_accuracy: 0.5866\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 1.4989 - accuracy: 0.5211 - val_loss: 1.4792 - val_accuracy: 0.5866\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 1.4716 - accuracy: 0.5337 - val_loss: 1.4789 - val_accuracy: 0.5866\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4940 - accuracy: 0.4789 - val_loss: 1.4786 - val_accuracy: 0.5866\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.4810 - accuracy: 0.5365 - val_loss: 1.4779 - val_accuracy: 0.5866\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 1.4861 - accuracy: 0.5183 - val_loss: 1.4773 - val_accuracy: 0.5922\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4833 - accuracy: 0.5295 - val_loss: 1.4769 - val_accuracy: 0.5866\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4960 - accuracy: 0.4902 - val_loss: 1.4764 - val_accuracy: 0.6313\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.4999 - accuracy: 0.5253 - val_loss: 1.4758 - val_accuracy: 0.6760\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 1.4849 - accuracy: 0.5084 - val_loss: 1.4755 - val_accuracy: 0.6480\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 1.4860 - accuracy: 0.5056 - val_loss: 1.4751 - val_accuracy: 0.6648\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4795 - accuracy: 0.5169 - val_loss: 1.4748 - val_accuracy: 0.6592\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 1.4773 - accuracy: 0.5211 - val_loss: 1.4744 - val_accuracy: 0.6760\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 1.4770 - accuracy: 0.5435 - val_loss: 1.4740 - val_accuracy: 0.6983\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 1.4887 - accuracy: 0.4916 - val_loss: 1.4736 - val_accuracy: 0.6816\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 1.4937 - accuracy: 0.4916 - val_loss: 1.4732 - val_accuracy: 0.6816\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 1.4924 - accuracy: 0.4958 - val_loss: 1.4728 - val_accuracy: 0.7095\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 1.4848 - accuracy: 0.4958 - val_loss: 1.4727 - val_accuracy: 0.6536\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4643 - accuracy: 0.5225 - val_loss: 1.4722 - val_accuracy: 0.6760\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 1.4768 - accuracy: 0.5225 - val_loss: 1.4718 - val_accuracy: 0.6760\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 1.4768 - accuracy: 0.5042 - val_loss: 1.4712 - val_accuracy: 0.5084\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 1.4913 - accuracy: 0.4944 - val_loss: 1.4708 - val_accuracy: 0.4972\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 1.4871 - accuracy: 0.5028 - val_loss: 1.4703 - val_accuracy: 0.4134\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4842 - accuracy: 0.5197 - val_loss: 1.4699 - val_accuracy: 0.4134\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 1.4825 - accuracy: 0.5070 - val_loss: 1.4696 - val_accuracy: 0.4134\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4882 - accuracy: 0.4846 - val_loss: 1.4692 - val_accuracy: 0.4134\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4858 - accuracy: 0.4944 - val_loss: 1.4688 - val_accuracy: 0.4134\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 1.4721 - accuracy: 0.5281 - val_loss: 1.4683 - val_accuracy: 0.4134\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4801 - accuracy: 0.5281 - val_loss: 1.4680 - val_accuracy: 0.4134\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 1.4899 - accuracy: 0.5000 - val_loss: 1.4675 - val_accuracy: 0.4134\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4790 - accuracy: 0.5014 - val_loss: 1.4672 - val_accuracy: 0.4134\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 1.4643 - accuracy: 0.5323 - val_loss: 1.4669 - val_accuracy: 0.4134\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 1.4739 - accuracy: 0.5056 - val_loss: 1.4666 - val_accuracy: 0.4134\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 1.4864 - accuracy: 0.5056 - val_loss: 1.4661 - val_accuracy: 0.4134\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 1.4810 - accuracy: 0.5070 - val_loss: 1.4657 - val_accuracy: 0.4134\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 1.4793 - accuracy: 0.5028 - val_loss: 1.4653 - val_accuracy: 0.4134\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 1.4741 - accuracy: 0.4958 - val_loss: 1.4651 - val_accuracy: 0.4134\n",
      "Epoch 64/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4768 - accuracy: 0.4972 - val_loss: 1.4649 - val_accuracy: 0.4134\n",
      "Epoch 65/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 1.4676 - accuracy: 0.5084 - val_loss: 1.4645 - val_accuracy: 0.4134\n",
      "Epoch 66/400\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 1.4611 - accuracy: 0.5084 - val_loss: 1.4643 - val_accuracy: 0.4134\n",
      "Epoch 67/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4705 - accuracy: 0.5056 - val_loss: 1.4637 - val_accuracy: 0.4134\n",
      "Epoch 68/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 1.4851 - accuracy: 0.4846 - val_loss: 1.4633 - val_accuracy: 0.4134\n",
      "Epoch 69/400\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 1.4820 - accuracy: 0.4958 - val_loss: 1.4629 - val_accuracy: 0.4134\n",
      "Epoch 70/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7524 - accuracy: 0.6236 - val_loss: 0.7645 - val_accuracy: 0.5866\n",
      "Epoch 183/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7511 - accuracy: 0.6236 - val_loss: 0.7633 - val_accuracy: 0.5866\n",
      "Epoch 184/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7500 - accuracy: 0.6236 - val_loss: 0.7621 - val_accuracy: 0.5866\n",
      "Epoch 185/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7488 - accuracy: 0.6236 - val_loss: 0.7610 - val_accuracy: 0.5866\n",
      "Epoch 186/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7476 - accuracy: 0.6236 - val_loss: 0.7598 - val_accuracy: 0.5866\n",
      "Epoch 187/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7465 - accuracy: 0.6236 - val_loss: 0.7587 - val_accuracy: 0.5866\n",
      "Epoch 188/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.7454 - accuracy: 0.6236 - val_loss: 0.7577 - val_accuracy: 0.5866\n",
      "Epoch 189/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7443 - accuracy: 0.6236 - val_loss: 0.7566 - val_accuracy: 0.5866\n",
      "Epoch 190/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7432 - accuracy: 0.6236 - val_loss: 0.7555 - val_accuracy: 0.5866\n",
      "Epoch 191/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7422 - accuracy: 0.6236 - val_loss: 0.7545 - val_accuracy: 0.5866\n",
      "Epoch 192/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7412 - accuracy: 0.6236 - val_loss: 0.7535 - val_accuracy: 0.5866\n",
      "Epoch 193/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7402 - accuracy: 0.6236 - val_loss: 0.7526 - val_accuracy: 0.5866\n",
      "Epoch 194/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7393 - accuracy: 0.6236 - val_loss: 0.7516 - val_accuracy: 0.5866\n",
      "Epoch 195/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7383 - accuracy: 0.6236 - val_loss: 0.7507 - val_accuracy: 0.5866\n",
      "Epoch 196/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7374 - accuracy: 0.6236 - val_loss: 0.7498 - val_accuracy: 0.5866\n",
      "Epoch 197/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.7365 - accuracy: 0.6236 - val_loss: 0.7489 - val_accuracy: 0.5866\n",
      "Epoch 198/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7356 - accuracy: 0.6236 - val_loss: 0.7480 - val_accuracy: 0.5866\n",
      "Epoch 199/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7347 - accuracy: 0.6236 - val_loss: 0.7472 - val_accuracy: 0.5866\n",
      "Epoch 200/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7338 - accuracy: 0.6236 - val_loss: 0.7463 - val_accuracy: 0.5866\n",
      "Epoch 201/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.7330 - accuracy: 0.6236 - val_loss: 0.7455 - val_accuracy: 0.5866\n",
      "Epoch 202/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.7322 - accuracy: 0.6236 - val_loss: 0.7447 - val_accuracy: 0.5866\n",
      "Epoch 203/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.7314 - accuracy: 0.6236 - val_loss: 0.7439 - val_accuracy: 0.5866\n",
      "Epoch 204/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.7306 - accuracy: 0.6236 - val_loss: 0.7432 - val_accuracy: 0.5866\n",
      "Epoch 205/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7298 - accuracy: 0.6236 - val_loss: 0.7424 - val_accuracy: 0.5866\n",
      "Epoch 206/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.7291 - accuracy: 0.6236 - val_loss: 0.7416 - val_accuracy: 0.5866\n",
      "Epoch 207/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.7283 - accuracy: 0.6236 - val_loss: 0.7409 - val_accuracy: 0.5866\n",
      "Epoch 208/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7276 - accuracy: 0.6236 - val_loss: 0.7402 - val_accuracy: 0.5866\n",
      "Epoch 209/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.7269 - accuracy: 0.6236 - val_loss: 0.7395 - val_accuracy: 0.5866\n",
      "Epoch 210/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7262 - accuracy: 0.6236 - val_loss: 0.7388 - val_accuracy: 0.5866\n",
      "Epoch 211/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.7255 - accuracy: 0.6236 - val_loss: 0.7382 - val_accuracy: 0.5866\n",
      "Epoch 212/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7249 - accuracy: 0.6236 - val_loss: 0.7375 - val_accuracy: 0.5866\n",
      "Epoch 213/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7242 - accuracy: 0.6236 - val_loss: 0.7369 - val_accuracy: 0.5866\n",
      "Epoch 214/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.7236 - accuracy: 0.6236 - val_loss: 0.7363 - val_accuracy: 0.5866\n",
      "Epoch 215/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.7229 - accuracy: 0.6236 - val_loss: 0.7356 - val_accuracy: 0.5866\n",
      "Epoch 216/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7223 - accuracy: 0.6236 - val_loss: 0.7350 - val_accuracy: 0.5866\n",
      "Epoch 217/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7217 - accuracy: 0.6236 - val_loss: 0.7345 - val_accuracy: 0.5866\n",
      "Epoch 218/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7212 - accuracy: 0.6236 - val_loss: 0.7339 - val_accuracy: 0.5866\n",
      "Epoch 219/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.7206 - accuracy: 0.6236 - val_loss: 0.7333 - val_accuracy: 0.5866\n",
      "Epoch 220/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.7200 - accuracy: 0.6236 - val_loss: 0.7328 - val_accuracy: 0.5866\n",
      "Epoch 221/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 1.4173 - accuracy: 0.5604 - val_loss: 1.4277 - val_accuracy: 0.5866\n",
      "Epoch 478/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 1.4152 - accuracy: 0.5407 - val_loss: 1.4267 - val_accuracy: 0.5866\n",
      "Epoch 479/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 1.4167 - accuracy: 0.5267 - val_loss: 1.4258 - val_accuracy: 0.5866\n",
      "Epoch 480/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 1.4139 - accuracy: 0.5618 - val_loss: 1.4248 - val_accuracy: 0.5866\n",
      "Epoch 481/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 1.4107 - accuracy: 0.5702 - val_loss: 1.4239 - val_accuracy: 0.5866\n",
      "Epoch 482/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 1.4139 - accuracy: 0.5225 - val_loss: 1.4229 - val_accuracy: 0.5866\n",
      "Epoch 483/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 1.4090 - accuracy: 0.5758 - val_loss: 1.4220 - val_accuracy: 0.5866\n",
      "Epoch 484/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 1.4089 - accuracy: 0.5801 - val_loss: 1.4209 - val_accuracy: 0.5866\n",
      "Epoch 485/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 1.4077 - accuracy: 0.5730 - val_loss: 1.4200 - val_accuracy: 0.5866\n",
      "Epoch 486/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 1.4081 - accuracy: 0.5632 - val_loss: 1.4189 - val_accuracy: 0.5866\n",
      "Epoch 487/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 1.4055 - accuracy: 0.5618 - val_loss: 1.4180 - val_accuracy: 0.5866\n",
      "Epoch 488/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 1.4071 - accuracy: 0.5421 - val_loss: 1.4170 - val_accuracy: 0.5866\n",
      "Epoch 489/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 1.4032 - accuracy: 0.5744 - val_loss: 1.4161 - val_accuracy: 0.5866\n",
      "Epoch 490/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 1.4028 - accuracy: 0.5646 - val_loss: 1.4151 - val_accuracy: 0.5866\n",
      "Epoch 491/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 1.4026 - accuracy: 0.5506 - val_loss: 1.4141 - val_accuracy: 0.5866\n",
      "Epoch 492/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 1.4023 - accuracy: 0.5393 - val_loss: 1.4131 - val_accuracy: 0.5866\n",
      "Epoch 493/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 1.3998 - accuracy: 0.5604 - val_loss: 1.4121 - val_accuracy: 0.5866\n",
      "Epoch 494/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 1.3991 - accuracy: 0.5407 - val_loss: 1.4111 - val_accuracy: 0.5866\n",
      "Epoch 495/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 1.3990 - accuracy: 0.5407 - val_loss: 1.4102 - val_accuracy: 0.5866\n",
      "Epoch 496/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 1.3957 - accuracy: 0.5829 - val_loss: 1.4092 - val_accuracy: 0.5866\n",
      "Epoch 497/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 1.3979 - accuracy: 0.5449 - val_loss: 1.4082 - val_accuracy: 0.5866\n",
      "Epoch 498/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 1.3954 - accuracy: 0.5534 - val_loss: 1.4073 - val_accuracy: 0.5866\n",
      "Epoch 499/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 1.3952 - accuracy: 0.5716 - val_loss: 1.4063 - val_accuracy: 0.5866\n",
      "Epoch 500/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 1.3952 - accuracy: 0.5534 - val_loss: 1.4053 - val_accuracy: 0.5866\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 003395316fcf017b9d003af1d6a4aa3e</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.5865921974182129</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-batch_size: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_0: sigmoid</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_1: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_2: sigmoid</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_3: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_4: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_5: sigmoid</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_6: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_2: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_3: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_4: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_5: 48</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_6: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_0: 0.30000000000000004</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_1: 0.35000000000000003</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_2: 0.1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_3: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_4: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_5: 0.2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_6: 0.1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-epoch_number: 500</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_0: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_1: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_2: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_3: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_4: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_5: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_6: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_0: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_1: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_2: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_3: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_4: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_5: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_6: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_layers: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: SGD</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/600\n",
      "712/712 [==============================] - 1s 2ms/sample - loss: 1.1729 - accuracy: 0.5702 - val_loss: 1.1212 - val_accuracy: 0.5866\n",
      "Epoch 2/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 1.0920 - accuracy: 0.5042 - val_loss: 1.0687 - val_accuracy: 0.6536\n",
      "Epoch 3/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 1.0525 - accuracy: 0.5267 - val_loss: 1.0259 - val_accuracy: 0.6592\n",
      "Epoch 4/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 1.0083 - accuracy: 0.5576 - val_loss: 0.9840 - val_accuracy: 0.6927\n",
      "Epoch 5/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.9617 - accuracy: 0.6053 - val_loss: 0.9444 - val_accuracy: 0.7039\n",
      "Epoch 6/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.9300 - accuracy: 0.6208 - val_loss: 0.9022 - val_accuracy: 0.7151\n",
      "Epoch 7/600\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.8959 - accuracy: 0.6615 - val_loss: 0.8639 - val_accuracy: 0.6983\n",
      "Epoch 8/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.8553 - accuracy: 0.6826 - val_loss: 0.8219 - val_accuracy: 0.6983\n",
      "Epoch 9/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.8306 - accuracy: 0.7037 - val_loss: 0.7862 - val_accuracy: 0.6983\n",
      "Epoch 10/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.7965 - accuracy: 0.7135 - val_loss: 0.7512 - val_accuracy: 0.7039\n",
      "Epoch 11/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.7555 - accuracy: 0.7346 - val_loss: 0.7129 - val_accuracy: 0.7374\n",
      "Epoch 12/600\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.7297 - accuracy: 0.7458 - val_loss: 0.6829 - val_accuracy: 0.7654\n",
      "Epoch 13/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.7173 - accuracy: 0.7331 - val_loss: 0.6682 - val_accuracy: 0.7709\n",
      "Epoch 14/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.7048 - accuracy: 0.7514 - val_loss: 0.6545 - val_accuracy: 0.7430\n",
      "Epoch 15/600\n",
      "712/712 [==============================] - 0s 177us/sample - loss: 0.6778 - accuracy: 0.7725 - val_loss: 0.6375 - val_accuracy: 0.7486\n",
      "Epoch 16/600\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.6581 - accuracy: 0.7612 - val_loss: 0.6267 - val_accuracy: 0.7486\n",
      "Epoch 17/600\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.6555 - accuracy: 0.7795 - val_loss: 0.6195 - val_accuracy: 0.7598\n",
      "Epoch 18/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6587 - accuracy: 0.7640 - val_loss: 0.6194 - val_accuracy: 0.7877\n",
      "Epoch 19/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6410 - accuracy: 0.7725 - val_loss: 0.6090 - val_accuracy: 0.7654\n",
      "Epoch 20/600\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6323 - accuracy: 0.7893 - val_loss: 0.6017 - val_accuracy: 0.7598\n",
      "Epoch 21/600\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.6351 - accuracy: 0.7795 - val_loss: 0.6004 - val_accuracy: 0.7709\n",
      "Epoch 22/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6374 - accuracy: 0.7753 - val_loss: 0.5964 - val_accuracy: 0.7486\n",
      "Epoch 23/600\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6286 - accuracy: 0.7753 - val_loss: 0.5950 - val_accuracy: 0.7709\n",
      "Epoch 24/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.6145 - accuracy: 0.8020 - val_loss: 0.5903 - val_accuracy: 0.7821\n",
      "Epoch 25/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6123 - accuracy: 0.7851 - val_loss: 0.5871 - val_accuracy: 0.7709\n",
      "Epoch 26/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.6292 - accuracy: 0.7767 - val_loss: 0.5874 - val_accuracy: 0.7654\n",
      "Epoch 27/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.6102 - accuracy: 0.7837 - val_loss: 0.5842 - val_accuracy: 0.7765\n",
      "Epoch 28/600\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.6050 - accuracy: 0.7949 - val_loss: 0.5813 - val_accuracy: 0.7765\n",
      "Epoch 29/600\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.6061 - accuracy: 0.7781 - val_loss: 0.5763 - val_accuracy: 0.7654\n",
      "Epoch 30/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6138 - accuracy: 0.7907 - val_loss: 0.5750 - val_accuracy: 0.7598\n",
      "Epoch 31/600\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.5968 - accuracy: 0.7865 - val_loss: 0.5729 - val_accuracy: 0.7765\n",
      "Epoch 32/600\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.6016 - accuracy: 0.7907 - val_loss: 0.5684 - val_accuracy: 0.7709\n",
      "Epoch 33/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5981 - accuracy: 0.7907 - val_loss: 0.5723 - val_accuracy: 0.7821\n",
      "Epoch 34/600\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5992 - accuracy: 0.7963 - val_loss: 0.5668 - val_accuracy: 0.7709\n",
      "Epoch 35/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5929 - accuracy: 0.7823 - val_loss: 0.5649 - val_accuracy: 0.7709\n",
      "Epoch 36/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5798 - accuracy: 0.8048 - val_loss: 0.5615 - val_accuracy: 0.7877\n",
      "Epoch 37/600\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5797 - accuracy: 0.8034 - val_loss: 0.5604 - val_accuracy: 0.7765\n",
      "Epoch 38/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5935 - accuracy: 0.7992 - val_loss: 0.5612 - val_accuracy: 0.7765\n",
      "Epoch 39/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5778 - accuracy: 0.8104 - val_loss: 0.5572 - val_accuracy: 0.7765\n",
      "Epoch 40/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5860 - accuracy: 0.7921 - val_loss: 0.5568 - val_accuracy: 0.7821\n",
      "Epoch 41/600\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5913 - accuracy: 0.7879 - val_loss: 0.5567 - val_accuracy: 0.7877\n",
      "Epoch 42/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5911 - accuracy: 0.7865 - val_loss: 0.5553 - val_accuracy: 0.7821\n",
      "Epoch 43/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5762 - accuracy: 0.7978 - val_loss: 0.5556 - val_accuracy: 0.7877\n",
      "Epoch 44/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5930 - accuracy: 0.7992 - val_loss: 0.5554 - val_accuracy: 0.7877\n",
      "Epoch 45/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5821 - accuracy: 0.8020 - val_loss: 0.5517 - val_accuracy: 0.7877\n",
      "Epoch 46/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5976 - accuracy: 0.8006 - val_loss: 0.5532 - val_accuracy: 0.7765\n",
      "Epoch 47/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5710 - accuracy: 0.8160 - val_loss: 0.5515 - val_accuracy: 0.7821\n",
      "Epoch 48/600\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5701 - accuracy: 0.7907 - val_loss: 0.5483 - val_accuracy: 0.7709\n",
      "Epoch 49/600\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.5809 - accuracy: 0.7992 - val_loss: 0.5480 - val_accuracy: 0.7709\n",
      "Epoch 50/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5733 - accuracy: 0.8160 - val_loss: 0.5477 - val_accuracy: 0.7877\n",
      "Epoch 51/600\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5716 - accuracy: 0.7879 - val_loss: 0.5468 - val_accuracy: 0.7877\n",
      "Epoch 52/600\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5736 - accuracy: 0.7963 - val_loss: 0.5483 - val_accuracy: 0.7821\n",
      "Epoch 53/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5782 - accuracy: 0.7963 - val_loss: 0.5476 - val_accuracy: 0.7765\n",
      "Epoch 54/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5697 - accuracy: 0.7935 - val_loss: 0.5481 - val_accuracy: 0.7765\n",
      "Epoch 55/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5699 - accuracy: 0.8006 - val_loss: 0.5480 - val_accuracy: 0.7933\n",
      "Epoch 56/600\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5646 - accuracy: 0.7978 - val_loss: 0.5450 - val_accuracy: 0.7765\n",
      "Epoch 57/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5739 - accuracy: 0.7949 - val_loss: 0.5480 - val_accuracy: 0.7933\n",
      "Epoch 58/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5663 - accuracy: 0.7978 - val_loss: 0.5444 - val_accuracy: 0.7877\n",
      "Epoch 59/600\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5728 - accuracy: 0.7963 - val_loss: 0.5462 - val_accuracy: 0.7877\n",
      "Epoch 60/600\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5749 - accuracy: 0.8076 - val_loss: 0.5476 - val_accuracy: 0.7933\n",
      "Epoch 61/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5600 - accuracy: 0.7978 - val_loss: 0.5449 - val_accuracy: 0.7933\n",
      "Epoch 62/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5626 - accuracy: 0.8104 - val_loss: 0.5401 - val_accuracy: 0.7933\n",
      "Epoch 63/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5561 - accuracy: 0.8020 - val_loss: 0.5404 - val_accuracy: 0.7933\n",
      "Epoch 64/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5593 - accuracy: 0.8062 - val_loss: 0.5389 - val_accuracy: 0.7933\n",
      "Epoch 65/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5638 - accuracy: 0.8020 - val_loss: 0.5395 - val_accuracy: 0.7989\n",
      "Epoch 66/600\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5563 - accuracy: 0.8062 - val_loss: 0.5373 - val_accuracy: 0.7989\n",
      "Epoch 67/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5582 - accuracy: 0.8062 - val_loss: 0.5357 - val_accuracy: 0.7933\n",
      "Epoch 68/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5694 - accuracy: 0.7992 - val_loss: 0.5405 - val_accuracy: 0.8101\n",
      "Epoch 69/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5585 - accuracy: 0.8006 - val_loss: 0.5396 - val_accuracy: 0.7933\n",
      "Epoch 70/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5617 - accuracy: 0.7992 - val_loss: 0.5367 - val_accuracy: 0.8101\n",
      "Epoch 71/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5567 - accuracy: 0.8048 - val_loss: 0.5343 - val_accuracy: 0.7877\n",
      "Epoch 72/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5524 - accuracy: 0.8062 - val_loss: 0.5364 - val_accuracy: 0.7933\n",
      "Epoch 73/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5500 - accuracy: 0.8006 - val_loss: 0.5375 - val_accuracy: 0.8045\n",
      "Epoch 74/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5369 - accuracy: 0.8244 - val_loss: 0.5338 - val_accuracy: 0.8101\n",
      "Epoch 75/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5575 - accuracy: 0.8076 - val_loss: 0.5325 - val_accuracy: 0.7877\n",
      "Epoch 76/600\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5472 - accuracy: 0.8160 - val_loss: 0.5333 - val_accuracy: 0.7821\n",
      "Epoch 77/600\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5596 - accuracy: 0.8048 - val_loss: 0.5345 - val_accuracy: 0.8101\n",
      "Epoch 78/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5556 - accuracy: 0.7963 - val_loss: 0.5320 - val_accuracy: 0.8045\n",
      "Epoch 79/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5588 - accuracy: 0.7978 - val_loss: 0.5340 - val_accuracy: 0.8101\n",
      "Epoch 80/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5555 - accuracy: 0.8132 - val_loss: 0.5313 - val_accuracy: 0.8101\n",
      "Epoch 81/600\n",
      "712/712 [==============================] - 0s 99us/sample - loss: 0.5638 - accuracy: 0.8048 - val_loss: 0.5312 - val_accuracy: 0.8101\n",
      "Epoch 82/600\n",
      "712/712 [==============================] - 0s 100us/sample - loss: 0.5453 - accuracy: 0.8090 - val_loss: 0.5306 - val_accuracy: 0.8101\n",
      "Epoch 83/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5616 - accuracy: 0.8076 - val_loss: 0.5329 - val_accuracy: 0.7933\n",
      "Epoch 84/600\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5451 - accuracy: 0.8090 - val_loss: 0.5311 - val_accuracy: 0.8101\n",
      "Epoch 85/600\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.5534 - accuracy: 0.8160 - val_loss: 0.5273 - val_accuracy: 0.7877\n",
      "Epoch 86/600\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5508 - accuracy: 0.8104 - val_loss: 0.5288 - val_accuracy: 0.8101\n",
      "Epoch 87/600\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5591 - accuracy: 0.8090 - val_loss: 0.5319 - val_accuracy: 0.7989\n",
      "Epoch 88/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5457 - accuracy: 0.8160 - val_loss: 0.5299 - val_accuracy: 0.8101\n",
      "Epoch 89/600\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5537 - accuracy: 0.8020 - val_loss: 0.5309 - val_accuracy: 0.7933\n",
      "Epoch 90/600\n",
      "712/712 [==============================] - 0s 100us/sample - loss: 0.5502 - accuracy: 0.8006 - val_loss: 0.5291 - val_accuracy: 0.8101\n",
      "Epoch 91/600\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.5483 - accuracy: 0.7992 - val_loss: 0.5295 - val_accuracy: 0.8101\n",
      "Epoch 92/600\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5611 - accuracy: 0.8118 - val_loss: 0.5311 - val_accuracy: 0.7933\n",
      "Epoch 93/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5460 - accuracy: 0.8062 - val_loss: 0.5282 - val_accuracy: 0.8045\n",
      "Epoch 94/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5526 - accuracy: 0.7949 - val_loss: 0.5293 - val_accuracy: 0.8045\n",
      "Epoch 95/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5551 - accuracy: 0.8048 - val_loss: 0.5287 - val_accuracy: 0.8045\n",
      "Epoch 96/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5541 - accuracy: 0.8034 - val_loss: 0.5288 - val_accuracy: 0.8045\n",
      "Epoch 97/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5601 - accuracy: 0.7978 - val_loss: 0.5291 - val_accuracy: 0.8101\n",
      "Epoch 98/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5471 - accuracy: 0.8146 - val_loss: 0.5302 - val_accuracy: 0.8101\n",
      "Epoch 99/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5441 - accuracy: 0.8272 - val_loss: 0.5286 - val_accuracy: 0.8045\n",
      "Epoch 100/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5412 - accuracy: 0.8020 - val_loss: 0.5260 - val_accuracy: 0.8045\n",
      "Epoch 101/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5560 - accuracy: 0.8048 - val_loss: 0.5256 - val_accuracy: 0.8045\n",
      "Epoch 102/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5639 - accuracy: 0.8006 - val_loss: 0.5269 - val_accuracy: 0.8101\n",
      "Epoch 103/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5573 - accuracy: 0.8132 - val_loss: 0.5262 - val_accuracy: 0.7877\n",
      "Epoch 104/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5598 - accuracy: 0.8090 - val_loss: 0.5274 - val_accuracy: 0.8045\n",
      "Epoch 105/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5523 - accuracy: 0.8006 - val_loss: 0.5286 - val_accuracy: 0.8101\n",
      "Epoch 106/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5487 - accuracy: 0.8048 - val_loss: 0.5285 - val_accuracy: 0.8101\n",
      "Epoch 107/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5368 - accuracy: 0.8258 - val_loss: 0.5265 - val_accuracy: 0.8045\n",
      "Epoch 108/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5451 - accuracy: 0.8118 - val_loss: 0.5244 - val_accuracy: 0.8045\n",
      "Epoch 109/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5497 - accuracy: 0.8020 - val_loss: 0.5304 - val_accuracy: 0.8101\n",
      "Epoch 110/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5376 - accuracy: 0.8104 - val_loss: 0.5297 - val_accuracy: 0.8045\n",
      "Epoch 111/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5339 - accuracy: 0.8090 - val_loss: 0.5246 - val_accuracy: 0.8101\n",
      "Epoch 112/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5494 - accuracy: 0.8034 - val_loss: 0.5271 - val_accuracy: 0.8101\n",
      "Epoch 113/600\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5449 - accuracy: 0.8174 - val_loss: 0.5274 - val_accuracy: 0.8101\n",
      "Epoch 114/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5526 - accuracy: 0.7978 - val_loss: 0.5269 - val_accuracy: 0.7989\n",
      "Epoch 115/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5481 - accuracy: 0.8104 - val_loss: 0.5268 - val_accuracy: 0.8101\n",
      "Epoch 116/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5537 - accuracy: 0.8216 - val_loss: 0.5261 - val_accuracy: 0.8101\n",
      "Epoch 117/600\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.5324 - accuracy: 0.8118 - val_loss: 0.5222 - val_accuracy: 0.8045\n",
      "Epoch 118/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5555 - accuracy: 0.8048 - val_loss: 0.5244 - val_accuracy: 0.8101\n",
      "Epoch 119/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5542 - accuracy: 0.8048 - val_loss: 0.5284 - val_accuracy: 0.8045\n",
      "Epoch 120/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5323 - accuracy: 0.8160 - val_loss: 0.5246 - val_accuracy: 0.8101\n",
      "Epoch 121/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5460 - accuracy: 0.8146 - val_loss: 0.5225 - val_accuracy: 0.8101\n",
      "Epoch 122/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5401 - accuracy: 0.8244 - val_loss: 0.5229 - val_accuracy: 0.8045\n",
      "Epoch 123/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5297 - accuracy: 0.8188 - val_loss: 0.5230 - val_accuracy: 0.8045\n",
      "Epoch 124/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5248 - accuracy: 0.8272 - val_loss: 0.5219 - val_accuracy: 0.8101\n",
      "Epoch 125/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5418 - accuracy: 0.8034 - val_loss: 0.5183 - val_accuracy: 0.8101\n",
      "Epoch 126/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5440 - accuracy: 0.8202 - val_loss: 0.5191 - val_accuracy: 0.8101\n",
      "Epoch 127/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5342 - accuracy: 0.8174 - val_loss: 0.5212 - val_accuracy: 0.8101\n",
      "Epoch 128/600\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5476 - accuracy: 0.8188 - val_loss: 0.5206 - val_accuracy: 0.8045\n",
      "Epoch 129/600\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5429 - accuracy: 0.8090 - val_loss: 0.5208 - val_accuracy: 0.8101\n",
      "Epoch 130/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5419 - accuracy: 0.8104 - val_loss: 0.5198 - val_accuracy: 0.8045\n",
      "Epoch 131/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5409 - accuracy: 0.8090 - val_loss: 0.5221 - val_accuracy: 0.7989\n",
      "Epoch 132/600\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5426 - accuracy: 0.7978 - val_loss: 0.5202 - val_accuracy: 0.8101\n",
      "Epoch 133/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5476 - accuracy: 0.8118 - val_loss: 0.5208 - val_accuracy: 0.8045\n",
      "Epoch 134/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5335 - accuracy: 0.8258 - val_loss: 0.5180 - val_accuracy: 0.7989\n",
      "Epoch 135/600\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5482 - accuracy: 0.7978 - val_loss: 0.5165 - val_accuracy: 0.8045\n",
      "Epoch 136/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5312 - accuracy: 0.8202 - val_loss: 0.5161 - val_accuracy: 0.8101\n",
      "Epoch 137/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5457 - accuracy: 0.8090 - val_loss: 0.5166 - val_accuracy: 0.8045\n",
      "Epoch 138/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5445 - accuracy: 0.8188 - val_loss: 0.5165 - val_accuracy: 0.8045\n",
      "Epoch 139/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5377 - accuracy: 0.8174 - val_loss: 0.5175 - val_accuracy: 0.8101\n",
      "Epoch 140/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5460 - accuracy: 0.8006 - val_loss: 0.5179 - val_accuracy: 0.8045\n",
      "Epoch 141/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5360 - accuracy: 0.8202 - val_loss: 0.5224 - val_accuracy: 0.8101\n",
      "Epoch 142/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5350 - accuracy: 0.8188 - val_loss: 0.5196 - val_accuracy: 0.8101\n",
      "Epoch 143/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5418 - accuracy: 0.8146 - val_loss: 0.5206 - val_accuracy: 0.8045\n",
      "Epoch 144/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5290 - accuracy: 0.8244 - val_loss: 0.5211 - val_accuracy: 0.8045\n",
      "Epoch 145/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5412 - accuracy: 0.8020 - val_loss: 0.5211 - val_accuracy: 0.8101\n",
      "Epoch 146/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5489 - accuracy: 0.8034 - val_loss: 0.5206 - val_accuracy: 0.8045\n",
      "Epoch 147/600\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5471 - accuracy: 0.8174 - val_loss: 0.5205 - val_accuracy: 0.8101\n",
      "Epoch 148/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5354 - accuracy: 0.8343 - val_loss: 0.5193 - val_accuracy: 0.8101\n",
      "Epoch 149/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5333 - accuracy: 0.8244 - val_loss: 0.5215 - val_accuracy: 0.8045\n",
      "Epoch 150/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5459 - accuracy: 0.8062 - val_loss: 0.5240 - val_accuracy: 0.8101\n",
      "Epoch 151/600\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.5293 - accuracy: 0.8315 - val_loss: 0.5174 - val_accuracy: 0.8045\n",
      "Epoch 152/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5472 - accuracy: 0.8146 - val_loss: 0.5186 - val_accuracy: 0.8045\n",
      "Epoch 153/600\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5216 - accuracy: 0.8174 - val_loss: 0.5191 - val_accuracy: 0.8101\n",
      "Epoch 154/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5316 - accuracy: 0.8076 - val_loss: 0.5179 - val_accuracy: 0.8045\n",
      "Epoch 155/600\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5292 - accuracy: 0.8216 - val_loss: 0.5191 - val_accuracy: 0.8101\n",
      "Epoch 156/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5474 - accuracy: 0.8174 - val_loss: 0.5183 - val_accuracy: 0.8045\n",
      "Epoch 157/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5527 - accuracy: 0.7978 - val_loss: 0.5188 - val_accuracy: 0.8101\n",
      "Epoch 158/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5307 - accuracy: 0.8188 - val_loss: 0.5167 - val_accuracy: 0.8045\n",
      "Epoch 159/600\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5504 - accuracy: 0.8048 - val_loss: 0.5209 - val_accuracy: 0.8101\n",
      "Epoch 160/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5374 - accuracy: 0.8230 - val_loss: 0.5171 - val_accuracy: 0.8045\n",
      "Epoch 161/600\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.5408 - accuracy: 0.8188 - val_loss: 0.5151 - val_accuracy: 0.8101\n",
      "Epoch 162/600\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5302 - accuracy: 0.8216 - val_loss: 0.5151 - val_accuracy: 0.8045\n",
      "Epoch 163/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5273 - accuracy: 0.8118 - val_loss: 0.5143 - val_accuracy: 0.8045\n",
      "Epoch 164/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5406 - accuracy: 0.8146 - val_loss: 0.5171 - val_accuracy: 0.8045\n",
      "Epoch 165/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5550 - accuracy: 0.8048 - val_loss: 0.5166 - val_accuracy: 0.8045\n",
      "Epoch 166/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5358 - accuracy: 0.8202 - val_loss: 0.5162 - val_accuracy: 0.8045\n",
      "Epoch 167/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5405 - accuracy: 0.8202 - val_loss: 0.5160 - val_accuracy: 0.8101\n",
      "Epoch 168/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5434 - accuracy: 0.8146 - val_loss: 0.5160 - val_accuracy: 0.8101\n",
      "Epoch 169/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5451 - accuracy: 0.8062 - val_loss: 0.5161 - val_accuracy: 0.8045\n",
      "Epoch 170/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5234 - accuracy: 0.8287 - val_loss: 0.5141 - val_accuracy: 0.8045\n",
      "Epoch 171/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5333 - accuracy: 0.8174 - val_loss: 0.5128 - val_accuracy: 0.8101\n",
      "Epoch 172/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5510 - accuracy: 0.8132 - val_loss: 0.5155 - val_accuracy: 0.8045\n",
      "Epoch 173/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5453 - accuracy: 0.8118 - val_loss: 0.5161 - val_accuracy: 0.8101\n",
      "Epoch 174/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5307 - accuracy: 0.8174 - val_loss: 0.5149 - val_accuracy: 0.8045\n",
      "Epoch 175/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5457 - accuracy: 0.8216 - val_loss: 0.5143 - val_accuracy: 0.8045\n",
      "Epoch 176/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5257 - accuracy: 0.8104 - val_loss: 0.5137 - val_accuracy: 0.8045\n",
      "Epoch 177/600\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5413 - accuracy: 0.8090 - val_loss: 0.5146 - val_accuracy: 0.8045\n",
      "Epoch 178/600\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5418 - accuracy: 0.8188 - val_loss: 0.5155 - val_accuracy: 0.8045\n",
      "Epoch 179/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5539 - accuracy: 0.7978 - val_loss: 0.5180 - val_accuracy: 0.8045\n",
      "Epoch 180/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5267 - accuracy: 0.8132 - val_loss: 0.5146 - val_accuracy: 0.8045\n",
      "Epoch 181/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5393 - accuracy: 0.8034 - val_loss: 0.5111 - val_accuracy: 0.8045\n",
      "Epoch 182/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5384 - accuracy: 0.8062 - val_loss: 0.5121 - val_accuracy: 0.8045\n",
      "Epoch 183/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5245 - accuracy: 0.8104 - val_loss: 0.5147 - val_accuracy: 0.8101\n",
      "Epoch 184/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5254 - accuracy: 0.8160 - val_loss: 0.5136 - val_accuracy: 0.8045\n",
      "Epoch 185/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5365 - accuracy: 0.8104 - val_loss: 0.5129 - val_accuracy: 0.8045\n",
      "Epoch 186/600\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5261 - accuracy: 0.8244 - val_loss: 0.5127 - val_accuracy: 0.8045\n",
      "Epoch 187/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5429 - accuracy: 0.8160 - val_loss: 0.5113 - val_accuracy: 0.8045\n",
      "Epoch 188/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5356 - accuracy: 0.8272 - val_loss: 0.5123 - val_accuracy: 0.8101\n",
      "Epoch 189/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5370 - accuracy: 0.8006 - val_loss: 0.5132 - val_accuracy: 0.8045\n",
      "Epoch 190/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5435 - accuracy: 0.8146 - val_loss: 0.5144 - val_accuracy: 0.8101\n",
      "Epoch 191/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5289 - accuracy: 0.8160 - val_loss: 0.5129 - val_accuracy: 0.8045\n",
      "Epoch 192/600\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5561 - accuracy: 0.8118 - val_loss: 0.5197 - val_accuracy: 0.8101\n",
      "Epoch 193/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5173 - accuracy: 0.8385 - val_loss: 0.5122 - val_accuracy: 0.7989\n",
      "Epoch 194/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5232 - accuracy: 0.8118 - val_loss: 0.5113 - val_accuracy: 0.8045\n",
      "Epoch 195/600\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5435 - accuracy: 0.8048 - val_loss: 0.5109 - val_accuracy: 0.8045\n",
      "Epoch 196/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5131 - accuracy: 0.8244 - val_loss: 0.5123 - val_accuracy: 0.8101\n",
      "Epoch 197/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5471 - accuracy: 0.8062 - val_loss: 0.5126 - val_accuracy: 0.7989\n",
      "Epoch 198/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5347 - accuracy: 0.8118 - val_loss: 0.5113 - val_accuracy: 0.8045\n",
      "Epoch 199/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5114 - accuracy: 0.8272 - val_loss: 0.5065 - val_accuracy: 0.8045\n",
      "Epoch 200/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5294 - accuracy: 0.8090 - val_loss: 0.5076 - val_accuracy: 0.8045\n",
      "Epoch 201/600\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5216 - accuracy: 0.8188 - val_loss: 0.5084 - val_accuracy: 0.8045\n",
      "Epoch 202/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5251 - accuracy: 0.8160 - val_loss: 0.5143 - val_accuracy: 0.8101\n",
      "Epoch 203/600\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.5303 - accuracy: 0.8132 - val_loss: 0.5102 - val_accuracy: 0.8045\n",
      "Epoch 204/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5285 - accuracy: 0.8160 - val_loss: 0.5095 - val_accuracy: 0.8045\n",
      "Epoch 205/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5446 - accuracy: 0.8006 - val_loss: 0.5097 - val_accuracy: 0.8101\n",
      "Epoch 206/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5316 - accuracy: 0.8104 - val_loss: 0.5107 - val_accuracy: 0.8045\n",
      "Epoch 207/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5317 - accuracy: 0.8174 - val_loss: 0.5128 - val_accuracy: 0.8101\n",
      "Epoch 208/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5348 - accuracy: 0.8118 - val_loss: 0.5094 - val_accuracy: 0.8045\n",
      "Epoch 209/600\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.5317 - accuracy: 0.8146 - val_loss: 0.5093 - val_accuracy: 0.8045\n",
      "Epoch 210/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5386 - accuracy: 0.8104 - val_loss: 0.5068 - val_accuracy: 0.8045\n",
      "Epoch 211/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5282 - accuracy: 0.8104 - val_loss: 0.5061 - val_accuracy: 0.8045\n",
      "Epoch 212/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5201 - accuracy: 0.8104 - val_loss: 0.5050 - val_accuracy: 0.8045\n",
      "Epoch 213/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5269 - accuracy: 0.8174 - val_loss: 0.5075 - val_accuracy: 0.8045\n",
      "Epoch 214/600\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5490 - accuracy: 0.8104 - val_loss: 0.5133 - val_accuracy: 0.8045\n",
      "Epoch 215/600\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5267 - accuracy: 0.8188 - val_loss: 0.5062 - val_accuracy: 0.8045\n",
      "Epoch 216/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5281 - accuracy: 0.8132 - val_loss: 0.5075 - val_accuracy: 0.8045\n",
      "Epoch 217/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5301 - accuracy: 0.8160 - val_loss: 0.5088 - val_accuracy: 0.8045\n",
      "Epoch 218/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5333 - accuracy: 0.8020 - val_loss: 0.5093 - val_accuracy: 0.8101\n",
      "Epoch 219/600\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5262 - accuracy: 0.8244 - val_loss: 0.5062 - val_accuracy: 0.8045\n",
      "Epoch 220/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5274 - accuracy: 0.8090 - val_loss: 0.5042 - val_accuracy: 0.8045\n",
      "Epoch 221/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5187 - accuracy: 0.8272 - val_loss: 0.5034 - val_accuracy: 0.8045\n",
      "Epoch 222/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5415 - accuracy: 0.8132 - val_loss: 0.5099 - val_accuracy: 0.8101\n",
      "Epoch 223/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5354 - accuracy: 0.8160 - val_loss: 0.5118 - val_accuracy: 0.8045\n",
      "Epoch 224/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5249 - accuracy: 0.8287 - val_loss: 0.5102 - val_accuracy: 0.8045\n",
      "Epoch 225/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5316 - accuracy: 0.8104 - val_loss: 0.5097 - val_accuracy: 0.8045\n",
      "Epoch 226/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5342 - accuracy: 0.8188 - val_loss: 0.5102 - val_accuracy: 0.8045\n",
      "Epoch 227/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5212 - accuracy: 0.8132 - val_loss: 0.5080 - val_accuracy: 0.8101\n",
      "Epoch 228/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5302 - accuracy: 0.8118 - val_loss: 0.5123 - val_accuracy: 0.8101\n",
      "Epoch 229/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5211 - accuracy: 0.8230 - val_loss: 0.5111 - val_accuracy: 0.8045\n",
      "Epoch 230/600\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.5263 - accuracy: 0.8160 - val_loss: 0.5107 - val_accuracy: 0.8045\n",
      "Epoch 231/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5285 - accuracy: 0.8230 - val_loss: 0.5086 - val_accuracy: 0.8045\n",
      "Epoch 232/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5285 - accuracy: 0.8076 - val_loss: 0.5087 - val_accuracy: 0.8045\n",
      "Epoch 233/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5168 - accuracy: 0.8160 - val_loss: 0.5071 - val_accuracy: 0.8045\n",
      "Epoch 234/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5281 - accuracy: 0.8244 - val_loss: 0.5089 - val_accuracy: 0.8045\n",
      "Epoch 235/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5287 - accuracy: 0.8174 - val_loss: 0.5101 - val_accuracy: 0.8045\n",
      "Epoch 236/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5206 - accuracy: 0.8244 - val_loss: 0.5101 - val_accuracy: 0.8101\n",
      "Epoch 237/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5209 - accuracy: 0.8174 - val_loss: 0.5071 - val_accuracy: 0.8101\n",
      "Epoch 238/600\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5189 - accuracy: 0.8216 - val_loss: 0.5075 - val_accuracy: 0.8101\n",
      "Epoch 239/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5164 - accuracy: 0.8174 - val_loss: 0.5066 - val_accuracy: 0.8045\n",
      "Epoch 240/600\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.5225 - accuracy: 0.8076 - val_loss: 0.5046 - val_accuracy: 0.8045\n",
      "Epoch 241/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5110 - accuracy: 0.8216 - val_loss: 0.5053 - val_accuracy: 0.8045\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5768 - accuracy: 0.7809 - val_loss: 0.5477 - val_accuracy: 0.7765\n",
      "Epoch 492/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.5679 - accuracy: 0.7809 - val_loss: 0.5475 - val_accuracy: 0.7765\n",
      "Epoch 493/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5780 - accuracy: 0.7683 - val_loss: 0.5474 - val_accuracy: 0.7765\n",
      "Epoch 494/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5591 - accuracy: 0.7781 - val_loss: 0.5472 - val_accuracy: 0.7765\n",
      "Epoch 495/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.5911 - accuracy: 0.7654 - val_loss: 0.5471 - val_accuracy: 0.7765\n",
      "Epoch 496/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.5733 - accuracy: 0.7753 - val_loss: 0.5470 - val_accuracy: 0.7765\n",
      "Epoch 497/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5879 - accuracy: 0.7584 - val_loss: 0.5469 - val_accuracy: 0.7765\n",
      "Epoch 498/600\n",
      "712/712 [==============================] - 0s 77us/sample - loss: 0.5764 - accuracy: 0.7753 - val_loss: 0.5468 - val_accuracy: 0.7765\n",
      "Epoch 499/600\n",
      "712/712 [==============================] - 0s 77us/sample - loss: 0.5735 - accuracy: 0.7697 - val_loss: 0.5467 - val_accuracy: 0.7765\n",
      "Epoch 500/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5926 - accuracy: 0.7458 - val_loss: 0.5466 - val_accuracy: 0.7765\n",
      "Epoch 501/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.5790 - accuracy: 0.7626 - val_loss: 0.5465 - val_accuracy: 0.7765\n",
      "Epoch 502/600\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5830 - accuracy: 0.7711 - val_loss: 0.5464 - val_accuracy: 0.7765\n",
      "Epoch 503/600\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5689 - accuracy: 0.7865 - val_loss: 0.5462 - val_accuracy: 0.7765\n",
      "Epoch 504/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5687 - accuracy: 0.7739 - val_loss: 0.5462 - val_accuracy: 0.7765\n",
      "Epoch 505/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5605 - accuracy: 0.7781 - val_loss: 0.5460 - val_accuracy: 0.7765\n",
      "Epoch 506/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5725 - accuracy: 0.7669 - val_loss: 0.5459 - val_accuracy: 0.7765\n",
      "Epoch 507/600\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5736 - accuracy: 0.7711 - val_loss: 0.5458 - val_accuracy: 0.7765\n",
      "Epoch 508/600\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5782 - accuracy: 0.7725 - val_loss: 0.5457 - val_accuracy: 0.7765\n",
      "Epoch 509/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.5673 - accuracy: 0.7795 - val_loss: 0.5456 - val_accuracy: 0.7765\n",
      "Epoch 510/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.5730 - accuracy: 0.7739 - val_loss: 0.5455 - val_accuracy: 0.7765\n",
      "Epoch 511/600\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5831 - accuracy: 0.7669 - val_loss: 0.5454 - val_accuracy: 0.7765\n",
      "Epoch 512/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5696 - accuracy: 0.7570 - val_loss: 0.5453 - val_accuracy: 0.7765\n",
      "Epoch 513/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5686 - accuracy: 0.7851 - val_loss: 0.5453 - val_accuracy: 0.7765\n",
      "Epoch 514/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5787 - accuracy: 0.7739 - val_loss: 0.5451 - val_accuracy: 0.7765\n",
      "Epoch 515/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5618 - accuracy: 0.7711 - val_loss: 0.5450 - val_accuracy: 0.7765\n",
      "Epoch 516/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.5785 - accuracy: 0.7654 - val_loss: 0.5449 - val_accuracy: 0.7765\n",
      "Epoch 517/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5840 - accuracy: 0.7584 - val_loss: 0.5449 - val_accuracy: 0.7765\n",
      "Epoch 518/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.5671 - accuracy: 0.7683 - val_loss: 0.5448 - val_accuracy: 0.7765\n",
      "Epoch 519/600\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5716 - accuracy: 0.7725 - val_loss: 0.5447 - val_accuracy: 0.7765\n",
      "Epoch 520/600\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.5675 - accuracy: 0.7753 - val_loss: 0.5446 - val_accuracy: 0.7765\n",
      "Epoch 521/600\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5747 - accuracy: 0.7767 - val_loss: 0.5444 - val_accuracy: 0.7765\n",
      "Epoch 522/600\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5724 - accuracy: 0.7683 - val_loss: 0.5444 - val_accuracy: 0.7765\n",
      "Epoch 523/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5736 - accuracy: 0.7781 - val_loss: 0.5443 - val_accuracy: 0.7765\n",
      "Epoch 524/600\n",
      "712/712 [==============================] - 0s 77us/sample - loss: 0.5746 - accuracy: 0.7697 - val_loss: 0.5442 - val_accuracy: 0.7765\n",
      "Epoch 525/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.5851 - accuracy: 0.7626 - val_loss: 0.5441 - val_accuracy: 0.7765\n",
      "Epoch 526/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5820 - accuracy: 0.7528 - val_loss: 0.5441 - val_accuracy: 0.7765\n",
      "Epoch 527/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.5644 - accuracy: 0.7823 - val_loss: 0.5441 - val_accuracy: 0.7765\n",
      "Epoch 528/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.5669 - accuracy: 0.7837 - val_loss: 0.5439 - val_accuracy: 0.7765\n",
      "Epoch 529/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5698 - accuracy: 0.7626 - val_loss: 0.5438 - val_accuracy: 0.7765\n",
      "Epoch 530/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5762 - accuracy: 0.7795 - val_loss: 0.5438 - val_accuracy: 0.7765\n",
      "Epoch 531/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5704 - accuracy: 0.7683 - val_loss: 0.5436 - val_accuracy: 0.7765\n",
      "Epoch 532/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5614 - accuracy: 0.7795 - val_loss: 0.5435 - val_accuracy: 0.7765\n",
      "Epoch 533/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5690 - accuracy: 0.7809 - val_loss: 0.5434 - val_accuracy: 0.7765\n",
      "Epoch 534/600\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5817 - accuracy: 0.7640 - val_loss: 0.5433 - val_accuracy: 0.7765\n",
      "Epoch 535/600\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.5767 - accuracy: 0.7697 - val_loss: 0.5433 - val_accuracy: 0.7765\n",
      "Epoch 536/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5658 - accuracy: 0.7626 - val_loss: 0.5432 - val_accuracy: 0.7765\n",
      "Epoch 537/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5714 - accuracy: 0.7767 - val_loss: 0.5431 - val_accuracy: 0.7765\n",
      "Epoch 538/600\n",
      "712/712 [==============================] - 0s 77us/sample - loss: 0.5845 - accuracy: 0.7683 - val_loss: 0.5430 - val_accuracy: 0.7765\n",
      "Epoch 539/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5828 - accuracy: 0.7598 - val_loss: 0.5429 - val_accuracy: 0.7765\n",
      "Epoch 540/600\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.5829 - accuracy: 0.7725 - val_loss: 0.5428 - val_accuracy: 0.7765\n",
      "Epoch 541/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5669 - accuracy: 0.7683 - val_loss: 0.5428 - val_accuracy: 0.7765\n",
      "Epoch 542/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.5720 - accuracy: 0.7542 - val_loss: 0.5427 - val_accuracy: 0.7765\n",
      "Epoch 543/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.5764 - accuracy: 0.7809 - val_loss: 0.5426 - val_accuracy: 0.7765\n",
      "Epoch 544/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5738 - accuracy: 0.7683 - val_loss: 0.5425 - val_accuracy: 0.7765\n",
      "Epoch 545/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.5627 - accuracy: 0.7654 - val_loss: 0.5424 - val_accuracy: 0.7765\n",
      "Epoch 546/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.5725 - accuracy: 0.7598 - val_loss: 0.5423 - val_accuracy: 0.7765\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.9114 - accuracy: 0.5604 - val_loss: 0.9058 - val_accuracy: 0.6536\n",
      "Epoch 6/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.9166 - accuracy: 0.5084 - val_loss: 0.8841 - val_accuracy: 0.6704\n",
      "Epoch 7/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.8805 - accuracy: 0.5730 - val_loss: 0.8695 - val_accuracy: 0.6927\n",
      "Epoch 8/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.8744 - accuracy: 0.5534 - val_loss: 0.8496 - val_accuracy: 0.6648\n",
      "Epoch 9/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.8491 - accuracy: 0.5548 - val_loss: 0.8352 - val_accuracy: 0.6872\n",
      "Epoch 10/400\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.8379 - accuracy: 0.5421 - val_loss: 0.8199 - val_accuracy: 0.6760\n",
      "Epoch 11/400\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.8242 - accuracy: 0.5520 - val_loss: 0.8049 - val_accuracy: 0.7039\n",
      "Epoch 12/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.8090 - accuracy: 0.5576 - val_loss: 0.7903 - val_accuracy: 0.7263\n",
      "Epoch 13/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7960 - accuracy: 0.5449 - val_loss: 0.7778 - val_accuracy: 0.7263\n",
      "Epoch 14/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.7905 - accuracy: 0.5379 - val_loss: 0.7668 - val_accuracy: 0.7151\n",
      "Epoch 15/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7723 - accuracy: 0.5871 - val_loss: 0.7569 - val_accuracy: 0.7151\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.7474 - accuracy: 0.6025 - val_loss: 0.7437 - val_accuracy: 0.7263\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.7611 - accuracy: 0.5646 - val_loss: 0.7349 - val_accuracy: 0.6872\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.7470 - accuracy: 0.5913 - val_loss: 0.7230 - val_accuracy: 0.6927\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.7328 - accuracy: 0.5787 - val_loss: 0.7151 - val_accuracy: 0.6816\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.7359 - accuracy: 0.6011 - val_loss: 0.7053 - val_accuracy: 0.7318\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.7218 - accuracy: 0.5969 - val_loss: 0.6992 - val_accuracy: 0.7263\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.7076 - accuracy: 0.6475 - val_loss: 0.6906 - val_accuracy: 0.7318\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.7068 - accuracy: 0.6110 - val_loss: 0.6847 - val_accuracy: 0.7374\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.7016 - accuracy: 0.6053 - val_loss: 0.6780 - val_accuracy: 0.7430\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.6936 - accuracy: 0.6461 - val_loss: 0.6721 - val_accuracy: 0.7430\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.6973 - accuracy: 0.6152 - val_loss: 0.6684 - val_accuracy: 0.7430\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.7021 - accuracy: 0.6067 - val_loss: 0.6637 - val_accuracy: 0.7430\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.7091 - accuracy: 0.5829 - val_loss: 0.6606 - val_accuracy: 0.7486\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.7004 - accuracy: 0.6194 - val_loss: 0.6581 - val_accuracy: 0.7430\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.6994 - accuracy: 0.6208 - val_loss: 0.6576 - val_accuracy: 0.7598\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.6937 - accuracy: 0.6180 - val_loss: 0.6529 - val_accuracy: 0.7430\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.6998 - accuracy: 0.6025 - val_loss: 0.6485 - val_accuracy: 0.7486\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.6828 - accuracy: 0.6348 - val_loss: 0.6464 - val_accuracy: 0.7430\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.6832 - accuracy: 0.6025 - val_loss: 0.6448 - val_accuracy: 0.7654\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.7035 - accuracy: 0.5997 - val_loss: 0.6414 - val_accuracy: 0.7430\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.6857 - accuracy: 0.6306 - val_loss: 0.6389 - val_accuracy: 0.7598\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 77us/sample - loss: 0.6879 - accuracy: 0.6320 - val_loss: 0.6371 - val_accuracy: 0.7709\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.6833 - accuracy: 0.6138 - val_loss: 0.6348 - val_accuracy: 0.7709\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6857 - accuracy: 0.6152 - val_loss: 0.6329 - val_accuracy: 0.7709\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.6828 - accuracy: 0.6320 - val_loss: 0.6309 - val_accuracy: 0.7765\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.6754 - accuracy: 0.6292 - val_loss: 0.6297 - val_accuracy: 0.7654\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.6854 - accuracy: 0.6208 - val_loss: 0.6265 - val_accuracy: 0.7709\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.6767 - accuracy: 0.6517 - val_loss: 0.6259 - val_accuracy: 0.7654\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.6686 - accuracy: 0.6489 - val_loss: 0.6256 - val_accuracy: 0.7654\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.6577 - accuracy: 0.6671 - val_loss: 0.6208 - val_accuracy: 0.7765\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.6810 - accuracy: 0.6264 - val_loss: 0.6180 - val_accuracy: 0.7709\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.6607 - accuracy: 0.6559 - val_loss: 0.6171 - val_accuracy: 0.7654\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.6777 - accuracy: 0.6292 - val_loss: 0.6144 - val_accuracy: 0.7709\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.6723 - accuracy: 0.6433 - val_loss: 0.6137 - val_accuracy: 0.7709\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.6703 - accuracy: 0.6334 - val_loss: 0.6137 - val_accuracy: 0.7598\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.6582 - accuracy: 0.6461 - val_loss: 0.6092 - val_accuracy: 0.7486\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.6742 - accuracy: 0.6292 - val_loss: 0.6086 - val_accuracy: 0.7709\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.6695 - accuracy: 0.6334 - val_loss: 0.6085 - val_accuracy: 0.7709\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.6803 - accuracy: 0.6236 - val_loss: 0.6080 - val_accuracy: 0.7654\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.6625 - accuracy: 0.6573 - val_loss: 0.6080 - val_accuracy: 0.7709\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.6965 - accuracy: 0.6081 - val_loss: 0.6090 - val_accuracy: 0.7598\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.6405 - accuracy: 0.6784 - val_loss: 0.6061 - val_accuracy: 0.7654\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.6563 - accuracy: 0.6461 - val_loss: 0.6051 - val_accuracy: 0.7598\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.6812 - accuracy: 0.6138 - val_loss: 0.6045 - val_accuracy: 0.7654\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.6939 - accuracy: 0.6236 - val_loss: 0.7076 - val_accuracy: 0.5866\n",
      "Epoch 424/700\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6942 - accuracy: 0.6236 - val_loss: 0.7076 - val_accuracy: 0.5866\n",
      "Epoch 425/700\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6943 - accuracy: 0.6236 - val_loss: 0.7077 - val_accuracy: 0.5866\n",
      "Epoch 426/700\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6944 - accuracy: 0.6236 - val_loss: 0.7076 - val_accuracy: 0.5866\n",
      "Epoch 427/700\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6943 - accuracy: 0.6236 - val_loss: 0.7074 - val_accuracy: 0.5866\n",
      "Epoch 428/700\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6942 - accuracy: 0.6236 - val_loss: 0.7074 - val_accuracy: 0.5866\n",
      "Epoch 429/700\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6940 - accuracy: 0.6236 - val_loss: 0.7073 - val_accuracy: 0.5866\n",
      "Epoch 430/700\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6942 - accuracy: 0.6236 - val_loss: 0.7073 - val_accuracy: 0.5866\n",
      "Epoch 431/700\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.6940 - accuracy: 0.6222 - val_loss: 0.7072 - val_accuracy: 0.5866\n",
      "Epoch 432/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6941 - accuracy: 0.6236 - val_loss: 0.7072 - val_accuracy: 0.5866\n",
      "Epoch 433/700\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.6939 - accuracy: 0.6236 - val_loss: 0.7071 - val_accuracy: 0.5866\n",
      "Epoch 434/700\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.6942 - accuracy: 0.6222 - val_loss: 0.7070 - val_accuracy: 0.5866\n",
      "Epoch 435/700\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6939 - accuracy: 0.6236 - val_loss: 0.7070 - val_accuracy: 0.5866\n",
      "Epoch 436/700\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6940 - accuracy: 0.6236 - val_loss: 0.7070 - val_accuracy: 0.5866\n",
      "Epoch 437/700\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.6936 - accuracy: 0.6236 - val_loss: 0.7070 - val_accuracy: 0.5866\n",
      "Epoch 438/700\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.6939 - accuracy: 0.6236 - val_loss: 0.7070 - val_accuracy: 0.5866\n",
      "Epoch 439/700\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.6939 - accuracy: 0.6236 - val_loss: 0.7070 - val_accuracy: 0.5866\n",
      "Epoch 440/700\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.6937 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 441/700\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.6936 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 442/700\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.6936 - accuracy: 0.6236 - val_loss: 0.7070 - val_accuracy: 0.5866\n",
      "Epoch 443/700\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.6937 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 444/700\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.6936 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 445/700\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.6935 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 446/700\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.6934 - accuracy: 0.6236 - val_loss: 0.7070 - val_accuracy: 0.5866\n",
      "Epoch 447/700\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.6938 - accuracy: 0.6236 - val_loss: 0.7070 - val_accuracy: 0.5866\n",
      "Epoch 448/700\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.6934 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 449/700\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.6935 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 450/700\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.6935 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 451/700\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.6936 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 452/700\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.6936 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 453/700\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.6935 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 454/700\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.6932 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 455/700\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6934 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 456/700\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.6935 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 457/700\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.6933 - accuracy: 0.6236 - val_loss: 0.7070 - val_accuracy: 0.5866\n",
      "Epoch 458/700\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.6933 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 459/700\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.6934 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 460/700\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.6934 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 461/700\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.6934 - accuracy: 0.6236 - val_loss: 0.7069 - val_accuracy: 0.5866\n",
      "Epoch 462/700\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.7897 - accuracy: 0.7711 - val_loss: 0.7497 - val_accuracy: 0.7765\n",
      "Epoch 330/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7792 - accuracy: 0.7795 - val_loss: 0.7494 - val_accuracy: 0.7765\n",
      "Epoch 331/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.7848 - accuracy: 0.7697 - val_loss: 0.7492 - val_accuracy: 0.7765\n",
      "Epoch 332/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.7991 - accuracy: 0.7556 - val_loss: 0.7489 - val_accuracy: 0.7765\n",
      "Epoch 333/400\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.7902 - accuracy: 0.7626 - val_loss: 0.7487 - val_accuracy: 0.7765\n",
      "Epoch 334/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.7926 - accuracy: 0.7753 - val_loss: 0.7484 - val_accuracy: 0.7765\n",
      "Epoch 335/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7871 - accuracy: 0.7781 - val_loss: 0.7482 - val_accuracy: 0.7765\n",
      "Epoch 336/400\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.7804 - accuracy: 0.7683 - val_loss: 0.7479 - val_accuracy: 0.7765\n",
      "Epoch 337/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7825 - accuracy: 0.7753 - val_loss: 0.7477 - val_accuracy: 0.7765\n",
      "Epoch 338/400\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.7828 - accuracy: 0.7654 - val_loss: 0.7475 - val_accuracy: 0.7765\n",
      "Epoch 339/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7807 - accuracy: 0.7697 - val_loss: 0.7472 - val_accuracy: 0.7765\n",
      "Epoch 340/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.7777 - accuracy: 0.7739 - val_loss: 0.7470 - val_accuracy: 0.7765\n",
      "Epoch 341/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.7740 - accuracy: 0.7753 - val_loss: 0.7467 - val_accuracy: 0.7765\n",
      "Epoch 342/400\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.7712 - accuracy: 0.7683 - val_loss: 0.7465 - val_accuracy: 0.7765\n",
      "Epoch 343/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.7789 - accuracy: 0.7781 - val_loss: 0.7462 - val_accuracy: 0.7765\n",
      "Epoch 344/400\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.7827 - accuracy: 0.7626 - val_loss: 0.7460 - val_accuracy: 0.7765\n",
      "Epoch 345/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.7875 - accuracy: 0.7697 - val_loss: 0.7458 - val_accuracy: 0.7765\n",
      "Epoch 346/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.7903 - accuracy: 0.7767 - val_loss: 0.7455 - val_accuracy: 0.7765\n",
      "Epoch 347/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7864 - accuracy: 0.7767 - val_loss: 0.7453 - val_accuracy: 0.7765\n",
      "Epoch 348/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.7798 - accuracy: 0.7711 - val_loss: 0.7451 - val_accuracy: 0.7765\n",
      "Epoch 349/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7747 - accuracy: 0.7683 - val_loss: 0.7448 - val_accuracy: 0.7765\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.7728 - accuracy: 0.7823 - val_loss: 0.7445 - val_accuracy: 0.7765\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.7767 - accuracy: 0.7683 - val_loss: 0.7443 - val_accuracy: 0.7765\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7776 - accuracy: 0.7654 - val_loss: 0.7440 - val_accuracy: 0.7765\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7817 - accuracy: 0.7640 - val_loss: 0.7438 - val_accuracy: 0.7765\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.7794 - accuracy: 0.7654 - val_loss: 0.7435 - val_accuracy: 0.7765\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7928 - accuracy: 0.7556 - val_loss: 0.7433 - val_accuracy: 0.7765\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7884 - accuracy: 0.7584 - val_loss: 0.7431 - val_accuracy: 0.7765\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7726 - accuracy: 0.7697 - val_loss: 0.7428 - val_accuracy: 0.7765\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7807 - accuracy: 0.7725 - val_loss: 0.7426 - val_accuracy: 0.7765\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.7864 - accuracy: 0.7711 - val_loss: 0.7424 - val_accuracy: 0.7765\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.7880 - accuracy: 0.7654 - val_loss: 0.7422 - val_accuracy: 0.7765\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.7828 - accuracy: 0.7739 - val_loss: 0.7419 - val_accuracy: 0.7765\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.7860 - accuracy: 0.7739 - val_loss: 0.7417 - val_accuracy: 0.7765\n",
      "Epoch 363/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.7801 - accuracy: 0.7640 - val_loss: 0.7414 - val_accuracy: 0.7765\n",
      "Epoch 364/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.7874 - accuracy: 0.7669 - val_loss: 0.7412 - val_accuracy: 0.7765\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.7708 - accuracy: 0.7809 - val_loss: 0.7410 - val_accuracy: 0.7765\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7703 - accuracy: 0.7795 - val_loss: 0.7407 - val_accuracy: 0.7765\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7767 - accuracy: 0.7711 - val_loss: 0.7405 - val_accuracy: 0.7765\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.7753 - accuracy: 0.7697 - val_loss: 0.7403 - val_accuracy: 0.7765\n",
      "Epoch 369/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7787 - accuracy: 0.7697 - val_loss: 0.7401 - val_accuracy: 0.7765\n",
      "Epoch 370/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7732 - accuracy: 0.7879 - val_loss: 0.7399 - val_accuracy: 0.7765\n",
      "Epoch 371/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.7559 - accuracy: 0.7795 - val_loss: 0.7396 - val_accuracy: 0.7765\n",
      "Epoch 372/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.7909 - accuracy: 0.7640 - val_loss: 0.7394 - val_accuracy: 0.7765\n",
      "Epoch 373/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7782 - accuracy: 0.7697 - val_loss: 0.7392 - val_accuracy: 0.7765\n",
      "Epoch 374/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7742 - accuracy: 0.7739 - val_loss: 0.7390 - val_accuracy: 0.7765\n",
      "Epoch 375/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7749 - accuracy: 0.7654 - val_loss: 0.7388 - val_accuracy: 0.7765\n",
      "Epoch 376/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.7803 - accuracy: 0.7725 - val_loss: 0.7386 - val_accuracy: 0.7765\n",
      "Epoch 377/400\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 0.7787 - accuracy: 0.7753 - val_loss: 0.7384 - val_accuracy: 0.7765\n",
      "Epoch 378/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7774 - accuracy: 0.7542 - val_loss: 0.7382 - val_accuracy: 0.7765\n",
      "Epoch 379/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7713 - accuracy: 0.7823 - val_loss: 0.7380 - val_accuracy: 0.7765\n",
      "Epoch 380/400\n",
      "712/712 [==============================] - 0s 85us/sample - loss: 0.7803 - accuracy: 0.7683 - val_loss: 0.7378 - val_accuracy: 0.7765\n",
      "Epoch 381/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7757 - accuracy: 0.7767 - val_loss: 0.7376 - val_accuracy: 0.7765\n",
      "Epoch 382/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.7829 - accuracy: 0.7753 - val_loss: 0.7374 - val_accuracy: 0.7765\n",
      "Epoch 383/400\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.7691 - accuracy: 0.7753 - val_loss: 0.7372 - val_accuracy: 0.7765\n",
      "Epoch 384/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7732 - accuracy: 0.7893 - val_loss: 0.7369 - val_accuracy: 0.7765\n",
      "Epoch 385/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7779 - accuracy: 0.7683 - val_loss: 0.7367 - val_accuracy: 0.7765\n",
      "Epoch 386/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7740 - accuracy: 0.7809 - val_loss: 0.7365 - val_accuracy: 0.7765\n",
      "Epoch 387/400\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 0.7820 - accuracy: 0.7697 - val_loss: 0.7363 - val_accuracy: 0.7765\n",
      "Epoch 388/400\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.7673 - accuracy: 0.7697 - val_loss: 0.7361 - val_accuracy: 0.7765\n",
      "Epoch 389/400\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 0.7704 - accuracy: 0.7711 - val_loss: 0.7358 - val_accuracy: 0.7765\n",
      "Epoch 390/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.7752 - accuracy: 0.7725 - val_loss: 0.7356 - val_accuracy: 0.7765\n",
      "Epoch 391/400\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.7781 - accuracy: 0.7725 - val_loss: 0.7354 - val_accuracy: 0.7765\n",
      "Epoch 392/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.7752 - accuracy: 0.7767 - val_loss: 0.7352 - val_accuracy: 0.7765\n",
      "Epoch 393/400\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.7697 - accuracy: 0.7711 - val_loss: 0.7350 - val_accuracy: 0.7765\n",
      "Epoch 394/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.7801 - accuracy: 0.7683 - val_loss: 0.7348 - val_accuracy: 0.7765\n",
      "Epoch 395/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.7741 - accuracy: 0.7640 - val_loss: 0.7346 - val_accuracy: 0.7765\n",
      "Epoch 396/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.7715 - accuracy: 0.7725 - val_loss: 0.7344 - val_accuracy: 0.7765\n",
      "Epoch 397/400\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 0.7692 - accuracy: 0.7612 - val_loss: 0.7342 - val_accuracy: 0.7765\n",
      "Epoch 398/400\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 0.7764 - accuracy: 0.7711 - val_loss: 0.7340 - val_accuracy: 0.7765\n",
      "Epoch 399/400\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 0.7730 - accuracy: 0.7725 - val_loss: 0.7338 - val_accuracy: 0.7765\n",
      "Epoch 400/400\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 0.7667 - accuracy: 0.7683 - val_loss: 0.7336 - val_accuracy: 0.7765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 8be712366cf9d81d1d6d25840d5844c4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7765362858772278</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-batch_size: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_0: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_1: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_2: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_3: sigmoid</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_4: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_5: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_6: sigmoid</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_0: 40</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_1: 40</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_2: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_3: 56</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_4: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_5: 40</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_6: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_0: 0.15000000000000002</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_1: 0.2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_2: 0.05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_3: 0.15000000000000002</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_4: 0.45</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_5: 0.1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_6: 0.30000000000000004</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-epoch_number: 400</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_0: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_1: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_2: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_3: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_4: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_5: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_6: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_0: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_1: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_2: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_3: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_4: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_5: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_6: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-learning_rate: 0.0005</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: SGD</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 1s 2ms/sample - loss: 1.2453 - accuracy: 0.4340 - val_loss: 1.2245 - val_accuracy: 0.5475\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 1.2177 - accuracy: 0.4410 - val_loss: 1.1891 - val_accuracy: 0.5642\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 1.1705 - accuracy: 0.5098 - val_loss: 1.1566 - val_accuracy: 0.5754\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 1.1335 - accuracy: 0.5295 - val_loss: 1.1221 - val_accuracy: 0.6760\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 1.1117 - accuracy: 0.5449 - val_loss: 1.0951 - val_accuracy: 0.6983\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 1.0867 - accuracy: 0.5084 - val_loss: 1.0669 - val_accuracy: 0.6927\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 1.0661 - accuracy: 0.5407 - val_loss: 1.0446 - val_accuracy: 0.7151\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 1.0387 - accuracy: 0.5562 - val_loss: 1.0183 - val_accuracy: 0.7151\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 1.0144 - accuracy: 0.5758 - val_loss: 0.9976 - val_accuracy: 0.7207\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 100us/sample - loss: 0.9941 - accuracy: 0.5969 - val_loss: 0.9756 - val_accuracy: 0.7207\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.9795 - accuracy: 0.5843 - val_loss: 0.9539 - val_accuracy: 0.7151\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.9552 - accuracy: 0.6180 - val_loss: 0.9299 - val_accuracy: 0.7207\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.9398 - accuracy: 0.6124 - val_loss: 0.9078 - val_accuracy: 0.6983\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.9173 - accuracy: 0.6503 - val_loss: 0.8864 - val_accuracy: 0.7095\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.8901 - accuracy: 0.6475 - val_loss: 0.8666 - val_accuracy: 0.7095\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.8959 - accuracy: 0.6334 - val_loss: 0.8448 - val_accuracy: 0.7095\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.8571 - accuracy: 0.6826 - val_loss: 0.8255 - val_accuracy: 0.7318\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.8386 - accuracy: 0.6840 - val_loss: 0.7985 - val_accuracy: 0.7486\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.8460 - accuracy: 0.6742 - val_loss: 0.7827 - val_accuracy: 0.7542\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.8199 - accuracy: 0.6868 - val_loss: 0.7653 - val_accuracy: 0.7486\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.7955 - accuracy: 0.7303 - val_loss: 0.7529 - val_accuracy: 0.7654\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.7879 - accuracy: 0.7261 - val_loss: 0.7340 - val_accuracy: 0.7486\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.7768 - accuracy: 0.7303 - val_loss: 0.7219 - val_accuracy: 0.7598\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.7536 - accuracy: 0.7458 - val_loss: 0.7122 - val_accuracy: 0.7598\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.7573 - accuracy: 0.7542 - val_loss: 0.7031 - val_accuracy: 0.7709\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.7355 - accuracy: 0.7514 - val_loss: 0.6947 - val_accuracy: 0.7654\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.7249 - accuracy: 0.7556 - val_loss: 0.6856 - val_accuracy: 0.7654\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.7267 - accuracy: 0.7528 - val_loss: 0.6808 - val_accuracy: 0.7709\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.7133 - accuracy: 0.7500 - val_loss: 0.6744 - val_accuracy: 0.7654\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.7233 - accuracy: 0.7472 - val_loss: 0.6729 - val_accuracy: 0.7709\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.7285 - accuracy: 0.7472 - val_loss: 0.6676 - val_accuracy: 0.7654\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7080 - accuracy: 0.7683 - val_loss: 0.6630 - val_accuracy: 0.7654\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.7137 - accuracy: 0.7444 - val_loss: 0.6620 - val_accuracy: 0.7709\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.6999 - accuracy: 0.7640 - val_loss: 0.6604 - val_accuracy: 0.7765\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.7111 - accuracy: 0.7458 - val_loss: 0.6524 - val_accuracy: 0.7654\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.7168 - accuracy: 0.7542 - val_loss: 0.6516 - val_accuracy: 0.7654\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.6857 - accuracy: 0.7851 - val_loss: 0.6502 - val_accuracy: 0.7709\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6846 - accuracy: 0.7570 - val_loss: 0.6496 - val_accuracy: 0.7709\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6770 - accuracy: 0.7907 - val_loss: 0.6455 - val_accuracy: 0.7709\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6761 - accuracy: 0.7654 - val_loss: 0.6418 - val_accuracy: 0.7654\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6747 - accuracy: 0.7739 - val_loss: 0.6403 - val_accuracy: 0.7709\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6917 - accuracy: 0.7486 - val_loss: 0.6374 - val_accuracy: 0.7654\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6531 - accuracy: 0.7795 - val_loss: 0.6365 - val_accuracy: 0.7765\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6647 - accuracy: 0.7935 - val_loss: 0.6337 - val_accuracy: 0.7821\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6671 - accuracy: 0.7809 - val_loss: 0.6298 - val_accuracy: 0.7765\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6776 - accuracy: 0.7542 - val_loss: 0.6301 - val_accuracy: 0.7765\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6585 - accuracy: 0.7949 - val_loss: 0.6285 - val_accuracy: 0.7765\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6552 - accuracy: 0.7753 - val_loss: 0.6258 - val_accuracy: 0.7765\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6644 - accuracy: 0.7598 - val_loss: 0.6233 - val_accuracy: 0.7654\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6605 - accuracy: 0.7767 - val_loss: 0.6224 - val_accuracy: 0.7654\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6569 - accuracy: 0.7739 - val_loss: 0.6215 - val_accuracy: 0.7709\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6796 - accuracy: 0.7612 - val_loss: 0.6214 - val_accuracy: 0.7709\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6624 - accuracy: 0.7711 - val_loss: 0.6209 - val_accuracy: 0.7709\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6470 - accuracy: 0.7837 - val_loss: 0.6197 - val_accuracy: 0.7709\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6650 - accuracy: 0.7570 - val_loss: 0.6203 - val_accuracy: 0.7821\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.6370 - accuracy: 0.7851 - val_loss: 0.6187 - val_accuracy: 0.7821\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6355 - accuracy: 0.7837 - val_loss: 0.6158 - val_accuracy: 0.7709\n",
      "Epoch 58/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6711 - accuracy: 0.7598 - val_loss: 0.6152 - val_accuracy: 0.7765\n",
      "Epoch 59/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.6602 - accuracy: 0.7697 - val_loss: 0.6139 - val_accuracy: 0.7709\n",
      "Epoch 60/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6531 - accuracy: 0.7795 - val_loss: 0.6143 - val_accuracy: 0.7821\n",
      "Epoch 61/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6500 - accuracy: 0.7654 - val_loss: 0.6122 - val_accuracy: 0.7709\n",
      "Epoch 62/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6351 - accuracy: 0.8062 - val_loss: 0.6111 - val_accuracy: 0.7821\n",
      "Epoch 63/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6421 - accuracy: 0.7935 - val_loss: 0.6072 - val_accuracy: 0.7765\n",
      "Epoch 64/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6498 - accuracy: 0.7654 - val_loss: 0.6076 - val_accuracy: 0.7821\n",
      "Epoch 65/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6608 - accuracy: 0.7654 - val_loss: 0.6066 - val_accuracy: 0.7709\n",
      "Epoch 66/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6667 - accuracy: 0.7598 - val_loss: 0.6073 - val_accuracy: 0.7765\n",
      "Epoch 67/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6485 - accuracy: 0.7907 - val_loss: 0.6091 - val_accuracy: 0.7821\n",
      "Epoch 68/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6358 - accuracy: 0.7823 - val_loss: 0.6081 - val_accuracy: 0.7821\n",
      "Epoch 69/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6224 - accuracy: 0.7963 - val_loss: 0.6052 - val_accuracy: 0.7765\n",
      "Epoch 70/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.6474 - accuracy: 0.7711 - val_loss: 0.6040 - val_accuracy: 0.7765\n",
      "Epoch 71/500\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.6378 - accuracy: 0.7837 - val_loss: 0.6029 - val_accuracy: 0.7709\n",
      "Epoch 72/500\n",
      "712/712 [==============================] - 0s 94us/sample - loss: 0.6508 - accuracy: 0.7767 - val_loss: 0.6026 - val_accuracy: 0.7821\n",
      "Epoch 73/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6429 - accuracy: 0.7753 - val_loss: 0.6026 - val_accuracy: 0.7821\n",
      "Epoch 74/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6165 - accuracy: 0.8048 - val_loss: 0.6030 - val_accuracy: 0.7765\n",
      "Epoch 75/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6477 - accuracy: 0.7683 - val_loss: 0.6010 - val_accuracy: 0.7821\n",
      "Epoch 76/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6294 - accuracy: 0.7879 - val_loss: 0.6005 - val_accuracy: 0.7709\n",
      "Epoch 77/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.6337 - accuracy: 0.7795 - val_loss: 0.5997 - val_accuracy: 0.7821\n",
      "Epoch 78/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6269 - accuracy: 0.7865 - val_loss: 0.5990 - val_accuracy: 0.7821\n",
      "Epoch 79/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6401 - accuracy: 0.7725 - val_loss: 0.5971 - val_accuracy: 0.7821\n",
      "Epoch 80/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6186 - accuracy: 0.7992 - val_loss: 0.6000 - val_accuracy: 0.7821\n",
      "Epoch 81/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6453 - accuracy: 0.7865 - val_loss: 0.5968 - val_accuracy: 0.7821\n",
      "Epoch 82/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6349 - accuracy: 0.7767 - val_loss: 0.5973 - val_accuracy: 0.7821\n",
      "Epoch 83/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6207 - accuracy: 0.7963 - val_loss: 0.5943 - val_accuracy: 0.7821\n",
      "Epoch 84/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.6299 - accuracy: 0.7809 - val_loss: 0.5940 - val_accuracy: 0.7821\n",
      "Epoch 85/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6164 - accuracy: 0.8006 - val_loss: 0.5923 - val_accuracy: 0.7765\n",
      "Epoch 86/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6282 - accuracy: 0.7739 - val_loss: 0.5913 - val_accuracy: 0.7821\n",
      "Epoch 87/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6246 - accuracy: 0.7949 - val_loss: 0.5900 - val_accuracy: 0.7709\n",
      "Epoch 88/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6223 - accuracy: 0.7739 - val_loss: 0.5899 - val_accuracy: 0.7821\n",
      "Epoch 89/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6305 - accuracy: 0.7767 - val_loss: 0.5891 - val_accuracy: 0.7765\n",
      "Epoch 90/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6374 - accuracy: 0.7725 - val_loss: 0.5895 - val_accuracy: 0.7821\n",
      "Epoch 91/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6186 - accuracy: 0.7739 - val_loss: 0.5887 - val_accuracy: 0.7765\n",
      "Epoch 92/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6340 - accuracy: 0.7753 - val_loss: 0.5893 - val_accuracy: 0.7821\n",
      "Epoch 93/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6130 - accuracy: 0.7921 - val_loss: 0.5881 - val_accuracy: 0.7821\n",
      "Epoch 94/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6244 - accuracy: 0.7879 - val_loss: 0.5863 - val_accuracy: 0.7877\n",
      "Epoch 95/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6118 - accuracy: 0.7865 - val_loss: 0.5859 - val_accuracy: 0.7877\n",
      "Epoch 96/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6096 - accuracy: 0.7992 - val_loss: 0.5853 - val_accuracy: 0.7877\n",
      "Epoch 97/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6223 - accuracy: 0.7795 - val_loss: 0.5854 - val_accuracy: 0.7821\n",
      "Epoch 98/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6203 - accuracy: 0.7809 - val_loss: 0.5856 - val_accuracy: 0.7821\n",
      "Epoch 99/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6248 - accuracy: 0.7683 - val_loss: 0.5860 - val_accuracy: 0.7877\n",
      "Epoch 100/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6126 - accuracy: 0.7739 - val_loss: 0.5845 - val_accuracy: 0.7821\n",
      "Epoch 101/500\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.6082 - accuracy: 0.7865 - val_loss: 0.5847 - val_accuracy: 0.7933\n",
      "Epoch 102/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6232 - accuracy: 0.7795 - val_loss: 0.5839 - val_accuracy: 0.7933\n",
      "Epoch 103/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6230 - accuracy: 0.7921 - val_loss: 0.5840 - val_accuracy: 0.7933\n",
      "Epoch 104/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6150 - accuracy: 0.7879 - val_loss: 0.5828 - val_accuracy: 0.7933\n",
      "Epoch 105/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6106 - accuracy: 0.7823 - val_loss: 0.5817 - val_accuracy: 0.7877\n",
      "Epoch 106/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6291 - accuracy: 0.7781 - val_loss: 0.5818 - val_accuracy: 0.7877\n",
      "Epoch 107/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6020 - accuracy: 0.7978 - val_loss: 0.5810 - val_accuracy: 0.7877\n",
      "Epoch 108/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6072 - accuracy: 0.7978 - val_loss: 0.5791 - val_accuracy: 0.7877\n",
      "Epoch 109/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5884 - accuracy: 0.7949 - val_loss: 0.5781 - val_accuracy: 0.7877\n",
      "Epoch 110/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6008 - accuracy: 0.7598 - val_loss: 0.5773 - val_accuracy: 0.7877\n",
      "Epoch 111/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6078 - accuracy: 0.7837 - val_loss: 0.5761 - val_accuracy: 0.7821\n",
      "Epoch 112/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6136 - accuracy: 0.7823 - val_loss: 0.5776 - val_accuracy: 0.7877\n",
      "Epoch 113/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6188 - accuracy: 0.7865 - val_loss: 0.5795 - val_accuracy: 0.7933\n",
      "Epoch 114/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6037 - accuracy: 0.7992 - val_loss: 0.5764 - val_accuracy: 0.7821\n",
      "Epoch 115/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6156 - accuracy: 0.7823 - val_loss: 0.5757 - val_accuracy: 0.7821\n",
      "Epoch 116/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6181 - accuracy: 0.7767 - val_loss: 0.5789 - val_accuracy: 0.7933\n",
      "Epoch 117/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6084 - accuracy: 0.7935 - val_loss: 0.5762 - val_accuracy: 0.7933\n",
      "Epoch 118/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6148 - accuracy: 0.7935 - val_loss: 0.5779 - val_accuracy: 0.7933\n",
      "Epoch 119/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6154 - accuracy: 0.7907 - val_loss: 0.5772 - val_accuracy: 0.7933\n",
      "Epoch 120/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6192 - accuracy: 0.7893 - val_loss: 0.5769 - val_accuracy: 0.7877\n",
      "Epoch 121/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6190 - accuracy: 0.7907 - val_loss: 0.5765 - val_accuracy: 0.7933\n",
      "Epoch 122/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6117 - accuracy: 0.7893 - val_loss: 0.5770 - val_accuracy: 0.7877\n",
      "Epoch 123/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6023 - accuracy: 0.7949 - val_loss: 0.5752 - val_accuracy: 0.7877\n",
      "Epoch 124/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6015 - accuracy: 0.7893 - val_loss: 0.5749 - val_accuracy: 0.7877\n",
      "Epoch 125/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6214 - accuracy: 0.7823 - val_loss: 0.5747 - val_accuracy: 0.7933\n",
      "Epoch 126/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5974 - accuracy: 0.8006 - val_loss: 0.5745 - val_accuracy: 0.7877\n",
      "Epoch 127/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5963 - accuracy: 0.7978 - val_loss: 0.5735 - val_accuracy: 0.7933\n",
      "Epoch 128/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5990 - accuracy: 0.8034 - val_loss: 0.5735 - val_accuracy: 0.7877\n",
      "Epoch 129/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6171 - accuracy: 0.7879 - val_loss: 0.5727 - val_accuracy: 0.7933\n",
      "Epoch 130/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5985 - accuracy: 0.7992 - val_loss: 0.5721 - val_accuracy: 0.7933\n",
      "Epoch 131/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6024 - accuracy: 0.7935 - val_loss: 0.5729 - val_accuracy: 0.8101\n",
      "Epoch 132/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6160 - accuracy: 0.7879 - val_loss: 0.5727 - val_accuracy: 0.7989\n",
      "Epoch 133/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6174 - accuracy: 0.7753 - val_loss: 0.5726 - val_accuracy: 0.7877\n",
      "Epoch 134/500\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 0.5994 - accuracy: 0.8062 - val_loss: 0.5735 - val_accuracy: 0.7933\n",
      "Epoch 135/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6119 - accuracy: 0.7851 - val_loss: 0.5722 - val_accuracy: 0.8045\n",
      "Epoch 136/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5926 - accuracy: 0.7992 - val_loss: 0.5713 - val_accuracy: 0.8101\n",
      "Epoch 137/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5987 - accuracy: 0.7963 - val_loss: 0.5704 - val_accuracy: 0.8045\n",
      "Epoch 138/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5777 - accuracy: 0.8104 - val_loss: 0.5704 - val_accuracy: 0.7933\n",
      "Epoch 139/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6032 - accuracy: 0.7935 - val_loss: 0.5692 - val_accuracy: 0.8101\n",
      "Epoch 140/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5939 - accuracy: 0.8160 - val_loss: 0.5709 - val_accuracy: 0.7933\n",
      "Epoch 141/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5891 - accuracy: 0.8132 - val_loss: 0.5703 - val_accuracy: 0.7989\n",
      "Epoch 142/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5926 - accuracy: 0.7935 - val_loss: 0.5689 - val_accuracy: 0.8101\n",
      "Epoch 143/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6047 - accuracy: 0.7992 - val_loss: 0.5688 - val_accuracy: 0.8101\n",
      "Epoch 144/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6048 - accuracy: 0.7963 - val_loss: 0.5690 - val_accuracy: 0.8101\n",
      "Epoch 145/500\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 0.5842 - accuracy: 0.8062 - val_loss: 0.5677 - val_accuracy: 0.8101\n",
      "Epoch 146/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6013 - accuracy: 0.7978 - val_loss: 0.5678 - val_accuracy: 0.8101\n",
      "Epoch 147/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.6002 - accuracy: 0.7921 - val_loss: 0.5675 - val_accuracy: 0.8101\n",
      "Epoch 148/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5912 - accuracy: 0.7963 - val_loss: 0.5675 - val_accuracy: 0.8101\n",
      "Epoch 149/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5781 - accuracy: 0.8118 - val_loss: 0.5672 - val_accuracy: 0.8101\n",
      "Epoch 150/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5892 - accuracy: 0.7978 - val_loss: 0.5664 - val_accuracy: 0.8101\n",
      "Epoch 151/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5809 - accuracy: 0.8104 - val_loss: 0.5651 - val_accuracy: 0.8045\n",
      "Epoch 152/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.6080 - accuracy: 0.7837 - val_loss: 0.5648 - val_accuracy: 0.8101\n",
      "Epoch 153/500\n",
      "712/712 [==============================] - 0s 95us/sample - loss: 0.6017 - accuracy: 0.7823 - val_loss: 0.5662 - val_accuracy: 0.8101\n",
      "Epoch 154/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5854 - accuracy: 0.7992 - val_loss: 0.5672 - val_accuracy: 0.8101\n",
      "Epoch 155/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5900 - accuracy: 0.7992 - val_loss: 0.5664 - val_accuracy: 0.8101\n",
      "Epoch 156/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5996 - accuracy: 0.8132 - val_loss: 0.5660 - val_accuracy: 0.8101\n",
      "Epoch 157/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.6134 - accuracy: 0.8020 - val_loss: 0.5656 - val_accuracy: 0.8101\n",
      "Epoch 158/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.6014 - accuracy: 0.7963 - val_loss: 0.5653 - val_accuracy: 0.8045\n",
      "Epoch 159/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5892 - accuracy: 0.8020 - val_loss: 0.5659 - val_accuracy: 0.8101\n",
      "Epoch 160/500\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 0.5994 - accuracy: 0.7879 - val_loss: 0.5657 - val_accuracy: 0.8045\n",
      "Epoch 161/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5853 - accuracy: 0.8146 - val_loss: 0.5642 - val_accuracy: 0.8045\n",
      "Epoch 162/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5937 - accuracy: 0.7963 - val_loss: 0.5642 - val_accuracy: 0.8101\n",
      "Epoch 163/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5935 - accuracy: 0.8048 - val_loss: 0.5653 - val_accuracy: 0.8101\n",
      "Epoch 164/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5979 - accuracy: 0.7935 - val_loss: 0.5646 - val_accuracy: 0.8101\n",
      "Epoch 165/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6047 - accuracy: 0.7921 - val_loss: 0.5655 - val_accuracy: 0.8101\n",
      "Epoch 166/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5959 - accuracy: 0.8104 - val_loss: 0.5649 - val_accuracy: 0.8101\n",
      "Epoch 167/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5824 - accuracy: 0.8048 - val_loss: 0.5650 - val_accuracy: 0.8101\n",
      "Epoch 168/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6135 - accuracy: 0.7823 - val_loss: 0.5637 - val_accuracy: 0.8101\n",
      "Epoch 169/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5876 - accuracy: 0.8048 - val_loss: 0.5642 - val_accuracy: 0.8101\n",
      "Epoch 170/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5759 - accuracy: 0.8104 - val_loss: 0.5635 - val_accuracy: 0.8101\n",
      "Epoch 171/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5906 - accuracy: 0.8048 - val_loss: 0.5635 - val_accuracy: 0.8101\n",
      "Epoch 172/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6025 - accuracy: 0.7935 - val_loss: 0.5640 - val_accuracy: 0.8101\n",
      "Epoch 173/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5874 - accuracy: 0.8020 - val_loss: 0.5632 - val_accuracy: 0.8101\n",
      "Epoch 174/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6005 - accuracy: 0.7935 - val_loss: 0.5644 - val_accuracy: 0.8101\n",
      "Epoch 175/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5921 - accuracy: 0.7921 - val_loss: 0.5638 - val_accuracy: 0.8101\n",
      "Epoch 176/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6028 - accuracy: 0.7893 - val_loss: 0.5628 - val_accuracy: 0.8101\n",
      "Epoch 177/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5989 - accuracy: 0.8020 - val_loss: 0.5641 - val_accuracy: 0.8101\n",
      "Epoch 178/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.6035 - accuracy: 0.7851 - val_loss: 0.5660 - val_accuracy: 0.8101\n",
      "Epoch 179/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5859 - accuracy: 0.8006 - val_loss: 0.5635 - val_accuracy: 0.8101\n",
      "Epoch 180/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5903 - accuracy: 0.7949 - val_loss: 0.5631 - val_accuracy: 0.7933\n",
      "Epoch 181/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5935 - accuracy: 0.7963 - val_loss: 0.5618 - val_accuracy: 0.8101\n",
      "Epoch 182/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5847 - accuracy: 0.8048 - val_loss: 0.5615 - val_accuracy: 0.8101\n",
      "Epoch 183/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6090 - accuracy: 0.7865 - val_loss: 0.5614 - val_accuracy: 0.8101\n",
      "Epoch 184/500\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 0.5989 - accuracy: 0.7949 - val_loss: 0.5610 - val_accuracy: 0.8045\n",
      "Epoch 185/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5876 - accuracy: 0.7992 - val_loss: 0.5611 - val_accuracy: 0.8101\n",
      "Epoch 186/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5783 - accuracy: 0.8062 - val_loss: 0.5614 - val_accuracy: 0.8101\n",
      "Epoch 187/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5907 - accuracy: 0.7963 - val_loss: 0.5614 - val_accuracy: 0.8101\n",
      "Epoch 188/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5817 - accuracy: 0.7921 - val_loss: 0.5608 - val_accuracy: 0.8101\n",
      "Epoch 189/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5944 - accuracy: 0.7963 - val_loss: 0.5624 - val_accuracy: 0.7989\n",
      "Epoch 190/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.6050 - accuracy: 0.7879 - val_loss: 0.5634 - val_accuracy: 0.8101\n",
      "Epoch 191/500\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 0.5927 - accuracy: 0.8020 - val_loss: 0.5639 - val_accuracy: 0.8101\n",
      "Epoch 192/500\n",
      "712/712 [==============================] - 0s 90us/sample - loss: 0.5869 - accuracy: 0.7921 - val_loss: 0.5621 - val_accuracy: 0.8101\n",
      "Epoch 193/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5822 - accuracy: 0.8132 - val_loss: 0.5627 - val_accuracy: 0.8101\n",
      "Epoch 194/500\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 0.5809 - accuracy: 0.8076 - val_loss: 0.5609 - val_accuracy: 0.8101\n",
      "Epoch 195/500\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 0.5936 - accuracy: 0.8076 - val_loss: 0.5613 - val_accuracy: 0.8101\n",
      "Epoch 196/500\n",
      "712/712 [==============================] - 0s 91us/sample - loss: 0.5870 - accuracy: 0.8090 - val_loss: 0.5631 - val_accuracy: 0.8101\n",
      "Epoch 197/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.5963 - accuracy: 0.7963 - val_loss: 0.5637 - val_accuracy: 0.8101\n",
      "Epoch 198/500\n",
      "712/712 [==============================] - 0s 92us/sample - loss: 0.6026 - accuracy: 0.7921 - val_loss: 0.5623 - val_accuracy: 0.8101\n",
      "Epoch 199/500\n",
      "712/712 [==============================] - 0s 93us/sample - loss: 0.5820 - accuracy: 0.8048 - val_loss: 0.5611 - val_accuracy: 0.8045\n",
      "Epoch 200/500\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, Y_train, validation_data=(X_dev, Y_dev))\n",
    "\n",
    "# tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Results of the tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'num_layers': 6,\n",
       " 'dense_units_0': 40,\n",
       " 'dense_activation_0': 'relu',\n",
       " 'l1_0': 0.001,\n",
       " 'l2_0': 0.0,\n",
       " 'dropout_0': 0.45,\n",
       " 'dense_units_1': 16,\n",
       " 'dense_activation_1': 'tanh',\n",
       " 'l1_1': 0.0001,\n",
       " 'l2_1': 0.0001,\n",
       " 'dropout_1': 0.1,\n",
       " 'dense_units_2': 24,\n",
       " 'dense_activation_2': 'relu',\n",
       " 'l1_2': 0.0001,\n",
       " 'l2_2': 0.0,\n",
       " 'dropout_2': 0.4,\n",
       " 'learning_rate': 0.001,\n",
       " 'optimizer': 'adam',\n",
       " 'epoch_number': 700,\n",
       " 'dense_units_3': 16,\n",
       " 'dense_activation_3': 'tanh',\n",
       " 'l1_3': 0.001,\n",
       " 'l2_3': 0.001,\n",
       " 'dropout_3': 0.15000000000000002,\n",
       " 'dense_units_4': 24,\n",
       " 'dense_activation_4': 'tanh',\n",
       " 'l1_4': 0.01,\n",
       " 'l2_4': 0.0,\n",
       " 'dropout_4': 0.05,\n",
       " 'dense_units_5': 56,\n",
       " 'dense_activation_5': 'relu',\n",
       " 'l1_5': 0.0,\n",
       " 'l2_5': 0.01,\n",
       " 'dropout_5': 0.4,\n",
       " 'dense_units_6': 56,\n",
       " 'dense_activation_6': 'tanh',\n",
       " 'l1_6': 1e-05,\n",
       " 'l2_6': 0.01,\n",
       " 'dropout_6': 0.4}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model\n",
      "Tuned train:\n",
      "712/712 [==============================] - 0s 340us/sample - loss: 0.4302 - accuracy: 0.8553\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 75us/sample - loss: 0.4770 - accuracy: 0.8380\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                640       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                656       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 56)                1400      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 57        \n",
      "=================================================================\n",
      "Total params: 3,969\n",
      "Trainable params: 3,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model\")\n",
    "\n",
    "# Get the best model tuned.\n",
    "best_model = tuner.get_best_models()[0]\n",
    "\n",
    "print(\"Tuned train:\")\n",
    "_ = best_model.evaluate(X_train, Y_train)\n",
    "\n",
    "print(\"Tuned dev:\")\n",
    "_ = best_model.evaluate(X_dev, Y_dev)\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_predictions(model, submission_name):\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    predictions = np.round(predictions).astype(np.uint8).reshape((-1))\n",
    "\n",
    "    print(f\"{submission_name}:\\n{predictions}\")\n",
    "    \n",
    "    output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "    output.to_csv(f\"{submission_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1]\n",
      "dl_tuned_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "store_predictions(model, \"dl_submission\")\n",
    "store_predictions(best_model, \"dl_tuned_submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
