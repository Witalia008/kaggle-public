{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONHASHSEED=0\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONHASHSEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\r\n",
      "  Downloading pip-20.1.1-py2.py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 2.7 MB/s \r\n",
      "\u001b[?25hInstalling collected packages: pip\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 20.1\r\n",
      "    Uninstalling pip-20.1:\r\n",
      "      Successfully uninstalled pip-20.1\r\n",
      "Successfully installed pip-20.1.1\r\n",
      "Collecting keras-tuner\r\n",
      "  Downloading keras-tuner-1.0.1.tar.gz (54 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 54 kB 995 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (1.18.1)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.8.7)\r\n",
      "Collecting terminaltables\r\n",
      "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (4.45.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (2.23.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (1.4.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from keras-tuner) (0.22.2.post1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (2020.4.5.1)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (2.9)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (1.24.3)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->keras-tuner) (3.0.4)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->keras-tuner) (0.14.1)\r\n",
      "Building wheels for collected packages: keras-tuner, terminaltables\r\n",
      "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-py3-none-any.whl size=73198 sha256=1fcbadea74b4cf8dd3afa9ef7edfab170cb222b4a868629611d84a828f6d50f7\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/cf/2f/1a1749d3a3650fac3305a8d7f9237b6de7c41068e2f8520ca2\r\n",
      "  Building wheel for terminaltables (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=05a96d2c2775da38cdf37c724792bc027845acf46a7361d7e7349d419b0146b7\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\r\n",
      "Successfully built keras-tuner terminaltables\r\n",
      "Installing collected packages: terminaltables, keras-tuner\r\n",
      "Successfully installed keras-tuner-1.0.1 terminaltables-3.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# To display all the columns from left to right without breaking into next line.\n",
    "pd.set_option(\"display.width\", 1500)\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# notebook\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define seed to reprodicibility of random generation\n",
    "SEED = 42\n",
    "\n",
    "DEV_SPLIT=0.2\n",
    "\n",
    "# MODE = \"DEV\"\n",
    "MODE = \"EVAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as python_random\n",
    "\n",
    "# Make sure Keras produces reproducible results.\n",
    "\n",
    "np.random.seed(SEED)\n",
    "python_random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print(physical_devices)\n",
    "for device in (physical_devices or []):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Read data and extract usable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n",
      "(891,)\n",
      "(418, 9)\n"
     ]
    }
   ],
   "source": [
    "features = \"Pclass Sex SibSp Parch Fare Embarked Name Cabin Age\".split()\n",
    "\n",
    "X_train_init = train_data[features]\n",
    "Y_train_init = train_data.Survived\n",
    "\n",
    "print(X_train_init.shape)\n",
    "print(Y_train_init.shape)\n",
    "\n",
    "X_test_init = test_data[features]\n",
    "\n",
    "print(X_test_init.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Split into train/dev sets\n",
    "## Needs to be done before pre-processing to avoid test-train contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 9) (712,)\n",
      "(179, 9) (179,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# if MODE == \"DEV\":\n",
    "X_train_unproc, X_dev_unproc, Y_train_unproc, Y_dev_unproc = train_test_split(X_train_init, Y_train_init, test_size=DEV_SPLIT, random_state=SEED)\n",
    "\n",
    "print(X_train_unproc.shape, Y_train_unproc.shape)\n",
    "print(X_dev_unproc.shape, Y_dev_unproc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Data observations\n",
    "*Have NaNs:* Age, Fare (some zeros, nans too), Cabin, Embarked\n",
    "*NOTE:* maybe need to approximate missing values using some other technique, like an additional model?\n",
    "\n",
    "* (+) Pclass:\n",
    "  * 1 - 3 number, 1 being the highest\n",
    "  * Range: 1-3\n",
    "  * Current approach: convert to one-hot.\n",
    "  * Previous approaches:\n",
    "      * normalize by 3.\n",
    "* (+) Name:\n",
    "  * has person's title, which could be used (Mr, Ms, Mrs, etc.)\n",
    "  * From title, can infer marital status?\n",
    "  * Current approach: extract titles, replace infrequent ones with \"Others\", convert them to one-hot, and calculate 'Married' based on title (1 - married (Mr, Mrs), -1 - unmarried (Miss, Master), 0 - unknown (other titles))\n",
    "  * Potential improvements: use more titles for getting 'married'; use 'maiden name' in calculation of 'married'; use 'nickname' somehow?\n",
    "* (+) Sex:\n",
    "  * Either male or female\n",
    "  * male: 65%, female: 35%\n",
    "  * Current approach: convert to one-hot.\n",
    "  * Potential improvements: use 1 and -1 for sexes?\n",
    "* (+) Age:\n",
    "  * has fractions if approximated. Has missing values.\n",
    "  * Range: 0.42-80\n",
    "  * Current approach: fill NaN with average in group-by Pclass-Sex, but create a column that identifies missing values. Also, normalize by 80.\n",
    "  * Potential improvements: have a better approximation of age. Convert to age categories?\n",
    "* (+) SibSp:\n",
    "  * how many siblings or spouses on board.\n",
    "  * Range: 0-8\n",
    "  * Current approach: Add to 'Family'.\n",
    "  * Previous approaches:\n",
    "    * normalize by 8.\n",
    "* (+) Parch:\n",
    "  * How many parents/children. (can be 0 for babies, if with nannies)\n",
    "  * Range: 0-6\n",
    "  * Current approach: Add to 'Family'\n",
    "  * Previous approachesL\n",
    "    * normalize by 6.\n",
    "* Ticket:\n",
    "  * A number with some optional letters (which can have some meaning?).\n",
    "  * Has repetitions (maybe for people travelling together).\n",
    "* (+) Fare:\n",
    "  * can have zeros (what do they mean?). Can have omitted (just one in test).\n",
    "  * Range: 0-512.3292\n",
    "  * Current approach: fill nan with mean, normalize by 512.\n",
    "  * Potential improvements: most fare is <= 30 USD, so maybe use fare categories.\n",
    "* (+) Cabin:\n",
    "  * has a lot of omitted values (78%). Can have multiple values (probably for families?).\n",
    "  * One value is a letter with a number. (both probably have meaning and impact?)\n",
    "  * Current approach: convert to one-hot (based on letter), include a 'nan' column for those that are missing values. Create a column for cabin number, and a column to identify missing numbers.\n",
    "  * Potential improvements: maybe cabin number itself doesn't mean much? Also, maybe need to deal with missing values in a different way? Also, maybe deal with multiple values better?\n",
    "* (+) Embarked:\n",
    "  * Either of 3 letters (with different frequency). Has just a few omitted.\n",
    "  * S - 72/65%, C - 19/24%, Q - 9/11%\n",
    "  * Current approach: convert to one-hot matrix (fill 2 missing with mode)\n",
    "  * Potential improvements: somehow take into the account different distribution of embarkation city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X):\n",
    "    import re\n",
    "    \n",
    "    titles = ['Mr', 'Mrs', 'Miss', 'Master', 'Ms', 'Don', 'Rev', 'Dr', 'Mme', 'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess', 'Jonkheer', 'Dona']\n",
    "    \n",
    "    X = X.copy()\n",
    "    \n",
    "    # === Get X - the features. ===\n",
    "\n",
    "    # == Post-process data ==\n",
    "\n",
    "#     if \"SibSp\" in X:\n",
    "#         X.SibSp = X.SibSp.divide(8)\n",
    "\n",
    "#     if \"Parch\" in X:\n",
    "#         X.Parch = X.Parch.divide(6)\n",
    "        \n",
    "    if \"Parch\" in X and \"SibSp\" in X:\n",
    "        X[\"Family\"] = X.Parch + X.SibSp\n",
    "#         X.Family = X.Family.divide(14)\n",
    "        X = X.drop(columns=\"Parch SibSp\".split())\n",
    "\n",
    "    if \"Fare\" in X:\n",
    "        # Since only a few would miss 'fare' value, it's okay to fill with average.\n",
    "        X.Fare = X.Fare.fillna(X.Fare.mean())\n",
    "        \n",
    "        X.Fare = np.where(X.Fare < 50, 1, 2)\n",
    "        \n",
    "#         X.Fare = X.Fare.divide(512)\n",
    "\n",
    "    if \"Embarked\" in X:\n",
    "        X.Embarked = X.Embarked.fillna(X.Embarked.mode()[0])\n",
    "        X.Embarked = X.Embarked.astype(pd.api.types.CategoricalDtype(categories=\"C Q S\".split()))\n",
    "        X = pd.get_dummies(X, columns=[\"Embarked\"])\n",
    "\n",
    "    if \"Name\" in X:\n",
    "        X[\"Title\"] = X.Name.apply(lambda name: re.search(\", ([\\w ]+).\", name).group(1))\n",
    "\n",
    "        # Try to see if the person is married (1), or not (-1), or unknown (0).\n",
    "        X[\"Married\"] = X.Title.apply(lambda title: 1 if title in \"Mrs Mr\".split() else -1 if title in \"Miss Master\".split() else 0)\n",
    "\n",
    "        # Get dummies for title\n",
    "        \n",
    "        # Include all possible values, even those not present in current dataset.\n",
    "#         X.Title = X.Title.astype(pd.api.types.CategoricalDtype(categories=titles))\n",
    "        \n",
    "        # Titles that are rare are converted to 'Others'\n",
    "        important_titles = ['Mr', 'Mrs', 'Miss', 'Master']\n",
    "        X.Title = X.Title.apply(lambda title: title if title in important_titles else \"Others\")\n",
    "        \n",
    "        X = pd.get_dummies(X, columns=[\"Title\"])\n",
    "        \n",
    "        # We don't need the name itself.\n",
    "        X = X.drop(columns=[\"Name\"])\n",
    "        \n",
    "    if \"Cabin\" in X:\n",
    "        X[\"Cabin_Missing\"] = np.where(X.Cabin.isnull(), 1, 0)\n",
    "        X.Cabin = X.Cabin.fillna(\"-\")\n",
    "        \n",
    "#         X[\"Cabin_Number\"] = X.Cabin.apply(lambda cabin: int(re.search(\"\\w(\\d+)\", cabin).group(1)) if len(cabin) > 1 else 0)\n",
    "#         # Do some sort of normalization.\n",
    "#         X.Cabin_Number = X.Cabin_Number.divide(200)\n",
    "#         X[\"Cabin_Number_Missing\"] = np.where(X.Cabin_Number == 0, 1, 0)\n",
    "        \n",
    "        X.Cabin = X.Cabin.apply(lambda cabin: cabin[:1])\n",
    "        \n",
    "        # Convert to one-hot\n",
    "#         X.Cabin = X.Cabin.astype(pd.api.types.CategoricalDtype(categories=list(\"ABCDEFGT\")))\n",
    "#         X = pd.get_dummies(X, columns=[\"Cabin\"], dummy_na=True)\n",
    "\n",
    "        # Convert to numbers with T beeing the lowest deck and S - the highest (sun deck).\n",
    "        X[\"Deck_Level\"] = X.Cabin.apply(lambda cabin: \"SABCDEFGT\".find(cabin[0]))\n",
    "        X = X.drop(columns=[\"Cabin\"])\n",
    "\n",
    "    if \"Age\" in X:\n",
    "        X[\"Age_Missing\"] = np.where(X.Age.isnull(), 1, 0)\n",
    "\n",
    "        # No need to skip 'nan' for Age when calculating mean, as Pandas does that automatically.\n",
    "        # 'transform' will go through each group, and fill its nan values with its mean value.\n",
    "        # Then, all that will be aggregated back into the column, thus replacing nan values with group's mean.\n",
    "        X[\"Age\"] = X.groupby(\"Pclass Sex\".split())[\"Age\"].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "#         X.Age = X.Age.divide(80)\n",
    "\n",
    "        # Convert age to categories 1 - child, 2 - young, 3 - older, 4 - senile\n",
    "        X.Age = pd.cut(X.Age, bins=[0, 16, 30, 50, 80], labels=False) + 1\n",
    "        \n",
    "    # Needs to be after 'Age', since age is using original Sex column.\n",
    "    if \"Sex\" in X:\n",
    "        X.Sex = X.Sex.astype(pd.api.types.CategoricalDtype(categories=\"male female\".split()))\n",
    "        X = pd.get_dummies(X, columns=[\"Sex\"])\n",
    "\n",
    "    if \"Pclass\" in X:\n",
    "        X = pd.get_dummies(X, columns=[\"Pclass\"])\n",
    "        # Do not normalize small numbers\n",
    "#         X.Pclass = X.Pclass.divide(3)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_clean(X):\n",
    "    import re\n",
    "\n",
    "    important_titles = [\"Mr\", \"Mrs\", \"Miss\", \"Master\"]\n",
    "    \n",
    "    X = X.copy()\n",
    "    \n",
    "    # Remember missing values\n",
    "    for col in \"Age\".split():\n",
    "        X[f\"{col}_Missing\"] = np.where(X[col].isnull(), 1, 0)\n",
    "        \n",
    "    if \"Parch\" in X and \"SibSp\" in X:\n",
    "        X[\"Family\"] = X.Parch + X.SibSp\n",
    "\n",
    "    if \"Fare\" in X:\n",
    "        X.Fare = X.Fare.fillna(X.Fare.mean())\n",
    "        X.Fare = pd.cut(X.Fare, bins=[-1, 15, 30, 50, 70, 100, 600], labels=False) + 1\n",
    "\n",
    "    if \"Embarked\" in X:\n",
    "        X.Embarked = X.Embarked.fillna(X.Embarked.mode()[0])\n",
    "        X.Embarked = X.Embarked.astype(pd.api.types.CategoricalDtype(categories=\"C Q S\".split()))\n",
    "\n",
    "    if \"Name\" in X:\n",
    "        X[\"Title\"] = X.Name.apply(lambda name: re.search(\", ([\\w ]+).\", name).group(1))\n",
    "\n",
    "        X.Title = X.Title.apply(lambda title: title if title in important_titles else \"Others\")\n",
    "\n",
    "#         X[\"Married\"] = X.Title.apply(lambda title: 1 if title in \"Mrs Mr\".split() else -1 if title in \"Miss Master\".split() else 0)\n",
    "        \n",
    "#     if \"Cabin\" in X:   \n",
    "#         X[\"Deck_Level\"] = X.Cabin.fillna(\"-\").apply(lambda cabin: \"SABCDEFGT\".find(cabin[0]))\n",
    "\n",
    "    if \"Age\" in X:\n",
    "        X[\"Age\"] = X.groupby(\"Pclass Sex\".split())[\"Age\"].transform(lambda x: x.fillna(x.mean()))\n",
    "        X.Age = pd.cut(X.Age, bins=[0, 16, 30, 50, 80], labels=False) + 1\n",
    "        \n",
    "    X = X.drop(columns=\"Name Cabin Parch SibSp\".split())\n",
    "        \n",
    "    X = pd.get_dummies(X, columns=\"Sex Embarked Title\".split())\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "     Pclass  Fare  Age  Age_Missing  Family  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Others\n",
      "331       1     2    3            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "733       2     1    2            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "382       3     1    3            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "704       3     1    2            0       1           0         1           0           0           1             0           0         1          0             0\n",
      "813       3     3    1            0       6           1         0           0           0           1             0           1         0          0             0\n",
      "Dev data:\n",
      "     Pclass  Fare  Age  Age_Missing  Family  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Others\n",
      "709       3     2    2            1       2           0         1           1           0           0             1           0         0          0             0\n",
      "439       2     1    3            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "840       3     1    2            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "720       2     3    1            0       1           1         0           0           0           1             0           1         0          0             0\n",
      "39        3     1    1            0       1           1         0           1           0           0             0           1         0          0             0\n",
      "Test data:\n",
      "   Pclass  Fare  Age  Age_Missing  Family  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Others\n",
      "0       3     1    3            0       0           0         1           0           1           0             0           0         1          0             0\n",
      "1       3     1    3            0       1           1         0           0           0           1             0           0         0          1             0\n",
      "2       2     1    4            0       0           0         1           0           1           0             0           0         1          0             0\n",
      "3       3     1    2            0       0           0         1           0           0           1             0           0         1          0             0\n",
      "4       3     1    2            0       2           1         0           0           0           1             0           0         0          1             0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\")\n",
    "X_train = prepare_data_clean(X_train_unproc)\n",
    "Y_train = Y_train_unproc\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"Dev data:\")\n",
    "X_dev = prepare_data_clean(X_dev_unproc)\n",
    "Y_dev = Y_dev_unproc\n",
    "print(X_dev.head())\n",
    "\n",
    "print(\"Test data:\")\n",
    "X_test = prepare_data_clean(X_test_init)\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# DL model using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name=\"tp\"),\n",
    "      keras.metrics.FalsePositives(name=\"fp\"),\n",
    "      keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "      keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "      keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "      keras.metrics.Precision(name=\"precision\"),\n",
    "      keras.metrics.Recall(name=\"recall\"),\n",
    "      keras.metrics.AUC(name=\"auc\"),\n",
    "]\n",
    "\n",
    "def get_model(input_size):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(128, input_shape=(input_size,), activation=\"relu\", kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation=\"relu\", kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),\n",
    "        Dense(20, activation=\"relu\", kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.25),\n",
    "        Dense(6, activation=\"tanh\", kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), metrics=METRICS, loss=\"binary_crossentropy\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "died_cnt, survived_cnt = np.bincount(Y_train_init)\n",
    "total_cnt = died_cnt + survived_cnt\n",
    "\n",
    "weight_died = total_cnt / died_cnt / 2\n",
    "weight_survived = total_cnt / survived_cnt / 2\n",
    "\n",
    "class_weights = {0: weight_died, 1: weight_survived}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 3s 5ms/sample - loss: 1.7119 - tp: 71.0000 - fp: 111.0000 - tn: 333.0000 - fn: 197.0000 - accuracy: 0.5674 - precision: 0.3901 - recall: 0.2649 - auc: 0.5337 - val_loss: 1.5482 - val_tp: 57.0000 - val_fp: 44.0000 - val_tn: 61.0000 - val_fn: 17.0000 - val_accuracy: 0.6592 - val_precision: 0.5644 - val_recall: 0.7703 - val_auc: 0.7886\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.4760 - tp: 170.0000 - fp: 164.0000 - tn: 280.0000 - fn: 98.0000 - accuracy: 0.6320 - precision: 0.5090 - recall: 0.6343 - auc: 0.6768 - val_loss: 1.3488 - val_tp: 47.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 27.0000 - val_accuracy: 0.7039 - val_precision: 0.6438 - val_recall: 0.6351 - val_auc: 0.8332\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2907 - tp: 168.0000 - fp: 100.0000 - tn: 344.0000 - fn: 100.0000 - accuracy: 0.7191 - precision: 0.6269 - recall: 0.6269 - auc: 0.7671 - val_loss: 1.1731 - val_tp: 62.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 12.0000 - val_accuracy: 0.7542 - val_precision: 0.6596 - val_recall: 0.8378 - val_auc: 0.8400\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.1697 - tp: 197.0000 - fp: 127.0000 - tn: 317.0000 - fn: 71.0000 - accuracy: 0.7219 - precision: 0.6080 - recall: 0.7351 - auc: 0.7678 - val_loss: 1.0596 - val_tp: 58.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 16.0000 - val_accuracy: 0.7374 - val_precision: 0.6517 - val_recall: 0.7838 - val_auc: 0.8567\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.0694 - tp: 182.0000 - fp: 96.0000 - tn: 348.0000 - fn: 86.0000 - accuracy: 0.7444 - precision: 0.6547 - recall: 0.6791 - auc: 0.7917 - val_loss: 0.9729 - val_tp: 61.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 13.0000 - val_accuracy: 0.7542 - val_precision: 0.6630 - val_recall: 0.8243 - val_auc: 0.8508\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.9830 - tp: 204.0000 - fp: 109.0000 - tn: 335.0000 - fn: 64.0000 - accuracy: 0.7570 - precision: 0.6518 - recall: 0.7612 - auc: 0.8048 - val_loss: 0.9014 - val_tp: 58.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 16.0000 - val_accuracy: 0.7542 - val_precision: 0.6744 - val_recall: 0.7838 - val_auc: 0.8626\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.8971 - tp: 189.0000 - fp: 72.0000 - tn: 372.0000 - fn: 79.0000 - accuracy: 0.7879 - precision: 0.7241 - recall: 0.7052 - auc: 0.8352 - val_loss: 0.8477 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8678\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.8688 - tp: 203.0000 - fp: 93.0000 - tn: 351.0000 - fn: 65.0000 - accuracy: 0.7781 - precision: 0.6858 - recall: 0.7575 - auc: 0.8158 - val_loss: 0.8053 - val_tp: 54.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 20.0000 - val_accuracy: 0.7765 - val_precision: 0.7297 - val_recall: 0.7297 - val_auc: 0.8720\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.8287 - tp: 195.0000 - fp: 73.0000 - tn: 371.0000 - fn: 73.0000 - accuracy: 0.7949 - precision: 0.7276 - recall: 0.7276 - auc: 0.8188 - val_loss: 0.7716 - val_tp: 62.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 12.0000 - val_accuracy: 0.7709 - val_precision: 0.6813 - val_recall: 0.8378 - val_auc: 0.8643\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7857 - tp: 199.0000 - fp: 90.0000 - tn: 354.0000 - fn: 69.0000 - accuracy: 0.7767 - precision: 0.6886 - recall: 0.7425 - auc: 0.8262 - val_loss: 0.7416 - val_tp: 54.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 20.0000 - val_accuracy: 0.7821 - val_precision: 0.7397 - val_recall: 0.7297 - val_auc: 0.8745\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7550 - tp: 201.0000 - fp: 87.0000 - tn: 357.0000 - fn: 67.0000 - accuracy: 0.7837 - precision: 0.6979 - recall: 0.7500 - auc: 0.8330 - val_loss: 0.7096 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8732\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7437 - tp: 198.0000 - fp: 84.0000 - tn: 360.0000 - fn: 70.0000 - accuracy: 0.7837 - precision: 0.7021 - recall: 0.7388 - auc: 0.8225 - val_loss: 0.6875 - val_tp: 56.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 18.0000 - val_accuracy: 0.7933 - val_precision: 0.7467 - val_recall: 0.7568 - val_auc: 0.8759\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7043 - tp: 208.0000 - fp: 82.0000 - tn: 362.0000 - fn: 60.0000 - accuracy: 0.8006 - precision: 0.7172 - recall: 0.7761 - auc: 0.8422 - val_loss: 0.6708 - val_tp: 56.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 18.0000 - val_accuracy: 0.7877 - val_precision: 0.7368 - val_recall: 0.7568 - val_auc: 0.8790\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6909 - tp: 203.0000 - fp: 78.0000 - tn: 366.0000 - fn: 65.0000 - accuracy: 0.7992 - precision: 0.7224 - recall: 0.7575 - auc: 0.8373 - val_loss: 0.6521 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8760\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.6814 - tp: 204.0000 - fp: 80.0000 - tn: 364.0000 - fn: 64.0000 - accuracy: 0.7978 - precision: 0.7183 - recall: 0.7612 - auc: 0.8337 - val_loss: 0.6382 - val_tp: 59.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 15.0000 - val_accuracy: 0.7765 - val_precision: 0.7024 - val_recall: 0.7973 - val_auc: 0.8754\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.6816 - tp: 208.0000 - fp: 90.0000 - tn: 354.0000 - fn: 60.0000 - accuracy: 0.7893 - precision: 0.6980 - recall: 0.7761 - auc: 0.8216 - val_loss: 0.6309 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8754\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.6630 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8317 - val_loss: 0.6169 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8827\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6501 - tp: 211.0000 - fp: 78.0000 - tn: 366.0000 - fn: 57.0000 - accuracy: 0.8104 - precision: 0.7301 - recall: 0.7873 - auc: 0.8345 - val_loss: 0.6132 - val_tp: 56.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 18.0000 - val_accuracy: 0.7933 - val_precision: 0.7467 - val_recall: 0.7568 - val_auc: 0.8814\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6360 - tp: 198.0000 - fp: 69.0000 - tn: 375.0000 - fn: 70.0000 - accuracy: 0.8048 - precision: 0.7416 - recall: 0.7388 - auc: 0.8378 - val_loss: 0.5992 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8825\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.6220 - tp: 209.0000 - fp: 71.0000 - tn: 373.0000 - fn: 59.0000 - accuracy: 0.8174 - precision: 0.7464 - recall: 0.7799 - auc: 0.8431 - val_loss: 0.5893 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8824\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.6234 - tp: 201.0000 - fp: 60.0000 - tn: 384.0000 - fn: 67.0000 - accuracy: 0.8216 - precision: 0.7701 - recall: 0.7500 - auc: 0.8353 - val_loss: 0.5883 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8778\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6107 - tp: 211.0000 - fp: 78.0000 - tn: 366.0000 - fn: 57.0000 - accuracy: 0.8104 - precision: 0.7301 - recall: 0.7873 - auc: 0.8407 - val_loss: 0.5839 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8825\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6250 - tp: 203.0000 - fp: 66.0000 - tn: 378.0000 - fn: 65.0000 - accuracy: 0.8160 - precision: 0.7546 - recall: 0.7575 - auc: 0.8277 - val_loss: 0.5822 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8808\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5875 - tp: 203.0000 - fp: 65.0000 - tn: 379.0000 - fn: 65.0000 - accuracy: 0.8174 - precision: 0.7575 - recall: 0.7575 - auc: 0.8546 - val_loss: 0.5686 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8829\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5946 - tp: 205.0000 - fp: 72.0000 - tn: 372.0000 - fn: 63.0000 - accuracy: 0.8104 - precision: 0.7401 - recall: 0.7649 - auc: 0.8465 - val_loss: 0.5626 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8822\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5931 - tp: 204.0000 - fp: 69.0000 - tn: 375.0000 - fn: 64.0000 - accuracy: 0.8132 - precision: 0.7473 - recall: 0.7612 - auc: 0.8434 - val_loss: 0.5601 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8831\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5661 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8581 - val_loss: 0.5534 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8838\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5690 - tp: 205.0000 - fp: 53.0000 - tn: 391.0000 - fn: 63.0000 - accuracy: 0.8371 - precision: 0.7946 - recall: 0.7649 - auc: 0.8580 - val_loss: 0.5532 - val_tp: 61.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 13.0000 - val_accuracy: 0.7821 - val_precision: 0.7011 - val_recall: 0.8243 - val_auc: 0.8804\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5544 - tp: 210.0000 - fp: 86.0000 - tn: 358.0000 - fn: 58.0000 - accuracy: 0.7978 - precision: 0.7095 - recall: 0.7836 - auc: 0.8647 - val_loss: 0.5485 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8867\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5907 - tp: 197.0000 - fp: 69.0000 - tn: 375.0000 - fn: 71.0000 - accuracy: 0.8034 - precision: 0.7406 - recall: 0.7351 - auc: 0.8373 - val_loss: 0.5524 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8794\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5856 - tp: 199.0000 - fp: 64.0000 - tn: 380.0000 - fn: 69.0000 - accuracy: 0.8132 - precision: 0.7567 - recall: 0.7425 - auc: 0.8425 - val_loss: 0.5481 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8832\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5606 - tp: 205.0000 - fp: 72.0000 - tn: 372.0000 - fn: 63.0000 - accuracy: 0.8104 - precision: 0.7401 - recall: 0.7649 - auc: 0.8519 - val_loss: 0.5417 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8862\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5444 - tp: 204.0000 - fp: 62.0000 - tn: 382.0000 - fn: 64.0000 - accuracy: 0.8230 - precision: 0.7669 - recall: 0.7612 - auc: 0.8681 - val_loss: 0.5395 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8849\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5622 - tp: 207.0000 - fp: 79.0000 - tn: 365.0000 - fn: 61.0000 - accuracy: 0.8034 - precision: 0.7238 - recall: 0.7724 - auc: 0.8517 - val_loss: 0.5361 - val_tp: 63.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 11.0000 - val_accuracy: 0.7821 - val_precision: 0.6923 - val_recall: 0.8514 - val_auc: 0.8793\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5425 - tp: 210.0000 - fp: 63.0000 - tn: 381.0000 - fn: 58.0000 - accuracy: 0.8301 - precision: 0.7692 - recall: 0.7836 - auc: 0.8607 - val_loss: 0.5332 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8874\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5557 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8558 - val_loss: 0.5374 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8869\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5590 - tp: 204.0000 - fp: 76.0000 - tn: 368.0000 - fn: 64.0000 - accuracy: 0.8034 - precision: 0.7286 - recall: 0.7612 - auc: 0.8545 - val_loss: 0.5308 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8846\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5696 - tp: 198.0000 - fp: 60.0000 - tn: 384.0000 - fn: 70.0000 - accuracy: 0.8174 - precision: 0.7674 - recall: 0.7388 - auc: 0.8390 - val_loss: 0.5448 - val_tp: 65.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 9.0000 - val_accuracy: 0.7709 - val_precision: 0.6701 - val_recall: 0.8784 - val_auc: 0.8773\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5557 - tp: 213.0000 - fp: 73.0000 - tn: 371.0000 - fn: 55.0000 - accuracy: 0.8202 - precision: 0.7448 - recall: 0.7948 - auc: 0.8475 - val_loss: 0.5328 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8833\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5417 - tp: 209.0000 - fp: 66.0000 - tn: 378.0000 - fn: 59.0000 - accuracy: 0.8244 - precision: 0.7600 - recall: 0.7799 - auc: 0.8601 - val_loss: 0.5293 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8851\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5456 - tp: 204.0000 - fp: 61.0000 - tn: 383.0000 - fn: 64.0000 - accuracy: 0.8244 - precision: 0.7698 - recall: 0.7612 - auc: 0.8575 - val_loss: 0.5263 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8855\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5572 - tp: 206.0000 - fp: 76.0000 - tn: 368.0000 - fn: 62.0000 - accuracy: 0.8062 - precision: 0.7305 - recall: 0.7687 - auc: 0.8456 - val_loss: 0.5268 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8864\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5261 - tp: 210.0000 - fp: 63.0000 - tn: 381.0000 - fn: 58.0000 - accuracy: 0.8301 - precision: 0.7692 - recall: 0.7836 - auc: 0.8696 - val_loss: 0.5201 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8894\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5500 - tp: 209.0000 - fp: 63.0000 - tn: 381.0000 - fn: 59.0000 - accuracy: 0.8287 - precision: 0.7684 - recall: 0.7799 - auc: 0.8559 - val_loss: 0.5188 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8874\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.5411 - tp: 200.0000 - fp: 67.0000 - tn: 377.0000 - fn: 68.0000 - accuracy: 0.8104 - precision: 0.7491 - recall: 0.7463 - auc: 0.8563 - val_loss: 0.5170 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8866\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 359us/sample - loss: 0.5476 - tp: 206.0000 - fp: 69.0000 - tn: 375.0000 - fn: 62.0000 - accuracy: 0.8160 - precision: 0.7491 - recall: 0.7687 - auc: 0.8513 - val_loss: 0.5217 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8869\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5481 - tp: 205.0000 - fp: 72.0000 - tn: 372.0000 - fn: 63.0000 - accuracy: 0.8104 - precision: 0.7401 - recall: 0.7649 - auc: 0.8503 - val_loss: 0.5157 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8902\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5268 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8653 - val_loss: 0.5138 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8884\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5586 - tp: 205.0000 - fp: 73.0000 - tn: 371.0000 - fn: 63.0000 - accuracy: 0.8090 - precision: 0.7374 - recall: 0.7649 - auc: 0.8391 - val_loss: 0.5175 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8869\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5389 - tp: 209.0000 - fp: 60.0000 - tn: 384.0000 - fn: 59.0000 - accuracy: 0.8329 - precision: 0.7770 - recall: 0.7799 - auc: 0.8522 - val_loss: 0.5172 - val_tp: 61.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 13.0000 - val_accuracy: 0.7765 - val_precision: 0.6932 - val_recall: 0.8243 - val_auc: 0.8851\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5479 - tp: 204.0000 - fp: 78.0000 - tn: 366.0000 - fn: 64.0000 - accuracy: 0.8006 - precision: 0.7234 - recall: 0.7612 - auc: 0.8492 - val_loss: 0.5138 - val_tp: 64.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 10.0000 - val_accuracy: 0.7877 - val_precision: 0.6957 - val_recall: 0.8649 - val_auc: 0.8887\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5316 - tp: 201.0000 - fp: 60.0000 - tn: 384.0000 - fn: 67.0000 - accuracy: 0.8216 - precision: 0.7701 - recall: 0.7500 - auc: 0.8599 - val_loss: 0.5159 - val_tp: 64.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 10.0000 - val_accuracy: 0.7709 - val_precision: 0.6737 - val_recall: 0.8649 - val_auc: 0.8871\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5391 - tp: 206.0000 - fp: 72.0000 - tn: 372.0000 - fn: 62.0000 - accuracy: 0.8118 - precision: 0.7410 - recall: 0.7687 - auc: 0.8513 - val_loss: 0.5145 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8860\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5465 - tp: 209.0000 - fp: 78.0000 - tn: 366.0000 - fn: 59.0000 - accuracy: 0.8076 - precision: 0.7282 - recall: 0.7799 - auc: 0.8487 - val_loss: 0.5131 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8919\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.5354 - tp: 204.0000 - fp: 71.0000 - tn: 373.0000 - fn: 64.0000 - accuracy: 0.8104 - precision: 0.7418 - recall: 0.7612 - auc: 0.8549 - val_loss: 0.5128 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8927\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5308 - tp: 203.0000 - fp: 57.0000 - tn: 387.0000 - fn: 65.0000 - accuracy: 0.8287 - precision: 0.7808 - recall: 0.7575 - auc: 0.8560 - val_loss: 0.5174 - val_tp: 64.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 10.0000 - val_accuracy: 0.7821 - val_precision: 0.6882 - val_recall: 0.8649 - val_auc: 0.8878\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5403 - tp: 207.0000 - fp: 83.0000 - tn: 361.0000 - fn: 61.0000 - accuracy: 0.7978 - precision: 0.7138 - recall: 0.7724 - auc: 0.8504 - val_loss: 0.5083 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8919\n",
      "Epoch 58/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5357 - tp: 205.0000 - fp: 74.0000 - tn: 370.0000 - fn: 63.0000 - accuracy: 0.8076 - precision: 0.7348 - recall: 0.7649 - auc: 0.8497 - val_loss: 0.5080 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8902\n",
      "Epoch 59/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5311 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8526 - val_loss: 0.5084 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8898\n",
      "Epoch 60/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.5429 - tp: 202.0000 - fp: 71.0000 - tn: 373.0000 - fn: 66.0000 - accuracy: 0.8076 - precision: 0.7399 - recall: 0.7537 - auc: 0.8458 - val_loss: 0.5040 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8912\n",
      "Epoch 61/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5214 - tp: 212.0000 - fp: 81.0000 - tn: 363.0000 - fn: 56.0000 - accuracy: 0.8076 - precision: 0.7235 - recall: 0.7910 - auc: 0.8669 - val_loss: 0.5067 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8921\n",
      "Epoch 62/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5371 - tp: 202.0000 - fp: 57.0000 - tn: 387.0000 - fn: 66.0000 - accuracy: 0.8272 - precision: 0.7799 - recall: 0.7537 - auc: 0.8493 - val_loss: 0.5149 - val_tp: 65.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 9.0000 - val_accuracy: 0.7821 - val_precision: 0.6842 - val_recall: 0.8784 - val_auc: 0.8859\n",
      "Epoch 63/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5305 - tp: 205.0000 - fp: 66.0000 - tn: 378.0000 - fn: 63.0000 - accuracy: 0.8188 - precision: 0.7565 - recall: 0.7649 - auc: 0.8569 - val_loss: 0.5024 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8902\n",
      "Epoch 64/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5211 - tp: 198.0000 - fp: 59.0000 - tn: 385.0000 - fn: 70.0000 - accuracy: 0.8188 - precision: 0.7704 - recall: 0.7388 - auc: 0.8637 - val_loss: 0.5022 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8912\n",
      "Epoch 65/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5483 - tp: 209.0000 - fp: 68.0000 - tn: 376.0000 - fn: 59.0000 - accuracy: 0.8216 - precision: 0.7545 - recall: 0.7799 - auc: 0.8403 - val_loss: 0.5010 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8937\n",
      "Epoch 66/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5161 - tp: 212.0000 - fp: 63.0000 - tn: 381.0000 - fn: 56.0000 - accuracy: 0.8329 - precision: 0.7709 - recall: 0.7910 - auc: 0.8672 - val_loss: 0.5014 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8909\n",
      "Epoch 67/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5182 - tp: 203.0000 - fp: 63.0000 - tn: 381.0000 - fn: 65.0000 - accuracy: 0.8202 - precision: 0.7632 - recall: 0.7575 - auc: 0.8626 - val_loss: 0.4937 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8931\n",
      "Epoch 68/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5279 - tp: 207.0000 - fp: 79.0000 - tn: 365.0000 - fn: 61.0000 - accuracy: 0.8034 - precision: 0.7238 - recall: 0.7724 - auc: 0.8559 - val_loss: 0.4981 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8943\n",
      "Epoch 69/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5297 - tp: 205.0000 - fp: 67.0000 - tn: 377.0000 - fn: 63.0000 - accuracy: 0.8174 - precision: 0.7537 - recall: 0.7649 - auc: 0.8530 - val_loss: 0.5027 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8910\n",
      "Epoch 70/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5209 - tp: 208.0000 - fp: 64.0000 - tn: 380.0000 - fn: 60.0000 - accuracy: 0.8258 - precision: 0.7647 - recall: 0.7761 - auc: 0.8540 - val_loss: 0.5020 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8925\n",
      "Epoch 71/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.5138 - tp: 208.0000 - fp: 70.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.8174 - precision: 0.7482 - recall: 0.7761 - auc: 0.8655 - val_loss: 0.4962 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8921\n",
      "Epoch 72/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5260 - tp: 208.0000 - fp: 67.0000 - tn: 377.0000 - fn: 60.0000 - accuracy: 0.8216 - precision: 0.7564 - recall: 0.7761 - auc: 0.8555 - val_loss: 0.4993 - val_tp: 61.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 13.0000 - val_accuracy: 0.8156 - val_precision: 0.7531 - val_recall: 0.8243 - val_auc: 0.8916\n",
      "Epoch 73/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5123 - tp: 204.0000 - fp: 63.0000 - tn: 381.0000 - fn: 64.0000 - accuracy: 0.8216 - precision: 0.7640 - recall: 0.7612 - auc: 0.8620 - val_loss: 0.4982 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8949\n",
      "Epoch 74/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5219 - tp: 207.0000 - fp: 76.0000 - tn: 368.0000 - fn: 61.0000 - accuracy: 0.8076 - precision: 0.7314 - recall: 0.7724 - auc: 0.8571 - val_loss: 0.5042 - val_tp: 54.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 20.0000 - val_accuracy: 0.8156 - val_precision: 0.8060 - val_recall: 0.7297 - val_auc: 0.8922\n",
      "Epoch 75/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5363 - tp: 199.0000 - fp: 58.0000 - tn: 386.0000 - fn: 69.0000 - accuracy: 0.8216 - precision: 0.7743 - recall: 0.7425 - auc: 0.8488 - val_loss: 0.4959 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8903\n",
      "Epoch 76/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.5157 - tp: 203.0000 - fp: 65.0000 - tn: 379.0000 - fn: 65.0000 - accuracy: 0.8174 - precision: 0.7575 - recall: 0.7575 - auc: 0.8610 - val_loss: 0.4976 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8917\n",
      "Epoch 77/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5157 - tp: 203.0000 - fp: 61.0000 - tn: 383.0000 - fn: 65.0000 - accuracy: 0.8230 - precision: 0.7689 - recall: 0.7575 - auc: 0.8564 - val_loss: 0.4950 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8918\n",
      "Epoch 78/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.5194 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8585 - val_loss: 0.4945 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8921\n",
      "Epoch 79/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5202 - tp: 212.0000 - fp: 78.0000 - tn: 366.0000 - fn: 56.0000 - accuracy: 0.8118 - precision: 0.7310 - recall: 0.7910 - auc: 0.8606 - val_loss: 0.5057 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8910\n",
      "Epoch 80/500\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.5308 - tp: 199.0000 - fp: 54.0000 - tn: 390.0000 - fn: 69.0000 - accuracy: 0.8272 - precision: 0.7866 - recall: 0.7425 - auc: 0.8484 - val_loss: 0.4968 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8905\n",
      "Epoch 81/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5130 - tp: 209.0000 - fp: 69.0000 - tn: 375.0000 - fn: 59.0000 - accuracy: 0.8202 - precision: 0.7518 - recall: 0.7799 - auc: 0.8631 - val_loss: 0.4920 - val_tp: 62.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 12.0000 - val_accuracy: 0.8268 - val_precision: 0.7654 - val_recall: 0.8378 - val_auc: 0.8921\n",
      "Epoch 82/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5291 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8500 - val_loss: 0.4996 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8936\n",
      "Epoch 83/500\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.5018 - tp: 209.0000 - fp: 71.0000 - tn: 373.0000 - fn: 59.0000 - accuracy: 0.8174 - precision: 0.7464 - recall: 0.7799 - auc: 0.8747 - val_loss: 0.4893 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8933\n",
      "Epoch 84/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.5126 - tp: 210.0000 - fp: 68.0000 - tn: 376.0000 - fn: 58.0000 - accuracy: 0.8230 - precision: 0.7554 - recall: 0.7836 - auc: 0.8647 - val_loss: 0.4930 - val_tp: 62.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 12.0000 - val_accuracy: 0.8436 - val_precision: 0.7949 - val_recall: 0.8378 - val_auc: 0.8914\n",
      "Epoch 85/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4953 - tp: 208.0000 - fp: 63.0000 - tn: 381.0000 - fn: 60.0000 - accuracy: 0.8272 - precision: 0.7675 - recall: 0.7761 - auc: 0.8766 - val_loss: 0.4907 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8939\n",
      "Epoch 86/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.5198 - tp: 199.0000 - fp: 61.0000 - tn: 383.0000 - fn: 69.0000 - accuracy: 0.8174 - precision: 0.7654 - recall: 0.7425 - auc: 0.8637 - val_loss: 0.4921 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8937\n",
      "Epoch 87/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5213 - tp: 208.0000 - fp: 76.0000 - tn: 368.0000 - fn: 60.0000 - accuracy: 0.8090 - precision: 0.7324 - recall: 0.7761 - auc: 0.8567 - val_loss: 0.4936 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8943\n",
      "Epoch 88/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5130 - tp: 206.0000 - fp: 66.0000 - tn: 378.0000 - fn: 62.0000 - accuracy: 0.8202 - precision: 0.7574 - recall: 0.7687 - auc: 0.8623 - val_loss: 0.4943 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8940\n",
      "Epoch 89/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5135 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8616 - val_loss: 0.4913 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8930\n",
      "Epoch 90/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5076 - tp: 204.0000 - fp: 52.0000 - tn: 392.0000 - fn: 64.0000 - accuracy: 0.8371 - precision: 0.7969 - recall: 0.7612 - auc: 0.8675 - val_loss: 0.4981 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8939\n",
      "Epoch 91/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5078 - tp: 206.0000 - fp: 70.0000 - tn: 374.0000 - fn: 62.0000 - accuracy: 0.8146 - precision: 0.7464 - recall: 0.7687 - auc: 0.8623 - val_loss: 0.4915 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8950\n",
      "Epoch 92/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5189 - tp: 201.0000 - fp: 57.0000 - tn: 387.0000 - fn: 67.0000 - accuracy: 0.8258 - precision: 0.7791 - recall: 0.7500 - auc: 0.8574 - val_loss: 0.4970 - val_tp: 62.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 12.0000 - val_accuracy: 0.7877 - val_precision: 0.7045 - val_recall: 0.8378 - val_auc: 0.8941\n",
      "Epoch 93/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5124 - tp: 209.0000 - fp: 61.0000 - tn: 383.0000 - fn: 59.0000 - accuracy: 0.8315 - precision: 0.7741 - recall: 0.7799 - auc: 0.8618 - val_loss: 0.4944 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8921\n",
      "Epoch 94/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5138 - tp: 207.0000 - fp: 67.0000 - tn: 377.0000 - fn: 61.0000 - accuracy: 0.8202 - precision: 0.7555 - recall: 0.7724 - auc: 0.8621 - val_loss: 0.5044 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8940\n",
      "Epoch 95/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5227 - tp: 206.0000 - fp: 71.0000 - tn: 373.0000 - fn: 62.0000 - accuracy: 0.8132 - precision: 0.7437 - recall: 0.7687 - auc: 0.8588 - val_loss: 0.4967 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8941\n",
      "Epoch 96/500\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.5131 - tp: 201.0000 - fp: 51.0000 - tn: 393.0000 - fn: 67.0000 - accuracy: 0.8343 - precision: 0.7976 - recall: 0.7500 - auc: 0.8591 - val_loss: 0.4969 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8922\n",
      "Epoch 97/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5090 - tp: 205.0000 - fp: 58.0000 - tn: 386.0000 - fn: 63.0000 - accuracy: 0.8301 - precision: 0.7795 - recall: 0.7649 - auc: 0.8572 - val_loss: 0.4917 - val_tp: 62.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 12.0000 - val_accuracy: 0.8212 - val_precision: 0.7561 - val_recall: 0.8378 - val_auc: 0.8940\n",
      "Epoch 98/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5028 - tp: 215.0000 - fp: 68.0000 - tn: 376.0000 - fn: 53.0000 - accuracy: 0.8301 - precision: 0.7597 - recall: 0.8022 - auc: 0.8708 - val_loss: 0.4993 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8945\n",
      "Epoch 99/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5146 - tp: 198.0000 - fp: 51.0000 - tn: 393.0000 - fn: 70.0000 - accuracy: 0.8301 - precision: 0.7952 - recall: 0.7388 - auc: 0.8581 - val_loss: 0.4938 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8933\n",
      "Epoch 100/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5164 - tp: 206.0000 - fp: 70.0000 - tn: 374.0000 - fn: 62.0000 - accuracy: 0.8146 - precision: 0.7464 - recall: 0.7687 - auc: 0.8548 - val_loss: 0.4899 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8941\n",
      "Epoch 101/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.5006 - tp: 200.0000 - fp: 44.0000 - tn: 400.0000 - fn: 68.0000 - accuracy: 0.8427 - precision: 0.8197 - recall: 0.7463 - auc: 0.8704 - val_loss: 0.4920 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8921\n",
      "Epoch 102/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.5120 - tp: 199.0000 - fp: 51.0000 - tn: 393.0000 - fn: 69.0000 - accuracy: 0.8315 - precision: 0.7960 - recall: 0.7425 - auc: 0.8583 - val_loss: 0.4931 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8934\n",
      "Epoch 103/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.4983 - tp: 205.0000 - fp: 62.0000 - tn: 382.0000 - fn: 63.0000 - accuracy: 0.8244 - precision: 0.7678 - recall: 0.7649 - auc: 0.8708 - val_loss: 0.4896 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8938\n",
      "Epoch 104/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5190 - tp: 206.0000 - fp: 66.0000 - tn: 378.0000 - fn: 62.0000 - accuracy: 0.8202 - precision: 0.7574 - recall: 0.7687 - auc: 0.8530 - val_loss: 0.4878 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8951\n",
      "Epoch 105/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5108 - tp: 206.0000 - fp: 60.0000 - tn: 384.0000 - fn: 62.0000 - accuracy: 0.8287 - precision: 0.7744 - recall: 0.7687 - auc: 0.8625 - val_loss: 0.4922 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8937\n",
      "Epoch 106/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5123 - tp: 209.0000 - fp: 65.0000 - tn: 379.0000 - fn: 59.0000 - accuracy: 0.8258 - precision: 0.7628 - recall: 0.7799 - auc: 0.8619 - val_loss: 0.4962 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8925\n",
      "Epoch 107/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4985 - tp: 200.0000 - fp: 59.0000 - tn: 385.0000 - fn: 68.0000 - accuracy: 0.8216 - precision: 0.7722 - recall: 0.7463 - auc: 0.8690 - val_loss: 0.4919 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8915\n",
      "Epoch 108/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5025 - tp: 204.0000 - fp: 63.0000 - tn: 381.0000 - fn: 64.0000 - accuracy: 0.8216 - precision: 0.7640 - recall: 0.7612 - auc: 0.8674 - val_loss: 0.4887 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8916\n",
      "Epoch 109/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5055 - tp: 208.0000 - fp: 67.0000 - tn: 377.0000 - fn: 60.0000 - accuracy: 0.8216 - precision: 0.7564 - recall: 0.7761 - auc: 0.8633 - val_loss: 0.4967 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8947\n",
      "Epoch 110/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5148 - tp: 202.0000 - fp: 59.0000 - tn: 385.0000 - fn: 66.0000 - accuracy: 0.8244 - precision: 0.7739 - recall: 0.7537 - auc: 0.8506 - val_loss: 0.4928 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8950\n",
      "Epoch 111/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.5160 - tp: 206.0000 - fp: 71.0000 - tn: 373.0000 - fn: 62.0000 - accuracy: 0.8132 - precision: 0.7437 - recall: 0.7687 - auc: 0.8608 - val_loss: 0.4872 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8945\n",
      "Epoch 112/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4917 - tp: 198.0000 - fp: 50.0000 - tn: 394.0000 - fn: 70.0000 - accuracy: 0.8315 - precision: 0.7984 - recall: 0.7388 - auc: 0.8717 - val_loss: 0.4915 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8940\n",
      "Epoch 113/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5130 - tp: 199.0000 - fp: 49.0000 - tn: 395.0000 - fn: 69.0000 - accuracy: 0.8343 - precision: 0.8024 - recall: 0.7425 - auc: 0.8557 - val_loss: 0.4956 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8905\n",
      "Epoch 114/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5123 - tp: 199.0000 - fp: 58.0000 - tn: 386.0000 - fn: 69.0000 - accuracy: 0.8216 - precision: 0.7743 - recall: 0.7425 - auc: 0.8665 - val_loss: 0.4852 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8944\n",
      "Epoch 115/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5130 - tp: 207.0000 - fp: 72.0000 - tn: 372.0000 - fn: 61.0000 - accuracy: 0.8132 - precision: 0.7419 - recall: 0.7724 - auc: 0.8612 - val_loss: 0.4923 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8957\n",
      "Epoch 116/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5155 - tp: 202.0000 - fp: 62.0000 - tn: 382.0000 - fn: 66.0000 - accuracy: 0.8202 - precision: 0.7652 - recall: 0.7537 - auc: 0.8574 - val_loss: 0.4851 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8956\n",
      "Epoch 117/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5085 - tp: 203.0000 - fp: 59.0000 - tn: 385.0000 - fn: 65.0000 - accuracy: 0.8258 - precision: 0.7748 - recall: 0.7575 - auc: 0.8619 - val_loss: 0.4891 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8940\n",
      "Epoch 118/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4953 - tp: 202.0000 - fp: 40.0000 - tn: 404.0000 - fn: 66.0000 - accuracy: 0.8511 - precision: 0.8347 - recall: 0.7537 - auc: 0.8690 - val_loss: 0.4988 - val_tp: 62.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 12.0000 - val_accuracy: 0.7877 - val_precision: 0.7045 - val_recall: 0.8378 - val_auc: 0.8887\n",
      "Epoch 119/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5015 - tp: 211.0000 - fp: 77.0000 - tn: 367.0000 - fn: 57.0000 - accuracy: 0.8118 - precision: 0.7326 - recall: 0.7873 - auc: 0.8668 - val_loss: 0.4949 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8937\n",
      "Epoch 120/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5076 - tp: 201.0000 - fp: 60.0000 - tn: 384.0000 - fn: 67.0000 - accuracy: 0.8216 - precision: 0.7701 - recall: 0.7500 - auc: 0.8631 - val_loss: 0.4885 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8945\n",
      "Epoch 121/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5205 - tp: 206.0000 - fp: 66.0000 - tn: 378.0000 - fn: 62.0000 - accuracy: 0.8202 - precision: 0.7574 - recall: 0.7687 - auc: 0.8514 - val_loss: 0.4882 - val_tp: 61.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 13.0000 - val_accuracy: 0.8380 - val_precision: 0.7922 - val_recall: 0.8243 - val_auc: 0.8934\n",
      "Epoch 122/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5070 - tp: 194.0000 - fp: 53.0000 - tn: 391.0000 - fn: 74.0000 - accuracy: 0.8216 - precision: 0.7854 - recall: 0.7239 - auc: 0.8582 - val_loss: 0.4918 - val_tp: 64.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 10.0000 - val_accuracy: 0.7877 - val_precision: 0.6957 - val_recall: 0.8649 - val_auc: 0.8916\n",
      "Epoch 123/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5140 - tp: 213.0000 - fp: 75.0000 - tn: 369.0000 - fn: 55.0000 - accuracy: 0.8174 - precision: 0.7396 - recall: 0.7948 - auc: 0.8586 - val_loss: 0.4879 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8945\n",
      "Epoch 124/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5039 - tp: 202.0000 - fp: 61.0000 - tn: 383.0000 - fn: 66.0000 - accuracy: 0.8216 - precision: 0.7681 - recall: 0.7537 - auc: 0.8643 - val_loss: 0.4915 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8951\n",
      "Epoch 125/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5126 - tp: 204.0000 - fp: 67.0000 - tn: 377.0000 - fn: 64.0000 - accuracy: 0.8160 - precision: 0.7528 - recall: 0.7612 - auc: 0.8613 - val_loss: 0.4833 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8954\n",
      "Epoch 126/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5187 - tp: 191.0000 - fp: 43.0000 - tn: 401.0000 - fn: 77.0000 - accuracy: 0.8315 - precision: 0.8162 - recall: 0.7127 - auc: 0.8560 - val_loss: 0.4903 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8908\n",
      "Epoch 127/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5051 - tp: 201.0000 - fp: 52.0000 - tn: 392.0000 - fn: 67.0000 - accuracy: 0.8329 - precision: 0.7945 - recall: 0.7500 - auc: 0.8596 - val_loss: 0.4863 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8936\n",
      "Epoch 128/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4935 - tp: 208.0000 - fp: 67.0000 - tn: 377.0000 - fn: 60.0000 - accuracy: 0.8216 - precision: 0.7564 - recall: 0.7761 - auc: 0.8717 - val_loss: 0.4854 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8934\n",
      "Epoch 129/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4989 - tp: 205.0000 - fp: 71.0000 - tn: 373.0000 - fn: 63.0000 - accuracy: 0.8118 - precision: 0.7428 - recall: 0.7649 - auc: 0.8688 - val_loss: 0.4920 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8936\n",
      "Epoch 130/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5005 - tp: 204.0000 - fp: 65.0000 - tn: 379.0000 - fn: 64.0000 - accuracy: 0.8188 - precision: 0.7584 - recall: 0.7612 - auc: 0.8669 - val_loss: 0.4843 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8946\n",
      "Epoch 131/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4958 - tp: 199.0000 - fp: 49.0000 - tn: 395.0000 - fn: 69.0000 - accuracy: 0.8343 - precision: 0.8024 - recall: 0.7425 - auc: 0.8700 - val_loss: 0.4869 - val_tp: 62.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 12.0000 - val_accuracy: 0.8324 - val_precision: 0.7750 - val_recall: 0.8378 - val_auc: 0.8949\n",
      "Epoch 132/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.4980 - tp: 204.0000 - fp: 64.0000 - tn: 380.0000 - fn: 64.0000 - accuracy: 0.8202 - precision: 0.7612 - recall: 0.7612 - auc: 0.8722 - val_loss: 0.4862 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8956\n",
      "Epoch 133/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4930 - tp: 210.0000 - fp: 59.0000 - tn: 385.0000 - fn: 58.0000 - accuracy: 0.8357 - precision: 0.7807 - recall: 0.7836 - auc: 0.8758 - val_loss: 0.4837 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8955\n",
      "Epoch 134/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5015 - tp: 202.0000 - fp: 53.0000 - tn: 391.0000 - fn: 66.0000 - accuracy: 0.8329 - precision: 0.7922 - recall: 0.7537 - auc: 0.8693 - val_loss: 0.4876 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8942\n",
      "Epoch 135/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5022 - tp: 201.0000 - fp: 52.0000 - tn: 392.0000 - fn: 67.0000 - accuracy: 0.8329 - precision: 0.7945 - recall: 0.7500 - auc: 0.8657 - val_loss: 0.4792 - val_tp: 61.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 13.0000 - val_accuracy: 0.8380 - val_precision: 0.7922 - val_recall: 0.8243 - val_auc: 0.8969\n",
      "Epoch 136/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5093 - tp: 206.0000 - fp: 62.0000 - tn: 382.0000 - fn: 62.0000 - accuracy: 0.8258 - precision: 0.7687 - recall: 0.7687 - auc: 0.8607 - val_loss: 0.4884 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8939\n",
      "Epoch 137/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4824 - tp: 212.0000 - fp: 65.0000 - tn: 379.0000 - fn: 56.0000 - accuracy: 0.8301 - precision: 0.7653 - recall: 0.7910 - auc: 0.8771 - val_loss: 0.4871 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8970\n",
      "Epoch 138/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4984 - tp: 202.0000 - fp: 47.0000 - tn: 397.0000 - fn: 66.0000 - accuracy: 0.8413 - precision: 0.8112 - recall: 0.7537 - auc: 0.8674 - val_loss: 0.4870 - val_tp: 61.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 13.0000 - val_accuracy: 0.8380 - val_precision: 0.7922 - val_recall: 0.8243 - val_auc: 0.8939\n",
      "Epoch 139/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4952 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8718 - val_loss: 0.4853 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8956\n",
      "Epoch 140/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5146 - tp: 196.0000 - fp: 54.0000 - tn: 390.0000 - fn: 72.0000 - accuracy: 0.8230 - precision: 0.7840 - recall: 0.7313 - auc: 0.8546 - val_loss: 0.4827 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8984\n",
      "Epoch 141/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5004 - tp: 199.0000 - fp: 55.0000 - tn: 389.0000 - fn: 69.0000 - accuracy: 0.8258 - precision: 0.7835 - recall: 0.7425 - auc: 0.8652 - val_loss: 0.4793 - val_tp: 61.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 13.0000 - val_accuracy: 0.8380 - val_precision: 0.7922 - val_recall: 0.8243 - val_auc: 0.8964\n",
      "Epoch 142/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5159 - tp: 204.0000 - fp: 63.0000 - tn: 381.0000 - fn: 64.0000 - accuracy: 0.8216 - precision: 0.7640 - recall: 0.7612 - auc: 0.8596 - val_loss: 0.4815 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8950\n",
      "Epoch 143/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5012 - tp: 191.0000 - fp: 47.0000 - tn: 397.0000 - fn: 77.0000 - accuracy: 0.8258 - precision: 0.8025 - recall: 0.7127 - auc: 0.8661 - val_loss: 0.4847 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8947\n",
      "Epoch 144/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5050 - tp: 204.0000 - fp: 62.0000 - tn: 382.0000 - fn: 64.0000 - accuracy: 0.8230 - precision: 0.7669 - recall: 0.7612 - auc: 0.8657 - val_loss: 0.5107 - val_tp: 69.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 5.0000 - val_accuracy: 0.7989 - val_precision: 0.6900 - val_recall: 0.9324 - val_auc: 0.8894\n",
      "Epoch 145/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5001 - tp: 210.0000 - fp: 71.0000 - tn: 373.0000 - fn: 58.0000 - accuracy: 0.8188 - precision: 0.7473 - recall: 0.7836 - auc: 0.8704 - val_loss: 0.4842 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8952\n",
      "Epoch 146/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5062 - tp: 203.0000 - fp: 62.0000 - tn: 382.0000 - fn: 65.0000 - accuracy: 0.8216 - precision: 0.7660 - recall: 0.7575 - auc: 0.8638 - val_loss: 0.4811 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8936\n",
      "Epoch 147/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5078 - tp: 195.0000 - fp: 46.0000 - tn: 398.0000 - fn: 73.0000 - accuracy: 0.8329 - precision: 0.8091 - recall: 0.7276 - auc: 0.8575 - val_loss: 0.4851 - val_tp: 61.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 13.0000 - val_accuracy: 0.8156 - val_precision: 0.7531 - val_recall: 0.8243 - val_auc: 0.8916\n",
      "Epoch 148/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4924 - tp: 208.0000 - fp: 68.0000 - tn: 376.0000 - fn: 60.0000 - accuracy: 0.8202 - precision: 0.7536 - recall: 0.7761 - auc: 0.8711 - val_loss: 0.4821 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8943\n",
      "Epoch 149/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4997 - tp: 203.0000 - fp: 58.0000 - tn: 386.0000 - fn: 65.0000 - accuracy: 0.8272 - precision: 0.7778 - recall: 0.7575 - auc: 0.8686 - val_loss: 0.5009 - val_tp: 64.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 10.0000 - val_accuracy: 0.7821 - val_precision: 0.6882 - val_recall: 0.8649 - val_auc: 0.8893\n",
      "Epoch 150/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5152 - tp: 201.0000 - fp: 73.0000 - tn: 371.0000 - fn: 67.0000 - accuracy: 0.8034 - precision: 0.7336 - recall: 0.7500 - auc: 0.8546 - val_loss: 0.4902 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8940\n",
      "Epoch 151/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5015 - tp: 205.0000 - fp: 56.0000 - tn: 388.0000 - fn: 63.0000 - accuracy: 0.8329 - precision: 0.7854 - recall: 0.7649 - auc: 0.8669 - val_loss: 0.4868 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8923\n",
      "Epoch 152/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4903 - tp: 203.0000 - fp: 59.0000 - tn: 385.0000 - fn: 65.0000 - accuracy: 0.8258 - precision: 0.7748 - recall: 0.7575 - auc: 0.8775 - val_loss: 0.4836 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8929\n",
      "Epoch 153/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4941 - tp: 201.0000 - fp: 61.0000 - tn: 383.0000 - fn: 67.0000 - accuracy: 0.8202 - precision: 0.7672 - recall: 0.7500 - auc: 0.8697 - val_loss: 0.4857 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8939\n",
      "Epoch 154/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4862 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8747 - val_loss: 0.4896 - val_tp: 62.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 12.0000 - val_accuracy: 0.8156 - val_precision: 0.7470 - val_recall: 0.8378 - val_auc: 0.8897\n",
      "Epoch 155/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4989 - tp: 201.0000 - fp: 55.0000 - tn: 389.0000 - fn: 67.0000 - accuracy: 0.8287 - precision: 0.7852 - recall: 0.7500 - auc: 0.8646 - val_loss: 0.4949 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8952\n",
      "Epoch 156/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4861 - tp: 198.0000 - fp: 38.0000 - tn: 406.0000 - fn: 70.0000 - accuracy: 0.8483 - precision: 0.8390 - recall: 0.7388 - auc: 0.8741 - val_loss: 0.4889 - val_tp: 62.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 12.0000 - val_accuracy: 0.8045 - val_precision: 0.7294 - val_recall: 0.8378 - val_auc: 0.8925\n",
      "Epoch 157/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5024 - tp: 203.0000 - fp: 62.0000 - tn: 382.0000 - fn: 65.0000 - accuracy: 0.8216 - precision: 0.7660 - recall: 0.7575 - auc: 0.8657 - val_loss: 0.4874 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8936\n",
      "Epoch 158/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5034 - tp: 200.0000 - fp: 58.0000 - tn: 386.0000 - fn: 68.0000 - accuracy: 0.8230 - precision: 0.7752 - recall: 0.7463 - auc: 0.8606 - val_loss: 0.4792 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8947\n",
      "Epoch 159/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5146 - tp: 202.0000 - fp: 73.0000 - tn: 371.0000 - fn: 66.0000 - accuracy: 0.8048 - precision: 0.7345 - recall: 0.7537 - auc: 0.8556 - val_loss: 0.4815 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8928\n",
      "Epoch 160/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4901 - tp: 204.0000 - fp: 66.0000 - tn: 378.0000 - fn: 64.0000 - accuracy: 0.8174 - precision: 0.7556 - recall: 0.7612 - auc: 0.8721 - val_loss: 0.4827 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8970\n",
      "Epoch 161/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4944 - tp: 203.0000 - fp: 60.0000 - tn: 384.0000 - fn: 65.0000 - accuracy: 0.8244 - precision: 0.7719 - recall: 0.7575 - auc: 0.8627 - val_loss: 0.4772 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8941\n",
      "Epoch 162/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4993 - tp: 199.0000 - fp: 57.0000 - tn: 387.0000 - fn: 69.0000 - accuracy: 0.8230 - precision: 0.7773 - recall: 0.7425 - auc: 0.8666 - val_loss: 0.4798 - val_tp: 62.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 12.0000 - val_accuracy: 0.7933 - val_precision: 0.7126 - val_recall: 0.8378 - val_auc: 0.8954\n",
      "Epoch 163/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4970 - tp: 200.0000 - fp: 61.0000 - tn: 383.0000 - fn: 68.0000 - accuracy: 0.8188 - precision: 0.7663 - recall: 0.7463 - auc: 0.8644 - val_loss: 0.4780 - val_tp: 60.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 14.0000 - val_accuracy: 0.8380 - val_precision: 0.8000 - val_recall: 0.8108 - val_auc: 0.8932\n",
      "Epoch 164/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5023 - tp: 206.0000 - fp: 73.0000 - tn: 371.0000 - fn: 62.0000 - accuracy: 0.8104 - precision: 0.7384 - recall: 0.7687 - auc: 0.8626 - val_loss: 0.4813 - val_tp: 60.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 14.0000 - val_accuracy: 0.8380 - val_precision: 0.8000 - val_recall: 0.8108 - val_auc: 0.8948\n",
      "Epoch 165/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4890 - tp: 205.0000 - fp: 60.0000 - tn: 384.0000 - fn: 63.0000 - accuracy: 0.8272 - precision: 0.7736 - recall: 0.7649 - auc: 0.8730 - val_loss: 0.4839 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8949\n",
      "Epoch 166/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5005 - tp: 203.0000 - fp: 52.0000 - tn: 392.0000 - fn: 65.0000 - accuracy: 0.8357 - precision: 0.7961 - recall: 0.7575 - auc: 0.8672 - val_loss: 0.4843 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8938\n",
      "Epoch 167/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.4845 - tp: 206.0000 - fp: 63.0000 - tn: 381.0000 - fn: 62.0000 - accuracy: 0.8244 - precision: 0.7658 - recall: 0.7687 - auc: 0.8749 - val_loss: 0.4855 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8943\n",
      "Epoch 168/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5060 - tp: 201.0000 - fp: 59.0000 - tn: 385.0000 - fn: 67.0000 - accuracy: 0.8230 - precision: 0.7731 - recall: 0.7500 - auc: 0.8561 - val_loss: 0.4761 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8983\n",
      "Epoch 169/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5037 - tp: 202.0000 - fp: 66.0000 - tn: 378.0000 - fn: 66.0000 - accuracy: 0.8146 - precision: 0.7537 - recall: 0.7537 - auc: 0.8646 - val_loss: 0.4845 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8969\n",
      "Epoch 170/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4922 - tp: 194.0000 - fp: 53.0000 - tn: 391.0000 - fn: 74.0000 - accuracy: 0.8216 - precision: 0.7854 - recall: 0.7239 - auc: 0.8717 - val_loss: 0.4826 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8924\n",
      "Epoch 171/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4864 - tp: 199.0000 - fp: 53.0000 - tn: 391.0000 - fn: 69.0000 - accuracy: 0.8287 - precision: 0.7897 - recall: 0.7425 - auc: 0.8729 - val_loss: 0.4855 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8955\n",
      "Epoch 172/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4827 - tp: 205.0000 - fp: 55.0000 - tn: 389.0000 - fn: 63.0000 - accuracy: 0.8343 - precision: 0.7885 - recall: 0.7649 - auc: 0.8787 - val_loss: 0.4806 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8940\n",
      "Epoch 173/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5052 - tp: 203.0000 - fp: 62.0000 - tn: 382.0000 - fn: 65.0000 - accuracy: 0.8216 - precision: 0.7660 - recall: 0.7575 - auc: 0.8639 - val_loss: 0.4766 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8963\n",
      "Epoch 174/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5048 - tp: 211.0000 - fp: 66.0000 - tn: 378.0000 - fn: 57.0000 - accuracy: 0.8272 - precision: 0.7617 - recall: 0.7873 - auc: 0.8655 - val_loss: 0.4794 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8972\n",
      "Epoch 175/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4983 - tp: 197.0000 - fp: 47.0000 - tn: 397.0000 - fn: 71.0000 - accuracy: 0.8343 - precision: 0.8074 - recall: 0.7351 - auc: 0.8688 - val_loss: 0.4819 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8940\n",
      "Epoch 176/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4953 - tp: 205.0000 - fp: 58.0000 - tn: 386.0000 - fn: 63.0000 - accuracy: 0.8301 - precision: 0.7795 - recall: 0.7649 - auc: 0.8663 - val_loss: 0.4797 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8921\n",
      "Epoch 177/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4954 - tp: 207.0000 - fp: 55.0000 - tn: 389.0000 - fn: 61.0000 - accuracy: 0.8371 - precision: 0.7901 - recall: 0.7724 - auc: 0.8688 - val_loss: 0.4758 - val_tp: 61.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 13.0000 - val_accuracy: 0.8380 - val_precision: 0.7922 - val_recall: 0.8243 - val_auc: 0.8955\n",
      "Epoch 178/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5008 - tp: 196.0000 - fp: 58.0000 - tn: 386.0000 - fn: 72.0000 - accuracy: 0.8174 - precision: 0.7717 - recall: 0.7313 - auc: 0.8577 - val_loss: 0.4805 - val_tp: 64.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 10.0000 - val_accuracy: 0.7989 - val_precision: 0.7111 - val_recall: 0.8649 - val_auc: 0.8950\n",
      "Epoch 179/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5020 - tp: 198.0000 - fp: 56.0000 - tn: 388.0000 - fn: 70.0000 - accuracy: 0.8230 - precision: 0.7795 - recall: 0.7388 - auc: 0.8626 - val_loss: 0.4812 - val_tp: 62.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 12.0000 - val_accuracy: 0.8268 - val_precision: 0.7654 - val_recall: 0.8378 - val_auc: 0.8939\n",
      "Epoch 180/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5117 - tp: 205.0000 - fp: 76.0000 - tn: 368.0000 - fn: 63.0000 - accuracy: 0.8048 - precision: 0.7295 - recall: 0.7649 - auc: 0.8534 - val_loss: 0.4772 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8949\n",
      "Epoch 181/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5044 - tp: 205.0000 - fp: 65.0000 - tn: 379.0000 - fn: 63.0000 - accuracy: 0.8202 - precision: 0.7593 - recall: 0.7649 - auc: 0.8607 - val_loss: 0.4773 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8967\n",
      "Epoch 182/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4866 - tp: 209.0000 - fp: 64.0000 - tn: 380.0000 - fn: 59.0000 - accuracy: 0.8272 - precision: 0.7656 - recall: 0.7799 - auc: 0.8733 - val_loss: 0.4783 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8949\n",
      "Epoch 183/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4959 - tp: 199.0000 - fp: 48.0000 - tn: 396.0000 - fn: 69.0000 - accuracy: 0.8357 - precision: 0.8057 - recall: 0.7425 - auc: 0.8648 - val_loss: 0.4792 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8948\n",
      "Epoch 184/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4922 - tp: 205.0000 - fp: 55.0000 - tn: 389.0000 - fn: 63.0000 - accuracy: 0.8343 - precision: 0.7885 - recall: 0.7649 - auc: 0.8685 - val_loss: 0.4734 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8964\n",
      "Epoch 185/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4907 - tp: 207.0000 - fp: 59.0000 - tn: 385.0000 - fn: 61.0000 - accuracy: 0.8315 - precision: 0.7782 - recall: 0.7724 - auc: 0.8692 - val_loss: 0.4771 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8943\n",
      "Epoch 186/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4872 - tp: 198.0000 - fp: 54.0000 - tn: 390.0000 - fn: 70.0000 - accuracy: 0.8258 - precision: 0.7857 - recall: 0.7388 - auc: 0.8735 - val_loss: 0.4767 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8959\n",
      "Epoch 187/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4870 - tp: 207.0000 - fp: 60.0000 - tn: 384.0000 - fn: 61.0000 - accuracy: 0.8301 - precision: 0.7753 - recall: 0.7724 - auc: 0.8712 - val_loss: 0.4773 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8950\n",
      "Epoch 188/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4918 - tp: 199.0000 - fp: 51.0000 - tn: 393.0000 - fn: 69.0000 - accuracy: 0.8315 - precision: 0.7960 - recall: 0.7425 - auc: 0.8684 - val_loss: 0.4797 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8954\n",
      "Epoch 189/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4725 - tp: 208.0000 - fp: 51.0000 - tn: 393.0000 - fn: 60.0000 - accuracy: 0.8441 - precision: 0.8031 - recall: 0.7761 - auc: 0.8835 - val_loss: 0.4720 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8952\n",
      "Epoch 190/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5041 - tp: 203.0000 - fp: 73.0000 - tn: 371.0000 - fn: 65.0000 - accuracy: 0.8062 - precision: 0.7355 - recall: 0.7575 - auc: 0.8602 - val_loss: 0.4755 - val_tp: 60.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 14.0000 - val_accuracy: 0.8380 - val_precision: 0.8000 - val_recall: 0.8108 - val_auc: 0.8946\n",
      "Epoch 191/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4900 - tp: 202.0000 - fp: 52.0000 - tn: 392.0000 - fn: 66.0000 - accuracy: 0.8343 - precision: 0.7953 - recall: 0.7537 - auc: 0.8706 - val_loss: 0.4839 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8968\n",
      "Epoch 192/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4873 - tp: 207.0000 - fp: 64.0000 - tn: 380.0000 - fn: 61.0000 - accuracy: 0.8244 - precision: 0.7638 - recall: 0.7724 - auc: 0.8761 - val_loss: 0.4782 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8940\n",
      "Epoch 193/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4933 - tp: 202.0000 - fp: 58.0000 - tn: 386.0000 - fn: 66.0000 - accuracy: 0.8258 - precision: 0.7769 - recall: 0.7537 - auc: 0.8636 - val_loss: 0.4839 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8946\n",
      "Epoch 194/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5173 - tp: 197.0000 - fp: 64.0000 - tn: 380.0000 - fn: 71.0000 - accuracy: 0.8104 - precision: 0.7548 - recall: 0.7351 - auc: 0.8539 - val_loss: 0.4807 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8934\n",
      "Epoch 195/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5065 - tp: 197.0000 - fp: 46.0000 - tn: 398.0000 - fn: 71.0000 - accuracy: 0.8357 - precision: 0.8107 - recall: 0.7351 - auc: 0.8584 - val_loss: 0.4770 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8945\n",
      "Epoch 196/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4948 - tp: 208.0000 - fp: 58.0000 - tn: 386.0000 - fn: 60.0000 - accuracy: 0.8343 - precision: 0.7820 - recall: 0.7761 - auc: 0.8728 - val_loss: 0.4791 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8994\n",
      "Epoch 197/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4882 - tp: 204.0000 - fp: 56.0000 - tn: 388.0000 - fn: 64.0000 - accuracy: 0.8315 - precision: 0.7846 - recall: 0.7612 - auc: 0.8677 - val_loss: 0.4805 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8979\n",
      "Epoch 198/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5019 - tp: 196.0000 - fp: 48.0000 - tn: 396.0000 - fn: 72.0000 - accuracy: 0.8315 - precision: 0.8033 - recall: 0.7313 - auc: 0.8621 - val_loss: 0.4769 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8956\n",
      "Epoch 199/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5068 - tp: 197.0000 - fp: 61.0000 - tn: 383.0000 - fn: 71.0000 - accuracy: 0.8146 - precision: 0.7636 - recall: 0.7351 - auc: 0.8549 - val_loss: 0.4750 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8965\n",
      "Epoch 200/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4952 - tp: 203.0000 - fp: 60.0000 - tn: 384.0000 - fn: 65.0000 - accuracy: 0.8244 - precision: 0.7719 - recall: 0.7575 - auc: 0.8671 - val_loss: 0.4814 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8970\n",
      "Epoch 201/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4955 - tp: 192.0000 - fp: 40.0000 - tn: 404.0000 - fn: 76.0000 - accuracy: 0.8371 - precision: 0.8276 - recall: 0.7164 - auc: 0.8626 - val_loss: 0.5008 - val_tp: 69.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 5.0000 - val_accuracy: 0.7877 - val_precision: 0.6765 - val_recall: 0.9324 - val_auc: 0.8922\n",
      "Epoch 202/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5046 - tp: 199.0000 - fp: 72.0000 - tn: 372.0000 - fn: 69.0000 - accuracy: 0.8020 - precision: 0.7343 - recall: 0.7425 - auc: 0.8646 - val_loss: 0.4768 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8935\n",
      "Epoch 203/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5059 - tp: 206.0000 - fp: 61.0000 - tn: 383.0000 - fn: 62.0000 - accuracy: 0.8272 - precision: 0.7715 - recall: 0.7687 - auc: 0.8574 - val_loss: 0.4907 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8945\n",
      "Epoch 204/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4982 - tp: 197.0000 - fp: 48.0000 - tn: 396.0000 - fn: 71.0000 - accuracy: 0.8329 - precision: 0.8041 - recall: 0.7351 - auc: 0.8634 - val_loss: 0.4793 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8938\n",
      "Epoch 205/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4945 - tp: 213.0000 - fp: 64.0000 - tn: 380.0000 - fn: 55.0000 - accuracy: 0.8329 - precision: 0.7690 - recall: 0.7948 - auc: 0.8632 - val_loss: 0.4798 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8958\n",
      "Epoch 206/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.4832 - tp: 203.0000 - fp: 48.0000 - tn: 396.0000 - fn: 65.0000 - accuracy: 0.8413 - precision: 0.8088 - recall: 0.7575 - auc: 0.8717 - val_loss: 0.4830 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8940\n",
      "Epoch 207/500\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.4763 - tp: 206.0000 - fp: 60.0000 - tn: 384.0000 - fn: 62.0000 - accuracy: 0.8287 - precision: 0.7744 - recall: 0.7687 - auc: 0.8847 - val_loss: 0.4815 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8954\n",
      "Epoch 208/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4973 - tp: 203.0000 - fp: 60.0000 - tn: 384.0000 - fn: 65.0000 - accuracy: 0.8244 - precision: 0.7719 - recall: 0.7575 - auc: 0.8671 - val_loss: 0.4760 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8965\n",
      "Epoch 209/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4948 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8629 - val_loss: 0.4754 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8964\n",
      "Epoch 210/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4809 - tp: 206.0000 - fp: 50.0000 - tn: 394.0000 - fn: 62.0000 - accuracy: 0.8427 - precision: 0.8047 - recall: 0.7687 - auc: 0.8761 - val_loss: 0.4698 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8968\n",
      "Epoch 211/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5008 - tp: 206.0000 - fp: 61.0000 - tn: 383.0000 - fn: 62.0000 - accuracy: 0.8272 - precision: 0.7715 - recall: 0.7687 - auc: 0.8576 - val_loss: 0.4715 - val_tp: 61.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 13.0000 - val_accuracy: 0.8101 - val_precision: 0.7439 - val_recall: 0.8243 - val_auc: 0.8946\n",
      "Epoch 212/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4920 - tp: 205.0000 - fp: 65.0000 - tn: 379.0000 - fn: 63.0000 - accuracy: 0.8202 - precision: 0.7593 - recall: 0.7649 - auc: 0.8663 - val_loss: 0.4751 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8988\n",
      "Epoch 213/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4979 - tp: 198.0000 - fp: 50.0000 - tn: 394.0000 - fn: 70.0000 - accuracy: 0.8315 - precision: 0.7984 - recall: 0.7388 - auc: 0.8635 - val_loss: 0.4770 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8974\n",
      "Epoch 214/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4919 - tp: 203.0000 - fp: 73.0000 - tn: 371.0000 - fn: 65.0000 - accuracy: 0.8062 - precision: 0.7355 - recall: 0.7575 - auc: 0.8672 - val_loss: 0.4752 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8979\n",
      "Epoch 215/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5033 - tp: 201.0000 - fp: 62.0000 - tn: 382.0000 - fn: 67.0000 - accuracy: 0.8188 - precision: 0.7643 - recall: 0.7500 - auc: 0.8554 - val_loss: 0.4753 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8958\n",
      "Epoch 216/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4951 - tp: 197.0000 - fp: 48.0000 - tn: 396.0000 - fn: 71.0000 - accuracy: 0.8329 - precision: 0.8041 - recall: 0.7351 - auc: 0.8728 - val_loss: 0.4770 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.9018\n",
      "Epoch 217/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4904 - tp: 208.0000 - fp: 60.0000 - tn: 384.0000 - fn: 60.0000 - accuracy: 0.8315 - precision: 0.7761 - recall: 0.7761 - auc: 0.8684 - val_loss: 0.4771 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8960\n",
      "Epoch 218/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.4845 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8727 - val_loss: 0.4811 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.9001\n",
      "Epoch 219/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.5030 - tp: 201.0000 - fp: 58.0000 - tn: 386.0000 - fn: 67.0000 - accuracy: 0.8244 - precision: 0.7761 - recall: 0.7500 - auc: 0.8524 - val_loss: 0.4726 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8975\n",
      "Epoch 220/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4975 - tp: 199.0000 - fp: 49.0000 - tn: 395.0000 - fn: 69.0000 - accuracy: 0.8343 - precision: 0.8024 - recall: 0.7425 - auc: 0.8608 - val_loss: 0.4748 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.9005\n",
      "Epoch 221/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5019 - tp: 197.0000 - fp: 61.0000 - tn: 383.0000 - fn: 71.0000 - accuracy: 0.8146 - precision: 0.7636 - recall: 0.7351 - auc: 0.8595 - val_loss: 0.4769 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8925\n",
      "Epoch 222/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4928 - tp: 203.0000 - fp: 60.0000 - tn: 384.0000 - fn: 65.0000 - accuracy: 0.8244 - precision: 0.7719 - recall: 0.7575 - auc: 0.8651 - val_loss: 0.4808 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8948\n",
      "Epoch 223/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4958 - tp: 198.0000 - fp: 49.0000 - tn: 395.0000 - fn: 70.0000 - accuracy: 0.8329 - precision: 0.8016 - recall: 0.7388 - auc: 0.8712 - val_loss: 0.4760 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8950\n",
      "Epoch 224/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.4994 - tp: 200.0000 - fp: 48.0000 - tn: 396.0000 - fn: 68.0000 - accuracy: 0.8371 - precision: 0.8065 - recall: 0.7463 - auc: 0.8562 - val_loss: 0.4790 - val_tp: 62.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 12.0000 - val_accuracy: 0.8380 - val_precision: 0.7848 - val_recall: 0.8378 - val_auc: 0.8985\n",
      "Epoch 225/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4970 - tp: 202.0000 - fp: 46.0000 - tn: 398.0000 - fn: 66.0000 - accuracy: 0.8427 - precision: 0.8145 - recall: 0.7537 - auc: 0.8631 - val_loss: 0.4773 - val_tp: 60.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 14.0000 - val_accuracy: 0.8380 - val_precision: 0.8000 - val_recall: 0.8108 - val_auc: 0.8956\n",
      "Epoch 226/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4971 - tp: 197.0000 - fp: 50.0000 - tn: 394.0000 - fn: 71.0000 - accuracy: 0.8301 - precision: 0.7976 - recall: 0.7351 - auc: 0.8633 - val_loss: 0.4779 - val_tp: 62.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 12.0000 - val_accuracy: 0.8268 - val_precision: 0.7654 - val_recall: 0.8378 - val_auc: 0.8966\n",
      "Epoch 227/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4827 - tp: 205.0000 - fp: 55.0000 - tn: 389.0000 - fn: 63.0000 - accuracy: 0.8343 - precision: 0.7885 - recall: 0.7649 - auc: 0.8704 - val_loss: 0.4768 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8945\n",
      "Epoch 228/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5066 - tp: 201.0000 - fp: 58.0000 - tn: 386.0000 - fn: 67.0000 - accuracy: 0.8244 - precision: 0.7761 - recall: 0.7500 - auc: 0.8511 - val_loss: 0.4777 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8964\n",
      "Epoch 229/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4967 - tp: 199.0000 - fp: 55.0000 - tn: 389.0000 - fn: 69.0000 - accuracy: 0.8258 - precision: 0.7835 - recall: 0.7425 - auc: 0.8691 - val_loss: 0.4814 - val_tp: 62.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 12.0000 - val_accuracy: 0.7933 - val_precision: 0.7126 - val_recall: 0.8378 - val_auc: 0.8956\n",
      "Epoch 230/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4952 - tp: 197.0000 - fp: 60.0000 - tn: 384.0000 - fn: 71.0000 - accuracy: 0.8160 - precision: 0.7665 - recall: 0.7351 - auc: 0.8679 - val_loss: 0.4754 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8975\n",
      "Epoch 231/500\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.4970 - tp: 205.0000 - fp: 59.0000 - tn: 385.0000 - fn: 63.0000 - accuracy: 0.8287 - precision: 0.7765 - recall: 0.7649 - auc: 0.8641 - val_loss: 0.4787 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8960\n",
      "Epoch 232/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4896 - tp: 200.0000 - fp: 56.0000 - tn: 388.0000 - fn: 68.0000 - accuracy: 0.8258 - precision: 0.7812 - recall: 0.7463 - auc: 0.8694 - val_loss: 0.4812 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.9016\n",
      "Epoch 233/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.4977 - tp: 198.0000 - fp: 46.0000 - tn: 398.0000 - fn: 70.0000 - accuracy: 0.8371 - precision: 0.8115 - recall: 0.7388 - auc: 0.8603 - val_loss: 0.4749 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8955\n",
      "Epoch 234/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4893 - tp: 199.0000 - fp: 49.0000 - tn: 395.0000 - fn: 69.0000 - accuracy: 0.8343 - precision: 0.8024 - recall: 0.7425 - auc: 0.8683 - val_loss: 0.4768 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8986\n",
      "Epoch 235/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4930 - tp: 204.0000 - fp: 58.0000 - tn: 386.0000 - fn: 64.0000 - accuracy: 0.8287 - precision: 0.7786 - recall: 0.7612 - auc: 0.8708 - val_loss: 0.4747 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8975\n",
      "Epoch 236/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.4976 - tp: 206.0000 - fp: 57.0000 - tn: 387.0000 - fn: 62.0000 - accuracy: 0.8329 - precision: 0.7833 - recall: 0.7687 - auc: 0.8601 - val_loss: 0.4771 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8972\n",
      "Epoch 237/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4930 - tp: 200.0000 - fp: 56.0000 - tn: 388.0000 - fn: 68.0000 - accuracy: 0.8258 - precision: 0.7812 - recall: 0.7463 - auc: 0.8730 - val_loss: 0.4725 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8975\n",
      "Epoch 238/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4913 - tp: 195.0000 - fp: 47.0000 - tn: 397.0000 - fn: 73.0000 - accuracy: 0.8315 - precision: 0.8058 - recall: 0.7276 - auc: 0.8654 - val_loss: 0.4753 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8968\n",
      "Epoch 239/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4892 - tp: 206.0000 - fp: 58.0000 - tn: 386.0000 - fn: 62.0000 - accuracy: 0.8315 - precision: 0.7803 - recall: 0.7687 - auc: 0.8676 - val_loss: 0.4729 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8963\n",
      "Epoch 240/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5046 - tp: 193.0000 - fp: 62.0000 - tn: 382.0000 - fn: 75.0000 - accuracy: 0.8076 - precision: 0.7569 - recall: 0.7201 - auc: 0.8593 - val_loss: 0.4818 - val_tp: 62.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 12.0000 - val_accuracy: 0.7989 - val_precision: 0.7209 - val_recall: 0.8378 - val_auc: 0.8944\n",
      "Epoch 241/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4898 - tp: 197.0000 - fp: 45.0000 - tn: 399.0000 - fn: 71.0000 - accuracy: 0.8371 - precision: 0.8140 - recall: 0.7351 - auc: 0.8678 - val_loss: 0.4794 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8998\n",
      "Epoch 242/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4905 - tp: 200.0000 - fp: 52.0000 - tn: 392.0000 - fn: 68.0000 - accuracy: 0.8315 - precision: 0.7937 - recall: 0.7463 - auc: 0.8706 - val_loss: 0.4751 - val_tp: 61.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 13.0000 - val_accuracy: 0.8101 - val_precision: 0.7439 - val_recall: 0.8243 - val_auc: 0.8955\n",
      "Epoch 243/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5075 - tp: 210.0000 - fp: 68.0000 - tn: 376.0000 - fn: 58.0000 - accuracy: 0.8230 - precision: 0.7554 - recall: 0.7836 - auc: 0.8560 - val_loss: 0.4756 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8976\n",
      "Epoch 244/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4955 - tp: 196.0000 - fp: 49.0000 - tn: 395.0000 - fn: 72.0000 - accuracy: 0.8301 - precision: 0.8000 - recall: 0.7313 - auc: 0.8659 - val_loss: 0.4834 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8952\n",
      "Epoch 245/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4739 - tp: 206.0000 - fp: 58.0000 - tn: 386.0000 - fn: 62.0000 - accuracy: 0.8315 - precision: 0.7803 - recall: 0.7687 - auc: 0.8757 - val_loss: 0.4762 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8986\n",
      "Epoch 246/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4771 - tp: 207.0000 - fp: 59.0000 - tn: 385.0000 - fn: 61.0000 - accuracy: 0.8315 - precision: 0.7782 - recall: 0.7724 - auc: 0.8783 - val_loss: 0.4737 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8977\n",
      "Epoch 247/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4995 - tp: 202.0000 - fp: 57.0000 - tn: 387.0000 - fn: 66.0000 - accuracy: 0.8272 - precision: 0.7799 - recall: 0.7537 - auc: 0.8620 - val_loss: 0.4819 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8934\n",
      "Epoch 248/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4965 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8631 - val_loss: 0.4774 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8963\n",
      "Epoch 249/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4875 - tp: 201.0000 - fp: 56.0000 - tn: 388.0000 - fn: 67.0000 - accuracy: 0.8272 - precision: 0.7821 - recall: 0.7500 - auc: 0.8709 - val_loss: 0.4714 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8948\n",
      "Epoch 250/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4867 - tp: 200.0000 - fp: 48.0000 - tn: 396.0000 - fn: 68.0000 - accuracy: 0.8371 - precision: 0.8065 - recall: 0.7463 - auc: 0.8737 - val_loss: 0.4766 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8979\n",
      "Epoch 251/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4894 - tp: 202.0000 - fp: 56.0000 - tn: 388.0000 - fn: 66.0000 - accuracy: 0.8287 - precision: 0.7829 - recall: 0.7537 - auc: 0.8692 - val_loss: 0.4803 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8934\n",
      "Epoch 252/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5079 - tp: 202.0000 - fp: 59.0000 - tn: 385.0000 - fn: 66.0000 - accuracy: 0.8244 - precision: 0.7739 - recall: 0.7537 - auc: 0.8588 - val_loss: 0.4808 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8951\n",
      "Epoch 253/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5022 - tp: 195.0000 - fp: 47.0000 - tn: 397.0000 - fn: 73.0000 - accuracy: 0.8315 - precision: 0.8058 - recall: 0.7276 - auc: 0.8607 - val_loss: 0.4746 - val_tp: 61.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 13.0000 - val_accuracy: 0.8436 - val_precision: 0.8026 - val_recall: 0.8243 - val_auc: 0.8961\n",
      "Epoch 254/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4901 - tp: 204.0000 - fp: 67.0000 - tn: 377.0000 - fn: 64.0000 - accuracy: 0.8160 - precision: 0.7528 - recall: 0.7612 - auc: 0.8695 - val_loss: 0.4741 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.9001\n",
      "Epoch 255/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4796 - tp: 207.0000 - fp: 53.0000 - tn: 391.0000 - fn: 61.0000 - accuracy: 0.8399 - precision: 0.7962 - recall: 0.7724 - auc: 0.8727 - val_loss: 0.4765 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8968\n",
      "Epoch 256/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4914 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8664 - val_loss: 0.4782 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8993\n",
      "Epoch 257/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.4764 - tp: 196.0000 - fp: 44.0000 - tn: 400.0000 - fn: 72.0000 - accuracy: 0.8371 - precision: 0.8167 - recall: 0.7313 - auc: 0.8805 - val_loss: 0.4874 - val_tp: 62.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 12.0000 - val_accuracy: 0.7933 - val_precision: 0.7126 - val_recall: 0.8378 - val_auc: 0.8947\n",
      "Epoch 258/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4898 - tp: 208.0000 - fp: 60.0000 - tn: 384.0000 - fn: 60.0000 - accuracy: 0.8315 - precision: 0.7761 - recall: 0.7761 - auc: 0.8703 - val_loss: 0.4763 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8999\n",
      "Epoch 259/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4982 - tp: 203.0000 - fp: 55.0000 - tn: 389.0000 - fn: 65.0000 - accuracy: 0.8315 - precision: 0.7868 - recall: 0.7575 - auc: 0.8619 - val_loss: 0.4762 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8969\n",
      "Epoch 260/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.4936 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8611 - val_loss: 0.4739 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8989\n",
      "Epoch 261/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4786 - tp: 197.0000 - fp: 50.0000 - tn: 394.0000 - fn: 71.0000 - accuracy: 0.8301 - precision: 0.7976 - recall: 0.7351 - auc: 0.8748 - val_loss: 0.4823 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8965\n",
      "Epoch 262/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4883 - tp: 205.0000 - fp: 60.0000 - tn: 384.0000 - fn: 63.0000 - accuracy: 0.8272 - precision: 0.7736 - recall: 0.7649 - auc: 0.8762 - val_loss: 0.4753 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8976\n",
      "Epoch 263/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4906 - tp: 204.0000 - fp: 54.0000 - tn: 390.0000 - fn: 64.0000 - accuracy: 0.8343 - precision: 0.7907 - recall: 0.7612 - auc: 0.8638 - val_loss: 0.4728 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8980\n",
      "Epoch 264/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4915 - tp: 198.0000 - fp: 45.0000 - tn: 399.0000 - fn: 70.0000 - accuracy: 0.8385 - precision: 0.8148 - recall: 0.7388 - auc: 0.8654 - val_loss: 0.4729 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8960\n",
      "Epoch 265/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4944 - tp: 201.0000 - fp: 54.0000 - tn: 390.0000 - fn: 67.0000 - accuracy: 0.8301 - precision: 0.7882 - recall: 0.7500 - auc: 0.8649 - val_loss: 0.4698 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.9031\n",
      "Epoch 266/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5022 - tp: 199.0000 - fp: 55.0000 - tn: 389.0000 - fn: 69.0000 - accuracy: 0.8258 - precision: 0.7835 - recall: 0.7425 - auc: 0.8610 - val_loss: 0.4769 - val_tp: 62.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 12.0000 - val_accuracy: 0.8212 - val_precision: 0.7561 - val_recall: 0.8378 - val_auc: 0.8953\n",
      "Epoch 267/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4800 - tp: 204.0000 - fp: 51.0000 - tn: 393.0000 - fn: 64.0000 - accuracy: 0.8385 - precision: 0.8000 - recall: 0.7612 - auc: 0.8735 - val_loss: 0.4749 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8953\n",
      "Epoch 268/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4898 - tp: 205.0000 - fp: 65.0000 - tn: 379.0000 - fn: 63.0000 - accuracy: 0.8202 - precision: 0.7593 - recall: 0.7649 - auc: 0.8724 - val_loss: 0.4771 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8967\n",
      "Epoch 269/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4884 - tp: 203.0000 - fp: 52.0000 - tn: 392.0000 - fn: 65.0000 - accuracy: 0.8357 - precision: 0.7961 - recall: 0.7575 - auc: 0.8717 - val_loss: 0.4769 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8965\n",
      "Epoch 270/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4776 - tp: 208.0000 - fp: 55.0000 - tn: 389.0000 - fn: 60.0000 - accuracy: 0.8385 - precision: 0.7909 - recall: 0.7761 - auc: 0.8791 - val_loss: 0.4720 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8961\n",
      "Epoch 271/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4868 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8669 - val_loss: 0.4797 - val_tp: 62.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 12.0000 - val_accuracy: 0.8045 - val_precision: 0.7294 - val_recall: 0.8378 - val_auc: 0.8965\n",
      "Epoch 272/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4806 - tp: 202.0000 - fp: 58.0000 - tn: 386.0000 - fn: 66.0000 - accuracy: 0.8258 - precision: 0.7769 - recall: 0.7537 - auc: 0.8692 - val_loss: 0.4762 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8949\n",
      "Epoch 273/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4847 - tp: 201.0000 - fp: 59.0000 - tn: 385.0000 - fn: 67.0000 - accuracy: 0.8230 - precision: 0.7731 - recall: 0.7500 - auc: 0.8693 - val_loss: 0.4807 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8938\n",
      "Epoch 274/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4869 - tp: 210.0000 - fp: 62.0000 - tn: 382.0000 - fn: 58.0000 - accuracy: 0.8315 - precision: 0.7721 - recall: 0.7836 - auc: 0.8664 - val_loss: 0.4701 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8966\n",
      "Epoch 275/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4879 - tp: 204.0000 - fp: 57.0000 - tn: 387.0000 - fn: 64.0000 - accuracy: 0.8301 - precision: 0.7816 - recall: 0.7612 - auc: 0.8651 - val_loss: 0.4773 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8977\n",
      "Epoch 276/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4792 - tp: 205.0000 - fp: 61.0000 - tn: 383.0000 - fn: 63.0000 - accuracy: 0.8258 - precision: 0.7707 - recall: 0.7649 - auc: 0.8752 - val_loss: 0.4708 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8961\n",
      "Epoch 277/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4856 - tp: 201.0000 - fp: 56.0000 - tn: 388.0000 - fn: 67.0000 - accuracy: 0.8272 - precision: 0.7821 - recall: 0.7500 - auc: 0.8698 - val_loss: 0.4771 - val_tp: 60.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 14.0000 - val_accuracy: 0.8380 - val_precision: 0.8000 - val_recall: 0.8108 - val_auc: 0.8958\n",
      "Epoch 278/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4813 - tp: 200.0000 - fp: 50.0000 - tn: 394.0000 - fn: 68.0000 - accuracy: 0.8343 - precision: 0.8000 - recall: 0.7463 - auc: 0.8700 - val_loss: 0.4761 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8967\n",
      "Epoch 279/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.4861 - tp: 205.0000 - fp: 63.0000 - tn: 381.0000 - fn: 63.0000 - accuracy: 0.8230 - precision: 0.7649 - recall: 0.7649 - auc: 0.8623 - val_loss: 0.4825 - val_tp: 54.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 20.0000 - val_accuracy: 0.8212 - val_precision: 0.8182 - val_recall: 0.7297 - val_auc: 0.8931\n",
      "Epoch 280/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4928 - tp: 193.0000 - fp: 45.0000 - tn: 399.0000 - fn: 75.0000 - accuracy: 0.8315 - precision: 0.8109 - recall: 0.7201 - auc: 0.8605 - val_loss: 0.4778 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8965\n",
      "Epoch 281/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4940 - tp: 204.0000 - fp: 63.0000 - tn: 381.0000 - fn: 64.0000 - accuracy: 0.8216 - precision: 0.7640 - recall: 0.7612 - auc: 0.8627 - val_loss: 0.4879 - val_tp: 56.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 18.0000 - val_accuracy: 0.8380 - val_precision: 0.8358 - val_recall: 0.7568 - val_auc: 0.8968\n",
      "Epoch 282/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5044 - tp: 205.0000 - fp: 52.0000 - tn: 392.0000 - fn: 63.0000 - accuracy: 0.8385 - precision: 0.7977 - recall: 0.7649 - auc: 0.8490 - val_loss: 0.4731 - val_tp: 61.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 13.0000 - val_accuracy: 0.8324 - val_precision: 0.7821 - val_recall: 0.8243 - val_auc: 0.8986\n",
      "Epoch 283/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4963 - tp: 204.0000 - fp: 49.0000 - tn: 395.0000 - fn: 64.0000 - accuracy: 0.8413 - precision: 0.8063 - recall: 0.7612 - auc: 0.8502 - val_loss: 0.4712 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8963\n",
      "Epoch 284/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4868 - tp: 201.0000 - fp: 52.0000 - tn: 392.0000 - fn: 67.0000 - accuracy: 0.8329 - precision: 0.7945 - recall: 0.7500 - auc: 0.8635 - val_loss: 0.4761 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8940\n",
      "Epoch 285/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5141 - tp: 205.0000 - fp: 63.0000 - tn: 381.0000 - fn: 63.0000 - accuracy: 0.8230 - precision: 0.7649 - recall: 0.7649 - auc: 0.8534 - val_loss: 0.4832 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8959\n",
      "Epoch 286/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4829 - tp: 205.0000 - fp: 56.0000 - tn: 388.0000 - fn: 63.0000 - accuracy: 0.8329 - precision: 0.7854 - recall: 0.7649 - auc: 0.8727 - val_loss: 0.4779 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8958\n",
      "Epoch 287/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4922 - tp: 201.0000 - fp: 57.0000 - tn: 387.0000 - fn: 67.0000 - accuracy: 0.8258 - precision: 0.7791 - recall: 0.7500 - auc: 0.8679 - val_loss: 0.4815 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8959\n",
      "Epoch 288/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4832 - tp: 202.0000 - fp: 45.0000 - tn: 399.0000 - fn: 66.0000 - accuracy: 0.8441 - precision: 0.8178 - recall: 0.7537 - auc: 0.8707 - val_loss: 0.4865 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8943\n",
      "Epoch 289/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4892 - tp: 199.0000 - fp: 54.0000 - tn: 390.0000 - fn: 69.0000 - accuracy: 0.8272 - precision: 0.7866 - recall: 0.7425 - auc: 0.8742 - val_loss: 0.4939 - val_tp: 64.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 10.0000 - val_accuracy: 0.7989 - val_precision: 0.7111 - val_recall: 0.8649 - val_auc: 0.8933\n",
      "Epoch 290/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.4721 - tp: 202.0000 - fp: 50.0000 - tn: 394.0000 - fn: 66.0000 - accuracy: 0.8371 - precision: 0.8016 - recall: 0.7537 - auc: 0.8804 - val_loss: 0.4721 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8950\n",
      "Epoch 291/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4809 - tp: 206.0000 - fp: 54.0000 - tn: 390.0000 - fn: 62.0000 - accuracy: 0.8371 - precision: 0.7923 - recall: 0.7687 - auc: 0.8724 - val_loss: 0.4703 - val_tp: 61.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 13.0000 - val_accuracy: 0.8101 - val_precision: 0.7439 - val_recall: 0.8243 - val_auc: 0.8953\n",
      "Epoch 292/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5035 - tp: 197.0000 - fp: 62.0000 - tn: 382.0000 - fn: 71.0000 - accuracy: 0.8132 - precision: 0.7606 - recall: 0.7351 - auc: 0.8566 - val_loss: 0.4683 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8994\n",
      "Epoch 293/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4856 - tp: 204.0000 - fp: 59.0000 - tn: 385.0000 - fn: 64.0000 - accuracy: 0.8272 - precision: 0.7757 - recall: 0.7612 - auc: 0.8688 - val_loss: 0.4727 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8987\n",
      "Epoch 294/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4864 - tp: 208.0000 - fp: 54.0000 - tn: 390.0000 - fn: 60.0000 - accuracy: 0.8399 - precision: 0.7939 - recall: 0.7761 - auc: 0.8634 - val_loss: 0.4744 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8948\n",
      "Epoch 295/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4930 - tp: 203.0000 - fp: 56.0000 - tn: 388.0000 - fn: 65.0000 - accuracy: 0.8301 - precision: 0.7838 - recall: 0.7575 - auc: 0.8606 - val_loss: 0.4827 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8969\n",
      "Epoch 296/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4881 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8668 - val_loss: 0.4815 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8923\n",
      "Epoch 297/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4794 - tp: 197.0000 - fp: 46.0000 - tn: 398.0000 - fn: 71.0000 - accuracy: 0.8357 - precision: 0.8107 - recall: 0.7351 - auc: 0.8757 - val_loss: 0.4783 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8949\n",
      "Epoch 298/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4812 - tp: 208.0000 - fp: 66.0000 - tn: 378.0000 - fn: 60.0000 - accuracy: 0.8230 - precision: 0.7591 - recall: 0.7761 - auc: 0.8720 - val_loss: 0.4747 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8956\n",
      "Epoch 299/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4820 - tp: 202.0000 - fp: 52.0000 - tn: 392.0000 - fn: 66.0000 - accuracy: 0.8343 - precision: 0.7953 - recall: 0.7537 - auc: 0.8676 - val_loss: 0.4738 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8983\n",
      "Epoch 300/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4847 - tp: 202.0000 - fp: 46.0000 - tn: 398.0000 - fn: 66.0000 - accuracy: 0.8427 - precision: 0.8145 - recall: 0.7537 - auc: 0.8664 - val_loss: 0.4792 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8944\n",
      "Epoch 301/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4915 - tp: 207.0000 - fp: 60.0000 - tn: 384.0000 - fn: 61.0000 - accuracy: 0.8301 - precision: 0.7753 - recall: 0.7724 - auc: 0.8677 - val_loss: 0.4745 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8934\n",
      "Epoch 302/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4813 - tp: 201.0000 - fp: 42.0000 - tn: 402.0000 - fn: 67.0000 - accuracy: 0.8469 - precision: 0.8272 - recall: 0.7500 - auc: 0.8736 - val_loss: 0.4776 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8954\n",
      "Epoch 303/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4846 - tp: 193.0000 - fp: 47.0000 - tn: 397.0000 - fn: 75.0000 - accuracy: 0.8287 - precision: 0.8042 - recall: 0.7201 - auc: 0.8725 - val_loss: 0.4694 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8978\n",
      "Epoch 304/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4882 - tp: 198.0000 - fp: 53.0000 - tn: 391.0000 - fn: 70.0000 - accuracy: 0.8272 - precision: 0.7888 - recall: 0.7388 - auc: 0.8726 - val_loss: 0.4748 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8986\n",
      "Epoch 305/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4837 - tp: 205.0000 - fp: 47.0000 - tn: 397.0000 - fn: 63.0000 - accuracy: 0.8455 - precision: 0.8135 - recall: 0.7649 - auc: 0.8684 - val_loss: 0.4728 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8973\n",
      "Epoch 306/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4895 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8713 - val_loss: 0.4698 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8972\n",
      "Epoch 307/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.4881 - tp: 197.0000 - fp: 52.0000 - tn: 392.0000 - fn: 71.0000 - accuracy: 0.8272 - precision: 0.7912 - recall: 0.7351 - auc: 0.8666 - val_loss: 0.4821 - val_tp: 62.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 12.0000 - val_accuracy: 0.8101 - val_precision: 0.7381 - val_recall: 0.8378 - val_auc: 0.8949\n",
      "Epoch 308/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4860 - tp: 204.0000 - fp: 61.0000 - tn: 383.0000 - fn: 64.0000 - accuracy: 0.8244 - precision: 0.7698 - recall: 0.7612 - auc: 0.8630 - val_loss: 0.4729 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8995\n",
      "Epoch 309/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.4777 - tp: 207.0000 - fp: 60.0000 - tn: 384.0000 - fn: 61.0000 - accuracy: 0.8301 - precision: 0.7753 - recall: 0.7724 - auc: 0.8810 - val_loss: 0.4834 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8974\n",
      "Epoch 310/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4956 - tp: 198.0000 - fp: 46.0000 - tn: 398.0000 - fn: 70.0000 - accuracy: 0.8371 - precision: 0.8115 - recall: 0.7388 - auc: 0.8642 - val_loss: 0.4689 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8951\n",
      "Epoch 311/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4810 - tp: 207.0000 - fp: 62.0000 - tn: 382.0000 - fn: 61.0000 - accuracy: 0.8272 - precision: 0.7695 - recall: 0.7724 - auc: 0.8690 - val_loss: 0.4722 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8955\n",
      "Epoch 312/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4899 - tp: 197.0000 - fp: 52.0000 - tn: 392.0000 - fn: 71.0000 - accuracy: 0.8272 - precision: 0.7912 - recall: 0.7351 - auc: 0.8675 - val_loss: 0.4744 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8943\n",
      "Epoch 313/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5005 - tp: 193.0000 - fp: 50.0000 - tn: 394.0000 - fn: 75.0000 - accuracy: 0.8244 - precision: 0.7942 - recall: 0.7201 - auc: 0.8535 - val_loss: 0.4809 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8938\n",
      "Epoch 314/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4828 - tp: 202.0000 - fp: 49.0000 - tn: 395.0000 - fn: 66.0000 - accuracy: 0.8385 - precision: 0.8048 - recall: 0.7537 - auc: 0.8685 - val_loss: 0.4770 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8930\n",
      "Epoch 315/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4907 - tp: 202.0000 - fp: 57.0000 - tn: 387.0000 - fn: 66.0000 - accuracy: 0.8272 - precision: 0.7799 - recall: 0.7537 - auc: 0.8638 - val_loss: 0.4898 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8970\n",
      "Epoch 316/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4980 - tp: 199.0000 - fp: 47.0000 - tn: 397.0000 - fn: 69.0000 - accuracy: 0.8371 - precision: 0.8089 - recall: 0.7425 - auc: 0.8579 - val_loss: 0.4738 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8976\n",
      "Epoch 317/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4803 - tp: 203.0000 - fp: 49.0000 - tn: 395.0000 - fn: 65.0000 - accuracy: 0.8399 - precision: 0.8056 - recall: 0.7575 - auc: 0.8755 - val_loss: 0.4753 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8959\n",
      "Epoch 318/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4997 - tp: 205.0000 - fp: 59.0000 - tn: 385.0000 - fn: 63.0000 - accuracy: 0.8287 - precision: 0.7765 - recall: 0.7649 - auc: 0.8530 - val_loss: 0.4804 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8962\n",
      "Epoch 319/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5031 - tp: 186.0000 - fp: 47.0000 - tn: 397.0000 - fn: 82.0000 - accuracy: 0.8188 - precision: 0.7983 - recall: 0.6940 - auc: 0.8681 - val_loss: 0.4720 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8970\n",
      "Epoch 320/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4825 - tp: 207.0000 - fp: 63.0000 - tn: 381.0000 - fn: 61.0000 - accuracy: 0.8258 - precision: 0.7667 - recall: 0.7724 - auc: 0.8680 - val_loss: 0.4690 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8969\n",
      "Epoch 321/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4810 - tp: 200.0000 - fp: 59.0000 - tn: 385.0000 - fn: 68.0000 - accuracy: 0.8216 - precision: 0.7722 - recall: 0.7463 - auc: 0.8719 - val_loss: 0.4723 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.9001\n",
      "Epoch 322/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4862 - tp: 195.0000 - fp: 47.0000 - tn: 397.0000 - fn: 73.0000 - accuracy: 0.8315 - precision: 0.8058 - recall: 0.7276 - auc: 0.8672 - val_loss: 0.4761 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8981\n",
      "Epoch 323/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4812 - tp: 205.0000 - fp: 60.0000 - tn: 384.0000 - fn: 63.0000 - accuracy: 0.8272 - precision: 0.7736 - recall: 0.7649 - auc: 0.8731 - val_loss: 0.4707 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8948\n",
      "Epoch 324/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4868 - tp: 204.0000 - fp: 51.0000 - tn: 393.0000 - fn: 64.0000 - accuracy: 0.8385 - precision: 0.8000 - recall: 0.7612 - auc: 0.8694 - val_loss: 0.4719 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8981\n",
      "Epoch 325/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4868 - tp: 203.0000 - fp: 51.0000 - tn: 393.0000 - fn: 65.0000 - accuracy: 0.8371 - precision: 0.7992 - recall: 0.7575 - auc: 0.8697 - val_loss: 0.4758 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8950\n",
      "Epoch 326/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4715 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8779 - val_loss: 0.4699 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8961\n",
      "Epoch 327/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4741 - tp: 204.0000 - fp: 46.0000 - tn: 398.0000 - fn: 64.0000 - accuracy: 0.8455 - precision: 0.8160 - recall: 0.7612 - auc: 0.8720 - val_loss: 0.4736 - val_tp: 62.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 12.0000 - val_accuracy: 0.8045 - val_precision: 0.7294 - val_recall: 0.8378 - val_auc: 0.8958\n",
      "Epoch 328/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4866 - tp: 205.0000 - fp: 57.0000 - tn: 387.0000 - fn: 63.0000 - accuracy: 0.8315 - precision: 0.7824 - recall: 0.7649 - auc: 0.8704 - val_loss: 0.4624 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8973\n",
      "Epoch 329/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5043 - tp: 198.0000 - fp: 49.0000 - tn: 395.0000 - fn: 70.0000 - accuracy: 0.8329 - precision: 0.8016 - recall: 0.7388 - auc: 0.8546 - val_loss: 0.4674 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.9001\n",
      "Epoch 330/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4679 - tp: 205.0000 - fp: 57.0000 - tn: 387.0000 - fn: 63.0000 - accuracy: 0.8315 - precision: 0.7824 - recall: 0.7649 - auc: 0.8783 - val_loss: 0.4708 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8961\n",
      "Epoch 331/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4902 - tp: 196.0000 - fp: 56.0000 - tn: 388.0000 - fn: 72.0000 - accuracy: 0.8202 - precision: 0.7778 - recall: 0.7313 - auc: 0.8606 - val_loss: 0.4681 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8974\n",
      "Epoch 332/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.4874 - tp: 209.0000 - fp: 55.0000 - tn: 389.0000 - fn: 59.0000 - accuracy: 0.8399 - precision: 0.7917 - recall: 0.7799 - auc: 0.8657 - val_loss: 0.4791 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8960\n",
      "Epoch 333/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.4937 - tp: 200.0000 - fp: 58.0000 - tn: 386.0000 - fn: 68.0000 - accuracy: 0.8230 - precision: 0.7752 - recall: 0.7463 - auc: 0.8600 - val_loss: 0.4743 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8983\n",
      "Epoch 334/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.4768 - tp: 203.0000 - fp: 50.0000 - tn: 394.0000 - fn: 65.0000 - accuracy: 0.8385 - precision: 0.8024 - recall: 0.7575 - auc: 0.8776 - val_loss: 0.4679 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8987\n",
      "Epoch 335/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.4837 - tp: 202.0000 - fp: 49.0000 - tn: 395.0000 - fn: 66.0000 - accuracy: 0.8385 - precision: 0.8048 - recall: 0.7537 - auc: 0.8613 - val_loss: 0.4716 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8961\n",
      "Epoch 336/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.4879 - tp: 199.0000 - fp: 51.0000 - tn: 393.0000 - fn: 69.0000 - accuracy: 0.8315 - precision: 0.7960 - recall: 0.7425 - auc: 0.8653 - val_loss: 0.4695 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8981\n",
      "Epoch 337/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.4915 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8596 - val_loss: 0.4734 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8958\n",
      "Epoch 338/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4853 - tp: 202.0000 - fp: 56.0000 - tn: 388.0000 - fn: 66.0000 - accuracy: 0.8287 - precision: 0.7829 - recall: 0.7537 - auc: 0.8642 - val_loss: 0.4790 - val_tp: 61.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 13.0000 - val_accuracy: 0.8156 - val_precision: 0.7531 - val_recall: 0.8243 - val_auc: 0.8954\n",
      "Epoch 339/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4869 - tp: 197.0000 - fp: 57.0000 - tn: 387.0000 - fn: 71.0000 - accuracy: 0.8202 - precision: 0.7756 - recall: 0.7351 - auc: 0.8734 - val_loss: 0.4713 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.9044\n",
      "Epoch 340/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5064 - tp: 192.0000 - fp: 51.0000 - tn: 393.0000 - fn: 76.0000 - accuracy: 0.8216 - precision: 0.7901 - recall: 0.7164 - auc: 0.8518 - val_loss: 0.4715 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8950\n",
      "Epoch 341/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4846 - tp: 204.0000 - fp: 47.0000 - tn: 397.0000 - fn: 64.0000 - accuracy: 0.8441 - precision: 0.8127 - recall: 0.7612 - auc: 0.8658 - val_loss: 0.4831 - val_tp: 68.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 6.0000 - val_accuracy: 0.8156 - val_precision: 0.7158 - val_recall: 0.9189 - val_auc: 0.8958\n",
      "Epoch 342/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4874 - tp: 196.0000 - fp: 51.0000 - tn: 393.0000 - fn: 72.0000 - accuracy: 0.8272 - precision: 0.7935 - recall: 0.7313 - auc: 0.8658 - val_loss: 0.4766 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8954\n",
      "Epoch 343/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4835 - tp: 204.0000 - fp: 61.0000 - tn: 383.0000 - fn: 64.0000 - accuracy: 0.8244 - precision: 0.7698 - recall: 0.7612 - auc: 0.8707 - val_loss: 0.4795 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8936\n",
      "Epoch 344/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4841 - tp: 198.0000 - fp: 48.0000 - tn: 396.0000 - fn: 70.0000 - accuracy: 0.8343 - precision: 0.8049 - recall: 0.7388 - auc: 0.8740 - val_loss: 0.4787 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8968\n",
      "Epoch 345/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4864 - tp: 207.0000 - fp: 53.0000 - tn: 391.0000 - fn: 61.0000 - accuracy: 0.8399 - precision: 0.7962 - recall: 0.7724 - auc: 0.8627 - val_loss: 0.4658 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.9003\n",
      "Epoch 346/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4898 - tp: 196.0000 - fp: 47.0000 - tn: 397.0000 - fn: 72.0000 - accuracy: 0.8329 - precision: 0.8066 - recall: 0.7313 - auc: 0.8759 - val_loss: 0.4794 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8955\n",
      "Epoch 347/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4825 - tp: 201.0000 - fp: 57.0000 - tn: 387.0000 - fn: 67.0000 - accuracy: 0.8258 - precision: 0.7791 - recall: 0.7500 - auc: 0.8652 - val_loss: 0.4750 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8964\n",
      "Epoch 348/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4914 - tp: 204.0000 - fp: 54.0000 - tn: 390.0000 - fn: 64.0000 - accuracy: 0.8343 - precision: 0.7907 - recall: 0.7612 - auc: 0.8650 - val_loss: 0.4661 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.9000\n",
      "Epoch 349/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4799 - tp: 189.0000 - fp: 36.0000 - tn: 408.0000 - fn: 79.0000 - accuracy: 0.8385 - precision: 0.8400 - recall: 0.7052 - auc: 0.8861 - val_loss: 0.4723 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8949\n",
      "Epoch 350/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4983 - tp: 205.0000 - fp: 64.0000 - tn: 380.0000 - fn: 63.0000 - accuracy: 0.8216 - precision: 0.7621 - recall: 0.7649 - auc: 0.8630 - val_loss: 0.4662 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8974\n",
      "Epoch 351/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4794 - tp: 197.0000 - fp: 41.0000 - tn: 403.0000 - fn: 71.0000 - accuracy: 0.8427 - precision: 0.8277 - recall: 0.7351 - auc: 0.8768 - val_loss: 0.4668 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8974\n",
      "Epoch 352/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4863 - tp: 210.0000 - fp: 71.0000 - tn: 373.0000 - fn: 58.0000 - accuracy: 0.8188 - precision: 0.7473 - recall: 0.7836 - auc: 0.8678 - val_loss: 0.4761 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8964\n",
      "Epoch 353/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4973 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8665 - val_loss: 0.4753 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8958\n",
      "Epoch 354/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4710 - tp: 205.0000 - fp: 53.0000 - tn: 391.0000 - fn: 63.0000 - accuracy: 0.8371 - precision: 0.7946 - recall: 0.7649 - auc: 0.8836 - val_loss: 0.4753 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8935\n",
      "Epoch 355/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4971 - tp: 200.0000 - fp: 51.0000 - tn: 393.0000 - fn: 68.0000 - accuracy: 0.8329 - precision: 0.7968 - recall: 0.7463 - auc: 0.8604 - val_loss: 0.4838 - val_tp: 61.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 13.0000 - val_accuracy: 0.8156 - val_precision: 0.7531 - val_recall: 0.8243 - val_auc: 0.8936\n",
      "Epoch 356/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4785 - tp: 198.0000 - fp: 63.0000 - tn: 381.0000 - fn: 70.0000 - accuracy: 0.8132 - precision: 0.7586 - recall: 0.7388 - auc: 0.8751 - val_loss: 0.4758 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8949\n",
      "Epoch 357/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4796 - tp: 203.0000 - fp: 50.0000 - tn: 394.0000 - fn: 65.0000 - accuracy: 0.8385 - precision: 0.8024 - recall: 0.7575 - auc: 0.8689 - val_loss: 0.4753 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8954\n",
      "Epoch 358/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4933 - tp: 198.0000 - fp: 48.0000 - tn: 396.0000 - fn: 70.0000 - accuracy: 0.8343 - precision: 0.8049 - recall: 0.7388 - auc: 0.8694 - val_loss: 0.5046 - val_tp: 68.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 6.0000 - val_accuracy: 0.7877 - val_precision: 0.6800 - val_recall: 0.9189 - val_auc: 0.8932\n",
      "Epoch 359/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4887 - tp: 195.0000 - fp: 55.0000 - tn: 389.0000 - fn: 73.0000 - accuracy: 0.8202 - precision: 0.7800 - recall: 0.7276 - auc: 0.8688 - val_loss: 0.4714 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8957\n",
      "Epoch 360/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4874 - tp: 205.0000 - fp: 59.0000 - tn: 385.0000 - fn: 63.0000 - accuracy: 0.8287 - precision: 0.7765 - recall: 0.7649 - auc: 0.8725 - val_loss: 0.4640 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8995\n",
      "Epoch 361/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4922 - tp: 200.0000 - fp: 49.0000 - tn: 395.0000 - fn: 68.0000 - accuracy: 0.8357 - precision: 0.8032 - recall: 0.7463 - auc: 0.8637 - val_loss: 0.4662 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8976\n",
      "Epoch 362/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4947 - tp: 191.0000 - fp: 54.0000 - tn: 390.0000 - fn: 77.0000 - accuracy: 0.8160 - precision: 0.7796 - recall: 0.7127 - auc: 0.8588 - val_loss: 0.4695 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8944\n",
      "Epoch 363/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4841 - tp: 198.0000 - fp: 57.0000 - tn: 387.0000 - fn: 70.0000 - accuracy: 0.8216 - precision: 0.7765 - recall: 0.7388 - auc: 0.8716 - val_loss: 0.4760 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8923\n",
      "Epoch 364/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4829 - tp: 197.0000 - fp: 51.0000 - tn: 393.0000 - fn: 71.0000 - accuracy: 0.8287 - precision: 0.7944 - recall: 0.7351 - auc: 0.8688 - val_loss: 0.4768 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8962\n",
      "Epoch 365/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.4771 - tp: 203.0000 - fp: 53.0000 - tn: 391.0000 - fn: 65.0000 - accuracy: 0.8343 - precision: 0.7930 - recall: 0.7575 - auc: 0.8711 - val_loss: 0.4792 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8931\n",
      "Epoch 366/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4777 - tp: 207.0000 - fp: 48.0000 - tn: 396.0000 - fn: 61.0000 - accuracy: 0.8469 - precision: 0.8118 - recall: 0.7724 - auc: 0.8698 - val_loss: 0.4862 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8932\n",
      "Epoch 367/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4684 - tp: 206.0000 - fp: 57.0000 - tn: 387.0000 - fn: 62.0000 - accuracy: 0.8329 - precision: 0.7833 - recall: 0.7687 - auc: 0.8788 - val_loss: 0.4821 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8956\n",
      "Epoch 368/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4924 - tp: 197.0000 - fp: 43.0000 - tn: 401.0000 - fn: 71.0000 - accuracy: 0.8399 - precision: 0.8208 - recall: 0.7351 - auc: 0.8602 - val_loss: 0.4836 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8947\n",
      "Epoch 369/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4794 - tp: 195.0000 - fp: 54.0000 - tn: 390.0000 - fn: 73.0000 - accuracy: 0.8216 - precision: 0.7831 - recall: 0.7276 - auc: 0.8740 - val_loss: 0.4661 - val_tp: 62.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 12.0000 - val_accuracy: 0.8156 - val_precision: 0.7470 - val_recall: 0.8378 - val_auc: 0.8921\n",
      "Epoch 370/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4828 - tp: 210.0000 - fp: 67.0000 - tn: 377.0000 - fn: 58.0000 - accuracy: 0.8244 - precision: 0.7581 - recall: 0.7836 - auc: 0.8676 - val_loss: 0.4669 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8929\n",
      "Epoch 371/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4901 - tp: 198.0000 - fp: 44.0000 - tn: 400.0000 - fn: 70.0000 - accuracy: 0.8399 - precision: 0.8182 - recall: 0.7388 - auc: 0.8635 - val_loss: 0.4945 - val_tp: 65.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 9.0000 - val_accuracy: 0.7877 - val_precision: 0.6915 - val_recall: 0.8784 - val_auc: 0.8918\n",
      "Epoch 372/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4991 - tp: 205.0000 - fp: 64.0000 - tn: 380.0000 - fn: 63.0000 - accuracy: 0.8216 - precision: 0.7621 - recall: 0.7649 - auc: 0.8709 - val_loss: 0.4636 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8909\n",
      "Epoch 373/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4785 - tp: 202.0000 - fp: 56.0000 - tn: 388.0000 - fn: 66.0000 - accuracy: 0.8287 - precision: 0.7829 - recall: 0.7537 - auc: 0.8705 - val_loss: 0.4710 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8976\n",
      "Epoch 374/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4910 - tp: 204.0000 - fp: 54.0000 - tn: 390.0000 - fn: 64.0000 - accuracy: 0.8343 - precision: 0.7907 - recall: 0.7612 - auc: 0.8577 - val_loss: 0.4755 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8976\n",
      "Epoch 375/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4851 - tp: 199.0000 - fp: 45.0000 - tn: 399.0000 - fn: 69.0000 - accuracy: 0.8399 - precision: 0.8156 - recall: 0.7425 - auc: 0.8685 - val_loss: 0.4737 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8956\n",
      "Epoch 376/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4791 - tp: 202.0000 - fp: 54.0000 - tn: 390.0000 - fn: 66.0000 - accuracy: 0.8315 - precision: 0.7891 - recall: 0.7537 - auc: 0.8701 - val_loss: 0.4765 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8977\n",
      "Epoch 377/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4970 - tp: 194.0000 - fp: 50.0000 - tn: 394.0000 - fn: 74.0000 - accuracy: 0.8258 - precision: 0.7951 - recall: 0.7239 - auc: 0.8633 - val_loss: 0.4845 - val_tp: 54.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 20.0000 - val_accuracy: 0.8268 - val_precision: 0.8308 - val_recall: 0.7297 - val_auc: 0.8999\n",
      "Epoch 378/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4972 - tp: 201.0000 - fp: 70.0000 - tn: 374.0000 - fn: 67.0000 - accuracy: 0.8076 - precision: 0.7417 - recall: 0.7500 - auc: 0.8617 - val_loss: 0.4683 - val_tp: 59.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 15.0000 - val_accuracy: 0.8436 - val_precision: 0.8194 - val_recall: 0.7973 - val_auc: 0.8986\n",
      "Epoch 379/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4840 - tp: 208.0000 - fp: 55.0000 - tn: 389.0000 - fn: 60.0000 - accuracy: 0.8385 - precision: 0.7909 - recall: 0.7761 - auc: 0.8717 - val_loss: 0.4678 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8953\n",
      "Epoch 380/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4775 - tp: 202.0000 - fp: 46.0000 - tn: 398.0000 - fn: 66.0000 - accuracy: 0.8427 - precision: 0.8145 - recall: 0.7537 - auc: 0.8732 - val_loss: 0.4855 - val_tp: 64.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 10.0000 - val_accuracy: 0.7877 - val_precision: 0.6957 - val_recall: 0.8649 - val_auc: 0.8939\n",
      "Epoch 381/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4956 - tp: 196.0000 - fp: 52.0000 - tn: 392.0000 - fn: 72.0000 - accuracy: 0.8258 - precision: 0.7903 - recall: 0.7313 - auc: 0.8640 - val_loss: 0.4829 - val_tp: 64.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 10.0000 - val_accuracy: 0.8045 - val_precision: 0.7191 - val_recall: 0.8649 - val_auc: 0.8966\n",
      "Epoch 382/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4951 - tp: 203.0000 - fp: 62.0000 - tn: 382.0000 - fn: 65.0000 - accuracy: 0.8216 - precision: 0.7660 - recall: 0.7575 - auc: 0.8628 - val_loss: 0.4730 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8976\n",
      "Epoch 383/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5025 - tp: 206.0000 - fp: 53.0000 - tn: 391.0000 - fn: 62.0000 - accuracy: 0.8385 - precision: 0.7954 - recall: 0.7687 - auc: 0.8575 - val_loss: 0.4720 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8968\n",
      "Epoch 384/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4858 - tp: 204.0000 - fp: 57.0000 - tn: 387.0000 - fn: 64.0000 - accuracy: 0.8301 - precision: 0.7816 - recall: 0.7612 - auc: 0.8671 - val_loss: 0.4736 - val_tp: 60.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 14.0000 - val_accuracy: 0.8380 - val_precision: 0.8000 - val_recall: 0.8108 - val_auc: 0.8953\n",
      "Epoch 385/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4835 - tp: 206.0000 - fp: 50.0000 - tn: 394.0000 - fn: 62.0000 - accuracy: 0.8427 - precision: 0.8047 - recall: 0.7687 - auc: 0.8675 - val_loss: 0.4723 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8983\n",
      "Epoch 386/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4762 - tp: 204.0000 - fp: 51.0000 - tn: 393.0000 - fn: 64.0000 - accuracy: 0.8385 - precision: 0.8000 - recall: 0.7612 - auc: 0.8689 - val_loss: 0.4746 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8952\n",
      "Epoch 387/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4664 - tp: 209.0000 - fp: 67.0000 - tn: 377.0000 - fn: 59.0000 - accuracy: 0.8230 - precision: 0.7572 - recall: 0.7799 - auc: 0.8847 - val_loss: 0.4788 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8922\n",
      "Epoch 388/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4701 - tp: 204.0000 - fp: 51.0000 - tn: 393.0000 - fn: 64.0000 - accuracy: 0.8385 - precision: 0.8000 - recall: 0.7612 - auc: 0.8866 - val_loss: 0.4683 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8979\n",
      "Epoch 389/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4868 - tp: 191.0000 - fp: 52.0000 - tn: 392.0000 - fn: 77.0000 - accuracy: 0.8188 - precision: 0.7860 - recall: 0.7127 - auc: 0.8656 - val_loss: 0.4627 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8974\n",
      "Epoch 390/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.4800 - tp: 202.0000 - fp: 51.0000 - tn: 393.0000 - fn: 66.0000 - accuracy: 0.8357 - precision: 0.7984 - recall: 0.7537 - auc: 0.8700 - val_loss: 0.4704 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8955\n",
      "Epoch 391/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4839 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8710 - val_loss: 0.4729 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8959\n",
      "Epoch 392/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4856 - tp: 199.0000 - fp: 56.0000 - tn: 388.0000 - fn: 69.0000 - accuracy: 0.8244 - precision: 0.7804 - recall: 0.7425 - auc: 0.8730 - val_loss: 0.4677 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8926\n",
      "Epoch 393/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4927 - tp: 198.0000 - fp: 55.0000 - tn: 389.0000 - fn: 70.0000 - accuracy: 0.8244 - precision: 0.7826 - recall: 0.7388 - auc: 0.8633 - val_loss: 0.4702 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8982\n",
      "Epoch 394/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4762 - tp: 214.0000 - fp: 74.0000 - tn: 370.0000 - fn: 54.0000 - accuracy: 0.8202 - precision: 0.7431 - recall: 0.7985 - auc: 0.8742 - val_loss: 0.4759 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8939\n",
      "Epoch 395/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4875 - tp: 199.0000 - fp: 50.0000 - tn: 394.0000 - fn: 69.0000 - accuracy: 0.8329 - precision: 0.7992 - recall: 0.7425 - auc: 0.8703 - val_loss: 0.4751 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8961\n",
      "Epoch 396/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4875 - tp: 203.0000 - fp: 50.0000 - tn: 394.0000 - fn: 65.0000 - accuracy: 0.8385 - precision: 0.8024 - recall: 0.7575 - auc: 0.8679 - val_loss: 0.4696 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8942\n",
      "Epoch 397/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4805 - tp: 202.0000 - fp: 63.0000 - tn: 381.0000 - fn: 66.0000 - accuracy: 0.8188 - precision: 0.7623 - recall: 0.7537 - auc: 0.8669 - val_loss: 0.4688 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8956\n",
      "Epoch 398/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4812 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8733 - val_loss: 0.4643 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8982\n",
      "Epoch 399/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4810 - tp: 194.0000 - fp: 48.0000 - tn: 396.0000 - fn: 74.0000 - accuracy: 0.8287 - precision: 0.8017 - recall: 0.7239 - auc: 0.8657 - val_loss: 0.4755 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8956\n",
      "Epoch 400/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4935 - tp: 203.0000 - fp: 64.0000 - tn: 380.0000 - fn: 65.0000 - accuracy: 0.8188 - precision: 0.7603 - recall: 0.7575 - auc: 0.8642 - val_loss: 0.4749 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8947\n",
      "Epoch 401/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4858 - tp: 193.0000 - fp: 50.0000 - tn: 394.0000 - fn: 75.0000 - accuracy: 0.8244 - precision: 0.7942 - recall: 0.7201 - auc: 0.8690 - val_loss: 0.4703 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8996\n",
      "Epoch 402/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4665 - tp: 206.0000 - fp: 51.0000 - tn: 393.0000 - fn: 62.0000 - accuracy: 0.8413 - precision: 0.8016 - recall: 0.7687 - auc: 0.8827 - val_loss: 0.4725 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8932\n",
      "Epoch 403/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4918 - tp: 199.0000 - fp: 42.0000 - tn: 402.0000 - fn: 69.0000 - accuracy: 0.8441 - precision: 0.8257 - recall: 0.7425 - auc: 0.8613 - val_loss: 0.4864 - val_tp: 64.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 10.0000 - val_accuracy: 0.7989 - val_precision: 0.7111 - val_recall: 0.8649 - val_auc: 0.8954\n",
      "Epoch 404/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4947 - tp: 201.0000 - fp: 57.0000 - tn: 387.0000 - fn: 67.0000 - accuracy: 0.8258 - precision: 0.7791 - recall: 0.7500 - auc: 0.8632 - val_loss: 0.4661 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8957\n",
      "Epoch 405/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4918 - tp: 200.0000 - fp: 49.0000 - tn: 395.0000 - fn: 68.0000 - accuracy: 0.8357 - precision: 0.8032 - recall: 0.7463 - auc: 0.8574 - val_loss: 0.4745 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8977\n",
      "Epoch 406/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4785 - tp: 212.0000 - fp: 51.0000 - tn: 393.0000 - fn: 56.0000 - accuracy: 0.8497 - precision: 0.8061 - recall: 0.7910 - auc: 0.8707 - val_loss: 0.4876 - val_tp: 54.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 20.0000 - val_accuracy: 0.8212 - val_precision: 0.8182 - val_recall: 0.7297 - val_auc: 0.8909\n",
      "Epoch 407/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4852 - tp: 198.0000 - fp: 46.0000 - tn: 398.0000 - fn: 70.0000 - accuracy: 0.8371 - precision: 0.8115 - recall: 0.7388 - auc: 0.8692 - val_loss: 0.4749 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8940\n",
      "Epoch 408/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4716 - tp: 200.0000 - fp: 54.0000 - tn: 390.0000 - fn: 68.0000 - accuracy: 0.8287 - precision: 0.7874 - recall: 0.7463 - auc: 0.8818 - val_loss: 0.4681 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8993\n",
      "Epoch 409/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4800 - tp: 206.0000 - fp: 52.0000 - tn: 392.0000 - fn: 62.0000 - accuracy: 0.8399 - precision: 0.7984 - recall: 0.7687 - auc: 0.8735 - val_loss: 0.4594 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8961\n",
      "Epoch 410/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4847 - tp: 202.0000 - fp: 53.0000 - tn: 391.0000 - fn: 66.0000 - accuracy: 0.8329 - precision: 0.7922 - recall: 0.7537 - auc: 0.8707 - val_loss: 0.4709 - val_tp: 65.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 9.0000 - val_accuracy: 0.8101 - val_precision: 0.7222 - val_recall: 0.8784 - val_auc: 0.8976\n",
      "Epoch 411/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4888 - tp: 211.0000 - fp: 69.0000 - tn: 375.0000 - fn: 57.0000 - accuracy: 0.8230 - precision: 0.7536 - recall: 0.7873 - auc: 0.8709 - val_loss: 0.4655 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8961\n",
      "Epoch 412/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4951 - tp: 205.0000 - fp: 67.0000 - tn: 377.0000 - fn: 63.0000 - accuracy: 0.8174 - precision: 0.7537 - recall: 0.7649 - auc: 0.8600 - val_loss: 0.4748 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8945\n",
      "Epoch 413/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4937 - tp: 194.0000 - fp: 46.0000 - tn: 398.0000 - fn: 74.0000 - accuracy: 0.8315 - precision: 0.8083 - recall: 0.7239 - auc: 0.8687 - val_loss: 0.4735 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 14.0000 - val_accuracy: 0.8268 - val_precision: 0.7792 - val_recall: 0.8108 - val_auc: 0.8986\n",
      "Epoch 414/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4754 - tp: 197.0000 - fp: 45.0000 - tn: 399.0000 - fn: 71.0000 - accuracy: 0.8371 - precision: 0.8140 - recall: 0.7351 - auc: 0.8765 - val_loss: 0.4778 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 14.0000 - val_accuracy: 0.8156 - val_precision: 0.7595 - val_recall: 0.8108 - val_auc: 0.8956\n",
      "Epoch 415/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4898 - tp: 201.0000 - fp: 62.0000 - tn: 382.0000 - fn: 67.0000 - accuracy: 0.8188 - precision: 0.7643 - recall: 0.7500 - auc: 0.8630 - val_loss: 0.4683 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8977\n",
      "Epoch 416/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4781 - tp: 198.0000 - fp: 55.0000 - tn: 389.0000 - fn: 70.0000 - accuracy: 0.8244 - precision: 0.7826 - recall: 0.7388 - auc: 0.8746 - val_loss: 0.4778 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8918\n",
      "Epoch 417/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4900 - tp: 201.0000 - fp: 47.0000 - tn: 397.0000 - fn: 67.0000 - accuracy: 0.8399 - precision: 0.8105 - recall: 0.7500 - auc: 0.8698 - val_loss: 0.4821 - val_tp: 64.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 10.0000 - val_accuracy: 0.8101 - val_precision: 0.7273 - val_recall: 0.8649 - val_auc: 0.8941\n",
      "Epoch 418/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4875 - tp: 194.0000 - fp: 49.0000 - tn: 395.0000 - fn: 74.0000 - accuracy: 0.8272 - precision: 0.7984 - recall: 0.7239 - auc: 0.8710 - val_loss: 0.4705 - val_tp: 64.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 10.0000 - val_accuracy: 0.8045 - val_precision: 0.7191 - val_recall: 0.8649 - val_auc: 0.8988\n",
      "Epoch 419/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4984 - tp: 197.0000 - fp: 50.0000 - tn: 394.0000 - fn: 71.0000 - accuracy: 0.8301 - precision: 0.7976 - recall: 0.7351 - auc: 0.8608 - val_loss: 0.4690 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8974\n",
      "Epoch 420/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4741 - tp: 204.0000 - fp: 56.0000 - tn: 388.0000 - fn: 64.0000 - accuracy: 0.8315 - precision: 0.7846 - recall: 0.7612 - auc: 0.8744 - val_loss: 0.4835 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.8947\n",
      "Epoch 421/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4901 - tp: 195.0000 - fp: 51.0000 - tn: 393.0000 - fn: 73.0000 - accuracy: 0.8258 - precision: 0.7927 - recall: 0.7276 - auc: 0.8644 - val_loss: 0.4716 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8981\n",
      "Epoch 422/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4961 - tp: 197.0000 - fp: 55.0000 - tn: 389.0000 - fn: 71.0000 - accuracy: 0.8230 - precision: 0.7817 - recall: 0.7351 - auc: 0.8606 - val_loss: 0.4756 - val_tp: 61.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 13.0000 - val_accuracy: 0.7989 - val_precision: 0.7262 - val_recall: 0.8243 - val_auc: 0.8967\n",
      "Epoch 423/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4807 - tp: 202.0000 - fp: 47.0000 - tn: 397.0000 - fn: 66.0000 - accuracy: 0.8413 - precision: 0.8112 - recall: 0.7537 - auc: 0.8723 - val_loss: 0.4827 - val_tp: 63.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 11.0000 - val_accuracy: 0.7989 - val_precision: 0.7159 - val_recall: 0.8514 - val_auc: 0.8931\n",
      "Epoch 424/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4851 - tp: 210.0000 - fp: 56.0000 - tn: 388.0000 - fn: 58.0000 - accuracy: 0.8399 - precision: 0.7895 - recall: 0.7836 - auc: 0.8688 - val_loss: 0.4658 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8932\n",
      "Epoch 425/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4777 - tp: 207.0000 - fp: 59.0000 - tn: 385.0000 - fn: 61.0000 - accuracy: 0.8315 - precision: 0.7782 - recall: 0.7724 - auc: 0.8773 - val_loss: 0.4617 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8959\n",
      "Epoch 426/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4748 - tp: 203.0000 - fp: 44.0000 - tn: 400.0000 - fn: 65.0000 - accuracy: 0.8469 - precision: 0.8219 - recall: 0.7575 - auc: 0.8703 - val_loss: 0.4804 - val_tp: 68.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 6.0000 - val_accuracy: 0.8101 - val_precision: 0.7083 - val_recall: 0.9189 - val_auc: 0.8969\n",
      "Epoch 427/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4916 - tp: 205.0000 - fp: 75.0000 - tn: 369.0000 - fn: 63.0000 - accuracy: 0.8062 - precision: 0.7321 - recall: 0.7649 - auc: 0.8669 - val_loss: 0.4650 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8988\n",
      "Epoch 428/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4746 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8765 - val_loss: 0.4612 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.9015\n",
      "Epoch 429/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4938 - tp: 203.0000 - fp: 62.0000 - tn: 382.0000 - fn: 65.0000 - accuracy: 0.8216 - precision: 0.7660 - recall: 0.7575 - auc: 0.8613 - val_loss: 0.4606 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8979\n",
      "Epoch 430/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4740 - tp: 200.0000 - fp: 49.0000 - tn: 395.0000 - fn: 68.0000 - accuracy: 0.8357 - precision: 0.8032 - recall: 0.7463 - auc: 0.8711 - val_loss: 0.4650 - val_tp: 63.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 11.0000 - val_accuracy: 0.8212 - val_precision: 0.7500 - val_recall: 0.8514 - val_auc: 0.9005\n",
      "Epoch 431/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.4736 - tp: 205.0000 - fp: 56.0000 - tn: 388.0000 - fn: 63.0000 - accuracy: 0.8329 - precision: 0.7854 - recall: 0.7649 - auc: 0.8721 - val_loss: 0.4678 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8976\n",
      "Epoch 432/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4696 - tp: 201.0000 - fp: 61.0000 - tn: 383.0000 - fn: 67.0000 - accuracy: 0.8202 - precision: 0.7672 - recall: 0.7500 - auc: 0.8777 - val_loss: 0.4630 - val_tp: 62.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 12.0000 - val_accuracy: 0.8380 - val_precision: 0.7848 - val_recall: 0.8378 - val_auc: 0.8974\n",
      "Epoch 433/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4821 - tp: 209.0000 - fp: 69.0000 - tn: 375.0000 - fn: 59.0000 - accuracy: 0.8202 - precision: 0.7518 - recall: 0.7799 - auc: 0.8703 - val_loss: 0.4607 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8950\n",
      "Epoch 434/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4701 - tp: 201.0000 - fp: 46.0000 - tn: 398.0000 - fn: 67.0000 - accuracy: 0.8413 - precision: 0.8138 - recall: 0.7500 - auc: 0.8794 - val_loss: 0.4620 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.9005\n",
      "Epoch 435/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4739 - tp: 201.0000 - fp: 62.0000 - tn: 382.0000 - fn: 67.0000 - accuracy: 0.8188 - precision: 0.7643 - recall: 0.7500 - auc: 0.8830 - val_loss: 0.4586 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8941\n",
      "Epoch 436/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4934 - tp: 198.0000 - fp: 50.0000 - tn: 394.0000 - fn: 70.0000 - accuracy: 0.8315 - precision: 0.7984 - recall: 0.7388 - auc: 0.8676 - val_loss: 0.4642 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8983\n",
      "Epoch 437/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4774 - tp: 205.0000 - fp: 56.0000 - tn: 388.0000 - fn: 63.0000 - accuracy: 0.8329 - precision: 0.7854 - recall: 0.7649 - auc: 0.8697 - val_loss: 0.4721 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8992\n",
      "Epoch 438/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4879 - tp: 196.0000 - fp: 44.0000 - tn: 400.0000 - fn: 72.0000 - accuracy: 0.8371 - precision: 0.8167 - recall: 0.7313 - auc: 0.8682 - val_loss: 0.4668 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8976\n",
      "Epoch 439/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4814 - tp: 202.0000 - fp: 56.0000 - tn: 388.0000 - fn: 66.0000 - accuracy: 0.8287 - precision: 0.7829 - recall: 0.7537 - auc: 0.8721 - val_loss: 0.4673 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8965\n",
      "Epoch 440/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4658 - tp: 209.0000 - fp: 56.0000 - tn: 388.0000 - fn: 59.0000 - accuracy: 0.8385 - precision: 0.7887 - recall: 0.7799 - auc: 0.8814 - val_loss: 0.4701 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 18.0000 - val_accuracy: 0.8324 - val_precision: 0.8235 - val_recall: 0.7568 - val_auc: 0.8974\n",
      "Epoch 441/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4777 - tp: 197.0000 - fp: 44.0000 - tn: 400.0000 - fn: 71.0000 - accuracy: 0.8385 - precision: 0.8174 - recall: 0.7351 - auc: 0.8668 - val_loss: 0.4755 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.9030\n",
      "Epoch 442/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4752 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8718 - val_loss: 0.4658 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 14.0000 - val_accuracy: 0.8324 - val_precision: 0.7895 - val_recall: 0.8108 - val_auc: 0.8978\n",
      "Epoch 443/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4899 - tp: 193.0000 - fp: 44.0000 - tn: 400.0000 - fn: 75.0000 - accuracy: 0.8329 - precision: 0.8143 - recall: 0.7201 - auc: 0.8642 - val_loss: 0.4653 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.9003\n",
      "Epoch 444/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4891 - tp: 201.0000 - fp: 61.0000 - tn: 383.0000 - fn: 67.0000 - accuracy: 0.8202 - precision: 0.7672 - recall: 0.7500 - auc: 0.8634 - val_loss: 0.4628 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8983\n",
      "Epoch 445/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4824 - tp: 197.0000 - fp: 54.0000 - tn: 390.0000 - fn: 71.0000 - accuracy: 0.8244 - precision: 0.7849 - recall: 0.7351 - auc: 0.8634 - val_loss: 0.4658 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8977\n",
      "Epoch 446/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4663 - tp: 204.0000 - fp: 53.0000 - tn: 391.0000 - fn: 64.0000 - accuracy: 0.8357 - precision: 0.7938 - recall: 0.7612 - auc: 0.8821 - val_loss: 0.4660 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 16.0000 - val_accuracy: 0.8380 - val_precision: 0.8169 - val_recall: 0.7838 - val_auc: 0.8983\n",
      "Epoch 447/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4819 - tp: 199.0000 - fp: 49.0000 - tn: 395.0000 - fn: 69.0000 - accuracy: 0.8343 - precision: 0.8024 - recall: 0.7425 - auc: 0.8709 - val_loss: 0.4659 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.9037\n",
      "Epoch 448/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4753 - tp: 206.0000 - fp: 50.0000 - tn: 394.0000 - fn: 62.0000 - accuracy: 0.8427 - precision: 0.8047 - recall: 0.7687 - auc: 0.8756 - val_loss: 0.4631 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8978\n",
      "Epoch 449/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4895 - tp: 199.0000 - fp: 52.0000 - tn: 392.0000 - fn: 69.0000 - accuracy: 0.8301 - precision: 0.7928 - recall: 0.7425 - auc: 0.8619 - val_loss: 0.4639 - val_tp: 67.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 7.0000 - val_accuracy: 0.8212 - val_precision: 0.7283 - val_recall: 0.9054 - val_auc: 0.9025\n",
      "Epoch 450/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4910 - tp: 205.0000 - fp: 59.0000 - tn: 385.0000 - fn: 63.0000 - accuracy: 0.8287 - precision: 0.7765 - recall: 0.7649 - auc: 0.8641 - val_loss: 0.4633 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.9015\n",
      "Epoch 451/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4727 - tp: 200.0000 - fp: 56.0000 - tn: 388.0000 - fn: 68.0000 - accuracy: 0.8258 - precision: 0.7812 - recall: 0.7463 - auc: 0.8771 - val_loss: 0.4675 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8989\n",
      "Epoch 452/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4921 - tp: 203.0000 - fp: 59.0000 - tn: 385.0000 - fn: 65.0000 - accuracy: 0.8258 - precision: 0.7748 - recall: 0.7575 - auc: 0.8632 - val_loss: 0.4712 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.9014\n",
      "Epoch 453/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4728 - tp: 205.0000 - fp: 44.0000 - tn: 400.0000 - fn: 63.0000 - accuracy: 0.8497 - precision: 0.8233 - recall: 0.7649 - auc: 0.8724 - val_loss: 0.4647 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.9001\n",
      "Epoch 454/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4815 - tp: 198.0000 - fp: 47.0000 - tn: 397.0000 - fn: 70.0000 - accuracy: 0.8357 - precision: 0.8082 - recall: 0.7388 - auc: 0.8677 - val_loss: 0.4625 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.9040\n",
      "Epoch 455/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4734 - tp: 207.0000 - fp: 58.0000 - tn: 386.0000 - fn: 61.0000 - accuracy: 0.8329 - precision: 0.7811 - recall: 0.7724 - auc: 0.8776 - val_loss: 0.4658 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.9015\n",
      "Epoch 456/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4955 - tp: 198.0000 - fp: 58.0000 - tn: 386.0000 - fn: 70.0000 - accuracy: 0.8202 - precision: 0.7734 - recall: 0.7388 - auc: 0.8649 - val_loss: 0.4613 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.9031\n",
      "Epoch 457/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4689 - tp: 201.0000 - fp: 48.0000 - tn: 396.0000 - fn: 67.0000 - accuracy: 0.8385 - precision: 0.8072 - recall: 0.7500 - auc: 0.8826 - val_loss: 0.4687 - val_tp: 61.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 13.0000 - val_accuracy: 0.8212 - val_precision: 0.7625 - val_recall: 0.8243 - val_auc: 0.8995\n",
      "Epoch 458/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4797 - tp: 196.0000 - fp: 53.0000 - tn: 391.0000 - fn: 72.0000 - accuracy: 0.8244 - precision: 0.7871 - recall: 0.7313 - auc: 0.8673 - val_loss: 0.4683 - val_tp: 67.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 7.0000 - val_accuracy: 0.8212 - val_precision: 0.7283 - val_recall: 0.9054 - val_auc: 0.8985\n",
      "Epoch 459/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4852 - tp: 202.0000 - fp: 61.0000 - tn: 383.0000 - fn: 66.0000 - accuracy: 0.8216 - precision: 0.7681 - recall: 0.7537 - auc: 0.8694 - val_loss: 0.4664 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.9012\n",
      "Epoch 460/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4793 - tp: 203.0000 - fp: 51.0000 - tn: 393.0000 - fn: 65.0000 - accuracy: 0.8371 - precision: 0.7992 - recall: 0.7575 - auc: 0.8721 - val_loss: 0.4676 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.9014\n",
      "Epoch 461/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4779 - tp: 205.0000 - fp: 61.0000 - tn: 383.0000 - fn: 63.0000 - accuracy: 0.8258 - precision: 0.7707 - recall: 0.7649 - auc: 0.8692 - val_loss: 0.4705 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 16.0000 - val_accuracy: 0.8324 - val_precision: 0.8056 - val_recall: 0.7838 - val_auc: 0.8946\n",
      "Epoch 462/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4739 - tp: 200.0000 - fp: 55.0000 - tn: 389.0000 - fn: 68.0000 - accuracy: 0.8272 - precision: 0.7843 - recall: 0.7463 - auc: 0.8772 - val_loss: 0.4665 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 16.0000 - val_accuracy: 0.8268 - val_precision: 0.7945 - val_recall: 0.7838 - val_auc: 0.8959\n",
      "Epoch 463/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4896 - tp: 196.0000 - fp: 62.0000 - tn: 382.0000 - fn: 72.0000 - accuracy: 0.8118 - precision: 0.7597 - recall: 0.7313 - auc: 0.8725 - val_loss: 0.4665 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8998\n",
      "Epoch 464/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4843 - tp: 206.0000 - fp: 65.0000 - tn: 379.0000 - fn: 62.0000 - accuracy: 0.8216 - precision: 0.7601 - recall: 0.7687 - auc: 0.8657 - val_loss: 0.4655 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8994\n",
      "Epoch 465/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4733 - tp: 207.0000 - fp: 46.0000 - tn: 398.0000 - fn: 61.0000 - accuracy: 0.8497 - precision: 0.8182 - recall: 0.7724 - auc: 0.8724 - val_loss: 0.4659 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8938\n",
      "Epoch 466/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4731 - tp: 204.0000 - fp: 57.0000 - tn: 387.0000 - fn: 64.0000 - accuracy: 0.8301 - precision: 0.7816 - recall: 0.7612 - auc: 0.8722 - val_loss: 0.4719 - val_tp: 64.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 10.0000 - val_accuracy: 0.8324 - val_precision: 0.7619 - val_recall: 0.8649 - val_auc: 0.9017\n",
      "Epoch 467/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4868 - tp: 208.0000 - fp: 61.0000 - tn: 383.0000 - fn: 60.0000 - accuracy: 0.8301 - precision: 0.7732 - recall: 0.7761 - auc: 0.8717 - val_loss: 0.4632 - val_tp: 63.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 11.0000 - val_accuracy: 0.8268 - val_precision: 0.7590 - val_recall: 0.8514 - val_auc: 0.8969\n",
      "Epoch 468/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4614 - tp: 208.0000 - fp: 51.0000 - tn: 393.0000 - fn: 60.0000 - accuracy: 0.8441 - precision: 0.8031 - recall: 0.7761 - auc: 0.8826 - val_loss: 0.4657 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.9001\n",
      "Epoch 469/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4878 - tp: 205.0000 - fp: 67.0000 - tn: 377.0000 - fn: 63.0000 - accuracy: 0.8174 - precision: 0.7537 - recall: 0.7649 - auc: 0.8724 - val_loss: 0.4663 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8969\n",
      "Epoch 470/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4698 - tp: 208.0000 - fp: 60.0000 - tn: 384.0000 - fn: 60.0000 - accuracy: 0.8315 - precision: 0.7761 - recall: 0.7761 - auc: 0.8808 - val_loss: 0.4637 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8961\n",
      "Epoch 471/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4763 - tp: 198.0000 - fp: 42.0000 - tn: 402.0000 - fn: 70.0000 - accuracy: 0.8427 - precision: 0.8250 - recall: 0.7388 - auc: 0.8745 - val_loss: 0.4677 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8983\n",
      "Epoch 472/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4851 - tp: 205.0000 - fp: 53.0000 - tn: 391.0000 - fn: 63.0000 - accuracy: 0.8371 - precision: 0.7946 - recall: 0.7649 - auc: 0.8696 - val_loss: 0.4697 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8967\n",
      "Epoch 473/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4887 - tp: 205.0000 - fp: 58.0000 - tn: 386.0000 - fn: 63.0000 - accuracy: 0.8301 - precision: 0.7795 - recall: 0.7649 - auc: 0.8663 - val_loss: 0.4716 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8971\n",
      "Epoch 474/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4699 - tp: 195.0000 - fp: 46.0000 - tn: 398.0000 - fn: 73.0000 - accuracy: 0.8329 - precision: 0.8091 - recall: 0.7276 - auc: 0.8823 - val_loss: 0.4690 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8997\n",
      "Epoch 475/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4756 - tp: 201.0000 - fp: 52.0000 - tn: 392.0000 - fn: 67.0000 - accuracy: 0.8329 - precision: 0.7945 - recall: 0.7500 - auc: 0.8743 - val_loss: 0.4699 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 15.0000 - val_accuracy: 0.8324 - val_precision: 0.7973 - val_recall: 0.7973 - val_auc: 0.8943\n",
      "Epoch 476/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4777 - tp: 197.0000 - fp: 49.0000 - tn: 395.0000 - fn: 71.0000 - accuracy: 0.8315 - precision: 0.8008 - recall: 0.7351 - auc: 0.8739 - val_loss: 0.4690 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 13.0000 - val_accuracy: 0.8268 - val_precision: 0.7722 - val_recall: 0.8243 - val_auc: 0.8987\n",
      "Epoch 477/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4761 - tp: 207.0000 - fp: 60.0000 - tn: 384.0000 - fn: 61.0000 - accuracy: 0.8301 - precision: 0.7753 - recall: 0.7724 - auc: 0.8761 - val_loss: 0.4763 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 19.0000 - val_accuracy: 0.8268 - val_precision: 0.8209 - val_recall: 0.7432 - val_auc: 0.9060\n",
      "Epoch 478/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4707 - tp: 196.0000 - fp: 43.0000 - tn: 401.0000 - fn: 72.0000 - accuracy: 0.8385 - precision: 0.8201 - recall: 0.7313 - auc: 0.8748 - val_loss: 0.4682 - val_tp: 62.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 12.0000 - val_accuracy: 0.8268 - val_precision: 0.7654 - val_recall: 0.8378 - val_auc: 0.8979\n",
      "Epoch 479/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.4740 - tp: 202.0000 - fp: 45.0000 - tn: 399.0000 - fn: 66.0000 - accuracy: 0.8441 - precision: 0.8178 - recall: 0.7537 - auc: 0.8722 - val_loss: 0.4644 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.9084\n",
      "Epoch 480/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.4858 - tp: 207.0000 - fp: 56.0000 - tn: 388.0000 - fn: 61.0000 - accuracy: 0.8357 - precision: 0.7871 - recall: 0.7724 - auc: 0.8662 - val_loss: 0.4613 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.9028\n",
      "Epoch 481/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4817 - tp: 198.0000 - fp: 55.0000 - tn: 389.0000 - fn: 70.0000 - accuracy: 0.8244 - precision: 0.7826 - recall: 0.7388 - auc: 0.8693 - val_loss: 0.4638 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8996\n",
      "Epoch 482/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4746 - tp: 199.0000 - fp: 37.0000 - tn: 407.0000 - fn: 69.0000 - accuracy: 0.8511 - precision: 0.8432 - recall: 0.7425 - auc: 0.8669 - val_loss: 0.4674 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8990\n",
      "Epoch 483/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4757 - tp: 193.0000 - fp: 42.0000 - tn: 402.0000 - fn: 75.0000 - accuracy: 0.8357 - precision: 0.8213 - recall: 0.7201 - auc: 0.8721 - val_loss: 0.4645 - val_tp: 62.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 12.0000 - val_accuracy: 0.8268 - val_precision: 0.7654 - val_recall: 0.8378 - val_auc: 0.8981\n",
      "Epoch 484/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4860 - tp: 210.0000 - fp: 69.0000 - tn: 375.0000 - fn: 58.0000 - accuracy: 0.8216 - precision: 0.7527 - recall: 0.7836 - auc: 0.8710 - val_loss: 0.4772 - val_tp: 55.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 19.0000 - val_accuracy: 0.8380 - val_precision: 0.8462 - val_recall: 0.7432 - val_auc: 0.8994\n",
      "Epoch 485/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4912 - tp: 201.0000 - fp: 55.0000 - tn: 389.0000 - fn: 67.0000 - accuracy: 0.8287 - precision: 0.7852 - recall: 0.7500 - auc: 0.8610 - val_loss: 0.4703 - val_tp: 67.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 7.0000 - val_accuracy: 0.8324 - val_precision: 0.7444 - val_recall: 0.9054 - val_auc: 0.9017\n",
      "Epoch 486/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4760 - tp: 197.0000 - fp: 41.0000 - tn: 403.0000 - fn: 71.0000 - accuracy: 0.8427 - precision: 0.8277 - recall: 0.7351 - auc: 0.8692 - val_loss: 0.4656 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.9029\n",
      "Epoch 487/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4693 - tp: 203.0000 - fp: 52.0000 - tn: 392.0000 - fn: 65.0000 - accuracy: 0.8357 - precision: 0.7961 - recall: 0.7575 - auc: 0.8848 - val_loss: 0.4694 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.8981\n",
      "Epoch 488/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4843 - tp: 206.0000 - fp: 62.0000 - tn: 382.0000 - fn: 62.0000 - accuracy: 0.8258 - precision: 0.7687 - recall: 0.7687 - auc: 0.8632 - val_loss: 0.4643 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.9006\n",
      "Epoch 489/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4698 - tp: 207.0000 - fp: 58.0000 - tn: 386.0000 - fn: 61.0000 - accuracy: 0.8329 - precision: 0.7811 - recall: 0.7724 - auc: 0.8778 - val_loss: 0.4658 - val_tp: 57.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 17.0000 - val_accuracy: 0.8380 - val_precision: 0.8261 - val_recall: 0.7703 - val_auc: 0.8956\n",
      "Epoch 490/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4804 - tp: 194.0000 - fp: 45.0000 - tn: 399.0000 - fn: 74.0000 - accuracy: 0.8329 - precision: 0.8117 - recall: 0.7239 - auc: 0.8714 - val_loss: 0.4722 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.9021\n",
      "Epoch 491/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4698 - tp: 199.0000 - fp: 39.0000 - tn: 405.0000 - fn: 69.0000 - accuracy: 0.8483 - precision: 0.8361 - recall: 0.7425 - auc: 0.8779 - val_loss: 0.4672 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8977\n",
      "Epoch 492/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4734 - tp: 209.0000 - fp: 59.0000 - tn: 385.0000 - fn: 59.0000 - accuracy: 0.8343 - precision: 0.7799 - recall: 0.7799 - auc: 0.8724 - val_loss: 0.4686 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8979\n",
      "Epoch 493/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4747 - tp: 209.0000 - fp: 61.0000 - tn: 383.0000 - fn: 59.0000 - accuracy: 0.8315 - precision: 0.7741 - recall: 0.7799 - auc: 0.8696 - val_loss: 0.4633 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 15.0000 - val_accuracy: 0.8268 - val_precision: 0.7867 - val_recall: 0.7973 - val_auc: 0.8962\n",
      "Epoch 494/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4748 - tp: 203.0000 - fp: 51.0000 - tn: 393.0000 - fn: 65.0000 - accuracy: 0.8371 - precision: 0.7992 - recall: 0.7575 - auc: 0.8759 - val_loss: 0.4632 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8975\n",
      "Epoch 495/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4699 - tp: 195.0000 - fp: 38.0000 - tn: 406.0000 - fn: 73.0000 - accuracy: 0.8441 - precision: 0.8369 - recall: 0.7276 - auc: 0.8792 - val_loss: 0.4734 - val_tp: 64.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 10.0000 - val_accuracy: 0.8324 - val_precision: 0.7619 - val_recall: 0.8649 - val_auc: 0.9002\n",
      "Epoch 496/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4753 - tp: 208.0000 - fp: 49.0000 - tn: 395.0000 - fn: 60.0000 - accuracy: 0.8469 - precision: 0.8093 - recall: 0.7761 - auc: 0.8725 - val_loss: 0.4622 - val_tp: 58.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 16.0000 - val_accuracy: 0.8212 - val_precision: 0.7838 - val_recall: 0.7838 - val_auc: 0.8961\n",
      "Epoch 497/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4675 - tp: 201.0000 - fp: 53.0000 - tn: 391.0000 - fn: 67.0000 - accuracy: 0.8315 - precision: 0.7913 - recall: 0.7500 - auc: 0.8805 - val_loss: 0.4701 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.9035\n",
      "Epoch 498/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4714 - tp: 203.0000 - fp: 49.0000 - tn: 395.0000 - fn: 65.0000 - accuracy: 0.8399 - precision: 0.8056 - recall: 0.7575 - auc: 0.8744 - val_loss: 0.4638 - val_tp: 59.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 15.0000 - val_accuracy: 0.8380 - val_precision: 0.8082 - val_recall: 0.7973 - val_auc: 0.8940\n",
      "Epoch 499/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4963 - tp: 197.0000 - fp: 62.0000 - tn: 382.0000 - fn: 71.0000 - accuracy: 0.8132 - precision: 0.7606 - recall: 0.7351 - auc: 0.8583 - val_loss: 0.4662 - val_tp: 59.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 15.0000 - val_accuracy: 0.8212 - val_precision: 0.7763 - val_recall: 0.7973 - val_auc: 0.9010\n",
      "Epoch 500/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4854 - tp: 201.0000 - fp: 57.0000 - tn: 387.0000 - fn: 67.0000 - accuracy: 0.8258 - precision: 0.7791 - recall: 0.7500 - auc: 0.8650 - val_loss: 0.4693 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8947\n"
     ]
    }
   ],
   "source": [
    "# Create a new model each time before running training (otherwise new trainings would just be on already trained model)\n",
    "model = get_model(X_train.shape[1])\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=500, batch_size=32, validation_data=(X_dev, Y_dev), class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Results of the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.plot(history.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'tp', 'fp', 'tn', 'fn', 'accuracy', 'precision', 'recall', 'auc', 'val_loss', 'val_tp', 'val_fp', 'val_tn', 'val_fn', 'val_accuracy', 'val_precision', 'val_recall', 'val_auc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(evaluation_result, label):\n",
    "    # TP FP\n",
    "    # FN TN\n",
    "    matrix = np.round(np.array([[evaluation_result[1], evaluation_result[2]], [evaluation_result[4], evaluation_result[3]]]))\n",
    "    \n",
    "    plt.figure(figsize=(4,3))\n",
    "    \n",
    "    ax = sns.heatmap(data=matrix, annot=True, fmt=\".0f\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.invert_xaxis()\n",
    "    \n",
    "    plt.xlabel(\"True\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.title(f\"Confusion matrix for {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train evaluation:\n",
      "712/712 - 1s - loss: 0.4405 - tp: 200.0000 - fp: 39.0000 - tn: 405.0000 - fn: 68.0000 - accuracy: 0.8497 - precision: 0.8368 - recall: 0.7463 - auc: 0.8798\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train evaluation:\")\n",
    "evaluation_train = model.evaluate(X_train, Y_train, verbose=2)\n",
    "draw_confusion_matrix(evaluation_train, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev evaluation:\n",
      "179/179 - 0s - loss: 0.4769 - tp: 57.0000 - fp: 15.0000 - tn: 90.0000 - fn: 17.0000 - accuracy: 0.8212 - precision: 0.7917 - recall: 0.7703 - auc: 0.8947\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Dev evaluation:\")\n",
    "evaluation_dev = model.evaluate(X_dev, Y_dev, verbose=2)\n",
    "draw_confusion_matrix(evaluation_dev, \"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Predict with DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_predictions(model, submission_name):\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    predictions = np.round(predictions).astype(np.uint8).reshape((-1))\n",
    "\n",
    "    print(f\"{submission_name}:\\n{predictions}\")\n",
    "    \n",
    "    output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "    output.to_csv(f\"{submission_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "store_predictions(model, \"dl_submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Tune hyperparameters for the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt\n",
    "\n",
    "# https://www.sicara.ai/blog/hyperparameter-tuning-keras-tuner\n",
    "# https://www.curiousily.com/posts/hackers-guide-to-hyperparameter-tuning/\n",
    "\n",
    "class TitanicHyperModel(kt.HyperModel):\n",
    "    def __init__(self, input_size):\n",
    "        self.input_shape = (input_size, )\n",
    "\n",
    "    def build(self, hp):\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import Dense, Dropout, InputLayer\n",
    "        from tensorflow.keras.regularizers import L1L2\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(input_shape=self.input_shape))\n",
    "        \n",
    "        for layer_n in range(hp.Int(\"num_layers\", min_value=2, max_value=7, step=1, default=3)):\n",
    "            units = hp.Int(\n",
    "                f\"dense_units_{layer_n}\",\n",
    "                min_value=8,\n",
    "                max_value=64,\n",
    "                step=8,\n",
    "                default=64\n",
    "            )\n",
    "            activation = hp.Choice(\n",
    "                f\"dense_activation_{layer_n}\",\n",
    "                values=[\"relu\", \"tanh\", \"sigmoid\"],\n",
    "                default=\"relu\"\n",
    "            )\n",
    "            regularizer_l1 = hp.Choice(\n",
    "                f\"l1_{layer_n}\",\n",
    "                values=[1e-2, 1e-3, 1e-4, 1e-5, 0.0],\n",
    "                default=1e-2\n",
    "            )\n",
    "            regularizer_l2 = hp.Choice(\n",
    "                f\"l2_{layer_n}\",\n",
    "                values=[1e-2, 1e-3, 1e-4, 1e-5, 0.0],\n",
    "                default=1e-2\n",
    "            )\n",
    "\n",
    "            model.add(Dense(\n",
    "                units=units,\n",
    "                activation=activation,\n",
    "                kernel_regularizer=L1L2(l1=regularizer_l1, l2=regularizer_l2),\n",
    "                bias_regularizer=L1L2(l1=regularizer_l1, l2=regularizer_l2)\n",
    "            ))\n",
    "            \n",
    "            droupout_rate = hp.Float(\n",
    "                f\"dropout_{layer_n}\",\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            )\n",
    "            \n",
    "            model.add(Dropout(rate=droupout_rate))\n",
    "        \n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "        \n",
    "        learning_rate = hp.Choice(\n",
    "            \"learning_rate\",\n",
    "            values=[1e-3, 5e-4, 3e-4, 1e-4, 1e-5],\n",
    "            default=1e-3\n",
    "        )\n",
    "        \n",
    "        optimizer = hp.Choice(\n",
    "            \"optimizer\",\n",
    "            values=[\"adam\", \"RMSprop\", \"SGD\"],\n",
    "            default=\"adam\"\n",
    "        )\n",
    "        optimizer_type = {\n",
    "            \"adam\": keras.optimizers.Adam,\n",
    "            \"RMSprop\": keras.optimizers.RMSprop,\n",
    "            \"SGD\": keras.optimizers.SGD\n",
    "        }\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer_type[optimizer](learning_rate=learning_rate),\n",
    "            metrics=METRICS,\n",
    "            loss=\"binary_crossentropy\",\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "hypermodel = TitanicHyperModel(input_size=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTuner(kt.Tuner):\n",
    "    def run_trial(self, trial, X_train, Y_train, validation_data):\n",
    "        hp = trial.hyperparameters\n",
    "        \n",
    "        batch_size = hp.Int(\"batch_size\", 16, 128, step=16, default=32)\n",
    "        epoch_number = hp.Int(\"epoch_number\", 400, 700, step=100, default=500)\n",
    "        \n",
    "        model = self.hypermodel.build(hp)\n",
    "        \n",
    "        history = model.fit(X_train, Y_train, epochs=epoch_number, batch_size=batch_size, validation_data=validation_data, class_weight=class_weights)\n",
    "        \n",
    "        self.oracle.update_trial(trial.trial_id, {\"val_accuracy\": history.history[\"val_accuracy\"][-1]})\n",
    "        self.save_model(trial.trial_id, model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dev mode\n",
    "\n",
    "if MODE == \"DEV\":\n",
    "    MAX_TRIALS = 20\n",
    "else:\n",
    "    MAX_TRIALS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ATTEMPT = ATTEMPT + 1\n",
    "except NameError:\n",
    "    ATTEMPT = 0\n",
    "\n",
    "hp = kt.HyperParameters()\n",
    "if MODE == \"DEV\":\n",
    "    hp.Fixed(\"epoch_number\", 50)\n",
    "\n",
    "# Seems like 32 always comes to be the best option...\n",
    "hp.Fixed(\"batch_size\", 32)\n",
    "\n",
    "tuner = MyTuner(\n",
    "    oracle=kt.oracles.RandomSearch(\n",
    "        objective=\"val_accuracy\",\n",
    "        seed=SEED,\n",
    "        hyperparameters=hp,\n",
    "        tune_new_entries=True,\n",
    "        max_trials=MAX_TRIALS),\n",
    "    hypermodel=hypermodel,\n",
    "    directory=f\"my_search_{ATTEMPT}\",\n",
    "    project_name=\"titanic\"\n",
    ")\n",
    "\n",
    "# tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 3s 4ms/sample - loss: 1.6340 - tp: 104.0000 - fp: 91.0000 - tn: 353.0000 - fn: 164.0000 - accuracy: 0.6419 - precision: 0.5333 - recall: 0.3881 - auc: 0.6566 - val_loss: 1.4581 - val_tp: 39.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 35.0000 - val_accuracy: 0.7207 - val_precision: 0.7222 - val_recall: 0.5270 - val_auc: 0.8349\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.5431 - tp: 147.0000 - fp: 126.0000 - tn: 318.0000 - fn: 121.0000 - accuracy: 0.6531 - precision: 0.5385 - recall: 0.5485 - auc: 0.6846 - val_loss: 1.4060 - val_tp: 44.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 30.0000 - val_accuracy: 0.7318 - val_precision: 0.7097 - val_recall: 0.5946 - val_auc: 0.8421\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.4899 - tp: 150.0000 - fp: 115.0000 - tn: 329.0000 - fn: 118.0000 - accuracy: 0.6728 - precision: 0.5660 - recall: 0.5597 - auc: 0.7057 - val_loss: 1.3612 - val_tp: 53.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 21.0000 - val_accuracy: 0.7542 - val_precision: 0.6974 - val_recall: 0.7162 - val_auc: 0.8479\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.4565 - tp: 164.0000 - fp: 134.0000 - tn: 310.0000 - fn: 104.0000 - accuracy: 0.6657 - precision: 0.5503 - recall: 0.6119 - auc: 0.7127 - val_loss: 1.3229 - val_tp: 49.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 25.0000 - val_accuracy: 0.7430 - val_precision: 0.7000 - val_recall: 0.6622 - val_auc: 0.8518\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.4180 - tp: 160.0000 - fp: 132.0000 - tn: 312.0000 - fn: 108.0000 - accuracy: 0.6629 - precision: 0.5479 - recall: 0.5970 - auc: 0.7185 - val_loss: 1.2846 - val_tp: 56.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 18.0000 - val_accuracy: 0.7598 - val_precision: 0.6914 - val_recall: 0.7568 - val_auc: 0.8547\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.3440 - tp: 179.0000 - fp: 118.0000 - tn: 326.0000 - fn: 89.0000 - accuracy: 0.7093 - precision: 0.6027 - recall: 0.6679 - auc: 0.7655 - val_loss: 1.2475 - val_tp: 54.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 20.0000 - val_accuracy: 0.7542 - val_precision: 0.6923 - val_recall: 0.7297 - val_auc: 0.8557\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.3115 - tp: 176.0000 - fp: 117.0000 - tn: 327.0000 - fn: 92.0000 - accuracy: 0.7065 - precision: 0.6007 - recall: 0.6567 - auc: 0.7719 - val_loss: 1.2098 - val_tp: 62.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 12.0000 - val_accuracy: 0.7709 - val_precision: 0.6813 - val_recall: 0.8378 - val_auc: 0.8569\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.2829 - tp: 195.0000 - fp: 112.0000 - tn: 332.0000 - fn: 73.0000 - accuracy: 0.7402 - precision: 0.6352 - recall: 0.7276 - auc: 0.7817 - val_loss: 1.1778 - val_tp: 60.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 14.0000 - val_accuracy: 0.7709 - val_precision: 0.6897 - val_recall: 0.8108 - val_auc: 0.8593\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.2399 - tp: 184.0000 - fp: 101.0000 - tn: 343.0000 - fn: 84.0000 - accuracy: 0.7402 - precision: 0.6456 - recall: 0.6866 - auc: 0.7923 - val_loss: 1.1456 - val_tp: 60.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 14.0000 - val_accuracy: 0.7542 - val_precision: 0.6667 - val_recall: 0.8108 - val_auc: 0.8649\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.2215 - tp: 185.0000 - fp: 112.0000 - tn: 332.0000 - fn: 83.0000 - accuracy: 0.7261 - precision: 0.6229 - recall: 0.6903 - auc: 0.7840 - val_loss: 1.1147 - val_tp: 60.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 14.0000 - val_accuracy: 0.7486 - val_precision: 0.6593 - val_recall: 0.8108 - val_auc: 0.8690\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 1.1693 - tp: 201.0000 - fp: 111.0000 - tn: 333.0000 - fn: 67.0000 - accuracy: 0.7500 - precision: 0.6442 - recall: 0.7500 - auc: 0.8054 - val_loss: 1.0853 - val_tp: 59.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 15.0000 - val_accuracy: 0.7430 - val_precision: 0.6556 - val_recall: 0.7973 - val_auc: 0.8743\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.1416 - tp: 195.0000 - fp: 109.0000 - tn: 335.0000 - fn: 73.0000 - accuracy: 0.7444 - precision: 0.6414 - recall: 0.7276 - auc: 0.8104 - val_loss: 1.0587 - val_tp: 59.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 15.0000 - val_accuracy: 0.7430 - val_precision: 0.6556 - val_recall: 0.7973 - val_auc: 0.8743\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.1122 - tp: 198.0000 - fp: 97.0000 - tn: 347.0000 - fn: 70.0000 - accuracy: 0.7654 - precision: 0.6712 - recall: 0.7388 - auc: 0.8162 - val_loss: 1.0326 - val_tp: 59.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 15.0000 - val_accuracy: 0.7430 - val_precision: 0.6556 - val_recall: 0.7973 - val_auc: 0.8757\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.0936 - tp: 201.0000 - fp: 96.0000 - tn: 348.0000 - fn: 67.0000 - accuracy: 0.7711 - precision: 0.6768 - recall: 0.7500 - auc: 0.8117 - val_loss: 1.0084 - val_tp: 59.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 15.0000 - val_accuracy: 0.7542 - val_precision: 0.6705 - val_recall: 0.7973 - val_auc: 0.8770\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.0805 - tp: 190.0000 - fp: 102.0000 - tn: 342.0000 - fn: 78.0000 - accuracy: 0.7472 - precision: 0.6507 - recall: 0.7090 - auc: 0.8012 - val_loss: 0.9853 - val_tp: 59.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 15.0000 - val_accuracy: 0.7542 - val_precision: 0.6705 - val_recall: 0.7973 - val_auc: 0.8777\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.0293 - tp: 202.0000 - fp: 91.0000 - tn: 353.0000 - fn: 66.0000 - accuracy: 0.7795 - precision: 0.6894 - recall: 0.7537 - auc: 0.8220 - val_loss: 0.9640 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8780\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.0093 - tp: 201.0000 - fp: 98.0000 - tn: 346.0000 - fn: 67.0000 - accuracy: 0.7683 - precision: 0.6722 - recall: 0.7500 - auc: 0.8235 - val_loss: 0.9411 - val_tp: 59.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 15.0000 - val_accuracy: 0.7542 - val_precision: 0.6705 - val_recall: 0.7973 - val_auc: 0.8777\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.9851 - tp: 196.0000 - fp: 110.0000 - tn: 334.0000 - fn: 72.0000 - accuracy: 0.7444 - precision: 0.6405 - recall: 0.7313 - auc: 0.8264 - val_loss: 0.9202 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8793\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.9678 - tp: 194.0000 - fp: 93.0000 - tn: 351.0000 - fn: 74.0000 - accuracy: 0.7654 - precision: 0.6760 - recall: 0.7239 - auc: 0.8239 - val_loss: 0.8999 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8789\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.9484 - tp: 202.0000 - fp: 96.0000 - tn: 348.0000 - fn: 66.0000 - accuracy: 0.7725 - precision: 0.6779 - recall: 0.7537 - auc: 0.8238 - val_loss: 0.8807 - val_tp: 59.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 15.0000 - val_accuracy: 0.7654 - val_precision: 0.6860 - val_recall: 0.7973 - val_auc: 0.8779\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.9195 - tp: 194.0000 - fp: 93.0000 - tn: 351.0000 - fn: 74.0000 - accuracy: 0.7654 - precision: 0.6760 - recall: 0.7239 - auc: 0.8305 - val_loss: 0.8616 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8769\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.9103 - tp: 201.0000 - fp: 90.0000 - tn: 354.0000 - fn: 67.0000 - accuracy: 0.7795 - precision: 0.6907 - recall: 0.7500 - auc: 0.8256 - val_loss: 0.8450 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8757\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.9004 - tp: 195.0000 - fp: 97.0000 - tn: 347.0000 - fn: 73.0000 - accuracy: 0.7612 - precision: 0.6678 - recall: 0.7276 - auc: 0.8187 - val_loss: 0.8280 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8753\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.8749 - tp: 201.0000 - fp: 96.0000 - tn: 348.0000 - fn: 67.0000 - accuracy: 0.7711 - precision: 0.6768 - recall: 0.7500 - auc: 0.8213 - val_loss: 0.8116 - val_tp: 58.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 16.0000 - val_accuracy: 0.7598 - val_precision: 0.6824 - val_recall: 0.7838 - val_auc: 0.8758\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.8623 - tp: 202.0000 - fp: 84.0000 - tn: 360.0000 - fn: 66.0000 - accuracy: 0.7893 - precision: 0.7063 - recall: 0.7537 - auc: 0.8225 - val_loss: 0.7977 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8754\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.8244 - tp: 200.0000 - fp: 86.0000 - tn: 358.0000 - fn: 68.0000 - accuracy: 0.7837 - precision: 0.6993 - recall: 0.7463 - auc: 0.8406 - val_loss: 0.7837 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8763\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.8293 - tp: 199.0000 - fp: 92.0000 - tn: 352.0000 - fn: 69.0000 - accuracy: 0.7739 - precision: 0.6838 - recall: 0.7425 - auc: 0.8273 - val_loss: 0.7705 - val_tp: 55.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 19.0000 - val_accuracy: 0.7542 - val_precision: 0.6875 - val_recall: 0.7432 - val_auc: 0.8753\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.8071 - tp: 198.0000 - fp: 85.0000 - tn: 359.0000 - fn: 70.0000 - accuracy: 0.7823 - precision: 0.6996 - recall: 0.7388 - auc: 0.8303 - val_loss: 0.7598 - val_tp: 59.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 15.0000 - val_accuracy: 0.7542 - val_precision: 0.6705 - val_recall: 0.7973 - val_auc: 0.8741\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.7886 - tp: 199.0000 - fp: 90.0000 - tn: 354.0000 - fn: 69.0000 - accuracy: 0.7767 - precision: 0.6886 - recall: 0.7425 - auc: 0.8387 - val_loss: 0.7475 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8749\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7764 - tp: 194.0000 - fp: 82.0000 - tn: 362.0000 - fn: 74.0000 - accuracy: 0.7809 - precision: 0.7029 - recall: 0.7239 - auc: 0.8396 - val_loss: 0.7364 - val_tp: 57.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 17.0000 - val_accuracy: 0.7542 - val_precision: 0.6786 - val_recall: 0.7703 - val_auc: 0.8741\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7801 - tp: 201.0000 - fp: 90.0000 - tn: 354.0000 - fn: 67.0000 - accuracy: 0.7795 - precision: 0.6907 - recall: 0.7500 - auc: 0.8265 - val_loss: 0.7269 - val_tp: 58.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 16.0000 - val_accuracy: 0.7542 - val_precision: 0.6744 - val_recall: 0.7838 - val_auc: 0.8734\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7382 - tp: 205.0000 - fp: 88.0000 - tn: 356.0000 - fn: 63.0000 - accuracy: 0.7879 - precision: 0.6997 - recall: 0.7649 - auc: 0.8522 - val_loss: 0.7180 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8746\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7479 - tp: 205.0000 - fp: 80.0000 - tn: 364.0000 - fn: 63.0000 - accuracy: 0.7992 - precision: 0.7193 - recall: 0.7649 - auc: 0.8387 - val_loss: 0.7102 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8743\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7319 - tp: 198.0000 - fp: 78.0000 - tn: 366.0000 - fn: 70.0000 - accuracy: 0.7921 - precision: 0.7174 - recall: 0.7388 - auc: 0.8448 - val_loss: 0.7032 - val_tp: 58.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 16.0000 - val_accuracy: 0.7598 - val_precision: 0.6824 - val_recall: 0.7838 - val_auc: 0.8729\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7291 - tp: 200.0000 - fp: 77.0000 - tn: 367.0000 - fn: 68.0000 - accuracy: 0.7963 - precision: 0.7220 - recall: 0.7463 - auc: 0.8395 - val_loss: 0.6949 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8734\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7281 - tp: 208.0000 - fp: 89.0000 - tn: 355.0000 - fn: 60.0000 - accuracy: 0.7907 - precision: 0.7003 - recall: 0.7761 - auc: 0.8356 - val_loss: 0.6898 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8741\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7192 - tp: 201.0000 - fp: 85.0000 - tn: 359.0000 - fn: 67.0000 - accuracy: 0.7865 - precision: 0.7028 - recall: 0.7500 - auc: 0.8386 - val_loss: 0.6853 - val_tp: 54.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 20.0000 - val_accuracy: 0.7765 - val_precision: 0.7297 - val_recall: 0.7297 - val_auc: 0.8760\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7028 - tp: 203.0000 - fp: 78.0000 - tn: 366.0000 - fn: 65.0000 - accuracy: 0.7992 - precision: 0.7224 - recall: 0.7575 - auc: 0.8476 - val_loss: 0.6780 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8743\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7130 - tp: 200.0000 - fp: 84.0000 - tn: 360.0000 - fn: 68.0000 - accuracy: 0.7865 - precision: 0.7042 - recall: 0.7463 - auc: 0.8368 - val_loss: 0.6738 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8730\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7094 - tp: 202.0000 - fp: 88.0000 - tn: 356.0000 - fn: 66.0000 - accuracy: 0.7837 - precision: 0.6966 - recall: 0.7537 - auc: 0.8335 - val_loss: 0.6674 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8754\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6899 - tp: 198.0000 - fp: 78.0000 - tn: 366.0000 - fn: 70.0000 - accuracy: 0.7921 - precision: 0.7174 - recall: 0.7388 - auc: 0.8482 - val_loss: 0.6624 - val_tp: 59.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 15.0000 - val_accuracy: 0.7654 - val_precision: 0.6860 - val_recall: 0.7973 - val_auc: 0.8733\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6970 - tp: 205.0000 - fp: 84.0000 - tn: 360.0000 - fn: 63.0000 - accuracy: 0.7935 - precision: 0.7093 - recall: 0.7649 - auc: 0.8374 - val_loss: 0.6570 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8752\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6781 - tp: 201.0000 - fp: 83.0000 - tn: 361.0000 - fn: 67.0000 - accuracy: 0.7893 - precision: 0.7077 - recall: 0.7500 - auc: 0.8476 - val_loss: 0.6540 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8766\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6947 - tp: 200.0000 - fp: 76.0000 - tn: 368.0000 - fn: 68.0000 - accuracy: 0.7978 - precision: 0.7246 - recall: 0.7463 - auc: 0.8346 - val_loss: 0.6490 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8760\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6772 - tp: 198.0000 - fp: 78.0000 - tn: 366.0000 - fn: 70.0000 - accuracy: 0.7921 - precision: 0.7174 - recall: 0.7388 - auc: 0.8435 - val_loss: 0.6460 - val_tp: 59.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 15.0000 - val_accuracy: 0.7654 - val_precision: 0.6860 - val_recall: 0.7973 - val_auc: 0.8752\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6846 - tp: 201.0000 - fp: 89.0000 - tn: 355.0000 - fn: 67.0000 - accuracy: 0.7809 - precision: 0.6931 - recall: 0.7500 - auc: 0.8332 - val_loss: 0.6417 - val_tp: 56.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 18.0000 - val_accuracy: 0.7542 - val_precision: 0.6829 - val_recall: 0.7568 - val_auc: 0.8750\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.6741 - tp: 207.0000 - fp: 88.0000 - tn: 356.0000 - fn: 61.0000 - accuracy: 0.7907 - precision: 0.7017 - recall: 0.7724 - auc: 0.8379 - val_loss: 0.6391 - val_tp: 59.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 15.0000 - val_accuracy: 0.7654 - val_precision: 0.6860 - val_recall: 0.7973 - val_auc: 0.8750\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6689 - tp: 204.0000 - fp: 82.0000 - tn: 362.0000 - fn: 64.0000 - accuracy: 0.7949 - precision: 0.7133 - recall: 0.7612 - auc: 0.8369 - val_loss: 0.6341 - val_tp: 55.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 19.0000 - val_accuracy: 0.7654 - val_precision: 0.7051 - val_recall: 0.7432 - val_auc: 0.8757\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6720 - tp: 202.0000 - fp: 84.0000 - tn: 360.0000 - fn: 66.0000 - accuracy: 0.7893 - precision: 0.7063 - recall: 0.7537 - auc: 0.8359 - val_loss: 0.6299 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8751\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6591 - tp: 197.0000 - fp: 76.0000 - tn: 368.0000 - fn: 71.0000 - accuracy: 0.7935 - precision: 0.7216 - recall: 0.7351 - auc: 0.8440 - val_loss: 0.6300 - val_tp: 60.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 14.0000 - val_accuracy: 0.7542 - val_precision: 0.6667 - val_recall: 0.8108 - val_auc: 0.8745\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6525 - tp: 206.0000 - fp: 87.0000 - tn: 357.0000 - fn: 62.0000 - accuracy: 0.7907 - precision: 0.7031 - recall: 0.7687 - auc: 0.8471 - val_loss: 0.6258 - val_tp: 59.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 15.0000 - val_accuracy: 0.7598 - val_precision: 0.6782 - val_recall: 0.7973 - val_auc: 0.8749\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6571 - tp: 207.0000 - fp: 96.0000 - tn: 348.0000 - fn: 61.0000 - accuracy: 0.7795 - precision: 0.6832 - recall: 0.7724 - auc: 0.8440 - val_loss: 0.6221 - val_tp: 59.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 15.0000 - val_accuracy: 0.7654 - val_precision: 0.6860 - val_recall: 0.7973 - val_auc: 0.8763\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6606 - tp: 203.0000 - fp: 87.0000 - tn: 357.0000 - fn: 65.0000 - accuracy: 0.7865 - precision: 0.7000 - recall: 0.7575 - auc: 0.8351 - val_loss: 0.6202 - val_tp: 59.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 15.0000 - val_accuracy: 0.7654 - val_precision: 0.6860 - val_recall: 0.7973 - val_auc: 0.8752\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6387 - tp: 204.0000 - fp: 87.0000 - tn: 357.0000 - fn: 64.0000 - accuracy: 0.7879 - precision: 0.7010 - recall: 0.7612 - auc: 0.8500 - val_loss: 0.6169 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8772\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6459 - tp: 203.0000 - fp: 83.0000 - tn: 361.0000 - fn: 65.0000 - accuracy: 0.7921 - precision: 0.7098 - recall: 0.7575 - auc: 0.8430 - val_loss: 0.6131 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8772\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6396 - tp: 202.0000 - fp: 84.0000 - tn: 360.0000 - fn: 66.0000 - accuracy: 0.7893 - precision: 0.7063 - recall: 0.7537 - auc: 0.8460 - val_loss: 0.6136 - val_tp: 59.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 15.0000 - val_accuracy: 0.7654 - val_precision: 0.6860 - val_recall: 0.7973 - val_auc: 0.8765\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6421 - tp: 203.0000 - fp: 85.0000 - tn: 359.0000 - fn: 65.0000 - accuracy: 0.7893 - precision: 0.7049 - recall: 0.7575 - auc: 0.8400 - val_loss: 0.6086 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8769\n",
      "Epoch 58/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6429 - tp: 199.0000 - fp: 80.0000 - tn: 364.0000 - fn: 69.0000 - accuracy: 0.7907 - precision: 0.7133 - recall: 0.7425 - auc: 0.8407 - val_loss: 0.6086 - val_tp: 59.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 15.0000 - val_accuracy: 0.7654 - val_precision: 0.6860 - val_recall: 0.7973 - val_auc: 0.8755\n",
      "Epoch 59/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6274 - tp: 203.0000 - fp: 83.0000 - tn: 361.0000 - fn: 65.0000 - accuracy: 0.7921 - precision: 0.7098 - recall: 0.7575 - auc: 0.8533 - val_loss: 0.6038 - val_tp: 54.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 20.0000 - val_accuracy: 0.7765 - val_precision: 0.7297 - val_recall: 0.7297 - val_auc: 0.8788\n",
      "Epoch 60/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6387 - tp: 201.0000 - fp: 77.0000 - tn: 367.0000 - fn: 67.0000 - accuracy: 0.7978 - precision: 0.7230 - recall: 0.7500 - auc: 0.8393 - val_loss: 0.6012 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8793\n",
      "Epoch 61/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6338 - tp: 208.0000 - fp: 81.0000 - tn: 363.0000 - fn: 60.0000 - accuracy: 0.8020 - precision: 0.7197 - recall: 0.7761 - auc: 0.8402 - val_loss: 0.5990 - val_tp: 54.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 20.0000 - val_accuracy: 0.7709 - val_precision: 0.7200 - val_recall: 0.7297 - val_auc: 0.8813\n",
      "Epoch 62/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.6374 - tp: 199.0000 - fp: 79.0000 - tn: 365.0000 - fn: 69.0000 - accuracy: 0.7921 - precision: 0.7158 - recall: 0.7425 - auc: 0.8370 - val_loss: 0.5971 - val_tp: 54.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 20.0000 - val_accuracy: 0.7709 - val_precision: 0.7200 - val_recall: 0.7297 - val_auc: 0.8802\n",
      "Epoch 63/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6324 - tp: 204.0000 - fp: 73.0000 - tn: 371.0000 - fn: 64.0000 - accuracy: 0.8076 - precision: 0.7365 - recall: 0.7612 - auc: 0.8409 - val_loss: 0.5938 - val_tp: 54.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 20.0000 - val_accuracy: 0.7765 - val_precision: 0.7297 - val_recall: 0.7297 - val_auc: 0.8812\n",
      "Epoch 64/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.6338 - tp: 196.0000 - fp: 81.0000 - tn: 363.0000 - fn: 72.0000 - accuracy: 0.7851 - precision: 0.7076 - recall: 0.7313 - auc: 0.8390 - val_loss: 0.5933 - val_tp: 57.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 17.0000 - val_accuracy: 0.7821 - val_precision: 0.7215 - val_recall: 0.7703 - val_auc: 0.8809\n",
      "Epoch 65/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.6254 - tp: 203.0000 - fp: 82.0000 - tn: 362.0000 - fn: 65.0000 - accuracy: 0.7935 - precision: 0.7123 - recall: 0.7575 - auc: 0.8421 - val_loss: 0.5881 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8823\n",
      "Epoch 66/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6305 - tp: 199.0000 - fp: 79.0000 - tn: 365.0000 - fn: 69.0000 - accuracy: 0.7921 - precision: 0.7158 - recall: 0.7425 - auc: 0.8363 - val_loss: 0.5855 - val_tp: 54.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 20.0000 - val_accuracy: 0.7765 - val_precision: 0.7297 - val_recall: 0.7297 - val_auc: 0.8824\n",
      "Epoch 67/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6095 - tp: 199.0000 - fp: 78.0000 - tn: 366.0000 - fn: 69.0000 - accuracy: 0.7935 - precision: 0.7184 - recall: 0.7425 - auc: 0.8502 - val_loss: 0.5849 - val_tp: 59.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 15.0000 - val_accuracy: 0.7933 - val_precision: 0.7284 - val_recall: 0.7973 - val_auc: 0.8802\n",
      "Epoch 68/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6137 - tp: 201.0000 - fp: 82.0000 - tn: 362.0000 - fn: 67.0000 - accuracy: 0.7907 - precision: 0.7102 - recall: 0.7500 - auc: 0.8426 - val_loss: 0.5822 - val_tp: 57.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 17.0000 - val_accuracy: 0.7821 - val_precision: 0.7215 - val_recall: 0.7703 - val_auc: 0.8808\n",
      "Epoch 69/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6123 - tp: 206.0000 - fp: 80.0000 - tn: 364.0000 - fn: 62.0000 - accuracy: 0.8006 - precision: 0.7203 - recall: 0.7687 - auc: 0.8444 - val_loss: 0.5789 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8826\n",
      "Epoch 70/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6064 - tp: 201.0000 - fp: 83.0000 - tn: 361.0000 - fn: 67.0000 - accuracy: 0.7893 - precision: 0.7077 - recall: 0.7500 - auc: 0.8501 - val_loss: 0.5762 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8825\n",
      "Epoch 71/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6139 - tp: 201.0000 - fp: 83.0000 - tn: 361.0000 - fn: 67.0000 - accuracy: 0.7893 - precision: 0.7077 - recall: 0.7500 - auc: 0.8402 - val_loss: 0.5742 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8820\n",
      "Epoch 72/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6169 - tp: 201.0000 - fp: 81.0000 - tn: 363.0000 - fn: 67.0000 - accuracy: 0.7921 - precision: 0.7128 - recall: 0.7500 - auc: 0.8372 - val_loss: 0.5726 - val_tp: 57.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 17.0000 - val_accuracy: 0.7877 - val_precision: 0.7308 - val_recall: 0.7703 - val_auc: 0.8821\n",
      "Epoch 73/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6010 - tp: 211.0000 - fp: 82.0000 - tn: 362.0000 - fn: 57.0000 - accuracy: 0.8048 - precision: 0.7201 - recall: 0.7873 - auc: 0.8490 - val_loss: 0.5707 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8858\n",
      "Epoch 74/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5921 - tp: 210.0000 - fp: 75.0000 - tn: 369.0000 - fn: 58.0000 - accuracy: 0.8132 - precision: 0.7368 - recall: 0.7836 - auc: 0.8529 - val_loss: 0.5687 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8869\n",
      "Epoch 75/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5951 - tp: 204.0000 - fp: 70.0000 - tn: 374.0000 - fn: 64.0000 - accuracy: 0.8118 - precision: 0.7445 - recall: 0.7612 - auc: 0.8496 - val_loss: 0.5647 - val_tp: 55.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 19.0000 - val_accuracy: 0.7821 - val_precision: 0.7333 - val_recall: 0.7432 - val_auc: 0.8869\n",
      "Epoch 76/500\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.5989 - tp: 208.0000 - fp: 82.0000 - tn: 362.0000 - fn: 60.0000 - accuracy: 0.8006 - precision: 0.7172 - recall: 0.7761 - auc: 0.8458 - val_loss: 0.5635 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8858\n",
      "Epoch 77/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5986 - tp: 210.0000 - fp: 82.0000 - tn: 362.0000 - fn: 58.0000 - accuracy: 0.8034 - precision: 0.7192 - recall: 0.7836 - auc: 0.8432 - val_loss: 0.5615 - val_tp: 56.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 18.0000 - val_accuracy: 0.7877 - val_precision: 0.7368 - val_recall: 0.7568 - val_auc: 0.8861\n",
      "Epoch 78/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5940 - tp: 205.0000 - fp: 79.0000 - tn: 365.0000 - fn: 63.0000 - accuracy: 0.8006 - precision: 0.7218 - recall: 0.7649 - auc: 0.8444 - val_loss: 0.5600 - val_tp: 56.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 18.0000 - val_accuracy: 0.7877 - val_precision: 0.7368 - val_recall: 0.7568 - val_auc: 0.8863\n",
      "Epoch 79/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5948 - tp: 204.0000 - fp: 79.0000 - tn: 365.0000 - fn: 64.0000 - accuracy: 0.7992 - precision: 0.7208 - recall: 0.7612 - auc: 0.8434 - val_loss: 0.5591 - val_tp: 54.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 20.0000 - val_accuracy: 0.7765 - val_precision: 0.7297 - val_recall: 0.7297 - val_auc: 0.8838\n",
      "Epoch 80/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5783 - tp: 203.0000 - fp: 71.0000 - tn: 373.0000 - fn: 65.0000 - accuracy: 0.8090 - precision: 0.7409 - recall: 0.7575 - auc: 0.8546 - val_loss: 0.5569 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8838\n",
      "Epoch 81/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6016 - tp: 202.0000 - fp: 78.0000 - tn: 366.0000 - fn: 66.0000 - accuracy: 0.7978 - precision: 0.7214 - recall: 0.7537 - auc: 0.8331 - val_loss: 0.5550 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8857\n",
      "Epoch 82/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5930 - tp: 209.0000 - fp: 81.0000 - tn: 363.0000 - fn: 59.0000 - accuracy: 0.8034 - precision: 0.7207 - recall: 0.7799 - auc: 0.8395 - val_loss: 0.5539 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8847\n",
      "Epoch 83/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5806 - tp: 207.0000 - fp: 78.0000 - tn: 366.0000 - fn: 61.0000 - accuracy: 0.8048 - precision: 0.7263 - recall: 0.7724 - auc: 0.8450 - val_loss: 0.5523 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8846\n",
      "Epoch 84/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5694 - tp: 210.0000 - fp: 78.0000 - tn: 366.0000 - fn: 58.0000 - accuracy: 0.8090 - precision: 0.7292 - recall: 0.7836 - auc: 0.8552 - val_loss: 0.5495 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8831\n",
      "Epoch 85/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5757 - tp: 205.0000 - fp: 81.0000 - tn: 363.0000 - fn: 63.0000 - accuracy: 0.7978 - precision: 0.7168 - recall: 0.7649 - auc: 0.8485 - val_loss: 0.5489 - val_tp: 56.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 18.0000 - val_accuracy: 0.7877 - val_precision: 0.7368 - val_recall: 0.7568 - val_auc: 0.8836\n",
      "Epoch 86/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5645 - tp: 206.0000 - fp: 73.0000 - tn: 371.0000 - fn: 62.0000 - accuracy: 0.8104 - precision: 0.7384 - recall: 0.7687 - auc: 0.8570 - val_loss: 0.5485 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8829\n",
      "Epoch 87/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5832 - tp: 200.0000 - fp: 81.0000 - tn: 363.0000 - fn: 68.0000 - accuracy: 0.7907 - precision: 0.7117 - recall: 0.7463 - auc: 0.8430 - val_loss: 0.5458 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8831\n",
      "Epoch 88/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5628 - tp: 208.0000 - fp: 84.0000 - tn: 360.0000 - fn: 60.0000 - accuracy: 0.7978 - precision: 0.7123 - recall: 0.7761 - auc: 0.8557 - val_loss: 0.5444 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8838\n",
      "Epoch 89/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5710 - tp: 208.0000 - fp: 85.0000 - tn: 359.0000 - fn: 60.0000 - accuracy: 0.7963 - precision: 0.7099 - recall: 0.7761 - auc: 0.8511 - val_loss: 0.5420 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8846\n",
      "Epoch 90/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5631 - tp: 206.0000 - fp: 76.0000 - tn: 368.0000 - fn: 62.0000 - accuracy: 0.8062 - precision: 0.7305 - recall: 0.7687 - auc: 0.8544 - val_loss: 0.5410 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8846\n",
      "Epoch 91/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5673 - tp: 205.0000 - fp: 80.0000 - tn: 364.0000 - fn: 63.0000 - accuracy: 0.7992 - precision: 0.7193 - recall: 0.7649 - auc: 0.8467 - val_loss: 0.5385 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8847\n",
      "Epoch 92/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5600 - tp: 204.0000 - fp: 70.0000 - tn: 374.0000 - fn: 64.0000 - accuracy: 0.8118 - precision: 0.7445 - recall: 0.7612 - auc: 0.8517 - val_loss: 0.5367 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8842\n",
      "Epoch 93/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5543 - tp: 207.0000 - fp: 79.0000 - tn: 365.0000 - fn: 61.0000 - accuracy: 0.8034 - precision: 0.7238 - recall: 0.7724 - auc: 0.8547 - val_loss: 0.5361 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8844\n",
      "Epoch 94/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5627 - tp: 206.0000 - fp: 80.0000 - tn: 364.0000 - fn: 62.0000 - accuracy: 0.8006 - precision: 0.7203 - recall: 0.7687 - auc: 0.8478 - val_loss: 0.5347 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8841\n",
      "Epoch 95/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5635 - tp: 212.0000 - fp: 82.0000 - tn: 362.0000 - fn: 56.0000 - accuracy: 0.8062 - precision: 0.7211 - recall: 0.7910 - auc: 0.8463 - val_loss: 0.5338 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8840\n",
      "Epoch 96/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5536 - tp: 207.0000 - fp: 76.0000 - tn: 368.0000 - fn: 61.0000 - accuracy: 0.8076 - precision: 0.7314 - recall: 0.7724 - auc: 0.8583 - val_loss: 0.5324 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8837\n",
      "Epoch 97/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5575 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8536 - val_loss: 0.5322 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8833\n",
      "Epoch 98/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5733 - tp: 207.0000 - fp: 82.0000 - tn: 362.0000 - fn: 61.0000 - accuracy: 0.7992 - precision: 0.7163 - recall: 0.7724 - auc: 0.8361 - val_loss: 0.5305 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8828\n",
      "Epoch 99/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.5535 - tp: 207.0000 - fp: 76.0000 - tn: 368.0000 - fn: 61.0000 - accuracy: 0.8076 - precision: 0.7314 - recall: 0.7724 - auc: 0.8538 - val_loss: 0.5296 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8833\n",
      "Epoch 100/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5613 - tp: 203.0000 - fp: 77.0000 - tn: 367.0000 - fn: 65.0000 - accuracy: 0.8006 - precision: 0.7250 - recall: 0.7575 - auc: 0.8455 - val_loss: 0.5289 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8840\n",
      "Epoch 101/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5635 - tp: 208.0000 - fp: 83.0000 - tn: 361.0000 - fn: 60.0000 - accuracy: 0.7992 - precision: 0.7148 - recall: 0.7761 - auc: 0.8461 - val_loss: 0.5282 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8831\n",
      "Epoch 102/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5400 - tp: 209.0000 - fp: 75.0000 - tn: 369.0000 - fn: 59.0000 - accuracy: 0.8118 - precision: 0.7359 - recall: 0.7799 - auc: 0.8635 - val_loss: 0.5267 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8848\n",
      "Epoch 103/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5627 - tp: 206.0000 - fp: 78.0000 - tn: 366.0000 - fn: 62.0000 - accuracy: 0.8034 - precision: 0.7254 - recall: 0.7687 - auc: 0.8451 - val_loss: 0.5266 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8844\n",
      "Epoch 104/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5477 - tp: 212.0000 - fp: 72.0000 - tn: 372.0000 - fn: 56.0000 - accuracy: 0.8202 - precision: 0.7465 - recall: 0.7910 - auc: 0.8522 - val_loss: 0.5265 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8842\n",
      "Epoch 105/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5443 - tp: 207.0000 - fp: 72.0000 - tn: 372.0000 - fn: 61.0000 - accuracy: 0.8132 - precision: 0.7419 - recall: 0.7724 - auc: 0.8561 - val_loss: 0.5242 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8838\n",
      "Epoch 106/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5415 - tp: 207.0000 - fp: 80.0000 - tn: 364.0000 - fn: 61.0000 - accuracy: 0.8020 - precision: 0.7213 - recall: 0.7724 - auc: 0.8582 - val_loss: 0.5222 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8834\n",
      "Epoch 107/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5430 - tp: 211.0000 - fp: 74.0000 - tn: 370.0000 - fn: 57.0000 - accuracy: 0.8160 - precision: 0.7404 - recall: 0.7873 - auc: 0.8562 - val_loss: 0.5213 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8831\n",
      "Epoch 108/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5497 - tp: 206.0000 - fp: 76.0000 - tn: 368.0000 - fn: 62.0000 - accuracy: 0.8062 - precision: 0.7305 - recall: 0.7687 - auc: 0.8540 - val_loss: 0.5217 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8829\n",
      "Epoch 109/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5494 - tp: 209.0000 - fp: 84.0000 - tn: 360.0000 - fn: 59.0000 - accuracy: 0.7992 - precision: 0.7133 - recall: 0.7799 - auc: 0.8488 - val_loss: 0.5202 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8825\n",
      "Epoch 110/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5481 - tp: 209.0000 - fp: 78.0000 - tn: 366.0000 - fn: 59.0000 - accuracy: 0.8076 - precision: 0.7282 - recall: 0.7799 - auc: 0.8480 - val_loss: 0.5203 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8829\n",
      "Epoch 111/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5510 - tp: 208.0000 - fp: 77.0000 - tn: 367.0000 - fn: 60.0000 - accuracy: 0.8076 - precision: 0.7298 - recall: 0.7761 - auc: 0.8468 - val_loss: 0.5205 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8828\n",
      "Epoch 112/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5444 - tp: 210.0000 - fp: 76.0000 - tn: 368.0000 - fn: 58.0000 - accuracy: 0.8118 - precision: 0.7343 - recall: 0.7836 - auc: 0.8518 - val_loss: 0.5185 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8842\n",
      "Epoch 113/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5427 - tp: 210.0000 - fp: 73.0000 - tn: 371.0000 - fn: 58.0000 - accuracy: 0.8160 - precision: 0.7420 - recall: 0.7836 - auc: 0.8545 - val_loss: 0.5170 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8837\n",
      "Epoch 114/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5432 - tp: 206.0000 - fp: 74.0000 - tn: 370.0000 - fn: 62.0000 - accuracy: 0.8090 - precision: 0.7357 - recall: 0.7687 - auc: 0.8529 - val_loss: 0.5176 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8838\n",
      "Epoch 115/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5449 - tp: 211.0000 - fp: 83.0000 - tn: 361.0000 - fn: 57.0000 - accuracy: 0.8034 - precision: 0.7177 - recall: 0.7873 - auc: 0.8516 - val_loss: 0.5177 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8837\n",
      "Epoch 116/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5546 - tp: 203.0000 - fp: 76.0000 - tn: 368.0000 - fn: 65.0000 - accuracy: 0.8020 - precision: 0.7276 - recall: 0.7575 - auc: 0.8454 - val_loss: 0.5152 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8840\n",
      "Epoch 117/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5486 - tp: 202.0000 - fp: 79.0000 - tn: 365.0000 - fn: 66.0000 - accuracy: 0.7963 - precision: 0.7189 - recall: 0.7537 - auc: 0.8489 - val_loss: 0.5157 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 118/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5462 - tp: 200.0000 - fp: 65.0000 - tn: 379.0000 - fn: 68.0000 - accuracy: 0.8132 - precision: 0.7547 - recall: 0.7463 - auc: 0.8500 - val_loss: 0.5200 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8833\n",
      "Epoch 119/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5448 - tp: 207.0000 - fp: 78.0000 - tn: 366.0000 - fn: 61.0000 - accuracy: 0.8048 - precision: 0.7263 - recall: 0.7724 - auc: 0.8460 - val_loss: 0.5157 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8835\n",
      "Epoch 120/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5444 - tp: 207.0000 - fp: 81.0000 - tn: 363.0000 - fn: 61.0000 - accuracy: 0.8006 - precision: 0.7188 - recall: 0.7724 - auc: 0.8484 - val_loss: 0.5137 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8840\n",
      "Epoch 121/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5377 - tp: 209.0000 - fp: 73.0000 - tn: 371.0000 - fn: 59.0000 - accuracy: 0.8146 - precision: 0.7411 - recall: 0.7799 - auc: 0.8542 - val_loss: 0.5137 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8825\n",
      "Epoch 122/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5323 - tp: 209.0000 - fp: 75.0000 - tn: 369.0000 - fn: 59.0000 - accuracy: 0.8118 - precision: 0.7359 - recall: 0.7799 - auc: 0.8600 - val_loss: 0.5147 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8826\n",
      "Epoch 123/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5457 - tp: 213.0000 - fp: 78.0000 - tn: 366.0000 - fn: 55.0000 - accuracy: 0.8132 - precision: 0.7320 - recall: 0.7948 - auc: 0.8444 - val_loss: 0.5126 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8834\n",
      "Epoch 124/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5311 - tp: 206.0000 - fp: 72.0000 - tn: 372.0000 - fn: 62.0000 - accuracy: 0.8118 - precision: 0.7410 - recall: 0.7687 - auc: 0.8581 - val_loss: 0.5112 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8837\n",
      "Epoch 125/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5363 - tp: 206.0000 - fp: 73.0000 - tn: 371.0000 - fn: 62.0000 - accuracy: 0.8104 - precision: 0.7384 - recall: 0.7687 - auc: 0.8539 - val_loss: 0.5124 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8842\n",
      "Epoch 126/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5367 - tp: 203.0000 - fp: 68.0000 - tn: 376.0000 - fn: 65.0000 - accuracy: 0.8132 - precision: 0.7491 - recall: 0.7575 - auc: 0.8506 - val_loss: 0.5110 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8828\n",
      "Epoch 127/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5405 - tp: 208.0000 - fp: 77.0000 - tn: 367.0000 - fn: 60.0000 - accuracy: 0.8076 - precision: 0.7298 - recall: 0.7761 - auc: 0.8513 - val_loss: 0.5095 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8838\n",
      "Epoch 128/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5407 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8499 - val_loss: 0.5095 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8833\n",
      "Epoch 129/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5330 - tp: 207.0000 - fp: 74.0000 - tn: 370.0000 - fn: 61.0000 - accuracy: 0.8104 - precision: 0.7367 - recall: 0.7724 - auc: 0.8565 - val_loss: 0.5069 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8842\n",
      "Epoch 130/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5387 - tp: 206.0000 - fp: 79.0000 - tn: 365.0000 - fn: 62.0000 - accuracy: 0.8020 - precision: 0.7228 - recall: 0.7687 - auc: 0.8509 - val_loss: 0.5069 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8837\n",
      "Epoch 131/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5207 - tp: 207.0000 - fp: 77.0000 - tn: 367.0000 - fn: 61.0000 - accuracy: 0.8062 - precision: 0.7289 - recall: 0.7724 - auc: 0.8667 - val_loss: 0.5089 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8835\n",
      "Epoch 132/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5455 - tp: 208.0000 - fp: 81.0000 - tn: 363.0000 - fn: 60.0000 - accuracy: 0.8020 - precision: 0.7197 - recall: 0.7761 - auc: 0.8467 - val_loss: 0.5058 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8842\n",
      "Epoch 133/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5278 - tp: 207.0000 - fp: 79.0000 - tn: 365.0000 - fn: 61.0000 - accuracy: 0.8034 - precision: 0.7238 - recall: 0.7724 - auc: 0.8598 - val_loss: 0.5072 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8847\n",
      "Epoch 134/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5336 - tp: 204.0000 - fp: 64.0000 - tn: 380.0000 - fn: 64.0000 - accuracy: 0.8202 - precision: 0.7612 - recall: 0.7612 - auc: 0.8552 - val_loss: 0.5062 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8835\n",
      "Epoch 135/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5380 - tp: 206.0000 - fp: 81.0000 - tn: 363.0000 - fn: 62.0000 - accuracy: 0.7992 - precision: 0.7178 - recall: 0.7687 - auc: 0.8496 - val_loss: 0.5057 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8836\n",
      "Epoch 136/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5230 - tp: 207.0000 - fp: 80.0000 - tn: 364.0000 - fn: 61.0000 - accuracy: 0.8020 - precision: 0.7213 - recall: 0.7724 - auc: 0.8587 - val_loss: 0.5055 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8832\n",
      "Epoch 137/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5155 - tp: 210.0000 - fp: 81.0000 - tn: 363.0000 - fn: 58.0000 - accuracy: 0.8048 - precision: 0.7216 - recall: 0.7836 - auc: 0.8660 - val_loss: 0.5040 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8841\n",
      "Epoch 138/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5173 - tp: 206.0000 - fp: 71.0000 - tn: 373.0000 - fn: 62.0000 - accuracy: 0.8132 - precision: 0.7437 - recall: 0.7687 - auc: 0.8643 - val_loss: 0.5029 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8837\n",
      "Epoch 139/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5253 - tp: 207.0000 - fp: 80.0000 - tn: 364.0000 - fn: 61.0000 - accuracy: 0.8020 - precision: 0.7213 - recall: 0.7724 - auc: 0.8591 - val_loss: 0.5042 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 140/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5195 - tp: 205.0000 - fp: 68.0000 - tn: 376.0000 - fn: 63.0000 - accuracy: 0.8160 - precision: 0.7509 - recall: 0.7649 - auc: 0.8630 - val_loss: 0.5021 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 141/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5222 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8600 - val_loss: 0.5018 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8846\n",
      "Epoch 142/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5342 - tp: 213.0000 - fp: 75.0000 - tn: 369.0000 - fn: 55.0000 - accuracy: 0.8174 - precision: 0.7396 - recall: 0.7948 - auc: 0.8501 - val_loss: 0.5016 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8837\n",
      "Epoch 143/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5276 - tp: 207.0000 - fp: 72.0000 - tn: 372.0000 - fn: 61.0000 - accuracy: 0.8132 - precision: 0.7419 - recall: 0.7724 - auc: 0.8549 - val_loss: 0.5039 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8835\n",
      "Epoch 144/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5337 - tp: 208.0000 - fp: 77.0000 - tn: 367.0000 - fn: 60.0000 - accuracy: 0.8076 - precision: 0.7298 - recall: 0.7761 - auc: 0.8476 - val_loss: 0.5021 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8834\n",
      "Epoch 145/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5345 - tp: 210.0000 - fp: 82.0000 - tn: 362.0000 - fn: 58.0000 - accuracy: 0.8034 - precision: 0.7192 - recall: 0.7836 - auc: 0.8482 - val_loss: 0.5017 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8839\n",
      "Epoch 146/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5361 - tp: 204.0000 - fp: 76.0000 - tn: 368.0000 - fn: 64.0000 - accuracy: 0.8034 - precision: 0.7286 - recall: 0.7612 - auc: 0.8483 - val_loss: 0.5006 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8830\n",
      "Epoch 147/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5244 - tp: 205.0000 - fp: 66.0000 - tn: 378.0000 - fn: 63.0000 - accuracy: 0.8188 - precision: 0.7565 - recall: 0.7649 - auc: 0.8566 - val_loss: 0.5006 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8830\n",
      "Epoch 148/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5245 - tp: 207.0000 - fp: 80.0000 - tn: 364.0000 - fn: 61.0000 - accuracy: 0.8020 - precision: 0.7213 - recall: 0.7724 - auc: 0.8555 - val_loss: 0.5004 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8831\n",
      "Epoch 149/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5264 - tp: 211.0000 - fp: 73.0000 - tn: 371.0000 - fn: 57.0000 - accuracy: 0.8174 - precision: 0.7430 - recall: 0.7873 - auc: 0.8510 - val_loss: 0.5030 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8828\n",
      "Epoch 150/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5176 - tp: 207.0000 - fp: 77.0000 - tn: 367.0000 - fn: 61.0000 - accuracy: 0.8062 - precision: 0.7289 - recall: 0.7724 - auc: 0.8620 - val_loss: 0.5004 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8826\n",
      "Epoch 151/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5236 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8559 - val_loss: 0.4998 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8828\n",
      "Epoch 152/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5213 - tp: 209.0000 - fp: 74.0000 - tn: 370.0000 - fn: 59.0000 - accuracy: 0.8132 - precision: 0.7385 - recall: 0.7799 - auc: 0.8586 - val_loss: 0.4999 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8828\n",
      "Epoch 153/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5284 - tp: 204.0000 - fp: 78.0000 - tn: 366.0000 - fn: 64.0000 - accuracy: 0.8006 - precision: 0.7234 - recall: 0.7612 - auc: 0.8541 - val_loss: 0.4986 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8833\n",
      "Epoch 154/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5230 - tp: 209.0000 - fp: 70.0000 - tn: 374.0000 - fn: 59.0000 - accuracy: 0.8188 - precision: 0.7491 - recall: 0.7799 - auc: 0.8516 - val_loss: 0.4989 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8824\n",
      "Epoch 155/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5075 - tp: 212.0000 - fp: 73.0000 - tn: 371.0000 - fn: 56.0000 - accuracy: 0.8188 - precision: 0.7439 - recall: 0.7910 - auc: 0.8681 - val_loss: 0.5010 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 156/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5225 - tp: 203.0000 - fp: 62.0000 - tn: 382.0000 - fn: 65.0000 - accuracy: 0.8216 - precision: 0.7660 - recall: 0.7575 - auc: 0.8582 - val_loss: 0.5008 - val_tp: 60.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 14.0000 - val_accuracy: 0.7821 - val_precision: 0.7059 - val_recall: 0.8108 - val_auc: 0.8818\n",
      "Epoch 157/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5282 - tp: 208.0000 - fp: 78.0000 - tn: 366.0000 - fn: 60.0000 - accuracy: 0.8062 - precision: 0.7273 - recall: 0.7761 - auc: 0.8541 - val_loss: 0.4990 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8819\n",
      "Epoch 158/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5293 - tp: 210.0000 - fp: 82.0000 - tn: 362.0000 - fn: 58.0000 - accuracy: 0.8034 - precision: 0.7192 - recall: 0.7836 - auc: 0.8499 - val_loss: 0.4990 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8828\n",
      "Epoch 159/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5207 - tp: 211.0000 - fp: 75.0000 - tn: 369.0000 - fn: 57.0000 - accuracy: 0.8146 - precision: 0.7378 - recall: 0.7873 - auc: 0.8566 - val_loss: 0.4980 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8822\n",
      "Epoch 160/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5333 - tp: 211.0000 - fp: 82.0000 - tn: 362.0000 - fn: 57.0000 - accuracy: 0.8048 - precision: 0.7201 - recall: 0.7873 - auc: 0.8472 - val_loss: 0.4967 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8819\n",
      "Epoch 161/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5108 - tp: 211.0000 - fp: 78.0000 - tn: 366.0000 - fn: 57.0000 - accuracy: 0.8104 - precision: 0.7301 - recall: 0.7873 - auc: 0.8622 - val_loss: 0.4974 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8813\n",
      "Epoch 162/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5300 - tp: 209.0000 - fp: 79.0000 - tn: 365.0000 - fn: 59.0000 - accuracy: 0.8062 - precision: 0.7257 - recall: 0.7799 - auc: 0.8507 - val_loss: 0.4947 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8822\n",
      "Epoch 163/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5323 - tp: 208.0000 - fp: 74.0000 - tn: 370.0000 - fn: 60.0000 - accuracy: 0.8118 - precision: 0.7376 - recall: 0.7761 - auc: 0.8452 - val_loss: 0.4979 - val_tp: 60.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 14.0000 - val_accuracy: 0.7765 - val_precision: 0.6977 - val_recall: 0.8108 - val_auc: 0.8809\n",
      "Epoch 164/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5332 - tp: 211.0000 - fp: 85.0000 - tn: 359.0000 - fn: 57.0000 - accuracy: 0.8006 - precision: 0.7128 - recall: 0.7873 - auc: 0.8483 - val_loss: 0.4945 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8825\n",
      "Epoch 165/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5150 - tp: 209.0000 - fp: 73.0000 - tn: 371.0000 - fn: 59.0000 - accuracy: 0.8146 - precision: 0.7411 - recall: 0.7799 - auc: 0.8599 - val_loss: 0.4947 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8828\n",
      "Epoch 166/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5187 - tp: 205.0000 - fp: 80.0000 - tn: 364.0000 - fn: 63.0000 - accuracy: 0.7992 - precision: 0.7193 - recall: 0.7649 - auc: 0.8576 - val_loss: 0.4937 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8831\n",
      "Epoch 167/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5167 - tp: 209.0000 - fp: 79.0000 - tn: 365.0000 - fn: 59.0000 - accuracy: 0.8062 - precision: 0.7257 - recall: 0.7799 - auc: 0.8588 - val_loss: 0.4935 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8835\n",
      "Epoch 168/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5219 - tp: 210.0000 - fp: 86.0000 - tn: 358.0000 - fn: 58.0000 - accuracy: 0.7978 - precision: 0.7095 - recall: 0.7836 - auc: 0.8538 - val_loss: 0.4949 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8823\n",
      "Epoch 169/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5180 - tp: 203.0000 - fp: 71.0000 - tn: 373.0000 - fn: 65.0000 - accuracy: 0.8090 - precision: 0.7409 - recall: 0.7575 - auc: 0.8563 - val_loss: 0.4939 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8824\n",
      "Epoch 170/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5140 - tp: 203.0000 - fp: 70.0000 - tn: 374.0000 - fn: 65.0000 - accuracy: 0.8104 - precision: 0.7436 - recall: 0.7575 - auc: 0.8606 - val_loss: 0.4932 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8827\n",
      "Epoch 171/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5124 - tp: 209.0000 - fp: 66.0000 - tn: 378.0000 - fn: 59.0000 - accuracy: 0.8244 - precision: 0.7600 - recall: 0.7799 - auc: 0.8600 - val_loss: 0.4938 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8819\n",
      "Epoch 172/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5280 - tp: 210.0000 - fp: 80.0000 - tn: 364.0000 - fn: 58.0000 - accuracy: 0.8062 - precision: 0.7241 - recall: 0.7836 - auc: 0.8463 - val_loss: 0.4930 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8824\n",
      "Epoch 173/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5193 - tp: 208.0000 - fp: 74.0000 - tn: 370.0000 - fn: 60.0000 - accuracy: 0.8118 - precision: 0.7376 - recall: 0.7761 - auc: 0.8549 - val_loss: 0.4937 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8818\n",
      "Epoch 174/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5101 - tp: 208.0000 - fp: 74.0000 - tn: 370.0000 - fn: 60.0000 - accuracy: 0.8118 - precision: 0.7376 - recall: 0.7761 - auc: 0.8644 - val_loss: 0.4921 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8828\n",
      "Epoch 175/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5174 - tp: 207.0000 - fp: 78.0000 - tn: 366.0000 - fn: 61.0000 - accuracy: 0.8048 - precision: 0.7263 - recall: 0.7724 - auc: 0.8546 - val_loss: 0.4921 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8822\n",
      "Epoch 176/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5293 - tp: 209.0000 - fp: 79.0000 - tn: 365.0000 - fn: 59.0000 - accuracy: 0.8062 - precision: 0.7257 - recall: 0.7799 - auc: 0.8490 - val_loss: 0.4925 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8824\n",
      "Epoch 177/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5266 - tp: 208.0000 - fp: 75.0000 - tn: 369.0000 - fn: 60.0000 - accuracy: 0.8104 - precision: 0.7350 - recall: 0.7761 - auc: 0.8460 - val_loss: 0.4921 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8828\n",
      "Epoch 178/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5244 - tp: 210.0000 - fp: 71.0000 - tn: 373.0000 - fn: 58.0000 - accuracy: 0.8188 - precision: 0.7473 - recall: 0.7836 - auc: 0.8509 - val_loss: 0.4926 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8822\n",
      "Epoch 179/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5173 - tp: 207.0000 - fp: 74.0000 - tn: 370.0000 - fn: 61.0000 - accuracy: 0.8104 - precision: 0.7367 - recall: 0.7724 - auc: 0.8535 - val_loss: 0.4921 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8821\n",
      "Epoch 180/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5189 - tp: 212.0000 - fp: 78.0000 - tn: 366.0000 - fn: 56.0000 - accuracy: 0.8118 - precision: 0.7310 - recall: 0.7910 - auc: 0.8556 - val_loss: 0.4919 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8823\n",
      "Epoch 181/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5177 - tp: 210.0000 - fp: 74.0000 - tn: 370.0000 - fn: 58.0000 - accuracy: 0.8146 - precision: 0.7394 - recall: 0.7836 - auc: 0.8524 - val_loss: 0.4907 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8827\n",
      "Epoch 182/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5217 - tp: 211.0000 - fp: 76.0000 - tn: 368.0000 - fn: 57.0000 - accuracy: 0.8132 - precision: 0.7352 - recall: 0.7873 - auc: 0.8520 - val_loss: 0.4907 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8829\n",
      "Epoch 183/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5086 - tp: 211.0000 - fp: 78.0000 - tn: 366.0000 - fn: 57.0000 - accuracy: 0.8104 - precision: 0.7301 - recall: 0.7873 - auc: 0.8628 - val_loss: 0.4902 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8827\n",
      "Epoch 184/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.5105 - tp: 211.0000 - fp: 77.0000 - tn: 367.0000 - fn: 57.0000 - accuracy: 0.8118 - precision: 0.7326 - recall: 0.7873 - auc: 0.8602 - val_loss: 0.4902 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8821\n",
      "Epoch 185/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5169 - tp: 206.0000 - fp: 68.0000 - tn: 376.0000 - fn: 62.0000 - accuracy: 0.8174 - precision: 0.7518 - recall: 0.7687 - auc: 0.8552 - val_loss: 0.4907 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8829\n",
      "Epoch 186/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5187 - tp: 209.0000 - fp: 76.0000 - tn: 368.0000 - fn: 59.0000 - accuracy: 0.8104 - precision: 0.7333 - recall: 0.7799 - auc: 0.8569 - val_loss: 0.4901 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8829\n",
      "Epoch 187/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5267 - tp: 207.0000 - fp: 78.0000 - tn: 366.0000 - fn: 61.0000 - accuracy: 0.8048 - precision: 0.7263 - recall: 0.7724 - auc: 0.8485 - val_loss: 0.4900 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8823\n",
      "Epoch 188/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5216 - tp: 208.0000 - fp: 70.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.8174 - precision: 0.7482 - recall: 0.7761 - auc: 0.8503 - val_loss: 0.4916 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8814\n",
      "Epoch 189/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5140 - tp: 207.0000 - fp: 76.0000 - tn: 368.0000 - fn: 61.0000 - accuracy: 0.8076 - precision: 0.7314 - recall: 0.7724 - auc: 0.8568 - val_loss: 0.4901 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8822\n",
      "Epoch 190/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5264 - tp: 209.0000 - fp: 83.0000 - tn: 361.0000 - fn: 59.0000 - accuracy: 0.8006 - precision: 0.7158 - recall: 0.7799 - auc: 0.8463 - val_loss: 0.4913 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8819\n",
      "Epoch 191/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5296 - tp: 207.0000 - fp: 80.0000 - tn: 364.0000 - fn: 61.0000 - accuracy: 0.8020 - precision: 0.7213 - recall: 0.7724 - auc: 0.8447 - val_loss: 0.4904 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8829\n",
      "Epoch 192/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5079 - tp: 208.0000 - fp: 74.0000 - tn: 370.0000 - fn: 60.0000 - accuracy: 0.8118 - precision: 0.7376 - recall: 0.7761 - auc: 0.8623 - val_loss: 0.4890 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8833\n",
      "Epoch 193/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.5188 - tp: 213.0000 - fp: 74.0000 - tn: 370.0000 - fn: 55.0000 - accuracy: 0.8188 - precision: 0.7422 - recall: 0.7948 - auc: 0.8559 - val_loss: 0.4885 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8829\n",
      "Epoch 194/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5082 - tp: 208.0000 - fp: 79.0000 - tn: 365.0000 - fn: 60.0000 - accuracy: 0.8048 - precision: 0.7247 - recall: 0.7761 - auc: 0.8597 - val_loss: 0.4882 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8828\n",
      "Epoch 195/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5208 - tp: 205.0000 - fp: 76.0000 - tn: 368.0000 - fn: 63.0000 - accuracy: 0.8048 - precision: 0.7295 - recall: 0.7649 - auc: 0.8521 - val_loss: 0.4890 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8824\n",
      "Epoch 196/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5190 - tp: 211.0000 - fp: 83.0000 - tn: 361.0000 - fn: 57.0000 - accuracy: 0.8034 - precision: 0.7177 - recall: 0.7873 - auc: 0.8555 - val_loss: 0.4880 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8830\n",
      "Epoch 197/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5084 - tp: 206.0000 - fp: 64.0000 - tn: 380.0000 - fn: 62.0000 - accuracy: 0.8230 - precision: 0.7630 - recall: 0.7687 - auc: 0.8618 - val_loss: 0.4876 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8831\n",
      "Epoch 198/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5191 - tp: 207.0000 - fp: 82.0000 - tn: 362.0000 - fn: 61.0000 - accuracy: 0.7992 - precision: 0.7163 - recall: 0.7724 - auc: 0.8536 - val_loss: 0.4877 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8824\n",
      "Epoch 199/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5169 - tp: 209.0000 - fp: 78.0000 - tn: 366.0000 - fn: 59.0000 - accuracy: 0.8076 - precision: 0.7282 - recall: 0.7799 - auc: 0.8546 - val_loss: 0.4881 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8828\n",
      "Epoch 200/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5062 - tp: 211.0000 - fp: 80.0000 - tn: 364.0000 - fn: 57.0000 - accuracy: 0.8076 - precision: 0.7251 - recall: 0.7873 - auc: 0.8615 - val_loss: 0.4878 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8827\n",
      "Epoch 201/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.5186 - tp: 207.0000 - fp: 65.0000 - tn: 379.0000 - fn: 61.0000 - accuracy: 0.8230 - precision: 0.7610 - recall: 0.7724 - auc: 0.8500 - val_loss: 0.4880 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8825\n",
      "Epoch 202/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.5082 - tp: 209.0000 - fp: 79.0000 - tn: 365.0000 - fn: 59.0000 - accuracy: 0.8062 - precision: 0.7257 - recall: 0.7799 - auc: 0.8569 - val_loss: 0.4870 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8831\n",
      "Epoch 203/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5148 - tp: 208.0000 - fp: 79.0000 - tn: 365.0000 - fn: 60.0000 - accuracy: 0.8048 - precision: 0.7247 - recall: 0.7761 - auc: 0.8538 - val_loss: 0.4868 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8829\n",
      "Epoch 204/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5158 - tp: 206.0000 - fp: 69.0000 - tn: 375.0000 - fn: 62.0000 - accuracy: 0.8160 - precision: 0.7491 - recall: 0.7687 - auc: 0.8514 - val_loss: 0.4902 - val_tp: 60.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 14.0000 - val_accuracy: 0.7709 - val_precision: 0.6897 - val_recall: 0.8108 - val_auc: 0.8822\n",
      "Epoch 205/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5106 - tp: 210.0000 - fp: 73.0000 - tn: 371.0000 - fn: 58.0000 - accuracy: 0.8160 - precision: 0.7420 - recall: 0.7836 - auc: 0.8569 - val_loss: 0.4884 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8832\n",
      "Epoch 206/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.5086 - tp: 210.0000 - fp: 71.0000 - tn: 373.0000 - fn: 58.0000 - accuracy: 0.8188 - precision: 0.7473 - recall: 0.7836 - auc: 0.8577 - val_loss: 0.4874 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8830\n",
      "Epoch 207/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5110 - tp: 209.0000 - fp: 80.0000 - tn: 364.0000 - fn: 59.0000 - accuracy: 0.8048 - precision: 0.7232 - recall: 0.7799 - auc: 0.8588 - val_loss: 0.4857 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8835\n",
      "Epoch 208/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5071 - tp: 209.0000 - fp: 71.0000 - tn: 373.0000 - fn: 59.0000 - accuracy: 0.8174 - precision: 0.7464 - recall: 0.7799 - auc: 0.8594 - val_loss: 0.4849 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8835\n",
      "Epoch 209/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5059 - tp: 210.0000 - fp: 74.0000 - tn: 370.0000 - fn: 58.0000 - accuracy: 0.8146 - precision: 0.7394 - recall: 0.7836 - auc: 0.8598 - val_loss: 0.4863 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8829\n",
      "Epoch 210/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5229 - tp: 207.0000 - fp: 74.0000 - tn: 370.0000 - fn: 61.0000 - accuracy: 0.8104 - precision: 0.7367 - recall: 0.7724 - auc: 0.8481 - val_loss: 0.4873 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8833\n",
      "Epoch 211/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5160 - tp: 211.0000 - fp: 80.0000 - tn: 364.0000 - fn: 57.0000 - accuracy: 0.8076 - precision: 0.7251 - recall: 0.7873 - auc: 0.8537 - val_loss: 0.4871 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8826\n",
      "Epoch 212/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5057 - tp: 208.0000 - fp: 75.0000 - tn: 369.0000 - fn: 60.0000 - accuracy: 0.8104 - precision: 0.7350 - recall: 0.7761 - auc: 0.8592 - val_loss: 0.4848 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8837\n",
      "Epoch 213/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5082 - tp: 205.0000 - fp: 69.0000 - tn: 375.0000 - fn: 63.0000 - accuracy: 0.8146 - precision: 0.7482 - recall: 0.7649 - auc: 0.8573 - val_loss: 0.4848 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8833\n",
      "Epoch 214/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5051 - tp: 211.0000 - fp: 75.0000 - tn: 369.0000 - fn: 57.0000 - accuracy: 0.8146 - precision: 0.7378 - recall: 0.7873 - auc: 0.8611 - val_loss: 0.4841 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8837\n",
      "Epoch 215/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5221 - tp: 209.0000 - fp: 74.0000 - tn: 370.0000 - fn: 59.0000 - accuracy: 0.8132 - precision: 0.7385 - recall: 0.7799 - auc: 0.8484 - val_loss: 0.4875 - val_tp: 60.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 14.0000 - val_accuracy: 0.7821 - val_precision: 0.7059 - val_recall: 0.8108 - val_auc: 0.8835\n",
      "Epoch 216/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5113 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8523 - val_loss: 0.4850 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8835\n",
      "Epoch 217/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5037 - tp: 209.0000 - fp: 78.0000 - tn: 366.0000 - fn: 59.0000 - accuracy: 0.8076 - precision: 0.7282 - recall: 0.7799 - auc: 0.8604 - val_loss: 0.4843 - val_tp: 57.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 17.0000 - val_accuracy: 0.7933 - val_precision: 0.7403 - val_recall: 0.7703 - val_auc: 0.8834\n",
      "Epoch 218/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5153 - tp: 209.0000 - fp: 80.0000 - tn: 364.0000 - fn: 59.0000 - accuracy: 0.8048 - precision: 0.7232 - recall: 0.7799 - auc: 0.8514 - val_loss: 0.4847 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8838\n",
      "Epoch 219/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5148 - tp: 207.0000 - fp: 78.0000 - tn: 366.0000 - fn: 61.0000 - accuracy: 0.8048 - precision: 0.7263 - recall: 0.7724 - auc: 0.8541 - val_loss: 0.4839 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8835\n",
      "Epoch 220/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5178 - tp: 208.0000 - fp: 75.0000 - tn: 369.0000 - fn: 60.0000 - accuracy: 0.8104 - precision: 0.7350 - recall: 0.7761 - auc: 0.8513 - val_loss: 0.4836 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8836\n",
      "Epoch 221/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5059 - tp: 205.0000 - fp: 65.0000 - tn: 379.0000 - fn: 63.0000 - accuracy: 0.8202 - precision: 0.7593 - recall: 0.7649 - auc: 0.8569 - val_loss: 0.4832 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8829\n",
      "Epoch 222/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5113 - tp: 210.0000 - fp: 78.0000 - tn: 366.0000 - fn: 58.0000 - accuracy: 0.8090 - precision: 0.7292 - recall: 0.7836 - auc: 0.8553 - val_loss: 0.4835 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8833\n",
      "Epoch 223/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4959 - tp: 208.0000 - fp: 66.0000 - tn: 378.0000 - fn: 60.0000 - accuracy: 0.8230 - precision: 0.7591 - recall: 0.7761 - auc: 0.8712 - val_loss: 0.4824 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8838\n",
      "Epoch 224/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5252 - tp: 205.0000 - fp: 72.0000 - tn: 372.0000 - fn: 63.0000 - accuracy: 0.8104 - precision: 0.7401 - recall: 0.7649 - auc: 0.8443 - val_loss: 0.4868 - val_tp: 60.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 14.0000 - val_accuracy: 0.7821 - val_precision: 0.7059 - val_recall: 0.8108 - val_auc: 0.8820\n",
      "Epoch 225/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5090 - tp: 210.0000 - fp: 78.0000 - tn: 366.0000 - fn: 58.0000 - accuracy: 0.8090 - precision: 0.7292 - recall: 0.7836 - auc: 0.8578 - val_loss: 0.4840 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8832\n",
      "Epoch 226/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.4916 - tp: 208.0000 - fp: 70.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.8174 - precision: 0.7482 - recall: 0.7761 - auc: 0.8708 - val_loss: 0.4824 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8842\n",
      "Epoch 227/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5086 - tp: 206.0000 - fp: 73.0000 - tn: 371.0000 - fn: 62.0000 - accuracy: 0.8104 - precision: 0.7384 - recall: 0.7687 - auc: 0.8583 - val_loss: 0.4839 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8820\n",
      "Epoch 228/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5152 - tp: 213.0000 - fp: 83.0000 - tn: 361.0000 - fn: 55.0000 - accuracy: 0.8062 - precision: 0.7196 - recall: 0.7948 - auc: 0.8529 - val_loss: 0.4825 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8847\n",
      "Epoch 229/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5025 - tp: 204.0000 - fp: 72.0000 - tn: 372.0000 - fn: 64.0000 - accuracy: 0.8090 - precision: 0.7391 - recall: 0.7612 - auc: 0.8590 - val_loss: 0.4816 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8838\n",
      "Epoch 230/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5064 - tp: 212.0000 - fp: 79.0000 - tn: 365.0000 - fn: 56.0000 - accuracy: 0.8104 - precision: 0.7285 - recall: 0.7910 - auc: 0.8557 - val_loss: 0.4819 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8847\n",
      "Epoch 231/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5142 - tp: 208.0000 - fp: 71.0000 - tn: 373.0000 - fn: 60.0000 - accuracy: 0.8160 - precision: 0.7455 - recall: 0.7761 - auc: 0.8522 - val_loss: 0.4825 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8837\n",
      "Epoch 232/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5103 - tp: 208.0000 - fp: 77.0000 - tn: 367.0000 - fn: 60.0000 - accuracy: 0.8076 - precision: 0.7298 - recall: 0.7761 - auc: 0.8553 - val_loss: 0.4818 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8846\n",
      "Epoch 233/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.4997 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8602 - val_loss: 0.4816 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8843\n",
      "Epoch 234/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5063 - tp: 207.0000 - fp: 65.0000 - tn: 379.0000 - fn: 61.0000 - accuracy: 0.8230 - precision: 0.7610 - recall: 0.7724 - auc: 0.8585 - val_loss: 0.4807 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8847\n",
      "Epoch 235/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5013 - tp: 208.0000 - fp: 76.0000 - tn: 368.0000 - fn: 60.0000 - accuracy: 0.8090 - precision: 0.7324 - recall: 0.7761 - auc: 0.8622 - val_loss: 0.4827 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8834\n",
      "Epoch 236/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5028 - tp: 208.0000 - fp: 80.0000 - tn: 364.0000 - fn: 60.0000 - accuracy: 0.8034 - precision: 0.7222 - recall: 0.7761 - auc: 0.8594 - val_loss: 0.4804 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8842\n",
      "Epoch 237/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5011 - tp: 208.0000 - fp: 75.0000 - tn: 369.0000 - fn: 60.0000 - accuracy: 0.8104 - precision: 0.7350 - recall: 0.7761 - auc: 0.8615 - val_loss: 0.4798 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8846\n",
      "Epoch 238/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5104 - tp: 209.0000 - fp: 68.0000 - tn: 376.0000 - fn: 59.0000 - accuracy: 0.8216 - precision: 0.7545 - recall: 0.7799 - auc: 0.8557 - val_loss: 0.4831 - val_tp: 60.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 14.0000 - val_accuracy: 0.7821 - val_precision: 0.7059 - val_recall: 0.8108 - val_auc: 0.8824\n",
      "Epoch 239/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5003 - tp: 207.0000 - fp: 77.0000 - tn: 367.0000 - fn: 61.0000 - accuracy: 0.8062 - precision: 0.7289 - recall: 0.7724 - auc: 0.8600 - val_loss: 0.4802 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8839\n",
      "Epoch 240/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5155 - tp: 208.0000 - fp: 83.0000 - tn: 361.0000 - fn: 60.0000 - accuracy: 0.7992 - precision: 0.7148 - recall: 0.7761 - auc: 0.8522 - val_loss: 0.4803 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8838\n",
      "Epoch 241/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5155 - tp: 205.0000 - fp: 79.0000 - tn: 365.0000 - fn: 63.0000 - accuracy: 0.8006 - precision: 0.7218 - recall: 0.7649 - auc: 0.8491 - val_loss: 0.4798 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8840\n",
      "Epoch 242/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5061 - tp: 208.0000 - fp: 71.0000 - tn: 373.0000 - fn: 60.0000 - accuracy: 0.8160 - precision: 0.7455 - recall: 0.7761 - auc: 0.8559 - val_loss: 0.4815 - val_tp: 60.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 14.0000 - val_accuracy: 0.7821 - val_precision: 0.7059 - val_recall: 0.8108 - val_auc: 0.8832\n",
      "Epoch 243/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5103 - tp: 209.0000 - fp: 76.0000 - tn: 368.0000 - fn: 59.0000 - accuracy: 0.8104 - precision: 0.7333 - recall: 0.7799 - auc: 0.8565 - val_loss: 0.4796 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8845\n",
      "Epoch 244/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5083 - tp: 211.0000 - fp: 69.0000 - tn: 375.0000 - fn: 57.0000 - accuracy: 0.8230 - precision: 0.7536 - recall: 0.7873 - auc: 0.8553 - val_loss: 0.4821 - val_tp: 60.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 14.0000 - val_accuracy: 0.7821 - val_precision: 0.7059 - val_recall: 0.8108 - val_auc: 0.8830\n",
      "Epoch 245/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5013 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8634 - val_loss: 0.4791 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8839\n",
      "Epoch 246/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5183 - tp: 208.0000 - fp: 71.0000 - tn: 373.0000 - fn: 60.0000 - accuracy: 0.8160 - precision: 0.7455 - recall: 0.7761 - auc: 0.8493 - val_loss: 0.4804 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8835\n",
      "Epoch 247/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5038 - tp: 205.0000 - fp: 71.0000 - tn: 373.0000 - fn: 63.0000 - accuracy: 0.8118 - precision: 0.7428 - recall: 0.7649 - auc: 0.8590 - val_loss: 0.4831 - val_tp: 60.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 14.0000 - val_accuracy: 0.7821 - val_precision: 0.7059 - val_recall: 0.8108 - val_auc: 0.8832\n",
      "Epoch 248/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5001 - tp: 209.0000 - fp: 81.0000 - tn: 363.0000 - fn: 59.0000 - accuracy: 0.8034 - precision: 0.7207 - recall: 0.7799 - auc: 0.8615 - val_loss: 0.4790 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8847\n",
      "Epoch 249/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5091 - tp: 208.0000 - fp: 74.0000 - tn: 370.0000 - fn: 60.0000 - accuracy: 0.8118 - precision: 0.7376 - recall: 0.7761 - auc: 0.8554 - val_loss: 0.4804 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8838\n",
      "Epoch 250/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5168 - tp: 209.0000 - fp: 80.0000 - tn: 364.0000 - fn: 59.0000 - accuracy: 0.8048 - precision: 0.7232 - recall: 0.7799 - auc: 0.8485 - val_loss: 0.4797 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8836\n",
      "Epoch 251/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5201 - tp: 208.0000 - fp: 76.0000 - tn: 368.0000 - fn: 60.0000 - accuracy: 0.8090 - precision: 0.7324 - recall: 0.7761 - auc: 0.8484 - val_loss: 0.4793 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8843\n",
      "Epoch 252/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5105 - tp: 209.0000 - fp: 75.0000 - tn: 369.0000 - fn: 59.0000 - accuracy: 0.8118 - precision: 0.7359 - recall: 0.7799 - auc: 0.8554 - val_loss: 0.4841 - val_tp: 61.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 13.0000 - val_accuracy: 0.7821 - val_precision: 0.7011 - val_recall: 0.8243 - val_auc: 0.8823\n",
      "Epoch 253/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.4905 - tp: 207.0000 - fp: 72.0000 - tn: 372.0000 - fn: 61.0000 - accuracy: 0.8132 - precision: 0.7419 - recall: 0.7724 - auc: 0.8678 - val_loss: 0.4799 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8831\n",
      "Epoch 254/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5092 - tp: 204.0000 - fp: 72.0000 - tn: 372.0000 - fn: 64.0000 - accuracy: 0.8090 - precision: 0.7391 - recall: 0.7612 - auc: 0.8538 - val_loss: 0.4791 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8828\n",
      "Epoch 255/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5009 - tp: 211.0000 - fp: 77.0000 - tn: 367.0000 - fn: 57.0000 - accuracy: 0.8118 - precision: 0.7326 - recall: 0.7873 - auc: 0.8598 - val_loss: 0.4783 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8846\n",
      "Epoch 256/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5099 - tp: 208.0000 - fp: 70.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.8174 - precision: 0.7482 - recall: 0.7761 - auc: 0.8525 - val_loss: 0.4813 - val_tp: 60.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 14.0000 - val_accuracy: 0.7821 - val_precision: 0.7059 - val_recall: 0.8108 - val_auc: 0.8823\n",
      "Epoch 257/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5114 - tp: 209.0000 - fp: 78.0000 - tn: 366.0000 - fn: 59.0000 - accuracy: 0.8076 - precision: 0.7282 - recall: 0.7799 - auc: 0.8502 - val_loss: 0.4817 - val_tp: 60.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 14.0000 - val_accuracy: 0.7821 - val_precision: 0.7059 - val_recall: 0.8108 - val_auc: 0.8826\n",
      "Epoch 258/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.4962 - tp: 206.0000 - fp: 76.0000 - tn: 368.0000 - fn: 62.0000 - accuracy: 0.8062 - precision: 0.7305 - recall: 0.7687 - auc: 0.8639 - val_loss: 0.4801 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8838\n",
      "Epoch 259/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5083 - tp: 209.0000 - fp: 77.0000 - tn: 367.0000 - fn: 59.0000 - accuracy: 0.8090 - precision: 0.7308 - recall: 0.7799 - auc: 0.8591 - val_loss: 0.4784 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8855\n",
      "Epoch 260/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5133 - tp: 211.0000 - fp: 68.0000 - tn: 376.0000 - fn: 57.0000 - accuracy: 0.8244 - precision: 0.7563 - recall: 0.7873 - auc: 0.8531 - val_loss: 0.4786 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8851\n",
      "Epoch 261/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4990 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8619 - val_loss: 0.4830 - val_tp: 60.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 14.0000 - val_accuracy: 0.7765 - val_precision: 0.6977 - val_recall: 0.8108 - val_auc: 0.8817\n",
      "Epoch 262/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5082 - tp: 212.0000 - fp: 72.0000 - tn: 372.0000 - fn: 56.0000 - accuracy: 0.8202 - precision: 0.7465 - recall: 0.7910 - auc: 0.8573 - val_loss: 0.4801 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8833\n",
      "Epoch 263/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5037 - tp: 205.0000 - fp: 65.0000 - tn: 379.0000 - fn: 63.0000 - accuracy: 0.8202 - precision: 0.7593 - recall: 0.7649 - auc: 0.8564 - val_loss: 0.4804 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8836\n",
      "Epoch 264/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5010 - tp: 209.0000 - fp: 74.0000 - tn: 370.0000 - fn: 59.0000 - accuracy: 0.8132 - precision: 0.7385 - recall: 0.7799 - auc: 0.8613 - val_loss: 0.4797 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8839\n",
      "Epoch 265/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5184 - tp: 205.0000 - fp: 77.0000 - tn: 367.0000 - fn: 63.0000 - accuracy: 0.8034 - precision: 0.7270 - recall: 0.7649 - auc: 0.8498 - val_loss: 0.4786 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8838\n",
      "Epoch 266/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.4972 - tp: 210.0000 - fp: 66.0000 - tn: 378.0000 - fn: 58.0000 - accuracy: 0.8258 - precision: 0.7609 - recall: 0.7836 - auc: 0.8618 - val_loss: 0.4780 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8847\n",
      "Epoch 267/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4941 - tp: 208.0000 - fp: 72.0000 - tn: 372.0000 - fn: 60.0000 - accuracy: 0.8146 - precision: 0.7429 - recall: 0.7761 - auc: 0.8669 - val_loss: 0.4783 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8829\n",
      "Epoch 268/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5097 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8499 - val_loss: 0.4779 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8837\n",
      "Epoch 269/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5099 - tp: 204.0000 - fp: 69.0000 - tn: 375.0000 - fn: 64.0000 - accuracy: 0.8132 - precision: 0.7473 - recall: 0.7612 - auc: 0.8516 - val_loss: 0.4794 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8842\n",
      "Epoch 270/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5065 - tp: 209.0000 - fp: 75.0000 - tn: 369.0000 - fn: 59.0000 - accuracy: 0.8118 - precision: 0.7359 - recall: 0.7799 - auc: 0.8547 - val_loss: 0.4809 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8832\n",
      "Epoch 271/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5120 - tp: 211.0000 - fp: 79.0000 - tn: 365.0000 - fn: 57.0000 - accuracy: 0.8090 - precision: 0.7276 - recall: 0.7873 - auc: 0.8527 - val_loss: 0.4780 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8837\n",
      "Epoch 272/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4787 - tp: 205.0000 - fp: 67.0000 - tn: 377.0000 - fn: 63.0000 - accuracy: 0.8174 - precision: 0.7537 - recall: 0.7649 - auc: 0.8764 - val_loss: 0.4764 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8846\n",
      "Epoch 273/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5037 - tp: 206.0000 - fp: 69.0000 - tn: 375.0000 - fn: 62.0000 - accuracy: 0.8160 - precision: 0.7491 - recall: 0.7687 - auc: 0.8575 - val_loss: 0.4770 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8846\n",
      "Epoch 274/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5025 - tp: 209.0000 - fp: 68.0000 - tn: 376.0000 - fn: 59.0000 - accuracy: 0.8216 - precision: 0.7545 - recall: 0.7799 - auc: 0.8581 - val_loss: 0.4772 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8853\n",
      "Epoch 275/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5156 - tp: 205.0000 - fp: 70.0000 - tn: 374.0000 - fn: 63.0000 - accuracy: 0.8132 - precision: 0.7455 - recall: 0.7649 - auc: 0.8470 - val_loss: 0.4770 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8851\n",
      "Epoch 276/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5040 - tp: 209.0000 - fp: 68.0000 - tn: 376.0000 - fn: 59.0000 - accuracy: 0.8216 - precision: 0.7545 - recall: 0.7799 - auc: 0.8595 - val_loss: 0.4784 - val_tp: 60.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 14.0000 - val_accuracy: 0.8101 - val_precision: 0.7500 - val_recall: 0.8108 - val_auc: 0.8843\n",
      "Epoch 277/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4983 - tp: 208.0000 - fp: 78.0000 - tn: 366.0000 - fn: 60.0000 - accuracy: 0.8062 - precision: 0.7273 - recall: 0.7761 - auc: 0.8630 - val_loss: 0.4760 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8853\n",
      "Epoch 278/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4893 - tp: 208.0000 - fp: 66.0000 - tn: 378.0000 - fn: 60.0000 - accuracy: 0.8230 - precision: 0.7591 - recall: 0.7761 - auc: 0.8713 - val_loss: 0.4757 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8854\n",
      "Epoch 279/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.4923 - tp: 210.0000 - fp: 75.0000 - tn: 369.0000 - fn: 58.0000 - accuracy: 0.8132 - precision: 0.7368 - recall: 0.7836 - auc: 0.8618 - val_loss: 0.4761 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8853\n",
      "Epoch 280/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4987 - tp: 207.0000 - fp: 66.0000 - tn: 378.0000 - fn: 61.0000 - accuracy: 0.8216 - precision: 0.7582 - recall: 0.7724 - auc: 0.8611 - val_loss: 0.4777 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8842\n",
      "Epoch 281/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5032 - tp: 205.0000 - fp: 78.0000 - tn: 366.0000 - fn: 63.0000 - accuracy: 0.8020 - precision: 0.7244 - recall: 0.7649 - auc: 0.8590 - val_loss: 0.4764 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8851\n",
      "Epoch 282/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.4940 - tp: 208.0000 - fp: 70.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.8174 - precision: 0.7482 - recall: 0.7761 - auc: 0.8652 - val_loss: 0.4771 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8852\n",
      "Epoch 283/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.5064 - tp: 207.0000 - fp: 76.0000 - tn: 368.0000 - fn: 61.0000 - accuracy: 0.8076 - precision: 0.7314 - recall: 0.7724 - auc: 0.8550 - val_loss: 0.4768 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8846\n",
      "Epoch 284/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4995 - tp: 210.0000 - fp: 72.0000 - tn: 372.0000 - fn: 58.0000 - accuracy: 0.8174 - precision: 0.7447 - recall: 0.7836 - auc: 0.8572 - val_loss: 0.4782 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8844\n",
      "Epoch 285/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5019 - tp: 211.0000 - fp: 67.0000 - tn: 377.0000 - fn: 57.0000 - accuracy: 0.8258 - precision: 0.7590 - recall: 0.7873 - auc: 0.8600 - val_loss: 0.4773 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8838\n",
      "Epoch 286/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5011 - tp: 208.0000 - fp: 76.0000 - tn: 368.0000 - fn: 60.0000 - accuracy: 0.8090 - precision: 0.7324 - recall: 0.7761 - auc: 0.8609 - val_loss: 0.4777 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8846\n",
      "Epoch 287/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4992 - tp: 209.0000 - fp: 75.0000 - tn: 369.0000 - fn: 59.0000 - accuracy: 0.8118 - precision: 0.7359 - recall: 0.7799 - auc: 0.8624 - val_loss: 0.4764 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8847\n",
      "Epoch 288/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5056 - tp: 209.0000 - fp: 69.0000 - tn: 375.0000 - fn: 59.0000 - accuracy: 0.8202 - precision: 0.7518 - recall: 0.7799 - auc: 0.8546 - val_loss: 0.4761 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8854\n",
      "Epoch 289/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4862 - tp: 208.0000 - fp: 69.0000 - tn: 375.0000 - fn: 60.0000 - accuracy: 0.8188 - precision: 0.7509 - recall: 0.7761 - auc: 0.8696 - val_loss: 0.4759 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8840\n",
      "Epoch 290/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4898 - tp: 207.0000 - fp: 63.0000 - tn: 381.0000 - fn: 61.0000 - accuracy: 0.8258 - precision: 0.7667 - recall: 0.7724 - auc: 0.8680 - val_loss: 0.4787 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8835\n",
      "Epoch 291/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4982 - tp: 207.0000 - fp: 68.0000 - tn: 376.0000 - fn: 61.0000 - accuracy: 0.8188 - precision: 0.7527 - recall: 0.7724 - auc: 0.8586 - val_loss: 0.4762 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8863\n",
      "Epoch 292/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4830 - tp: 208.0000 - fp: 70.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.8174 - precision: 0.7482 - recall: 0.7761 - auc: 0.8714 - val_loss: 0.4748 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8869\n",
      "Epoch 293/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4978 - tp: 208.0000 - fp: 74.0000 - tn: 370.0000 - fn: 60.0000 - accuracy: 0.8118 - precision: 0.7376 - recall: 0.7761 - auc: 0.8615 - val_loss: 0.4748 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8853\n",
      "Epoch 294/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.5009 - tp: 206.0000 - fp: 73.0000 - tn: 371.0000 - fn: 62.0000 - accuracy: 0.8104 - precision: 0.7384 - recall: 0.7687 - auc: 0.8593 - val_loss: 0.4752 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8845\n",
      "Epoch 295/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4981 - tp: 211.0000 - fp: 74.0000 - tn: 370.0000 - fn: 57.0000 - accuracy: 0.8160 - precision: 0.7404 - recall: 0.7873 - auc: 0.8627 - val_loss: 0.4758 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8842\n",
      "Epoch 296/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5062 - tp: 211.0000 - fp: 69.0000 - tn: 375.0000 - fn: 57.0000 - accuracy: 0.8230 - precision: 0.7536 - recall: 0.7873 - auc: 0.8536 - val_loss: 0.4753 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8851\n",
      "Epoch 297/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5113 - tp: 207.0000 - fp: 74.0000 - tn: 370.0000 - fn: 61.0000 - accuracy: 0.8104 - precision: 0.7367 - recall: 0.7724 - auc: 0.8516 - val_loss: 0.4758 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8835\n",
      "Epoch 298/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5058 - tp: 210.0000 - fp: 77.0000 - tn: 367.0000 - fn: 58.0000 - accuracy: 0.8104 - precision: 0.7317 - recall: 0.7836 - auc: 0.8556 - val_loss: 0.4749 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8850\n",
      "Epoch 299/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.5154 - tp: 205.0000 - fp: 73.0000 - tn: 371.0000 - fn: 63.0000 - accuracy: 0.8090 - precision: 0.7374 - recall: 0.7649 - auc: 0.8458 - val_loss: 0.4748 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8846\n",
      "Epoch 300/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.5098 - tp: 208.0000 - fp: 71.0000 - tn: 373.0000 - fn: 60.0000 - accuracy: 0.8160 - precision: 0.7455 - recall: 0.7761 - auc: 0.8511 - val_loss: 0.4750 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8856\n",
      "Epoch 301/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5059 - tp: 208.0000 - fp: 75.0000 - tn: 369.0000 - fn: 60.0000 - accuracy: 0.8104 - precision: 0.7350 - recall: 0.7761 - auc: 0.8529 - val_loss: 0.4756 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8853\n",
      "Epoch 302/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.4985 - tp: 209.0000 - fp: 68.0000 - tn: 376.0000 - fn: 59.0000 - accuracy: 0.8216 - precision: 0.7545 - recall: 0.7799 - auc: 0.8621 - val_loss: 0.4751 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8849\n",
      "Epoch 303/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.4980 - tp: 208.0000 - fp: 70.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.8174 - precision: 0.7482 - recall: 0.7761 - auc: 0.8595 - val_loss: 0.4764 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8842\n",
      "Epoch 304/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5175 - tp: 204.0000 - fp: 77.0000 - tn: 367.0000 - fn: 64.0000 - accuracy: 0.8020 - precision: 0.7260 - recall: 0.7612 - auc: 0.8464 - val_loss: 0.4757 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8849\n",
      "Epoch 305/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5018 - tp: 209.0000 - fp: 71.0000 - tn: 373.0000 - fn: 59.0000 - accuracy: 0.8174 - precision: 0.7464 - recall: 0.7799 - auc: 0.8573 - val_loss: 0.4764 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8855\n",
      "Epoch 306/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5144 - tp: 206.0000 - fp: 73.0000 - tn: 371.0000 - fn: 62.0000 - accuracy: 0.8104 - precision: 0.7384 - recall: 0.7687 - auc: 0.8476 - val_loss: 0.4798 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8828\n",
      "Epoch 307/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5199 - tp: 210.0000 - fp: 79.0000 - tn: 365.0000 - fn: 58.0000 - accuracy: 0.8076 - precision: 0.7266 - recall: 0.7836 - auc: 0.8465 - val_loss: 0.4802 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8835\n",
      "Epoch 308/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5027 - tp: 211.0000 - fp: 73.0000 - tn: 371.0000 - fn: 57.0000 - accuracy: 0.8174 - precision: 0.7430 - recall: 0.7873 - auc: 0.8555 - val_loss: 0.4776 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8840\n",
      "Epoch 309/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5144 - tp: 212.0000 - fp: 85.0000 - tn: 359.0000 - fn: 56.0000 - accuracy: 0.8020 - precision: 0.7138 - recall: 0.7910 - auc: 0.8519 - val_loss: 0.4770 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8840\n",
      "Epoch 310/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5043 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8546 - val_loss: 0.4802 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8838\n",
      "Epoch 311/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5005 - tp: 210.0000 - fp: 71.0000 - tn: 373.0000 - fn: 58.0000 - accuracy: 0.8188 - precision: 0.7473 - recall: 0.7836 - auc: 0.8589 - val_loss: 0.4767 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8850\n",
      "Epoch 312/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5019 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8561 - val_loss: 0.4763 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8850\n",
      "Epoch 313/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5078 - tp: 208.0000 - fp: 68.0000 - tn: 376.0000 - fn: 60.0000 - accuracy: 0.8202 - precision: 0.7536 - recall: 0.7761 - auc: 0.8557 - val_loss: 0.4756 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8852\n",
      "Epoch 314/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5039 - tp: 207.0000 - fp: 74.0000 - tn: 370.0000 - fn: 61.0000 - accuracy: 0.8104 - precision: 0.7367 - recall: 0.7724 - auc: 0.8559 - val_loss: 0.4773 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8847\n",
      "Epoch 315/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5037 - tp: 210.0000 - fp: 72.0000 - tn: 372.0000 - fn: 58.0000 - accuracy: 0.8174 - precision: 0.7447 - recall: 0.7836 - auc: 0.8549 - val_loss: 0.4760 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8849\n",
      "Epoch 316/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5042 - tp: 205.0000 - fp: 70.0000 - tn: 374.0000 - fn: 63.0000 - accuracy: 0.8132 - precision: 0.7455 - recall: 0.7649 - auc: 0.8582 - val_loss: 0.4746 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8848\n",
      "Epoch 317/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5019 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8562 - val_loss: 0.4750 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8846\n",
      "Epoch 318/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5043 - tp: 209.0000 - fp: 69.0000 - tn: 375.0000 - fn: 59.0000 - accuracy: 0.8202 - precision: 0.7518 - recall: 0.7799 - auc: 0.8550 - val_loss: 0.4780 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8857\n",
      "Epoch 319/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4961 - tp: 206.0000 - fp: 65.0000 - tn: 379.0000 - fn: 62.0000 - accuracy: 0.8216 - precision: 0.7601 - recall: 0.7687 - auc: 0.8620 - val_loss: 0.4758 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8851\n",
      "Epoch 320/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4971 - tp: 209.0000 - fp: 68.0000 - tn: 376.0000 - fn: 59.0000 - accuracy: 0.8216 - precision: 0.7545 - recall: 0.7799 - auc: 0.8600 - val_loss: 0.4757 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8850\n",
      "Epoch 321/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5032 - tp: 211.0000 - fp: 65.0000 - tn: 379.0000 - fn: 57.0000 - accuracy: 0.8287 - precision: 0.7645 - recall: 0.7873 - auc: 0.8557 - val_loss: 0.4748 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8848\n",
      "Epoch 322/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4948 - tp: 207.0000 - fp: 68.0000 - tn: 376.0000 - fn: 61.0000 - accuracy: 0.8188 - precision: 0.7527 - recall: 0.7724 - auc: 0.8597 - val_loss: 0.4778 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8844\n",
      "Epoch 323/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5070 - tp: 209.0000 - fp: 76.0000 - tn: 368.0000 - fn: 59.0000 - accuracy: 0.8104 - precision: 0.7333 - recall: 0.7799 - auc: 0.8551 - val_loss: 0.4765 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8845\n",
      "Epoch 324/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4986 - tp: 205.0000 - fp: 64.0000 - tn: 380.0000 - fn: 63.0000 - accuracy: 0.8216 - precision: 0.7621 - recall: 0.7649 - auc: 0.8569 - val_loss: 0.4747 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8840\n",
      "Epoch 325/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4800 - tp: 208.0000 - fp: 64.0000 - tn: 380.0000 - fn: 60.0000 - accuracy: 0.8258 - precision: 0.7647 - recall: 0.7761 - auc: 0.8723 - val_loss: 0.4740 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8838\n",
      "Epoch 326/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5127 - tp: 210.0000 - fp: 72.0000 - tn: 372.0000 - fn: 58.0000 - accuracy: 0.8174 - precision: 0.7447 - recall: 0.7836 - auc: 0.8518 - val_loss: 0.4741 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8857\n",
      "Epoch 327/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5021 - tp: 209.0000 - fp: 67.0000 - tn: 377.0000 - fn: 59.0000 - accuracy: 0.8230 - precision: 0.7572 - recall: 0.7799 - auc: 0.8575 - val_loss: 0.4733 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8848\n",
      "Epoch 328/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.4975 - tp: 211.0000 - fp: 70.0000 - tn: 374.0000 - fn: 57.0000 - accuracy: 0.8216 - precision: 0.7509 - recall: 0.7873 - auc: 0.8606 - val_loss: 0.4735 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8854\n",
      "Epoch 329/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.4964 - tp: 206.0000 - fp: 68.0000 - tn: 376.0000 - fn: 62.0000 - accuracy: 0.8174 - precision: 0.7518 - recall: 0.7687 - auc: 0.8663 - val_loss: 0.4746 - val_tp: 60.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 14.0000 - val_accuracy: 0.7821 - val_precision: 0.7059 - val_recall: 0.8108 - val_auc: 0.8829\n",
      "Epoch 330/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5033 - tp: 211.0000 - fp: 75.0000 - tn: 369.0000 - fn: 57.0000 - accuracy: 0.8146 - precision: 0.7378 - recall: 0.7873 - auc: 0.8524 - val_loss: 0.4747 - val_tp: 60.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 14.0000 - val_accuracy: 0.7821 - val_precision: 0.7059 - val_recall: 0.8108 - val_auc: 0.8840\n",
      "Epoch 331/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4941 - tp: 208.0000 - fp: 76.0000 - tn: 368.0000 - fn: 60.0000 - accuracy: 0.8090 - precision: 0.7324 - recall: 0.7761 - auc: 0.8629 - val_loss: 0.4726 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8844\n",
      "Epoch 332/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4889 - tp: 210.0000 - fp: 69.0000 - tn: 375.0000 - fn: 58.0000 - accuracy: 0.8216 - precision: 0.7527 - recall: 0.7836 - auc: 0.8642 - val_loss: 0.4733 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8857\n",
      "Epoch 333/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5081 - tp: 206.0000 - fp: 63.0000 - tn: 381.0000 - fn: 62.0000 - accuracy: 0.8244 - precision: 0.7658 - recall: 0.7687 - auc: 0.8583 - val_loss: 0.4742 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8855\n",
      "Epoch 334/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5111 - tp: 209.0000 - fp: 73.0000 - tn: 371.0000 - fn: 59.0000 - accuracy: 0.8146 - precision: 0.7411 - recall: 0.7799 - auc: 0.8531 - val_loss: 0.4739 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8862\n",
      "Epoch 335/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.4958 - tp: 208.0000 - fp: 71.0000 - tn: 373.0000 - fn: 60.0000 - accuracy: 0.8160 - precision: 0.7455 - recall: 0.7761 - auc: 0.8614 - val_loss: 0.4745 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8843\n",
      "Epoch 336/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5173 - tp: 206.0000 - fp: 74.0000 - tn: 370.0000 - fn: 62.0000 - accuracy: 0.8090 - precision: 0.7357 - recall: 0.7687 - auc: 0.8439 - val_loss: 0.4733 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8849\n",
      "Epoch 337/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5047 - tp: 206.0000 - fp: 62.0000 - tn: 382.0000 - fn: 62.0000 - accuracy: 0.8258 - precision: 0.7687 - recall: 0.7687 - auc: 0.8562 - val_loss: 0.4738 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8855\n",
      "Epoch 338/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5039 - tp: 211.0000 - fp: 71.0000 - tn: 373.0000 - fn: 57.0000 - accuracy: 0.8202 - precision: 0.7482 - recall: 0.7873 - auc: 0.8555 - val_loss: 0.4733 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8856\n",
      "Epoch 339/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5004 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8589 - val_loss: 0.4741 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8856\n",
      "Epoch 340/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.4993 - tp: 207.0000 - fp: 69.0000 - tn: 375.0000 - fn: 61.0000 - accuracy: 0.8174 - precision: 0.7500 - recall: 0.7724 - auc: 0.8621 - val_loss: 0.4734 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8855\n",
      "Epoch 341/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5013 - tp: 206.0000 - fp: 75.0000 - tn: 369.0000 - fn: 62.0000 - accuracy: 0.8076 - precision: 0.7331 - recall: 0.7687 - auc: 0.8565 - val_loss: 0.4751 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8838\n",
      "Epoch 342/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5040 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8579 - val_loss: 0.4737 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8851\n",
      "Epoch 343/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.4928 - tp: 212.0000 - fp: 73.0000 - tn: 371.0000 - fn: 56.0000 - accuracy: 0.8188 - precision: 0.7439 - recall: 0.7910 - auc: 0.8624 - val_loss: 0.4739 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8855\n",
      "Epoch 344/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5022 - tp: 208.0000 - fp: 76.0000 - tn: 368.0000 - fn: 60.0000 - accuracy: 0.8090 - precision: 0.7324 - recall: 0.7761 - auc: 0.8554 - val_loss: 0.4771 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8853\n",
      "Epoch 345/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5152 - tp: 209.0000 - fp: 79.0000 - tn: 365.0000 - fn: 59.0000 - accuracy: 0.8062 - precision: 0.7257 - recall: 0.7799 - auc: 0.8472 - val_loss: 0.4752 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8855\n",
      "Epoch 346/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5034 - tp: 208.0000 - fp: 69.0000 - tn: 375.0000 - fn: 60.0000 - accuracy: 0.8188 - precision: 0.7509 - recall: 0.7761 - auc: 0.8563 - val_loss: 0.4761 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8853\n",
      "Epoch 347/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4969 - tp: 208.0000 - fp: 70.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.8174 - precision: 0.7482 - recall: 0.7761 - auc: 0.8595 - val_loss: 0.4731 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8853\n",
      "Epoch 348/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.5010 - tp: 207.0000 - fp: 76.0000 - tn: 368.0000 - fn: 61.0000 - accuracy: 0.8076 - precision: 0.7314 - recall: 0.7724 - auc: 0.8592 - val_loss: 0.4729 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8840\n",
      "Epoch 349/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.4997 - tp: 206.0000 - fp: 63.0000 - tn: 381.0000 - fn: 62.0000 - accuracy: 0.8244 - precision: 0.7658 - recall: 0.7687 - auc: 0.8587 - val_loss: 0.4758 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8838\n",
      "Epoch 350/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5135 - tp: 209.0000 - fp: 79.0000 - tn: 365.0000 - fn: 59.0000 - accuracy: 0.8062 - precision: 0.7257 - recall: 0.7799 - auc: 0.8488 - val_loss: 0.4736 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8847\n",
      "Epoch 351/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4992 - tp: 207.0000 - fp: 72.0000 - tn: 372.0000 - fn: 61.0000 - accuracy: 0.8132 - precision: 0.7419 - recall: 0.7724 - auc: 0.8622 - val_loss: 0.4740 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8853\n",
      "Epoch 352/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5079 - tp: 211.0000 - fp: 67.0000 - tn: 377.0000 - fn: 57.0000 - accuracy: 0.8258 - precision: 0.7590 - recall: 0.7873 - auc: 0.8514 - val_loss: 0.4743 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8869\n",
      "Epoch 353/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4901 - tp: 207.0000 - fp: 67.0000 - tn: 377.0000 - fn: 61.0000 - accuracy: 0.8202 - precision: 0.7555 - recall: 0.7724 - auc: 0.8644 - val_loss: 0.4735 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8856\n",
      "Epoch 354/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.5041 - tp: 208.0000 - fp: 66.0000 - tn: 378.0000 - fn: 60.0000 - accuracy: 0.8230 - precision: 0.7591 - recall: 0.7761 - auc: 0.8578 - val_loss: 0.4717 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8853\n",
      "Epoch 355/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5121 - tp: 210.0000 - fp: 66.0000 - tn: 378.0000 - fn: 58.0000 - accuracy: 0.8258 - precision: 0.7609 - recall: 0.7836 - auc: 0.8549 - val_loss: 0.4741 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8840\n",
      "Epoch 356/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4916 - tp: 213.0000 - fp: 77.0000 - tn: 367.0000 - fn: 55.0000 - accuracy: 0.8146 - precision: 0.7345 - recall: 0.7948 - auc: 0.8670 - val_loss: 0.4716 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8858\n",
      "Epoch 357/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4991 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8600 - val_loss: 0.4715 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8863\n",
      "Epoch 358/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4990 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8589 - val_loss: 0.4729 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8862\n",
      "Epoch 359/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5024 - tp: 208.0000 - fp: 70.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.8174 - precision: 0.7482 - recall: 0.7761 - auc: 0.8564 - val_loss: 0.4734 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8862\n",
      "Epoch 360/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.4959 - tp: 208.0000 - fp: 69.0000 - tn: 375.0000 - fn: 60.0000 - accuracy: 0.8188 - precision: 0.7509 - recall: 0.7761 - auc: 0.8635 - val_loss: 0.4716 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8871\n",
      "Epoch 361/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.4923 - tp: 202.0000 - fp: 70.0000 - tn: 374.0000 - fn: 66.0000 - accuracy: 0.8090 - precision: 0.7426 - recall: 0.7537 - auc: 0.8608 - val_loss: 0.4719 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8860\n",
      "Epoch 362/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5039 - tp: 211.0000 - fp: 68.0000 - tn: 376.0000 - fn: 57.0000 - accuracy: 0.8244 - precision: 0.7563 - recall: 0.7873 - auc: 0.8532 - val_loss: 0.4736 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8857\n",
      "Epoch 363/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5059 - tp: 210.0000 - fp: 75.0000 - tn: 369.0000 - fn: 58.0000 - accuracy: 0.8132 - precision: 0.7368 - recall: 0.7836 - auc: 0.8518 - val_loss: 0.4721 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8856\n",
      "Epoch 364/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4993 - tp: 207.0000 - fp: 68.0000 - tn: 376.0000 - fn: 61.0000 - accuracy: 0.8188 - precision: 0.7527 - recall: 0.7724 - auc: 0.8580 - val_loss: 0.4730 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8854\n",
      "Epoch 365/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4820 - tp: 207.0000 - fp: 64.0000 - tn: 380.0000 - fn: 61.0000 - accuracy: 0.8244 - precision: 0.7638 - recall: 0.7724 - auc: 0.8697 - val_loss: 0.4719 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8864\n",
      "Epoch 366/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5058 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8528 - val_loss: 0.4735 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8855\n",
      "Epoch 367/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5003 - tp: 207.0000 - fp: 78.0000 - tn: 366.0000 - fn: 61.0000 - accuracy: 0.8048 - precision: 0.7263 - recall: 0.7724 - auc: 0.8563 - val_loss: 0.4735 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8871\n",
      "Epoch 368/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5010 - tp: 210.0000 - fp: 66.0000 - tn: 378.0000 - fn: 58.0000 - accuracy: 0.8258 - precision: 0.7609 - recall: 0.7836 - auc: 0.8574 - val_loss: 0.4737 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8869\n",
      "Epoch 369/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4947 - tp: 208.0000 - fp: 71.0000 - tn: 373.0000 - fn: 60.0000 - accuracy: 0.8160 - precision: 0.7455 - recall: 0.7761 - auc: 0.8594 - val_loss: 0.4726 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8858\n",
      "Epoch 370/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.4922 - tp: 207.0000 - fp: 72.0000 - tn: 372.0000 - fn: 61.0000 - accuracy: 0.8132 - precision: 0.7419 - recall: 0.7724 - auc: 0.8635 - val_loss: 0.4724 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8869\n",
      "Epoch 371/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4899 - tp: 205.0000 - fp: 59.0000 - tn: 385.0000 - fn: 63.0000 - accuracy: 0.8287 - precision: 0.7765 - recall: 0.7649 - auc: 0.8674 - val_loss: 0.4841 - val_tp: 64.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 10.0000 - val_accuracy: 0.7821 - val_precision: 0.6882 - val_recall: 0.8649 - val_auc: 0.8848\n",
      "Epoch 372/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.4932 - tp: 208.0000 - fp: 72.0000 - tn: 372.0000 - fn: 60.0000 - accuracy: 0.8146 - precision: 0.7429 - recall: 0.7761 - auc: 0.8613 - val_loss: 0.4732 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8871\n",
      "Epoch 373/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4867 - tp: 205.0000 - fp: 64.0000 - tn: 380.0000 - fn: 63.0000 - accuracy: 0.8216 - precision: 0.7621 - recall: 0.7649 - auc: 0.8684 - val_loss: 0.4776 - val_tp: 61.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 13.0000 - val_accuracy: 0.7821 - val_precision: 0.7011 - val_recall: 0.8243 - val_auc: 0.8846\n",
      "Epoch 374/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5086 - tp: 210.0000 - fp: 83.0000 - tn: 361.0000 - fn: 58.0000 - accuracy: 0.8020 - precision: 0.7167 - recall: 0.7836 - auc: 0.8507 - val_loss: 0.4740 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8856\n",
      "Epoch 375/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.4979 - tp: 206.0000 - fp: 63.0000 - tn: 381.0000 - fn: 62.0000 - accuracy: 0.8244 - precision: 0.7658 - recall: 0.7687 - auc: 0.8545 - val_loss: 0.4826 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8851\n",
      "Epoch 376/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5016 - tp: 208.0000 - fp: 69.0000 - tn: 375.0000 - fn: 60.0000 - accuracy: 0.8188 - precision: 0.7509 - recall: 0.7761 - auc: 0.8542 - val_loss: 0.4760 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8860\n",
      "Epoch 377/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5020 - tp: 210.0000 - fp: 78.0000 - tn: 366.0000 - fn: 58.0000 - accuracy: 0.8090 - precision: 0.7292 - recall: 0.7836 - auc: 0.8518 - val_loss: 0.4751 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8850\n",
      "Epoch 378/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4960 - tp: 208.0000 - fp: 68.0000 - tn: 376.0000 - fn: 60.0000 - accuracy: 0.8202 - precision: 0.7536 - recall: 0.7761 - auc: 0.8611 - val_loss: 0.4773 - val_tp: 61.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 13.0000 - val_accuracy: 0.7821 - val_precision: 0.7011 - val_recall: 0.8243 - val_auc: 0.8849\n",
      "Epoch 379/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5008 - tp: 209.0000 - fp: 75.0000 - tn: 369.0000 - fn: 59.0000 - accuracy: 0.8118 - precision: 0.7359 - recall: 0.7799 - auc: 0.8609 - val_loss: 0.4736 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8853\n",
      "Epoch 380/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5057 - tp: 207.0000 - fp: 72.0000 - tn: 372.0000 - fn: 61.0000 - accuracy: 0.8132 - precision: 0.7419 - recall: 0.7724 - auc: 0.8546 - val_loss: 0.4726 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8852\n",
      "Epoch 381/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4823 - tp: 204.0000 - fp: 72.0000 - tn: 372.0000 - fn: 64.0000 - accuracy: 0.8090 - precision: 0.7391 - recall: 0.7612 - auc: 0.8727 - val_loss: 0.4745 - val_tp: 61.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 13.0000 - val_accuracy: 0.7821 - val_precision: 0.7011 - val_recall: 0.8243 - val_auc: 0.8836\n",
      "Epoch 382/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5070 - tp: 207.0000 - fp: 76.0000 - tn: 368.0000 - fn: 61.0000 - accuracy: 0.8076 - precision: 0.7314 - recall: 0.7724 - auc: 0.8525 - val_loss: 0.4734 - val_tp: 61.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 13.0000 - val_accuracy: 0.7821 - val_precision: 0.7011 - val_recall: 0.8243 - val_auc: 0.8842\n",
      "Epoch 383/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5009 - tp: 212.0000 - fp: 78.0000 - tn: 366.0000 - fn: 56.0000 - accuracy: 0.8118 - precision: 0.7310 - recall: 0.7910 - auc: 0.8547 - val_loss: 0.4732 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8856\n",
      "Epoch 384/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4997 - tp: 210.0000 - fp: 67.0000 - tn: 377.0000 - fn: 58.0000 - accuracy: 0.8244 - precision: 0.7581 - recall: 0.7836 - auc: 0.8544 - val_loss: 0.4726 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8843\n",
      "Epoch 385/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5014 - tp: 208.0000 - fp: 77.0000 - tn: 367.0000 - fn: 60.0000 - accuracy: 0.8076 - precision: 0.7298 - recall: 0.7761 - auc: 0.8565 - val_loss: 0.4714 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8842\n",
      "Epoch 386/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4973 - tp: 206.0000 - fp: 70.0000 - tn: 374.0000 - fn: 62.0000 - accuracy: 0.8146 - precision: 0.7464 - recall: 0.7687 - auc: 0.8589 - val_loss: 0.4730 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8844\n",
      "Epoch 387/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5114 - tp: 213.0000 - fp: 78.0000 - tn: 366.0000 - fn: 55.0000 - accuracy: 0.8132 - precision: 0.7320 - recall: 0.7948 - auc: 0.8483 - val_loss: 0.4709 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8870\n",
      "Epoch 388/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.4977 - tp: 211.0000 - fp: 63.0000 - tn: 381.0000 - fn: 57.0000 - accuracy: 0.8315 - precision: 0.7701 - recall: 0.7873 - auc: 0.8602 - val_loss: 0.4711 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8885\n",
      "Epoch 389/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.5152 - tp: 205.0000 - fp: 69.0000 - tn: 375.0000 - fn: 63.0000 - accuracy: 0.8146 - precision: 0.7482 - recall: 0.7649 - auc: 0.8460 - val_loss: 0.4716 - val_tp: 61.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 13.0000 - val_accuracy: 0.7933 - val_precision: 0.7176 - val_recall: 0.8243 - val_auc: 0.8865\n",
      "Epoch 390/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4966 - tp: 210.0000 - fp: 80.0000 - tn: 364.0000 - fn: 58.0000 - accuracy: 0.8062 - precision: 0.7241 - recall: 0.7836 - auc: 0.8592 - val_loss: 0.4709 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8867\n",
      "Epoch 391/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4957 - tp: 210.0000 - fp: 74.0000 - tn: 370.0000 - fn: 58.0000 - accuracy: 0.8146 - precision: 0.7394 - recall: 0.7836 - auc: 0.8640 - val_loss: 0.4701 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8875\n",
      "Epoch 392/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5002 - tp: 207.0000 - fp: 68.0000 - tn: 376.0000 - fn: 61.0000 - accuracy: 0.8188 - precision: 0.7527 - recall: 0.7724 - auc: 0.8564 - val_loss: 0.4736 - val_tp: 61.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 13.0000 - val_accuracy: 0.7821 - val_precision: 0.7011 - val_recall: 0.8243 - val_auc: 0.8850\n",
      "Epoch 393/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5055 - tp: 211.0000 - fp: 75.0000 - tn: 369.0000 - fn: 57.0000 - accuracy: 0.8146 - precision: 0.7378 - recall: 0.7873 - auc: 0.8524 - val_loss: 0.4781 - val_tp: 64.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 10.0000 - val_accuracy: 0.7821 - val_precision: 0.6882 - val_recall: 0.8649 - val_auc: 0.8848\n",
      "Epoch 394/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.5003 - tp: 210.0000 - fp: 80.0000 - tn: 364.0000 - fn: 58.0000 - accuracy: 0.8062 - precision: 0.7241 - recall: 0.7836 - auc: 0.8561 - val_loss: 0.4700 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8856\n",
      "Epoch 395/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4958 - tp: 208.0000 - fp: 66.0000 - tn: 378.0000 - fn: 60.0000 - accuracy: 0.8230 - precision: 0.7591 - recall: 0.7761 - auc: 0.8614 - val_loss: 0.4701 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8857\n",
      "Epoch 396/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5029 - tp: 209.0000 - fp: 67.0000 - tn: 377.0000 - fn: 59.0000 - accuracy: 0.8230 - precision: 0.7572 - recall: 0.7799 - auc: 0.8583 - val_loss: 0.4695 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8851\n",
      "Epoch 397/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4934 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8675 - val_loss: 0.4726 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8851\n",
      "Epoch 398/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4869 - tp: 210.0000 - fp: 71.0000 - tn: 373.0000 - fn: 58.0000 - accuracy: 0.8188 - precision: 0.7473 - recall: 0.7836 - auc: 0.8681 - val_loss: 0.4701 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8855\n",
      "Epoch 399/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5068 - tp: 210.0000 - fp: 69.0000 - tn: 375.0000 - fn: 58.0000 - accuracy: 0.8216 - precision: 0.7527 - recall: 0.7836 - auc: 0.8528 - val_loss: 0.4732 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8837\n",
      "Epoch 400/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5003 - tp: 211.0000 - fp: 77.0000 - tn: 367.0000 - fn: 57.0000 - accuracy: 0.8118 - precision: 0.7326 - recall: 0.7873 - auc: 0.8558 - val_loss: 0.4704 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8862\n",
      "Epoch 401/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4987 - tp: 208.0000 - fp: 69.0000 - tn: 375.0000 - fn: 60.0000 - accuracy: 0.8188 - precision: 0.7509 - recall: 0.7761 - auc: 0.8595 - val_loss: 0.4706 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8844\n",
      "Epoch 402/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5031 - tp: 208.0000 - fp: 72.0000 - tn: 372.0000 - fn: 60.0000 - accuracy: 0.8146 - precision: 0.7429 - recall: 0.7761 - auc: 0.8553 - val_loss: 0.4707 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8849\n",
      "Epoch 403/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5039 - tp: 207.0000 - fp: 61.0000 - tn: 383.0000 - fn: 61.0000 - accuracy: 0.8287 - precision: 0.7724 - recall: 0.7724 - auc: 0.8559 - val_loss: 0.4746 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8856\n",
      "Epoch 404/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.4954 - tp: 207.0000 - fp: 68.0000 - tn: 376.0000 - fn: 61.0000 - accuracy: 0.8188 - precision: 0.7527 - recall: 0.7724 - auc: 0.8599 - val_loss: 0.4729 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8856\n",
      "Epoch 405/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.5046 - tp: 210.0000 - fp: 72.0000 - tn: 372.0000 - fn: 58.0000 - accuracy: 0.8174 - precision: 0.7447 - recall: 0.7836 - auc: 0.8551 - val_loss: 0.4717 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8872\n",
      "Epoch 406/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.4967 - tp: 210.0000 - fp: 73.0000 - tn: 371.0000 - fn: 58.0000 - accuracy: 0.8160 - precision: 0.7420 - recall: 0.7836 - auc: 0.8591 - val_loss: 0.4707 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8863\n",
      "Epoch 407/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4898 - tp: 210.0000 - fp: 67.0000 - tn: 377.0000 - fn: 58.0000 - accuracy: 0.8244 - precision: 0.7581 - recall: 0.7836 - auc: 0.8629 - val_loss: 0.4717 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8860\n",
      "Epoch 408/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.4864 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8690 - val_loss: 0.4706 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8858\n",
      "Epoch 409/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5117 - tp: 203.0000 - fp: 72.0000 - tn: 372.0000 - fn: 65.0000 - accuracy: 0.8076 - precision: 0.7382 - recall: 0.7575 - auc: 0.8512 - val_loss: 0.4729 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8847\n",
      "Epoch 410/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5128 - tp: 208.0000 - fp: 76.0000 - tn: 368.0000 - fn: 60.0000 - accuracy: 0.8090 - precision: 0.7324 - recall: 0.7761 - auc: 0.8461 - val_loss: 0.4807 - val_tp: 64.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 10.0000 - val_accuracy: 0.7821 - val_precision: 0.6882 - val_recall: 0.8649 - val_auc: 0.8843\n",
      "Epoch 411/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4928 - tp: 212.0000 - fp: 75.0000 - tn: 369.0000 - fn: 56.0000 - accuracy: 0.8160 - precision: 0.7387 - recall: 0.7910 - auc: 0.8611 - val_loss: 0.4705 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8856\n",
      "Epoch 412/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5056 - tp: 214.0000 - fp: 75.0000 - tn: 369.0000 - fn: 54.0000 - accuracy: 0.8188 - precision: 0.7405 - recall: 0.7985 - auc: 0.8538 - val_loss: 0.4688 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8865\n",
      "Epoch 413/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4799 - tp: 211.0000 - fp: 67.0000 - tn: 377.0000 - fn: 57.0000 - accuracy: 0.8258 - precision: 0.7590 - recall: 0.7873 - auc: 0.8719 - val_loss: 0.4696 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8857\n",
      "Epoch 414/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4931 - tp: 210.0000 - fp: 70.0000 - tn: 374.0000 - fn: 58.0000 - accuracy: 0.8202 - precision: 0.7500 - recall: 0.7836 - auc: 0.8589 - val_loss: 0.4707 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8842\n",
      "Epoch 415/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4938 - tp: 210.0000 - fp: 76.0000 - tn: 368.0000 - fn: 58.0000 - accuracy: 0.8118 - precision: 0.7343 - recall: 0.7836 - auc: 0.8646 - val_loss: 0.4706 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8848\n",
      "Epoch 416/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.4967 - tp: 210.0000 - fp: 79.0000 - tn: 365.0000 - fn: 58.0000 - accuracy: 0.8076 - precision: 0.7266 - recall: 0.7836 - auc: 0.8599 - val_loss: 0.4709 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.8854\n",
      "Epoch 417/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4894 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8656 - val_loss: 0.4694 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8856\n",
      "Epoch 418/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4951 - tp: 207.0000 - fp: 69.0000 - tn: 375.0000 - fn: 61.0000 - accuracy: 0.8174 - precision: 0.7500 - recall: 0.7724 - auc: 0.8606 - val_loss: 0.4708 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8859\n",
      "Epoch 419/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4987 - tp: 210.0000 - fp: 67.0000 - tn: 377.0000 - fn: 58.0000 - accuracy: 0.8244 - precision: 0.7581 - recall: 0.7836 - auc: 0.8583 - val_loss: 0.4735 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8863\n",
      "Epoch 420/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4910 - tp: 209.0000 - fp: 71.0000 - tn: 373.0000 - fn: 59.0000 - accuracy: 0.8174 - precision: 0.7464 - recall: 0.7799 - auc: 0.8627 - val_loss: 0.4700 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8872\n",
      "Epoch 421/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.4941 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8604 - val_loss: 0.4701 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8860\n",
      "Epoch 422/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.4995 - tp: 208.0000 - fp: 67.0000 - tn: 377.0000 - fn: 60.0000 - accuracy: 0.8216 - precision: 0.7564 - recall: 0.7761 - auc: 0.8570 - val_loss: 0.4707 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8868\n",
      "Epoch 423/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.4889 - tp: 209.0000 - fp: 74.0000 - tn: 370.0000 - fn: 59.0000 - accuracy: 0.8132 - precision: 0.7385 - recall: 0.7799 - auc: 0.8665 - val_loss: 0.4688 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8849\n",
      "Epoch 424/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4868 - tp: 208.0000 - fp: 68.0000 - tn: 376.0000 - fn: 60.0000 - accuracy: 0.8202 - precision: 0.7536 - recall: 0.7761 - auc: 0.8660 - val_loss: 0.4692 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8853\n",
      "Epoch 425/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4882 - tp: 212.0000 - fp: 75.0000 - tn: 369.0000 - fn: 56.0000 - accuracy: 0.8160 - precision: 0.7387 - recall: 0.7910 - auc: 0.8651 - val_loss: 0.4704 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8844\n",
      "Epoch 426/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5022 - tp: 212.0000 - fp: 73.0000 - tn: 371.0000 - fn: 56.0000 - accuracy: 0.8188 - precision: 0.7439 - recall: 0.7910 - auc: 0.8545 - val_loss: 0.4801 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8844\n",
      "Epoch 427/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4952 - tp: 211.0000 - fp: 78.0000 - tn: 366.0000 - fn: 57.0000 - accuracy: 0.8104 - precision: 0.7301 - recall: 0.7873 - auc: 0.8610 - val_loss: 0.4693 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8849\n",
      "Epoch 428/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5105 - tp: 207.0000 - fp: 78.0000 - tn: 366.0000 - fn: 61.0000 - accuracy: 0.8048 - precision: 0.7263 - recall: 0.7724 - auc: 0.8468 - val_loss: 0.4729 - val_tp: 61.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 13.0000 - val_accuracy: 0.7821 - val_precision: 0.7011 - val_recall: 0.8243 - val_auc: 0.8836\n",
      "Epoch 429/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.4946 - tp: 212.0000 - fp: 72.0000 - tn: 372.0000 - fn: 56.0000 - accuracy: 0.8202 - precision: 0.7465 - recall: 0.7910 - auc: 0.8565 - val_loss: 0.4688 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8850\n",
      "Epoch 430/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.4880 - tp: 205.0000 - fp: 61.0000 - tn: 383.0000 - fn: 63.0000 - accuracy: 0.8258 - precision: 0.7707 - recall: 0.7649 - auc: 0.8668 - val_loss: 0.4719 - val_tp: 61.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 13.0000 - val_accuracy: 0.7821 - val_precision: 0.7011 - val_recall: 0.8243 - val_auc: 0.8843\n",
      "Epoch 431/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4983 - tp: 205.0000 - fp: 78.0000 - tn: 366.0000 - fn: 63.0000 - accuracy: 0.8020 - precision: 0.7244 - recall: 0.7649 - auc: 0.8577 - val_loss: 0.4688 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8858\n",
      "Epoch 432/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5015 - tp: 203.0000 - fp: 65.0000 - tn: 379.0000 - fn: 65.0000 - accuracy: 0.8174 - precision: 0.7575 - recall: 0.7575 - auc: 0.8562 - val_loss: 0.4719 - val_tp: 61.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 13.0000 - val_accuracy: 0.7765 - val_precision: 0.6932 - val_recall: 0.8243 - val_auc: 0.8844\n",
      "Epoch 433/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4973 - tp: 212.0000 - fp: 75.0000 - tn: 369.0000 - fn: 56.0000 - accuracy: 0.8160 - precision: 0.7387 - recall: 0.7910 - auc: 0.8589 - val_loss: 0.4707 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8855\n",
      "Epoch 434/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4934 - tp: 209.0000 - fp: 70.0000 - tn: 374.0000 - fn: 59.0000 - accuracy: 0.8188 - precision: 0.7491 - recall: 0.7799 - auc: 0.8581 - val_loss: 0.4690 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8855\n",
      "Epoch 435/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4937 - tp: 209.0000 - fp: 75.0000 - tn: 369.0000 - fn: 59.0000 - accuracy: 0.8118 - precision: 0.7359 - recall: 0.7799 - auc: 0.8588 - val_loss: 0.4687 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8860\n",
      "Epoch 436/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4987 - tp: 209.0000 - fp: 71.0000 - tn: 373.0000 - fn: 59.0000 - accuracy: 0.8174 - precision: 0.7464 - recall: 0.7799 - auc: 0.8569 - val_loss: 0.4695 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8842\n",
      "Epoch 437/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4985 - tp: 206.0000 - fp: 71.0000 - tn: 373.0000 - fn: 62.0000 - accuracy: 0.8132 - precision: 0.7437 - recall: 0.7687 - auc: 0.8585 - val_loss: 0.4687 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8850\n",
      "Epoch 438/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5013 - tp: 207.0000 - fp: 76.0000 - tn: 368.0000 - fn: 61.0000 - accuracy: 0.8076 - precision: 0.7314 - recall: 0.7724 - auc: 0.8560 - val_loss: 0.4702 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8854\n",
      "Epoch 439/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.4907 - tp: 207.0000 - fp: 66.0000 - tn: 378.0000 - fn: 61.0000 - accuracy: 0.8216 - precision: 0.7582 - recall: 0.7724 - auc: 0.8598 - val_loss: 0.4766 - val_tp: 61.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 13.0000 - val_accuracy: 0.7765 - val_precision: 0.6932 - val_recall: 0.8243 - val_auc: 0.8844\n",
      "Epoch 440/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.4861 - tp: 207.0000 - fp: 72.0000 - tn: 372.0000 - fn: 61.0000 - accuracy: 0.8132 - precision: 0.7419 - recall: 0.7724 - auc: 0.8668 - val_loss: 0.4705 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8866\n",
      "Epoch 441/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.5136 - tp: 206.0000 - fp: 63.0000 - tn: 381.0000 - fn: 62.0000 - accuracy: 0.8244 - precision: 0.7658 - recall: 0.7687 - auc: 0.8458 - val_loss: 0.4725 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8858\n",
      "Epoch 442/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.4889 - tp: 207.0000 - fp: 67.0000 - tn: 377.0000 - fn: 61.0000 - accuracy: 0.8202 - precision: 0.7555 - recall: 0.7724 - auc: 0.8644 - val_loss: 0.4708 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8863\n",
      "Epoch 443/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5054 - tp: 207.0000 - fp: 74.0000 - tn: 370.0000 - fn: 61.0000 - accuracy: 0.8104 - precision: 0.7367 - recall: 0.7724 - auc: 0.8527 - val_loss: 0.4713 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8862\n",
      "Epoch 444/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.4901 - tp: 207.0000 - fp: 69.0000 - tn: 375.0000 - fn: 61.0000 - accuracy: 0.8174 - precision: 0.7500 - recall: 0.7724 - auc: 0.8626 - val_loss: 0.4699 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8868\n",
      "Epoch 445/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5014 - tp: 207.0000 - fp: 70.0000 - tn: 374.0000 - fn: 61.0000 - accuracy: 0.8160 - precision: 0.7473 - recall: 0.7724 - auc: 0.8544 - val_loss: 0.4698 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8862\n",
      "Epoch 446/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.4970 - tp: 205.0000 - fp: 72.0000 - tn: 372.0000 - fn: 63.0000 - accuracy: 0.8104 - precision: 0.7401 - recall: 0.7649 - auc: 0.8580 - val_loss: 0.4699 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8862\n",
      "Epoch 447/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4971 - tp: 208.0000 - fp: 69.0000 - tn: 375.0000 - fn: 60.0000 - accuracy: 0.8188 - precision: 0.7509 - recall: 0.7761 - auc: 0.8562 - val_loss: 0.4700 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8861\n",
      "Epoch 448/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.4935 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8624 - val_loss: 0.4702 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8855\n",
      "Epoch 449/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5057 - tp: 208.0000 - fp: 72.0000 - tn: 372.0000 - fn: 60.0000 - accuracy: 0.8146 - precision: 0.7429 - recall: 0.7761 - auc: 0.8513 - val_loss: 0.4717 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8855\n",
      "Epoch 450/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5035 - tp: 203.0000 - fp: 73.0000 - tn: 371.0000 - fn: 65.0000 - accuracy: 0.8062 - precision: 0.7355 - recall: 0.7575 - auc: 0.8556 - val_loss: 0.4716 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8856\n",
      "Epoch 451/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4971 - tp: 211.0000 - fp: 74.0000 - tn: 370.0000 - fn: 57.0000 - accuracy: 0.8160 - precision: 0.7404 - recall: 0.7873 - auc: 0.8564 - val_loss: 0.4699 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8856\n",
      "Epoch 452/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4876 - tp: 208.0000 - fp: 70.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.8174 - precision: 0.7482 - recall: 0.7761 - auc: 0.8676 - val_loss: 0.4690 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8848\n",
      "Epoch 453/500\n",
      "712/712 [==============================] - 0s 104us/sample - loss: 0.4868 - tp: 209.0000 - fp: 67.0000 - tn: 377.0000 - fn: 59.0000 - accuracy: 0.8230 - precision: 0.7572 - recall: 0.7799 - auc: 0.8664 - val_loss: 0.4688 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8861\n",
      "Epoch 454/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.5079 - tp: 210.0000 - fp: 76.0000 - tn: 368.0000 - fn: 58.0000 - accuracy: 0.8118 - precision: 0.7343 - recall: 0.7836 - auc: 0.8503 - val_loss: 0.4690 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8861\n",
      "Epoch 455/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.4916 - tp: 206.0000 - fp: 65.0000 - tn: 379.0000 - fn: 62.0000 - accuracy: 0.8216 - precision: 0.7601 - recall: 0.7687 - auc: 0.8646 - val_loss: 0.4691 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8861\n",
      "Epoch 456/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.5074 - tp: 211.0000 - fp: 70.0000 - tn: 374.0000 - fn: 57.0000 - accuracy: 0.8216 - precision: 0.7509 - recall: 0.7873 - auc: 0.8508 - val_loss: 0.4683 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8864\n",
      "Epoch 457/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.4812 - tp: 206.0000 - fp: 66.0000 - tn: 378.0000 - fn: 62.0000 - accuracy: 0.8202 - precision: 0.7574 - recall: 0.7687 - auc: 0.8683 - val_loss: 0.4686 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8855\n",
      "Epoch 458/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.4994 - tp: 209.0000 - fp: 75.0000 - tn: 369.0000 - fn: 59.0000 - accuracy: 0.8118 - precision: 0.7359 - recall: 0.7799 - auc: 0.8570 - val_loss: 0.4698 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8840\n",
      "Epoch 459/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.4904 - tp: 209.0000 - fp: 74.0000 - tn: 370.0000 - fn: 59.0000 - accuracy: 0.8132 - precision: 0.7385 - recall: 0.7799 - auc: 0.8640 - val_loss: 0.4692 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8861\n",
      "Epoch 460/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.5030 - tp: 205.0000 - fp: 64.0000 - tn: 380.0000 - fn: 63.0000 - accuracy: 0.8216 - precision: 0.7621 - recall: 0.7649 - auc: 0.8594 - val_loss: 0.4738 - val_tp: 61.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 13.0000 - val_accuracy: 0.7765 - val_precision: 0.6932 - val_recall: 0.8243 - val_auc: 0.8847\n",
      "Epoch 461/500\n",
      "712/712 [==============================] - 0s 103us/sample - loss: 0.5031 - tp: 211.0000 - fp: 73.0000 - tn: 371.0000 - fn: 57.0000 - accuracy: 0.8174 - precision: 0.7430 - recall: 0.7873 - auc: 0.8519 - val_loss: 0.4709 - val_tp: 61.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 13.0000 - val_accuracy: 0.7821 - val_precision: 0.7011 - val_recall: 0.8243 - val_auc: 0.8838\n",
      "Epoch 462/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.4977 - tp: 210.0000 - fp: 76.0000 - tn: 368.0000 - fn: 58.0000 - accuracy: 0.8118 - precision: 0.7343 - recall: 0.7836 - auc: 0.8552 - val_loss: 0.4689 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8844\n",
      "Epoch 463/500\n",
      "712/712 [==============================] - 0s 104us/sample - loss: 0.5142 - tp: 205.0000 - fp: 69.0000 - tn: 375.0000 - fn: 63.0000 - accuracy: 0.8146 - precision: 0.7482 - recall: 0.7649 - auc: 0.8431 - val_loss: 0.4748 - val_tp: 62.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 12.0000 - val_accuracy: 0.7877 - val_precision: 0.7045 - val_recall: 0.8378 - val_auc: 0.8842\n",
      "Epoch 464/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.4957 - tp: 210.0000 - fp: 77.0000 - tn: 367.0000 - fn: 58.0000 - accuracy: 0.8104 - precision: 0.7317 - recall: 0.7836 - auc: 0.8589 - val_loss: 0.4700 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8859\n",
      "Epoch 465/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.5021 - tp: 209.0000 - fp: 77.0000 - tn: 367.0000 - fn: 59.0000 - accuracy: 0.8090 - precision: 0.7308 - recall: 0.7799 - auc: 0.8526 - val_loss: 0.4679 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8865\n",
      "Epoch 466/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.4907 - tp: 207.0000 - fp: 63.0000 - tn: 381.0000 - fn: 61.0000 - accuracy: 0.8258 - precision: 0.7667 - recall: 0.7724 - auc: 0.8610 - val_loss: 0.4680 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8867\n",
      "Epoch 467/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.5069 - tp: 211.0000 - fp: 73.0000 - tn: 371.0000 - fn: 57.0000 - accuracy: 0.8174 - precision: 0.7430 - recall: 0.7873 - auc: 0.8550 - val_loss: 0.4696 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8869\n",
      "Epoch 468/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.4901 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8604 - val_loss: 0.4780 - val_tp: 64.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 10.0000 - val_accuracy: 0.7821 - val_precision: 0.6882 - val_recall: 0.8649 - val_auc: 0.8846\n",
      "Epoch 469/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.4855 - tp: 210.0000 - fp: 75.0000 - tn: 369.0000 - fn: 58.0000 - accuracy: 0.8132 - precision: 0.7368 - recall: 0.7836 - auc: 0.8670 - val_loss: 0.4686 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8869\n",
      "Epoch 470/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4888 - tp: 210.0000 - fp: 66.0000 - tn: 378.0000 - fn: 58.0000 - accuracy: 0.8258 - precision: 0.7609 - recall: 0.7836 - auc: 0.8666 - val_loss: 0.4686 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8866\n",
      "Epoch 471/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.4960 - tp: 203.0000 - fp: 65.0000 - tn: 379.0000 - fn: 65.0000 - accuracy: 0.8174 - precision: 0.7575 - recall: 0.7575 - auc: 0.8576 - val_loss: 0.4685 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8858\n",
      "Epoch 472/500\n",
      "712/712 [==============================] - 0s 104us/sample - loss: 0.4956 - tp: 209.0000 - fp: 71.0000 - tn: 373.0000 - fn: 59.0000 - accuracy: 0.8174 - precision: 0.7464 - recall: 0.7799 - auc: 0.8592 - val_loss: 0.4679 - val_tp: 59.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 15.0000 - val_accuracy: 0.7821 - val_precision: 0.7108 - val_recall: 0.7973 - val_auc: 0.8855\n",
      "Epoch 473/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.4971 - tp: 206.0000 - fp: 71.0000 - tn: 373.0000 - fn: 62.0000 - accuracy: 0.8132 - precision: 0.7437 - recall: 0.7687 - auc: 0.8577 - val_loss: 0.4673 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8861\n",
      "Epoch 474/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.4892 - tp: 208.0000 - fp: 72.0000 - tn: 372.0000 - fn: 60.0000 - accuracy: 0.8146 - precision: 0.7429 - recall: 0.7761 - auc: 0.8659 - val_loss: 0.4700 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8848\n",
      "Epoch 475/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.4886 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8662 - val_loss: 0.4692 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8869\n",
      "Epoch 476/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.4935 - tp: 209.0000 - fp: 67.0000 - tn: 377.0000 - fn: 59.0000 - accuracy: 0.8230 - precision: 0.7572 - recall: 0.7799 - auc: 0.8614 - val_loss: 0.4739 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8835\n",
      "Epoch 477/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.4859 - tp: 212.0000 - fp: 79.0000 - tn: 365.0000 - fn: 56.0000 - accuracy: 0.8104 - precision: 0.7285 - recall: 0.7910 - auc: 0.8681 - val_loss: 0.4689 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8864\n",
      "Epoch 478/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.4979 - tp: 207.0000 - fp: 70.0000 - tn: 374.0000 - fn: 61.0000 - accuracy: 0.8160 - precision: 0.7473 - recall: 0.7724 - auc: 0.8574 - val_loss: 0.4746 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8849\n",
      "Epoch 479/500\n",
      "712/712 [==============================] - 0s 104us/sample - loss: 0.5065 - tp: 210.0000 - fp: 80.0000 - tn: 364.0000 - fn: 58.0000 - accuracy: 0.8062 - precision: 0.7241 - recall: 0.7836 - auc: 0.8508 - val_loss: 0.4752 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8846\n",
      "Epoch 480/500\n",
      "712/712 [==============================] - 0s 102us/sample - loss: 0.4940 - tp: 207.0000 - fp: 73.0000 - tn: 371.0000 - fn: 61.0000 - accuracy: 0.8118 - precision: 0.7393 - recall: 0.7724 - auc: 0.8590 - val_loss: 0.4686 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8867\n",
      "Epoch 481/500\n",
      "712/712 [==============================] - 0s 101us/sample - loss: 0.4819 - tp: 211.0000 - fp: 69.0000 - tn: 375.0000 - fn: 57.0000 - accuracy: 0.8230 - precision: 0.7536 - recall: 0.7873 - auc: 0.8700 - val_loss: 0.4676 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8868\n",
      "Epoch 482/500\n",
      "712/712 [==============================] - 0s 101us/sample - loss: 0.5109 - tp: 206.0000 - fp: 63.0000 - tn: 381.0000 - fn: 62.0000 - accuracy: 0.8244 - precision: 0.7658 - recall: 0.7687 - auc: 0.8494 - val_loss: 0.4682 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8872\n",
      "Epoch 483/500\n",
      "712/712 [==============================] - 0s 104us/sample - loss: 0.4987 - tp: 207.0000 - fp: 65.0000 - tn: 379.0000 - fn: 61.0000 - accuracy: 0.8230 - precision: 0.7610 - recall: 0.7724 - auc: 0.8569 - val_loss: 0.4734 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8847\n",
      "Epoch 484/500\n",
      "712/712 [==============================] - 0s 102us/sample - loss: 0.4880 - tp: 208.0000 - fp: 69.0000 - tn: 375.0000 - fn: 60.0000 - accuracy: 0.8188 - precision: 0.7509 - recall: 0.7761 - auc: 0.8645 - val_loss: 0.4701 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8871\n",
      "Epoch 485/500\n",
      "712/712 [==============================] - 0s 104us/sample - loss: 0.4969 - tp: 209.0000 - fp: 68.0000 - tn: 376.0000 - fn: 59.0000 - accuracy: 0.8216 - precision: 0.7545 - recall: 0.7799 - auc: 0.8588 - val_loss: 0.4687 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8855\n",
      "Epoch 486/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.4825 - tp: 207.0000 - fp: 68.0000 - tn: 376.0000 - fn: 61.0000 - accuracy: 0.8188 - precision: 0.7527 - recall: 0.7724 - auc: 0.8702 - val_loss: 0.4703 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8853\n",
      "Epoch 487/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.4900 - tp: 207.0000 - fp: 65.0000 - tn: 379.0000 - fn: 61.0000 - accuracy: 0.8230 - precision: 0.7610 - recall: 0.7724 - auc: 0.8619 - val_loss: 0.4689 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8846\n",
      "Epoch 488/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5071 - tp: 209.0000 - fp: 75.0000 - tn: 369.0000 - fn: 59.0000 - accuracy: 0.8118 - precision: 0.7359 - recall: 0.7799 - auc: 0.8530 - val_loss: 0.4685 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8860\n",
      "Epoch 489/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.4966 - tp: 206.0000 - fp: 72.0000 - tn: 372.0000 - fn: 62.0000 - accuracy: 0.8118 - precision: 0.7410 - recall: 0.7687 - auc: 0.8564 - val_loss: 0.4685 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8868\n",
      "Epoch 490/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.4952 - tp: 209.0000 - fp: 66.0000 - tn: 378.0000 - fn: 59.0000 - accuracy: 0.8244 - precision: 0.7600 - recall: 0.7799 - auc: 0.8617 - val_loss: 0.4684 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8864\n",
      "Epoch 491/500\n",
      "712/712 [==============================] - 0s 102us/sample - loss: 0.5025 - tp: 208.0000 - fp: 68.0000 - tn: 376.0000 - fn: 60.0000 - accuracy: 0.8202 - precision: 0.7536 - recall: 0.7761 - auc: 0.8517 - val_loss: 0.4730 - val_tp: 61.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 13.0000 - val_accuracy: 0.7765 - val_precision: 0.6932 - val_recall: 0.8243 - val_auc: 0.8847\n",
      "Epoch 492/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.4939 - tp: 212.0000 - fp: 74.0000 - tn: 370.0000 - fn: 56.0000 - accuracy: 0.8174 - precision: 0.7413 - recall: 0.7910 - auc: 0.8606 - val_loss: 0.4679 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8854\n",
      "Epoch 493/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.4981 - tp: 207.0000 - fp: 68.0000 - tn: 376.0000 - fn: 61.0000 - accuracy: 0.8188 - precision: 0.7527 - recall: 0.7724 - auc: 0.8546 - val_loss: 0.4684 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8856\n",
      "Epoch 494/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.5015 - tp: 209.0000 - fp: 67.0000 - tn: 377.0000 - fn: 59.0000 - accuracy: 0.8230 - precision: 0.7572 - recall: 0.7799 - auc: 0.8547 - val_loss: 0.4684 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8866\n",
      "Epoch 495/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.5101 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8446 - val_loss: 0.4701 - val_tp: 61.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 13.0000 - val_accuracy: 0.7877 - val_precision: 0.7093 - val_recall: 0.8243 - val_auc: 0.8842\n",
      "Epoch 496/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.5005 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8546 - val_loss: 0.4755 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8841\n",
      "Epoch 497/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.4911 - tp: 210.0000 - fp: 71.0000 - tn: 373.0000 - fn: 58.0000 - accuracy: 0.8188 - precision: 0.7473 - recall: 0.7836 - auc: 0.8643 - val_loss: 0.4694 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8864\n",
      "Epoch 498/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.5073 - tp: 208.0000 - fp: 65.0000 - tn: 379.0000 - fn: 60.0000 - accuracy: 0.8244 - precision: 0.7619 - recall: 0.7761 - auc: 0.8509 - val_loss: 0.4696 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8865\n",
      "Epoch 499/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5026 - tp: 210.0000 - fp: 70.0000 - tn: 374.0000 - fn: 58.0000 - accuracy: 0.8202 - precision: 0.7500 - recall: 0.7836 - auc: 0.8527 - val_loss: 0.4696 - val_tp: 59.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 15.0000 - val_accuracy: 0.7877 - val_precision: 0.7195 - val_recall: 0.7973 - val_auc: 0.8862\n",
      "Epoch 500/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.5003 - tp: 207.0000 - fp: 73.0000 - tn: 371.0000 - fn: 61.0000 - accuracy: 0.8118 - precision: 0.7393 - recall: 0.7724 - auc: 0.8559 - val_loss: 0.4686 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 62d72b10733cc631c8b199b2c10b4763</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7988826632499695</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-batch_size: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_0: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_1: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_2: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_1: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_2: 56</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_0: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_1: 0.30000000000000004</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_2: 0.30000000000000004</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-epoch_number: 500</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_0: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_1: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_2: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_0: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_1: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_2: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-learning_rate: 0.0005</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: RMSprop</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 4s 5ms/sample - loss: 19.7631 - tp: 199.0000 - fp: 323.0000 - tn: 121.0000 - fn: 69.0000 - accuracy: 0.4494 - precision: 0.3812 - recall: 0.7425 - auc: 0.5177 - val_loss: 18.6924 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5645\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 17.7981 - tp: 191.0000 - fp: 323.0000 - tn: 121.0000 - fn: 77.0000 - accuracy: 0.4382 - precision: 0.3716 - recall: 0.7127 - auc: 0.4880 - val_loss: 16.7914 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5190\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 15.9474 - tp: 175.0000 - fp: 282.0000 - tn: 162.0000 - fn: 93.0000 - accuracy: 0.4733 - precision: 0.3829 - recall: 0.6530 - auc: 0.4994 - val_loss: 15.0093 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 14.2210 - tp: 164.0000 - fp: 261.0000 - tn: 183.0000 - fn: 104.0000 - accuracy: 0.4874 - precision: 0.3859 - recall: 0.6119 - auc: 0.4993 - val_loss: 13.3502 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 12.6165 - tp: 133.0000 - fp: 227.0000 - tn: 217.0000 - fn: 135.0000 - accuracy: 0.4916 - precision: 0.3694 - recall: 0.4963 - auc: 0.4816 - val_loss: 11.8083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 11.1298 - tp: 123.0000 - fp: 231.0000 - tn: 213.0000 - fn: 145.0000 - accuracy: 0.4719 - precision: 0.3475 - recall: 0.4590 - auc: 0.4539 - val_loss: 10.3861 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 9.7597 - tp: 112.0000 - fp: 173.0000 - tn: 271.0000 - fn: 156.0000 - accuracy: 0.5379 - precision: 0.3930 - recall: 0.4179 - auc: 0.5027 - val_loss: 9.0798 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 8.5058 - tp: 90.0000 - fp: 143.0000 - tn: 301.0000 - fn: 178.0000 - accuracy: 0.5492 - precision: 0.3863 - recall: 0.3358 - auc: 0.5054 - val_loss: 7.8855 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 7.3606 - tp: 47.0000 - fp: 80.0000 - tn: 364.0000 - fn: 221.0000 - accuracy: 0.5772 - precision: 0.3701 - recall: 0.1754 - auc: 0.4973 - val_loss: 6.7967 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 6.3191 - tp: 15.0000 - fp: 27.0000 - tn: 417.0000 - fn: 253.0000 - accuracy: 0.6067 - precision: 0.3571 - recall: 0.0560 - auc: 0.4786 - val_loss: 5.8096 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 5.3792 - tp: 1.0000 - fp: 4.0000 - tn: 440.0000 - fn: 267.0000 - accuracy: 0.6194 - precision: 0.2000 - recall: 0.0037 - auc: 0.4754 - val_loss: 4.9240 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 4.5374 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4953 - val_loss: 4.1332 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 3.7899 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 3.4356 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 3.1338 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4989 - val_loss: 2.8277 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 2.5661 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 2.3051 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 2.0824 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 1.8672 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 1.6818 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 1.5092 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 1.3593 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 1.2276 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 1.1139 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 1.0245 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.9448 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.8942 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.8453 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.8230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.7871 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7777 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.7500 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7494 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.7283 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7350 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.7184 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7293 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.7146 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7269 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.7127 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7255 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.7115 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7243 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7103 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7232 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.7094 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7084 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7214 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7078 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7207 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7070 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7201 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.7064 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7195 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7059 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7191 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.7054 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7187 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7050 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7183 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7046 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7179 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.7042 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7174 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.7038 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7172 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7035 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7169 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7034 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7167 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.7031 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7167 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7029 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7164 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.7027 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7162 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7026 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7160 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7024 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7159 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.7023 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7158 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.7021 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7156 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.7021 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7156 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.7021 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7155 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.7019 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7153 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.7017 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7153 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.7017 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7151 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.7016 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7151 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.7015 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7149 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.7014 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7149 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 58/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.7013 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7148 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 59/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.7014 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7147 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 60/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.7012 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7148 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 61/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.7012 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7147 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 62/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7011 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7146 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 63/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7011 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7147 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 64/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.7011 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4953 - val_loss: 0.7146 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 65/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7010 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7146 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 66/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.7009 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7145 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 67/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7009 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7144 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 68/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.7009 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7144 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 69/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.7008 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7143 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 70/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.7007 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7143 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 71/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7007 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7142 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 72/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7007 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7142 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 73/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.7006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7142 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 74/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.7007 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7144 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 75/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.7007 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4759 - val_loss: 0.7143 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 76/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.7006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4771 - val_loss: 0.7141 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 77/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.7005 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7141 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 78/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1851 - tp: 141.0000 - fp: 242.0000 - tn: 202.0000 - fn: 127.0000 - accuracy: 0.4817 - precision: 0.3681 - recall: 0.5261 - auc: 0.4912 - val_loss: 2.1652 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5918\n",
      "Epoch 109/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1761 - tp: 156.0000 - fp: 237.0000 - tn: 207.0000 - fn: 112.0000 - accuracy: 0.5098 - precision: 0.3969 - recall: 0.5821 - auc: 0.5178 - val_loss: 2.1648 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831\n",
      "Epoch 110/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.1675 - tp: 143.0000 - fp: 223.0000 - tn: 221.0000 - fn: 125.0000 - accuracy: 0.5112 - precision: 0.3907 - recall: 0.5336 - auc: 0.5288 - val_loss: 2.1644 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831\n",
      "Epoch 111/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1826 - tp: 131.0000 - fp: 242.0000 - tn: 202.0000 - fn: 137.0000 - accuracy: 0.4677 - precision: 0.3512 - recall: 0.4888 - auc: 0.4863 - val_loss: 2.1641 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5541\n",
      "Epoch 112/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1848 - tp: 144.0000 - fp: 235.0000 - tn: 209.0000 - fn: 124.0000 - accuracy: 0.4958 - precision: 0.3799 - recall: 0.5373 - auc: 0.4877 - val_loss: 2.1637 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5181\n",
      "Epoch 113/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1765 - tp: 133.0000 - fp: 234.0000 - tn: 210.0000 - fn: 135.0000 - accuracy: 0.4817 - precision: 0.3624 - recall: 0.4963 - auc: 0.5068 - val_loss: 2.1634 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5181\n",
      "Epoch 114/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.1721 - tp: 137.0000 - fp: 230.0000 - tn: 214.0000 - fn: 131.0000 - accuracy: 0.4930 - precision: 0.3733 - recall: 0.5112 - auc: 0.5040 - val_loss: 2.1630 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 115/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1707 - tp: 145.0000 - fp: 216.0000 - tn: 228.0000 - fn: 123.0000 - accuracy: 0.5239 - precision: 0.4017 - recall: 0.5410 - auc: 0.5138 - val_loss: 2.1627 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5095\n",
      "Epoch 116/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1635 - tp: 150.0000 - fp: 225.0000 - tn: 219.0000 - fn: 118.0000 - accuracy: 0.5183 - precision: 0.4000 - recall: 0.5597 - auc: 0.5283 - val_loss: 2.1624 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5313\n",
      "Epoch 117/600\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 2.1806 - tp: 137.0000 - fp: 220.0000 - tn: 224.0000 - fn: 131.0000 - accuracy: 0.5070 - precision: 0.3838 - recall: 0.5112 - auc: 0.5032 - val_loss: 2.1620 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5313\n",
      "Epoch 118/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1881 - tp: 123.0000 - fp: 224.0000 - tn: 220.0000 - fn: 145.0000 - accuracy: 0.4817 - precision: 0.3545 - recall: 0.4590 - auc: 0.4757 - val_loss: 2.1615 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5238\n",
      "Epoch 119/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1696 - tp: 148.0000 - fp: 242.0000 - tn: 202.0000 - fn: 120.0000 - accuracy: 0.4916 - precision: 0.3795 - recall: 0.5522 - auc: 0.5126 - val_loss: 2.1612 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5313\n",
      "Epoch 120/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.1744 - tp: 126.0000 - fp: 213.0000 - tn: 231.0000 - fn: 142.0000 - accuracy: 0.5014 - precision: 0.3717 - recall: 0.4701 - auc: 0.4981 - val_loss: 2.1608 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5313\n",
      "Epoch 121/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1886 - tp: 129.0000 - fp: 228.0000 - tn: 216.0000 - fn: 139.0000 - accuracy: 0.4846 - precision: 0.3613 - recall: 0.4813 - auc: 0.4674 - val_loss: 2.1604 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5409\n",
      "Epoch 122/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1659 - tp: 136.0000 - fp: 225.0000 - tn: 219.0000 - fn: 132.0000 - accuracy: 0.4986 - precision: 0.3767 - recall: 0.5075 - auc: 0.5159 - val_loss: 2.1600 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5409\n",
      "Epoch 123/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1670 - tp: 141.0000 - fp: 221.0000 - tn: 223.0000 - fn: 127.0000 - accuracy: 0.5112 - precision: 0.3895 - recall: 0.5261 - auc: 0.5140 - val_loss: 2.1597 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5587\n",
      "Epoch 124/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1752 - tp: 140.0000 - fp: 244.0000 - tn: 200.0000 - fn: 128.0000 - accuracy: 0.4775 - precision: 0.3646 - recall: 0.5224 - auc: 0.4896 - val_loss: 2.1594 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6304\n",
      "Epoch 125/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1689 - tp: 143.0000 - fp: 220.0000 - tn: 224.0000 - fn: 125.0000 - accuracy: 0.5154 - precision: 0.3939 - recall: 0.5336 - auc: 0.5138 - val_loss: 2.1590 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7375\n",
      "Epoch 126/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1554 - tp: 146.0000 - fp: 218.0000 - tn: 226.0000 - fn: 122.0000 - accuracy: 0.5225 - precision: 0.4011 - recall: 0.5448 - auc: 0.5366 - val_loss: 2.1587 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7188\n",
      "Epoch 127/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 2.1840 - tp: 133.0000 - fp: 247.0000 - tn: 197.0000 - fn: 135.0000 - accuracy: 0.4635 - precision: 0.3500 - recall: 0.4963 - auc: 0.4699 - val_loss: 2.1583 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7279\n",
      "Epoch 128/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1713 - tp: 134.0000 - fp: 231.0000 - tn: 213.0000 - fn: 134.0000 - accuracy: 0.4874 - precision: 0.3671 - recall: 0.5000 - auc: 0.4947 - val_loss: 2.1579 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7136\n",
      "Epoch 129/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 2.1877 - tp: 133.0000 - fp: 236.0000 - tn: 208.0000 - fn: 135.0000 - accuracy: 0.4789 - precision: 0.3604 - recall: 0.4963 - auc: 0.4650 - val_loss: 2.1576 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7524\n",
      "Epoch 130/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1750 - tp: 136.0000 - fp: 213.0000 - tn: 231.0000 - fn: 132.0000 - accuracy: 0.5154 - precision: 0.3897 - recall: 0.5075 - auc: 0.4899 - val_loss: 2.1572 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7254\n",
      "Epoch 131/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1771 - tp: 136.0000 - fp: 225.0000 - tn: 219.0000 - fn: 132.0000 - accuracy: 0.4986 - precision: 0.3767 - recall: 0.5075 - auc: 0.4904 - val_loss: 2.1568 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6364\n",
      "Epoch 132/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1754 - tp: 139.0000 - fp: 235.0000 - tn: 209.0000 - fn: 129.0000 - accuracy: 0.4888 - precision: 0.3717 - recall: 0.5187 - auc: 0.4843 - val_loss: 2.1564 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6296\n",
      "Epoch 133/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1786 - tp: 126.0000 - fp: 236.0000 - tn: 208.0000 - fn: 142.0000 - accuracy: 0.4691 - precision: 0.3481 - recall: 0.4701 - auc: 0.4699 - val_loss: 2.1561 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5986\n",
      "Epoch 134/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 2.1647 - tp: 142.0000 - fp: 219.0000 - tn: 225.0000 - fn: 126.0000 - accuracy: 0.5154 - precision: 0.3934 - recall: 0.5299 - auc: 0.5096 - val_loss: 2.1557 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831\n",
      "Epoch 135/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.1696 - tp: 137.0000 - fp: 222.0000 - tn: 222.0000 - fn: 131.0000 - accuracy: 0.5042 - precision: 0.3816 - recall: 0.5112 - auc: 0.4956 - val_loss: 2.1553 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6141\n",
      "Epoch 136/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 2.1671 - tp: 138.0000 - fp: 228.0000 - tn: 216.0000 - fn: 130.0000 - accuracy: 0.4972 - precision: 0.3770 - recall: 0.5149 - auc: 0.5037 - val_loss: 2.1548 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6606\n",
      "Epoch 137/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.1606 - tp: 143.0000 - fp: 228.0000 - tn: 216.0000 - fn: 125.0000 - accuracy: 0.5042 - precision: 0.3854 - recall: 0.5336 - auc: 0.5173 - val_loss: 2.1545 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6364\n",
      "Epoch 138/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1610 - tp: 142.0000 - fp: 213.0000 - tn: 231.0000 - fn: 126.0000 - accuracy: 0.5239 - precision: 0.4000 - recall: 0.5299 - auc: 0.5200 - val_loss: 2.1541 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831\n",
      "Epoch 139/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.1657 - tp: 140.0000 - fp: 237.0000 - tn: 207.0000 - fn: 128.0000 - accuracy: 0.4874 - precision: 0.3714 - recall: 0.5224 - auc: 0.4938 - val_loss: 2.1538 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5338\n",
      "Epoch 140/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1664 - tp: 131.0000 - fp: 213.0000 - tn: 231.0000 - fn: 137.0000 - accuracy: 0.5084 - precision: 0.3808 - recall: 0.4888 - auc: 0.4959 - val_loss: 2.1534 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5338\n",
      "Epoch 141/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1559 - tp: 131.0000 - fp: 225.0000 - tn: 219.0000 - fn: 137.0000 - accuracy: 0.4916 - precision: 0.3680 - recall: 0.4888 - auc: 0.5181 - val_loss: 2.1530 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5541\n",
      "Epoch 142/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1530 - tp: 137.0000 - fp: 229.0000 - tn: 215.0000 - fn: 131.0000 - accuracy: 0.4944 - precision: 0.3743 - recall: 0.5112 - auc: 0.5241 - val_loss: 2.1526 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 143/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1644 - tp: 132.0000 - fp: 226.0000 - tn: 218.0000 - fn: 136.0000 - accuracy: 0.4916 - precision: 0.3687 - recall: 0.4925 - auc: 0.4969 - val_loss: 2.1523 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 144/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1472 - tp: 148.0000 - fp: 209.0000 - tn: 235.0000 - fn: 120.0000 - accuracy: 0.5379 - precision: 0.4146 - recall: 0.5522 - auc: 0.5411 - val_loss: 2.1520 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 145/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1643 - tp: 135.0000 - fp: 233.0000 - tn: 211.0000 - fn: 133.0000 - accuracy: 0.4860 - precision: 0.3668 - recall: 0.5037 - auc: 0.4915 - val_loss: 2.1517 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5095\n",
      "Epoch 146/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1559 - tp: 140.0000 - fp: 213.0000 - tn: 231.0000 - fn: 128.0000 - accuracy: 0.5211 - precision: 0.3966 - recall: 0.5224 - auc: 0.5206 - val_loss: 2.1513 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5238\n",
      "Epoch 147/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1640 - tp: 127.0000 - fp: 224.0000 - tn: 220.0000 - fn: 141.0000 - accuracy: 0.4874 - precision: 0.3618 - recall: 0.4739 - auc: 0.4912 - val_loss: 2.1510 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5238\n",
      "Epoch 148/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 2.1596 - tp: 128.0000 - fp: 210.0000 - tn: 234.0000 - fn: 140.0000 - accuracy: 0.5084 - precision: 0.3787 - recall: 0.4776 - auc: 0.5113 - val_loss: 2.1505 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5095\n",
      "Epoch 149/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1606 - tp: 141.0000 - fp: 213.0000 - tn: 231.0000 - fn: 127.0000 - accuracy: 0.5225 - precision: 0.3983 - recall: 0.5261 - auc: 0.5065 - val_loss: 2.1501 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 150/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1678 - tp: 136.0000 - fp: 229.0000 - tn: 215.0000 - fn: 132.0000 - accuracy: 0.4930 - precision: 0.3726 - recall: 0.5075 - auc: 0.4806 - val_loss: 2.1497 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 151/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1606 - tp: 134.0000 - fp: 231.0000 - tn: 213.0000 - fn: 134.0000 - accuracy: 0.4874 - precision: 0.3671 - recall: 0.5000 - auc: 0.4975 - val_loss: 2.1493 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 152/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1671 - tp: 128.0000 - fp: 219.0000 - tn: 225.0000 - fn: 140.0000 - accuracy: 0.4958 - precision: 0.3689 - recall: 0.4776 - auc: 0.4810 - val_loss: 2.1489 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 153/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1471 - tp: 148.0000 - fp: 218.0000 - tn: 226.0000 - fn: 120.0000 - accuracy: 0.5253 - precision: 0.4044 - recall: 0.5522 - auc: 0.5312 - val_loss: 2.1485 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 154/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1669 - tp: 129.0000 - fp: 241.0000 - tn: 203.0000 - fn: 139.0000 - accuracy: 0.4663 - precision: 0.3486 - recall: 0.4813 - auc: 0.4751 - val_loss: 2.1481 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 155/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1682 - tp: 131.0000 - fp: 233.0000 - tn: 211.0000 - fn: 137.0000 - accuracy: 0.4803 - precision: 0.3599 - recall: 0.4888 - auc: 0.4702 - val_loss: 2.1478 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5095\n",
      "Epoch 156/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1516 - tp: 130.0000 - fp: 206.0000 - tn: 238.0000 - fn: 138.0000 - accuracy: 0.5169 - precision: 0.3869 - recall: 0.4851 - auc: 0.5144 - val_loss: 2.1474 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5238\n",
      "Epoch 157/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.1489 - tp: 127.0000 - fp: 207.0000 - tn: 237.0000 - fn: 141.0000 - accuracy: 0.5112 - precision: 0.3802 - recall: 0.4739 - auc: 0.5199 - val_loss: 2.1469 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 158/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.1647 - tp: 126.0000 - fp: 225.0000 - tn: 219.0000 - fn: 142.0000 - accuracy: 0.4846 - precision: 0.3590 - recall: 0.4701 - auc: 0.4700 - val_loss: 2.1465 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 159/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1480 - tp: 128.0000 - fp: 204.0000 - tn: 240.0000 - fn: 140.0000 - accuracy: 0.5169 - precision: 0.3855 - recall: 0.4776 - auc: 0.5172 - val_loss: 2.1461 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 160/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1652 - tp: 123.0000 - fp: 222.0000 - tn: 222.0000 - fn: 145.0000 - accuracy: 0.4846 - precision: 0.3565 - recall: 0.4590 - auc: 0.4739 - val_loss: 2.1457 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 161/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.1580 - tp: 133.0000 - fp: 228.0000 - tn: 216.0000 - fn: 135.0000 - accuracy: 0.4902 - precision: 0.3684 - recall: 0.4963 - auc: 0.4908 - val_loss: 2.1453 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 162/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1477 - tp: 127.0000 - fp: 225.0000 - tn: 219.0000 - fn: 141.0000 - accuracy: 0.4860 - precision: 0.3608 - recall: 0.4739 - auc: 0.5048 - val_loss: 2.1450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 163/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1453 - tp: 141.0000 - fp: 218.0000 - tn: 226.0000 - fn: 127.0000 - accuracy: 0.5154 - precision: 0.3928 - recall: 0.5261 - auc: 0.5276 - val_loss: 2.1446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 164/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.1419 - tp: 158.0000 - fp: 230.0000 - tn: 214.0000 - fn: 110.0000 - accuracy: 0.5225 - precision: 0.4072 - recall: 0.5896 - auc: 0.5325 - val_loss: 2.1443 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5171\n",
      "Epoch 165/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1550 - tp: 136.0000 - fp: 230.0000 - tn: 214.0000 - fn: 132.0000 - accuracy: 0.4916 - precision: 0.3716 - recall: 0.5075 - auc: 0.4929 - val_loss: 2.1439 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5266\n",
      "Epoch 166/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 2.1525 - tp: 136.0000 - fp: 222.0000 - tn: 222.0000 - fn: 132.0000 - accuracy: 0.5028 - precision: 0.3799 - recall: 0.5075 - auc: 0.5138 - val_loss: 2.1436 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5456\n",
      "Epoch 167/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.1729 - tp: 129.0000 - fp: 232.0000 - tn: 212.0000 - fn: 139.0000 - accuracy: 0.4789 - precision: 0.3573 - recall: 0.4813 - auc: 0.4548 - val_loss: 2.1432 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5627\n",
      "Epoch 168/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1404 - tp: 135.0000 - fp: 213.0000 - tn: 231.0000 - fn: 133.0000 - accuracy: 0.5140 - precision: 0.3879 - recall: 0.5037 - auc: 0.5216 - val_loss: 2.1429 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5976\n",
      "Epoch 169/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.1519 - tp: 130.0000 - fp: 213.0000 - tn: 231.0000 - fn: 138.0000 - accuracy: 0.5070 - precision: 0.3790 - recall: 0.4851 - auc: 0.4986 - val_loss: 2.1425 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5920\n",
      "Epoch 170/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1463 - tp: 138.0000 - fp: 220.0000 - tn: 224.0000 - fn: 130.0000 - accuracy: 0.5084 - precision: 0.3855 - recall: 0.5149 - auc: 0.5061 - val_loss: 2.1420 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5456\n",
      "Epoch 171/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1434 - tp: 142.0000 - fp: 214.0000 - tn: 230.0000 - fn: 126.0000 - accuracy: 0.5225 - precision: 0.3989 - recall: 0.5299 - auc: 0.5219 - val_loss: 2.1416 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5456\n",
      "Epoch 172/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 2.1378 - tp: 149.0000 - fp: 226.0000 - tn: 218.0000 - fn: 119.0000 - accuracy: 0.5154 - precision: 0.3973 - recall: 0.5560 - auc: 0.5369 - val_loss: 2.1413 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5587\n",
      "Epoch 173/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1608 - tp: 121.0000 - fp: 232.0000 - tn: 212.0000 - fn: 147.0000 - accuracy: 0.4677 - precision: 0.3428 - recall: 0.4515 - auc: 0.4723 - val_loss: 2.1409 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5968\n",
      "Epoch 174/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 2.1484 - tp: 133.0000 - fp: 228.0000 - tn: 216.0000 - fn: 135.0000 - accuracy: 0.4902 - precision: 0.3684 - recall: 0.4963 - auc: 0.5037 - val_loss: 2.1406 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6162\n",
      "Epoch 175/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1492 - tp: 125.0000 - fp: 215.0000 - tn: 229.0000 - fn: 143.0000 - accuracy: 0.4972 - precision: 0.3676 - recall: 0.4664 - auc: 0.4887 - val_loss: 2.1401 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5722\n",
      "Epoch 176/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.1485 - tp: 132.0000 - fp: 219.0000 - tn: 225.0000 - fn: 136.0000 - accuracy: 0.5014 - precision: 0.3761 - recall: 0.4925 - auc: 0.5023 - val_loss: 2.1397 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6111\n",
      "Epoch 177/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1473 - tp: 148.0000 - fp: 208.0000 - tn: 236.0000 - fn: 120.0000 - accuracy: 0.5393 - precision: 0.4157 - recall: 0.5522 - auc: 0.5183 - val_loss: 2.1393 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5976\n",
      "Epoch 178/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1420 - tp: 138.0000 - fp: 221.0000 - tn: 223.0000 - fn: 130.0000 - accuracy: 0.5070 - precision: 0.3844 - recall: 0.5149 - auc: 0.5159 - val_loss: 2.1390 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5976\n",
      "Epoch 179/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 2.1414 - tp: 144.0000 - fp: 213.0000 - tn: 231.0000 - fn: 124.0000 - accuracy: 0.5267 - precision: 0.4034 - recall: 0.5373 - auc: 0.5187 - val_loss: 2.1386 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6015\n",
      "Epoch 180/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1450 - tp: 123.0000 - fp: 201.0000 - tn: 243.0000 - fn: 145.0000 - accuracy: 0.5140 - precision: 0.3796 - recall: 0.4590 - auc: 0.5084 - val_loss: 2.1382 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5920\n",
      "Epoch 181/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 2.1493 - tp: 131.0000 - fp: 215.0000 - tn: 229.0000 - fn: 137.0000 - accuracy: 0.5056 - precision: 0.3786 - recall: 0.4888 - auc: 0.4941 - val_loss: 2.1377 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5674\n",
      "Epoch 182/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.1363 - tp: 141.0000 - fp: 214.0000 - tn: 230.0000 - fn: 127.0000 - accuracy: 0.5211 - precision: 0.3972 - recall: 0.5261 - auc: 0.5285 - val_loss: 2.1373 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5504\n",
      "Epoch 183/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1400 - tp: 142.0000 - fp: 228.0000 - tn: 216.0000 - fn: 126.0000 - accuracy: 0.5028 - precision: 0.3838 - recall: 0.5299 - auc: 0.5121 - val_loss: 2.1369 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5579\n",
      "Epoch 184/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1319 - tp: 145.0000 - fp: 220.0000 - tn: 224.0000 - fn: 123.0000 - accuracy: 0.5183 - precision: 0.3973 - recall: 0.5410 - auc: 0.5350 - val_loss: 2.1366 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5908\n",
      "Epoch 185/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1445 - tp: 137.0000 - fp: 221.0000 - tn: 223.0000 - fn: 131.0000 - accuracy: 0.5056 - precision: 0.3827 - recall: 0.5112 - auc: 0.5112 - val_loss: 2.1363 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6257\n",
      "Epoch 186/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1396 - tp: 151.0000 - fp: 220.0000 - tn: 224.0000 - fn: 117.0000 - accuracy: 0.5267 - precision: 0.4070 - recall: 0.5634 - auc: 0.5188 - val_loss: 2.1359 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6942\n",
      "Epoch 187/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 2.1433 - tp: 139.0000 - fp: 224.0000 - tn: 220.0000 - fn: 129.0000 - accuracy: 0.5042 - precision: 0.3829 - recall: 0.5187 - auc: 0.4997 - val_loss: 2.1356 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7144\n",
      "Epoch 188/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1506 - tp: 130.0000 - fp: 228.0000 - tn: 216.0000 - fn: 138.0000 - accuracy: 0.4860 - precision: 0.3631 - recall: 0.4851 - auc: 0.4832 - val_loss: 2.1352 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7406\n",
      "Epoch 189/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1410 - tp: 152.0000 - fp: 244.0000 - tn: 200.0000 - fn: 116.0000 - accuracy: 0.4944 - precision: 0.3838 - recall: 0.5672 - auc: 0.5070 - val_loss: 2.1349 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7079\n",
      "Epoch 190/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.1460 - tp: 127.0000 - fp: 213.0000 - tn: 231.0000 - fn: 141.0000 - accuracy: 0.5028 - precision: 0.3735 - recall: 0.4739 - auc: 0.4871 - val_loss: 2.1345 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7457\n",
      "Epoch 191/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1313 - tp: 146.0000 - fp: 228.0000 - tn: 216.0000 - fn: 122.0000 - accuracy: 0.5084 - precision: 0.3904 - recall: 0.5448 - auc: 0.5268 - val_loss: 2.1341 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6972\n",
      "Epoch 192/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.1418 - tp: 138.0000 - fp: 197.0000 - tn: 247.0000 - fn: 130.0000 - accuracy: 0.5407 - precision: 0.4119 - recall: 0.5149 - auc: 0.5092 - val_loss: 2.1337 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7254\n",
      "Epoch 193/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1540 - tp: 141.0000 - fp: 211.0000 - tn: 233.0000 - fn: 127.0000 - accuracy: 0.5253 - precision: 0.4006 - recall: 0.5261 - auc: 0.4777 - val_loss: 2.1333 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7211\n",
      "Epoch 194/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1330 - tp: 139.0000 - fp: 204.0000 - tn: 240.0000 - fn: 129.0000 - accuracy: 0.5323 - precision: 0.4052 - recall: 0.5187 - auc: 0.5220 - val_loss: 2.1329 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7147\n",
      "Epoch 195/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1426 - tp: 135.0000 - fp: 241.0000 - tn: 203.0000 - fn: 133.0000 - accuracy: 0.4747 - precision: 0.3590 - recall: 0.5037 - auc: 0.4929 - val_loss: 2.1326 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6208\n",
      "Epoch 196/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1521 - tp: 127.0000 - fp: 238.0000 - tn: 206.0000 - fn: 141.0000 - accuracy: 0.4677 - precision: 0.3479 - recall: 0.4739 - auc: 0.4703 - val_loss: 2.1324 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 197/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1361 - tp: 128.0000 - fp: 198.0000 - tn: 246.0000 - fn: 140.0000 - accuracy: 0.5253 - precision: 0.3926 - recall: 0.4776 - auc: 0.5082 - val_loss: 2.1320 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5338\n",
      "Epoch 198/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.1378 - tp: 125.0000 - fp: 207.0000 - tn: 237.0000 - fn: 143.0000 - accuracy: 0.5084 - precision: 0.3765 - recall: 0.4664 - auc: 0.5095 - val_loss: 2.1315 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5763\n",
      "Epoch 199/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 2.1378 - tp: 127.0000 - fp: 225.0000 - tn: 219.0000 - fn: 141.0000 - accuracy: 0.4860 - precision: 0.3608 - recall: 0.4739 - auc: 0.4984 - val_loss: 2.1312 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5541\n",
      "Epoch 200/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1358 - tp: 141.0000 - fp: 221.0000 - tn: 223.0000 - fn: 127.0000 - accuracy: 0.5112 - precision: 0.3895 - recall: 0.5261 - auc: 0.4993 - val_loss: 2.1308 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5405\n",
      "Epoch 201/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1440 - tp: 133.0000 - fp: 223.0000 - tn: 221.0000 - fn: 135.0000 - accuracy: 0.4972 - precision: 0.3736 - recall: 0.4963 - auc: 0.4925 - val_loss: 2.1304 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 202/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1413 - tp: 137.0000 - fp: 236.0000 - tn: 208.0000 - fn: 131.0000 - accuracy: 0.4846 - precision: 0.3673 - recall: 0.5112 - auc: 0.4869 - val_loss: 2.1300 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 203/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 2.1364 - tp: 134.0000 - fp: 217.0000 - tn: 227.0000 - fn: 134.0000 - accuracy: 0.5070 - precision: 0.3818 - recall: 0.5000 - auc: 0.5047 - val_loss: 2.1296 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 204/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.1330 - tp: 148.0000 - fp: 211.0000 - tn: 233.0000 - fn: 120.0000 - accuracy: 0.5351 - precision: 0.4123 - recall: 0.5522 - auc: 0.5200 - val_loss: 2.1292 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 205/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1386 - tp: 126.0000 - fp: 201.0000 - tn: 243.0000 - fn: 142.0000 - accuracy: 0.5183 - precision: 0.3853 - recall: 0.4701 - auc: 0.4982 - val_loss: 2.1288 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5743\n",
      "Epoch 206/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1496 - tp: 121.0000 - fp: 225.0000 - tn: 219.0000 - fn: 147.0000 - accuracy: 0.4775 - precision: 0.3497 - recall: 0.4515 - auc: 0.4616 - val_loss: 2.1284 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5541\n",
      "Epoch 207/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 2.1382 - tp: 122.0000 - fp: 212.0000 - tn: 232.0000 - fn: 146.0000 - accuracy: 0.4972 - precision: 0.3653 - recall: 0.4552 - auc: 0.4937 - val_loss: 2.1280 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5763\n",
      "Epoch 208/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1423 - tp: 127.0000 - fp: 202.0000 - tn: 242.0000 - fn: 141.0000 - accuracy: 0.5183 - precision: 0.3860 - recall: 0.4739 - auc: 0.4913 - val_loss: 2.1277 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 209/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1414 - tp: 119.0000 - fp: 218.0000 - tn: 226.0000 - fn: 149.0000 - accuracy: 0.4846 - precision: 0.3531 - recall: 0.4440 - auc: 0.4833 - val_loss: 2.1272 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5811\n",
      "Epoch 210/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.1367 - tp: 139.0000 - fp: 229.0000 - tn: 215.0000 - fn: 129.0000 - accuracy: 0.4972 - precision: 0.3777 - recall: 0.5187 - auc: 0.4926 - val_loss: 2.1269 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5541\n",
      "Epoch 211/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1187 - tp: 138.0000 - fp: 204.0000 - tn: 240.0000 - fn: 130.0000 - accuracy: 0.5309 - precision: 0.4035 - recall: 0.5149 - auc: 0.5356 - val_loss: 2.1265 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 212/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.1293 - tp: 126.0000 - fp: 205.0000 - tn: 239.0000 - fn: 142.0000 - accuracy: 0.5126 - precision: 0.3807 - recall: 0.4701 - auc: 0.5065 - val_loss: 2.1261 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 213/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1289 - tp: 136.0000 - fp: 229.0000 - tn: 215.0000 - fn: 132.0000 - accuracy: 0.4930 - precision: 0.3726 - recall: 0.5075 - auc: 0.5086 - val_loss: 2.1257 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 214/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1347 - tp: 130.0000 - fp: 221.0000 - tn: 223.0000 - fn: 138.0000 - accuracy: 0.4958 - precision: 0.3704 - recall: 0.4851 - auc: 0.4934 - val_loss: 2.1253 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5541\n",
      "Epoch 215/600\n",
      "712/712 [==============================] - 0s 201us/sample - loss: 2.1405 - tp: 114.0000 - fp: 208.0000 - tn: 236.0000 - fn: 154.0000 - accuracy: 0.4916 - precision: 0.3540 - recall: 0.4254 - auc: 0.4728 - val_loss: 2.1249 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5763\n",
      "Epoch 216/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 2.1322 - tp: 135.0000 - fp: 213.0000 - tn: 231.0000 - fn: 133.0000 - accuracy: 0.5140 - precision: 0.3879 - recall: 0.5037 - auc: 0.5082 - val_loss: 2.1245 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 217/600\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 2.1231 - tp: 122.0000 - fp: 218.0000 - tn: 226.0000 - fn: 146.0000 - accuracy: 0.4888 - precision: 0.3588 - recall: 0.4552 - auc: 0.5042 - val_loss: 2.1241 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5811\n",
      "Epoch 218/600\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 2.1188 - tp: 136.0000 - fp: 218.0000 - tn: 226.0000 - fn: 132.0000 - accuracy: 0.5084 - precision: 0.3842 - recall: 0.5075 - auc: 0.5253 - val_loss: 2.1238 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 219/600\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 2.1229 - tp: 133.0000 - fp: 207.0000 - tn: 237.0000 - fn: 135.0000 - accuracy: 0.5197 - precision: 0.3912 - recall: 0.4963 - auc: 0.5185 - val_loss: 2.1235 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 220/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 2.1337 - tp: 119.0000 - fp: 219.0000 - tn: 225.0000 - fn: 149.0000 - accuracy: 0.4831 - precision: 0.3521 - recall: 0.4440 - auc: 0.4810 - val_loss: 2.1230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 221/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1386 - tp: 121.0000 - fp: 226.0000 - tn: 218.0000 - fn: 147.0000 - accuracy: 0.4761 - precision: 0.3487 - recall: 0.4515 - auc: 0.4716 - val_loss: 2.1227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 222/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.1397 - tp: 122.0000 - fp: 218.0000 - tn: 226.0000 - fn: 146.0000 - accuracy: 0.4888 - precision: 0.3588 - recall: 0.4552 - auc: 0.4759 - val_loss: 2.1223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 223/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.1231 - tp: 127.0000 - fp: 232.0000 - tn: 212.0000 - fn: 141.0000 - accuracy: 0.4761 - precision: 0.3538 - recall: 0.4739 - auc: 0.4981 - val_loss: 2.1219 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 224/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1221 - tp: 126.0000 - fp: 213.0000 - tn: 231.0000 - fn: 142.0000 - accuracy: 0.5014 - precision: 0.3717 - recall: 0.4701 - auc: 0.5042 - val_loss: 2.1215 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 225/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1310 - tp: 129.0000 - fp: 235.0000 - tn: 209.0000 - fn: 139.0000 - accuracy: 0.4747 - precision: 0.3544 - recall: 0.4813 - auc: 0.4845 - val_loss: 2.1211 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 226/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 2.1261 - tp: 133.0000 - fp: 210.0000 - tn: 234.0000 - fn: 135.0000 - accuracy: 0.5154 - precision: 0.3878 - recall: 0.4963 - auc: 0.5052 - val_loss: 2.1208 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 227/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1385 - tp: 123.0000 - fp: 226.0000 - tn: 218.0000 - fn: 145.0000 - accuracy: 0.4789 - precision: 0.3524 - recall: 0.4590 - auc: 0.4735 - val_loss: 2.1203 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 228/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1424 - tp: 124.0000 - fp: 234.0000 - tn: 210.0000 - fn: 144.0000 - accuracy: 0.4691 - precision: 0.3464 - recall: 0.4627 - auc: 0.4577 - val_loss: 2.1199 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 229/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1180 - tp: 135.0000 - fp: 197.0000 - tn: 247.0000 - fn: 133.0000 - accuracy: 0.5365 - precision: 0.4066 - recall: 0.5037 - auc: 0.5286 - val_loss: 2.1196 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 230/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1231 - tp: 132.0000 - fp: 200.0000 - tn: 244.0000 - fn: 136.0000 - accuracy: 0.5281 - precision: 0.3976 - recall: 0.4925 - auc: 0.5195 - val_loss: 2.1192 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 231/600\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 2.1204 - tp: 134.0000 - fp: 219.0000 - tn: 225.0000 - fn: 134.0000 - accuracy: 0.5042 - precision: 0.3796 - recall: 0.5000 - auc: 0.5157 - val_loss: 2.1188 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 232/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 2.1287 - tp: 124.0000 - fp: 208.0000 - tn: 236.0000 - fn: 144.0000 - accuracy: 0.5056 - precision: 0.3735 - recall: 0.4627 - auc: 0.4876 - val_loss: 2.1185 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 233/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 2.1272 - tp: 122.0000 - fp: 210.0000 - tn: 234.0000 - fn: 146.0000 - accuracy: 0.5000 - precision: 0.3675 - recall: 0.4552 - auc: 0.4907 - val_loss: 2.1180 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 234/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.1205 - tp: 133.0000 - fp: 201.0000 - tn: 243.0000 - fn: 135.0000 - accuracy: 0.5281 - precision: 0.3982 - recall: 0.4963 - auc: 0.5083 - val_loss: 2.1176 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 235/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 2.1122 - tp: 134.0000 - fp: 197.0000 - tn: 247.0000 - fn: 134.0000 - accuracy: 0.5351 - precision: 0.4048 - recall: 0.5000 - auc: 0.5335 - val_loss: 2.1172 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 236/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 2.1212 - tp: 123.0000 - fp: 201.0000 - tn: 243.0000 - fn: 145.0000 - accuracy: 0.5140 - precision: 0.3796 - recall: 0.4590 - auc: 0.5105 - val_loss: 2.1168 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 237/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.1250 - tp: 129.0000 - fp: 228.0000 - tn: 216.0000 - fn: 139.0000 - accuracy: 0.4846 - precision: 0.3613 - recall: 0.4813 - auc: 0.4816 - val_loss: 2.1165 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 238/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1200 - tp: 125.0000 - fp: 208.0000 - tn: 236.0000 - fn: 143.0000 - accuracy: 0.5070 - precision: 0.3754 - recall: 0.4664 - auc: 0.5096 - val_loss: 2.1161 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 239/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1136 - tp: 142.0000 - fp: 220.0000 - tn: 224.0000 - fn: 126.0000 - accuracy: 0.5140 - precision: 0.3923 - recall: 0.5299 - auc: 0.5215 - val_loss: 2.1158 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 240/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 2.1152 - tp: 132.0000 - fp: 216.0000 - tn: 228.0000 - fn: 136.0000 - accuracy: 0.5056 - precision: 0.3793 - recall: 0.4925 - auc: 0.5069 - val_loss: 2.1155 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 241/600\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 2.1168 - tp: 127.0000 - fp: 196.0000 - tn: 248.0000 - fn: 141.0000 - accuracy: 0.5267 - precision: 0.3932 - recall: 0.4739 - auc: 0.5098 - val_loss: 2.1152 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 242/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 2.1277 - tp: 125.0000 - fp: 212.0000 - tn: 232.0000 - fn: 143.0000 - accuracy: 0.5014 - precision: 0.3709 - recall: 0.4664 - auc: 0.4756 - val_loss: 2.1147 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 243/600\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 2.1188 - tp: 139.0000 - fp: 216.0000 - tn: 228.0000 - fn: 129.0000 - accuracy: 0.5154 - precision: 0.3915 - recall: 0.5187 - auc: 0.4989 - val_loss: 2.1143 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 244/600\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 2.1153 - tp: 133.0000 - fp: 206.0000 - tn: 238.0000 - fn: 135.0000 - accuracy: 0.5211 - precision: 0.3923 - recall: 0.4963 - auc: 0.5161 - val_loss: 2.1139 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 245/600\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 2.1074 - tp: 132.0000 - fp: 195.0000 - tn: 249.0000 - fn: 136.0000 - accuracy: 0.5351 - precision: 0.4037 - recall: 0.4925 - auc: 0.5320 - val_loss: 2.1134 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 246/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 2.1173 - tp: 131.0000 - fp: 213.0000 - tn: 231.0000 - fn: 137.0000 - accuracy: 0.5084 - precision: 0.3808 - recall: 0.4888 - auc: 0.4997 - val_loss: 2.1131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 247/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 2.1232 - tp: 117.0000 - fp: 228.0000 - tn: 216.0000 - fn: 151.0000 - accuracy: 0.4677 - precision: 0.3391 - recall: 0.4366 - auc: 0.4769 - val_loss: 2.1128 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 248/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1151 - tp: 126.0000 - fp: 206.0000 - tn: 238.0000 - fn: 142.0000 - accuracy: 0.5112 - precision: 0.3795 - recall: 0.4701 - auc: 0.5045 - val_loss: 2.1124 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 249/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1051 - tp: 129.0000 - fp: 206.0000 - tn: 238.0000 - fn: 139.0000 - accuracy: 0.5154 - precision: 0.3851 - recall: 0.4813 - auc: 0.5288 - val_loss: 2.1119 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 250/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1277 - tp: 127.0000 - fp: 230.0000 - tn: 214.0000 - fn: 141.0000 - accuracy: 0.4789 - precision: 0.3557 - recall: 0.4739 - auc: 0.4677 - val_loss: 2.1115 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 251/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1003 - tp: 142.0000 - fp: 197.0000 - tn: 247.0000 - fn: 126.0000 - accuracy: 0.5463 - precision: 0.4189 - recall: 0.5299 - auc: 0.5443 - val_loss: 2.1112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 252/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1208 - tp: 123.0000 - fp: 213.0000 - tn: 231.0000 - fn: 145.0000 - accuracy: 0.4972 - precision: 0.3661 - recall: 0.4590 - auc: 0.4813 - val_loss: 2.1107 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 253/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1140 - tp: 139.0000 - fp: 216.0000 - tn: 228.0000 - fn: 129.0000 - accuracy: 0.5154 - precision: 0.3915 - recall: 0.5187 - auc: 0.5172 - val_loss: 2.1104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 254/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 2.1078 - tp: 137.0000 - fp: 212.0000 - tn: 232.0000 - fn: 131.0000 - accuracy: 0.5183 - precision: 0.3926 - recall: 0.5112 - auc: 0.5174 - val_loss: 2.1101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 255/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 2.1096 - tp: 133.0000 - fp: 220.0000 - tn: 224.0000 - fn: 135.0000 - accuracy: 0.5014 - precision: 0.3768 - recall: 0.4963 - auc: 0.5089 - val_loss: 2.1097 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 256/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1241 - tp: 123.0000 - fp: 213.0000 - tn: 231.0000 - fn: 145.0000 - accuracy: 0.4972 - precision: 0.3661 - recall: 0.4590 - auc: 0.4748 - val_loss: 2.1093 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 257/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1154 - tp: 136.0000 - fp: 221.0000 - tn: 223.0000 - fn: 132.0000 - accuracy: 0.5042 - precision: 0.3810 - recall: 0.5075 - auc: 0.5008 - val_loss: 2.1088 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 258/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1054 - tp: 128.0000 - fp: 192.0000 - tn: 252.0000 - fn: 140.0000 - accuracy: 0.5337 - precision: 0.4000 - recall: 0.4776 - auc: 0.5217 - val_loss: 2.1084 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 259/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1121 - tp: 129.0000 - fp: 218.0000 - tn: 226.0000 - fn: 139.0000 - accuracy: 0.4986 - precision: 0.3718 - recall: 0.4813 - auc: 0.5019 - val_loss: 2.1081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 260/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1154 - tp: 124.0000 - fp: 210.0000 - tn: 234.0000 - fn: 144.0000 - accuracy: 0.5028 - precision: 0.3713 - recall: 0.4627 - auc: 0.4933 - val_loss: 2.1077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 261/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1024 - tp: 127.0000 - fp: 213.0000 - tn: 231.0000 - fn: 141.0000 - accuracy: 0.5028 - precision: 0.3735 - recall: 0.4739 - auc: 0.5119 - val_loss: 2.1073 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 262/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0994 - tp: 143.0000 - fp: 204.0000 - tn: 240.0000 - fn: 125.0000 - accuracy: 0.5379 - precision: 0.4121 - recall: 0.5336 - auc: 0.5361 - val_loss: 2.1069 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 263/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1100 - tp: 141.0000 - fp: 217.0000 - tn: 227.0000 - fn: 127.0000 - accuracy: 0.5169 - precision: 0.3939 - recall: 0.5261 - auc: 0.5135 - val_loss: 2.1066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 264/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1104 - tp: 129.0000 - fp: 225.0000 - tn: 219.0000 - fn: 139.0000 - accuracy: 0.4888 - precision: 0.3644 - recall: 0.4813 - auc: 0.4976 - val_loss: 2.1062 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 265/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.1129 - tp: 133.0000 - fp: 194.0000 - tn: 250.0000 - fn: 135.0000 - accuracy: 0.5379 - precision: 0.4067 - recall: 0.4963 - auc: 0.5090 - val_loss: 2.1057 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 266/600\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 2.1211 - tp: 117.0000 - fp: 221.0000 - tn: 223.0000 - fn: 151.0000 - accuracy: 0.4775 - precision: 0.3462 - recall: 0.4366 - auc: 0.4673 - val_loss: 2.1053 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 267/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.1189 - tp: 123.0000 - fp: 210.0000 - tn: 234.0000 - fn: 145.0000 - accuracy: 0.5014 - precision: 0.3694 - recall: 0.4590 - auc: 0.4826 - val_loss: 2.1049 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 268/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1028 - tp: 142.0000 - fp: 215.0000 - tn: 229.0000 - fn: 126.0000 - accuracy: 0.5211 - precision: 0.3978 - recall: 0.5299 - auc: 0.5198 - val_loss: 2.1046 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 269/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 2.0995 - tp: 143.0000 - fp: 223.0000 - tn: 221.0000 - fn: 125.0000 - accuracy: 0.5112 - precision: 0.3907 - recall: 0.5336 - auc: 0.5291 - val_loss: 2.1042 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 270/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1066 - tp: 125.0000 - fp: 195.0000 - tn: 249.0000 - fn: 143.0000 - accuracy: 0.5253 - precision: 0.3906 - recall: 0.4664 - auc: 0.5151 - val_loss: 2.1038 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 271/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1077 - tp: 131.0000 - fp: 210.0000 - tn: 234.0000 - fn: 137.0000 - accuracy: 0.5126 - precision: 0.3842 - recall: 0.4888 - auc: 0.5045 - val_loss: 2.1034 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 272/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1199 - tp: 120.0000 - fp: 227.0000 - tn: 217.0000 - fn: 148.0000 - accuracy: 0.4733 - precision: 0.3458 - recall: 0.4478 - auc: 0.4631 - val_loss: 2.1030 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 273/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 2.1033 - tp: 133.0000 - fp: 221.0000 - tn: 223.0000 - fn: 135.0000 - accuracy: 0.5000 - precision: 0.3757 - recall: 0.4963 - auc: 0.5134 - val_loss: 2.1026 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 274/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0963 - tp: 142.0000 - fp: 210.0000 - tn: 234.0000 - fn: 126.0000 - accuracy: 0.5281 - precision: 0.4034 - recall: 0.5299 - auc: 0.5289 - val_loss: 2.1023 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 275/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0974 - tp: 144.0000 - fp: 212.0000 - tn: 232.0000 - fn: 124.0000 - accuracy: 0.5281 - precision: 0.4045 - recall: 0.5373 - auc: 0.5297 - val_loss: 2.1019 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 276/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 2.1071 - tp: 150.0000 - fp: 230.0000 - tn: 214.0000 - fn: 118.0000 - accuracy: 0.5112 - precision: 0.3947 - recall: 0.5597 - auc: 0.5066 - val_loss: 2.1015 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 277/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.1012 - tp: 136.0000 - fp: 213.0000 - tn: 231.0000 - fn: 132.0000 - accuracy: 0.5154 - precision: 0.3897 - recall: 0.5075 - auc: 0.5074 - val_loss: 2.1012 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 278/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1027 - tp: 128.0000 - fp: 209.0000 - tn: 235.0000 - fn: 140.0000 - accuracy: 0.5098 - precision: 0.3798 - recall: 0.4776 - auc: 0.5047 - val_loss: 2.1009 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 279/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0810 - tp: 156.0000 - fp: 194.0000 - tn: 250.0000 - fn: 112.0000 - accuracy: 0.5702 - precision: 0.4457 - recall: 0.5821 - auc: 0.5726 - val_loss: 2.1005 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048\n",
      "Epoch 280/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1132 - tp: 122.0000 - fp: 199.0000 - tn: 245.0000 - fn: 146.0000 - accuracy: 0.5154 - precision: 0.3801 - recall: 0.4552 - auc: 0.4797 - val_loss: 2.1000 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 281/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.1075 - tp: 126.0000 - fp: 213.0000 - tn: 231.0000 - fn: 142.0000 - accuracy: 0.5014 - precision: 0.3717 - recall: 0.4701 - auc: 0.4901 - val_loss: 2.0995 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 282/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.1199 - tp: 117.0000 - fp: 227.0000 - tn: 217.0000 - fn: 151.0000 - accuracy: 0.4691 - precision: 0.3401 - recall: 0.4366 - auc: 0.4618 - val_loss: 2.0990 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 283/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.1057 - tp: 121.0000 - fp: 222.0000 - tn: 222.0000 - fn: 147.0000 - accuracy: 0.4817 - precision: 0.3528 - recall: 0.4515 - auc: 0.4854 - val_loss: 2.0988 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 284/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.0939 - tp: 145.0000 - fp: 214.0000 - tn: 230.0000 - fn: 123.0000 - accuracy: 0.5267 - precision: 0.4039 - recall: 0.5410 - auc: 0.5273 - val_loss: 2.0984 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 285/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.0967 - tp: 132.0000 - fp: 195.0000 - tn: 249.0000 - fn: 136.0000 - accuracy: 0.5351 - precision: 0.4037 - recall: 0.4925 - auc: 0.5194 - val_loss: 2.0979 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 286/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0930 - tp: 135.0000 - fp: 206.0000 - tn: 238.0000 - fn: 133.0000 - accuracy: 0.5239 - precision: 0.3959 - recall: 0.5037 - auc: 0.5227 - val_loss: 2.0975 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 287/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 2.1098 - tp: 121.0000 - fp: 223.0000 - tn: 221.0000 - fn: 147.0000 - accuracy: 0.4803 - precision: 0.3517 - recall: 0.4515 - auc: 0.4728 - val_loss: 2.0972 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 288/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0903 - tp: 141.0000 - fp: 213.0000 - tn: 231.0000 - fn: 127.0000 - accuracy: 0.5225 - precision: 0.3983 - recall: 0.5261 - auc: 0.5355 - val_loss: 2.0968 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 289/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1028 - tp: 127.0000 - fp: 218.0000 - tn: 226.0000 - fn: 141.0000 - accuracy: 0.4958 - precision: 0.3681 - recall: 0.4739 - auc: 0.4918 - val_loss: 2.0965 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 290/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0992 - tp: 133.0000 - fp: 201.0000 - tn: 243.0000 - fn: 135.0000 - accuracy: 0.5281 - precision: 0.3982 - recall: 0.4963 - auc: 0.5064 - val_loss: 2.0960 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 291/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0962 - tp: 123.0000 - fp: 208.0000 - tn: 236.0000 - fn: 145.0000 - accuracy: 0.5042 - precision: 0.3716 - recall: 0.4590 - auc: 0.5001 - val_loss: 2.0956 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 292/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 2.1004 - tp: 124.0000 - fp: 208.0000 - tn: 236.0000 - fn: 144.0000 - accuracy: 0.5056 - precision: 0.3735 - recall: 0.4627 - auc: 0.4943 - val_loss: 2.0952 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 293/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 2.1003 - tp: 124.0000 - fp: 217.0000 - tn: 227.0000 - fn: 144.0000 - accuracy: 0.4930 - precision: 0.3636 - recall: 0.4627 - auc: 0.4981 - val_loss: 2.0948 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 294/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0985 - tp: 121.0000 - fp: 198.0000 - tn: 246.0000 - fn: 147.0000 - accuracy: 0.5154 - precision: 0.3793 - recall: 0.4515 - auc: 0.4967 - val_loss: 2.0945 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 295/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.0869 - tp: 142.0000 - fp: 202.0000 - tn: 242.0000 - fn: 126.0000 - accuracy: 0.5393 - precision: 0.4128 - recall: 0.5299 - auc: 0.5362 - val_loss: 2.0941 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 296/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.1046 - tp: 122.0000 - fp: 192.0000 - tn: 252.0000 - fn: 146.0000 - accuracy: 0.5253 - precision: 0.3885 - recall: 0.4552 - auc: 0.4845 - val_loss: 2.0938 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 297/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.1137 - tp: 107.0000 - fp: 208.0000 - tn: 236.0000 - fn: 161.0000 - accuracy: 0.4817 - precision: 0.3397 - recall: 0.3993 - auc: 0.4535 - val_loss: 2.0934 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 298/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 2.1029 - tp: 120.0000 - fp: 226.0000 - tn: 218.0000 - fn: 148.0000 - accuracy: 0.4747 - precision: 0.3468 - recall: 0.4478 - auc: 0.4709 - val_loss: 2.0930 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 299/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.0899 - tp: 144.0000 - fp: 204.0000 - tn: 240.0000 - fn: 124.0000 - accuracy: 0.5393 - precision: 0.4138 - recall: 0.5373 - auc: 0.5317 - val_loss: 2.0926 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 300/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.1003 - tp: 124.0000 - fp: 217.0000 - tn: 227.0000 - fn: 144.0000 - accuracy: 0.4930 - precision: 0.3636 - recall: 0.4627 - auc: 0.4827 - val_loss: 2.0922 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 301/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0887 - tp: 132.0000 - fp: 209.0000 - tn: 235.0000 - fn: 136.0000 - accuracy: 0.5154 - precision: 0.3871 - recall: 0.4925 - auc: 0.5090 - val_loss: 2.0918 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 302/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0877 - tp: 127.0000 - fp: 192.0000 - tn: 252.0000 - fn: 141.0000 - accuracy: 0.5323 - precision: 0.3981 - recall: 0.4739 - auc: 0.5191 - val_loss: 2.0914 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 303/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0983 - tp: 119.0000 - fp: 216.0000 - tn: 228.0000 - fn: 149.0000 - accuracy: 0.4874 - precision: 0.3552 - recall: 0.4440 - auc: 0.4787 - val_loss: 2.0910 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 304/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.0877 - tp: 128.0000 - fp: 207.0000 - tn: 237.0000 - fn: 140.0000 - accuracy: 0.5126 - precision: 0.3821 - recall: 0.4776 - auc: 0.5118 - val_loss: 2.0907 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 305/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0944 - tp: 119.0000 - fp: 194.0000 - tn: 250.0000 - fn: 149.0000 - accuracy: 0.5183 - precision: 0.3802 - recall: 0.4440 - auc: 0.4984 - val_loss: 2.0903 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 306/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0942 - tp: 126.0000 - fp: 218.0000 - tn: 226.0000 - fn: 142.0000 - accuracy: 0.4944 - precision: 0.3663 - recall: 0.4701 - auc: 0.4993 - val_loss: 2.0899 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 307/600\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 2.1077 - tp: 110.0000 - fp: 221.0000 - tn: 223.0000 - fn: 158.0000 - accuracy: 0.4677 - precision: 0.3323 - recall: 0.4104 - auc: 0.4457 - val_loss: 2.0894 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5763\n",
      "Epoch 308/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0838 - tp: 134.0000 - fp: 194.0000 - tn: 250.0000 - fn: 134.0000 - accuracy: 0.5393 - precision: 0.4085 - recall: 0.5000 - auc: 0.5290 - val_loss: 2.0890 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831\n",
      "Epoch 309/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.1090 - tp: 118.0000 - fp: 225.0000 - tn: 219.0000 - fn: 150.0000 - accuracy: 0.4733 - precision: 0.3440 - recall: 0.4403 - auc: 0.4469 - val_loss: 2.0886 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6797\n",
      "Epoch 310/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0923 - tp: 118.0000 - fp: 204.0000 - tn: 240.0000 - fn: 150.0000 - accuracy: 0.5028 - precision: 0.3665 - recall: 0.4403 - auc: 0.4913 - val_loss: 2.0882 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7262\n",
      "Epoch 311/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0733 - tp: 145.0000 - fp: 208.0000 - tn: 236.0000 - fn: 123.0000 - accuracy: 0.5351 - precision: 0.4108 - recall: 0.5410 - auc: 0.5562 - val_loss: 2.0878 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7242\n",
      "Epoch 312/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.0751 - tp: 140.0000 - fp: 210.0000 - tn: 234.0000 - fn: 128.0000 - accuracy: 0.5253 - precision: 0.4000 - recall: 0.5224 - auc: 0.5412 - val_loss: 2.0875 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6817\n",
      "Epoch 313/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0960 - tp: 118.0000 - fp: 209.0000 - tn: 235.0000 - fn: 150.0000 - accuracy: 0.4958 - precision: 0.3609 - recall: 0.4403 - auc: 0.4811 - val_loss: 2.0871 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6594\n",
      "Epoch 314/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0617 - tp: 143.0000 - fp: 193.0000 - tn: 251.0000 - fn: 125.0000 - accuracy: 0.5534 - precision: 0.4256 - recall: 0.5336 - auc: 0.5743 - val_loss: 2.0867 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6797\n",
      "Epoch 315/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0972 - tp: 132.0000 - fp: 229.0000 - tn: 215.0000 - fn: 136.0000 - accuracy: 0.4874 - precision: 0.3657 - recall: 0.4925 - auc: 0.4808 - val_loss: 2.0864 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5898\n",
      "Epoch 316/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.0784 - tp: 144.0000 - fp: 204.0000 - tn: 240.0000 - fn: 124.0000 - accuracy: 0.5393 - precision: 0.4138 - recall: 0.5373 - auc: 0.5369 - val_loss: 2.0861 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 317/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.0945 - tp: 123.0000 - fp: 212.0000 - tn: 232.0000 - fn: 145.0000 - accuracy: 0.4986 - precision: 0.3672 - recall: 0.4590 - auc: 0.4842 - val_loss: 2.0857 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 318/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0948 - tp: 128.0000 - fp: 227.0000 - tn: 217.0000 - fn: 140.0000 - accuracy: 0.4846 - precision: 0.3606 - recall: 0.4776 - auc: 0.4826 - val_loss: 2.0854 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 319/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.0978 - tp: 130.0000 - fp: 211.0000 - tn: 233.0000 - fn: 138.0000 - accuracy: 0.5098 - precision: 0.3812 - recall: 0.4851 - auc: 0.4841 - val_loss: 2.0849 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 320/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 2.0839 - tp: 134.0000 - fp: 211.0000 - tn: 233.0000 - fn: 134.0000 - accuracy: 0.5154 - precision: 0.3884 - recall: 0.5000 - auc: 0.5200 - val_loss: 2.0846 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 321/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0818 - tp: 128.0000 - fp: 196.0000 - tn: 248.0000 - fn: 140.0000 - accuracy: 0.5281 - precision: 0.3951 - recall: 0.4776 - auc: 0.5178 - val_loss: 2.0842 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 322/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0902 - tp: 132.0000 - fp: 227.0000 - tn: 217.0000 - fn: 136.0000 - accuracy: 0.4902 - precision: 0.3677 - recall: 0.4925 - auc: 0.4850 - val_loss: 2.0839 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 323/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0886 - tp: 119.0000 - fp: 206.0000 - tn: 238.0000 - fn: 149.0000 - accuracy: 0.5014 - precision: 0.3662 - recall: 0.4440 - auc: 0.4952 - val_loss: 2.0834 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 324/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0832 - tp: 119.0000 - fp: 195.0000 - tn: 249.0000 - fn: 149.0000 - accuracy: 0.5169 - precision: 0.3790 - recall: 0.4440 - auc: 0.5043 - val_loss: 2.0830 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5338\n",
      "Epoch 325/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0972 - tp: 117.0000 - fp: 220.0000 - tn: 224.0000 - fn: 151.0000 - accuracy: 0.4789 - precision: 0.3472 - recall: 0.4366 - auc: 0.4557 - val_loss: 2.0826 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5338\n",
      "Epoch 326/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0841 - tp: 127.0000 - fp: 212.0000 - tn: 232.0000 - fn: 141.0000 - accuracy: 0.5042 - precision: 0.3746 - recall: 0.4739 - auc: 0.5033 - val_loss: 2.0822 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5608\n",
      "Epoch 327/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0736 - tp: 135.0000 - fp: 218.0000 - tn: 226.0000 - fn: 133.0000 - accuracy: 0.5070 - precision: 0.3824 - recall: 0.5037 - auc: 0.5325 - val_loss: 2.0819 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5338\n",
      "Epoch 328/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0811 - tp: 129.0000 - fp: 200.0000 - tn: 244.0000 - fn: 139.0000 - accuracy: 0.5239 - precision: 0.3921 - recall: 0.4813 - auc: 0.5096 - val_loss: 2.0815 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5743\n",
      "Epoch 329/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0777 - tp: 131.0000 - fp: 208.0000 - tn: 236.0000 - fn: 137.0000 - accuracy: 0.5154 - precision: 0.3864 - recall: 0.4888 - auc: 0.5182 - val_loss: 2.0810 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5966\n",
      "Epoch 330/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 2.0646 - tp: 146.0000 - fp: 204.0000 - tn: 240.0000 - fn: 122.0000 - accuracy: 0.5421 - precision: 0.4171 - recall: 0.5448 - auc: 0.5526 - val_loss: 2.0807 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5473\n",
      "Epoch 331/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.0830 - tp: 124.0000 - fp: 212.0000 - tn: 232.0000 - fn: 144.0000 - accuracy: 0.5000 - precision: 0.3690 - recall: 0.4627 - auc: 0.4945 - val_loss: 2.0803 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5763\n",
      "Epoch 332/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.0690 - tp: 120.0000 - fp: 188.0000 - tn: 256.0000 - fn: 148.0000 - accuracy: 0.5281 - precision: 0.3896 - recall: 0.4478 - auc: 0.5256 - val_loss: 2.0799 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6101\n",
      "Epoch 333/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.0831 - tp: 131.0000 - fp: 227.0000 - tn: 217.0000 - fn: 137.0000 - accuracy: 0.4888 - precision: 0.3659 - recall: 0.4888 - auc: 0.4998 - val_loss: 2.0795 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6594\n",
      "Epoch 334/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0845 - tp: 126.0000 - fp: 225.0000 - tn: 219.0000 - fn: 142.0000 - accuracy: 0.4846 - precision: 0.3590 - recall: 0.4701 - auc: 0.4940 - val_loss: 2.0792 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831\n",
      "Epoch 335/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0771 - tp: 130.0000 - fp: 201.0000 - tn: 243.0000 - fn: 138.0000 - accuracy: 0.5239 - precision: 0.3927 - recall: 0.4851 - auc: 0.5196 - val_loss: 2.0787 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6884\n",
      "Epoch 336/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0878 - tp: 136.0000 - fp: 227.0000 - tn: 217.0000 - fn: 132.0000 - accuracy: 0.4958 - precision: 0.3747 - recall: 0.5075 - auc: 0.4817 - val_loss: 2.0784 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6817\n",
      "Epoch 337/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0694 - tp: 146.0000 - fp: 204.0000 - tn: 240.0000 - fn: 122.0000 - accuracy: 0.5421 - precision: 0.4171 - recall: 0.5448 - auc: 0.5373 - val_loss: 2.0780 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5898\n",
      "Epoch 338/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.0724 - tp: 126.0000 - fp: 216.0000 - tn: 228.0000 - fn: 142.0000 - accuracy: 0.4972 - precision: 0.3684 - recall: 0.4701 - auc: 0.5221 - val_loss: 2.0777 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5763\n",
      "Epoch 339/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0675 - tp: 152.0000 - fp: 214.0000 - tn: 230.0000 - fn: 116.0000 - accuracy: 0.5365 - precision: 0.4153 - recall: 0.5672 - auc: 0.5365 - val_loss: 2.0774 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 340/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0783 - tp: 134.0000 - fp: 232.0000 - tn: 212.0000 - fn: 134.0000 - accuracy: 0.4860 - precision: 0.3661 - recall: 0.5000 - auc: 0.5031 - val_loss: 2.0770 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 341/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0776 - tp: 134.0000 - fp: 201.0000 - tn: 243.0000 - fn: 134.0000 - accuracy: 0.5295 - precision: 0.4000 - recall: 0.5000 - auc: 0.5089 - val_loss: 2.0766 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 342/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 2.0840 - tp: 126.0000 - fp: 232.0000 - tn: 212.0000 - fn: 142.0000 - accuracy: 0.4747 - precision: 0.3520 - recall: 0.4701 - auc: 0.4795 - val_loss: 2.0763 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 343/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.0916 - tp: 122.0000 - fp: 215.0000 - tn: 229.0000 - fn: 146.0000 - accuracy: 0.4930 - precision: 0.3620 - recall: 0.4552 - auc: 0.4593 - val_loss: 2.0760 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 344/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 2.0826 - tp: 125.0000 - fp: 215.0000 - tn: 229.0000 - fn: 143.0000 - accuracy: 0.4972 - precision: 0.3676 - recall: 0.4664 - auc: 0.4887 - val_loss: 2.0756 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 345/600\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 2.0731 - tp: 129.0000 - fp: 212.0000 - tn: 232.0000 - fn: 139.0000 - accuracy: 0.5070 - precision: 0.3783 - recall: 0.4813 - auc: 0.5149 - val_loss: 2.0752 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 346/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.0736 - tp: 138.0000 - fp: 206.0000 - tn: 238.0000 - fn: 130.0000 - accuracy: 0.5281 - precision: 0.4012 - recall: 0.5149 - auc: 0.5129 - val_loss: 2.0749 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 347/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0776 - tp: 120.0000 - fp: 216.0000 - tn: 228.0000 - fn: 148.0000 - accuracy: 0.4888 - precision: 0.3571 - recall: 0.4478 - auc: 0.4966 - val_loss: 2.0745 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 348/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0623 - tp: 135.0000 - fp: 196.0000 - tn: 248.0000 - fn: 133.0000 - accuracy: 0.5379 - precision: 0.4079 - recall: 0.5037 - auc: 0.5410 - val_loss: 2.0742 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 349/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0674 - tp: 135.0000 - fp: 215.0000 - tn: 229.0000 - fn: 133.0000 - accuracy: 0.5112 - precision: 0.3857 - recall: 0.5037 - auc: 0.5279 - val_loss: 2.0738 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 350/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0752 - tp: 128.0000 - fp: 194.0000 - tn: 250.0000 - fn: 140.0000 - accuracy: 0.5309 - precision: 0.3975 - recall: 0.4776 - auc: 0.5139 - val_loss: 2.0734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 351/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0791 - tp: 135.0000 - fp: 212.0000 - tn: 232.0000 - fn: 133.0000 - accuracy: 0.5154 - precision: 0.3890 - recall: 0.5037 - auc: 0.4891 - val_loss: 2.0730 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 352/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0741 - tp: 129.0000 - fp: 211.0000 - tn: 233.0000 - fn: 139.0000 - accuracy: 0.5084 - precision: 0.3794 - recall: 0.4813 - auc: 0.4952 - val_loss: 2.0726 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 353/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0712 - tp: 125.0000 - fp: 212.0000 - tn: 232.0000 - fn: 143.0000 - accuracy: 0.5014 - precision: 0.3709 - recall: 0.4664 - auc: 0.5033 - val_loss: 2.0722 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 354/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0710 - tp: 125.0000 - fp: 220.0000 - tn: 224.0000 - fn: 143.0000 - accuracy: 0.4902 - precision: 0.3623 - recall: 0.4664 - auc: 0.5050 - val_loss: 2.0719 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 355/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0685 - tp: 131.0000 - fp: 209.0000 - tn: 235.0000 - fn: 137.0000 - accuracy: 0.5140 - precision: 0.3853 - recall: 0.4888 - auc: 0.5090 - val_loss: 2.0715 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 356/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0655 - tp: 125.0000 - fp: 197.0000 - tn: 247.0000 - fn: 143.0000 - accuracy: 0.5225 - precision: 0.3882 - recall: 0.4664 - auc: 0.5213 - val_loss: 2.0712 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 357/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0735 - tp: 123.0000 - fp: 208.0000 - tn: 236.0000 - fn: 145.0000 - accuracy: 0.5042 - precision: 0.3716 - recall: 0.4590 - auc: 0.4972 - val_loss: 2.0708 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 358/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0715 - tp: 144.0000 - fp: 221.0000 - tn: 223.0000 - fn: 124.0000 - accuracy: 0.5154 - precision: 0.3945 - recall: 0.5373 - auc: 0.5049 - val_loss: 2.0705 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 359/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0703 - tp: 125.0000 - fp: 218.0000 - tn: 226.0000 - fn: 143.0000 - accuracy: 0.4930 - precision: 0.3644 - recall: 0.4664 - auc: 0.4940 - val_loss: 2.0701 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 360/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0788 - tp: 130.0000 - fp: 227.0000 - tn: 217.0000 - fn: 138.0000 - accuracy: 0.4874 - precision: 0.3641 - recall: 0.4851 - auc: 0.4799 - val_loss: 2.0697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 361/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0605 - tp: 140.0000 - fp: 203.0000 - tn: 241.0000 - fn: 128.0000 - accuracy: 0.5351 - precision: 0.4082 - recall: 0.5224 - auc: 0.5410 - val_loss: 2.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 362/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0694 - tp: 139.0000 - fp: 209.0000 - tn: 235.0000 - fn: 129.0000 - accuracy: 0.5253 - precision: 0.3994 - recall: 0.5187 - auc: 0.5085 - val_loss: 2.0689 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 363/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0621 - tp: 128.0000 - fp: 184.0000 - tn: 260.0000 - fn: 140.0000 - accuracy: 0.5449 - precision: 0.4103 - recall: 0.4776 - auc: 0.5233 - val_loss: 2.0686 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 364/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0711 - tp: 120.0000 - fp: 205.0000 - tn: 239.0000 - fn: 148.0000 - accuracy: 0.5042 - precision: 0.3692 - recall: 0.4478 - auc: 0.5010 - val_loss: 2.0682 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 365/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 2.0608 - tp: 130.0000 - fp: 193.0000 - tn: 251.0000 - fn: 138.0000 - accuracy: 0.5351 - precision: 0.4025 - recall: 0.4851 - auc: 0.5251 - val_loss: 2.0677 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 366/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0728 - tp: 125.0000 - fp: 209.0000 - tn: 235.0000 - fn: 143.0000 - accuracy: 0.5056 - precision: 0.3743 - recall: 0.4664 - auc: 0.4847 - val_loss: 2.0673 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 367/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0690 - tp: 132.0000 - fp: 215.0000 - tn: 229.0000 - fn: 136.0000 - accuracy: 0.5070 - precision: 0.3804 - recall: 0.4925 - auc: 0.4959 - val_loss: 2.0669 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 368/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0636 - tp: 129.0000 - fp: 200.0000 - tn: 244.0000 - fn: 139.0000 - accuracy: 0.5239 - precision: 0.3921 - recall: 0.4813 - auc: 0.5200 - val_loss: 2.0666 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 369/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0725 - tp: 126.0000 - fp: 232.0000 - tn: 212.0000 - fn: 142.0000 - accuracy: 0.4747 - precision: 0.3520 - recall: 0.4701 - auc: 0.4810 - val_loss: 2.0661 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 370/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 2.0584 - tp: 127.0000 - fp: 204.0000 - tn: 240.0000 - fn: 141.0000 - accuracy: 0.5154 - precision: 0.3837 - recall: 0.4739 - auc: 0.5244 - val_loss: 2.0657 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 371/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.0620 - tp: 132.0000 - fp: 202.0000 - tn: 242.0000 - fn: 136.0000 - accuracy: 0.5253 - precision: 0.3952 - recall: 0.4925 - auc: 0.5147 - val_loss: 2.0653 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 372/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.0637 - tp: 126.0000 - fp: 209.0000 - tn: 235.0000 - fn: 142.0000 - accuracy: 0.5070 - precision: 0.3761 - recall: 0.4701 - auc: 0.5123 - val_loss: 2.0650 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 373/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0606 - tp: 127.0000 - fp: 204.0000 - tn: 240.0000 - fn: 141.0000 - accuracy: 0.5154 - precision: 0.3837 - recall: 0.4739 - auc: 0.5179 - val_loss: 2.0646 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 374/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0649 - tp: 129.0000 - fp: 210.0000 - tn: 234.0000 - fn: 139.0000 - accuracy: 0.5098 - precision: 0.3805 - recall: 0.4813 - auc: 0.5056 - val_loss: 2.0643 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 375/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0641 - tp: 119.0000 - fp: 215.0000 - tn: 229.0000 - fn: 149.0000 - accuracy: 0.4888 - precision: 0.3563 - recall: 0.4440 - auc: 0.4971 - val_loss: 2.0638 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 376/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0691 - tp: 118.0000 - fp: 201.0000 - tn: 243.0000 - fn: 150.0000 - accuracy: 0.5070 - precision: 0.3699 - recall: 0.4403 - auc: 0.4959 - val_loss: 2.0635 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 377/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.0724 - tp: 119.0000 - fp: 231.0000 - tn: 213.0000 - fn: 149.0000 - accuracy: 0.4663 - precision: 0.3400 - recall: 0.4440 - auc: 0.4777 - val_loss: 2.0631 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5763\n",
      "Epoch 378/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.0760 - tp: 122.0000 - fp: 231.0000 - tn: 213.0000 - fn: 146.0000 - accuracy: 0.4705 - precision: 0.3456 - recall: 0.4552 - auc: 0.4590 - val_loss: 2.0628 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 379/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0674 - tp: 121.0000 - fp: 207.0000 - tn: 237.0000 - fn: 147.0000 - accuracy: 0.5028 - precision: 0.3689 - recall: 0.4515 - auc: 0.4874 - val_loss: 2.0624 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 380/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0707 - tp: 122.0000 - fp: 225.0000 - tn: 219.0000 - fn: 146.0000 - accuracy: 0.4789 - precision: 0.3516 - recall: 0.4552 - auc: 0.4725 - val_loss: 2.0620 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 381/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0599 - tp: 127.0000 - fp: 212.0000 - tn: 232.0000 - fn: 141.0000 - accuracy: 0.5042 - precision: 0.3746 - recall: 0.4739 - auc: 0.5053 - val_loss: 2.0616 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 382/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0487 - tp: 145.0000 - fp: 207.0000 - tn: 237.0000 - fn: 123.0000 - accuracy: 0.5365 - precision: 0.4119 - recall: 0.5410 - auc: 0.5451 - val_loss: 2.0611 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6729\n",
      "Epoch 383/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.0591 - tp: 131.0000 - fp: 217.0000 - tn: 227.0000 - fn: 137.0000 - accuracy: 0.5028 - precision: 0.3764 - recall: 0.4888 - auc: 0.5070 - val_loss: 2.0608 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831\n",
      "Epoch 384/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 2.0515 - tp: 136.0000 - fp: 206.0000 - tn: 238.0000 - fn: 132.0000 - accuracy: 0.5253 - precision: 0.3977 - recall: 0.5075 - auc: 0.5319 - val_loss: 2.0604 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831\n",
      "Epoch 385/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0600 - tp: 143.0000 - fp: 208.0000 - tn: 236.0000 - fn: 125.0000 - accuracy: 0.5323 - precision: 0.4074 - recall: 0.5336 - auc: 0.5131 - val_loss: 2.0601 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831\n",
      "Epoch 386/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.0713 - tp: 116.0000 - fp: 205.0000 - tn: 239.0000 - fn: 152.0000 - accuracy: 0.4986 - precision: 0.3614 - recall: 0.4328 - auc: 0.4712 - val_loss: 2.0597 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6033\n",
      "Epoch 387/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 2.0529 - tp: 138.0000 - fp: 203.0000 - tn: 241.0000 - fn: 130.0000 - accuracy: 0.5323 - precision: 0.4047 - recall: 0.5149 - auc: 0.5238 - val_loss: 2.0593 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6439\n",
      "Epoch 388/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0650 - tp: 124.0000 - fp: 223.0000 - tn: 221.0000 - fn: 144.0000 - accuracy: 0.4846 - precision: 0.3573 - recall: 0.4627 - auc: 0.4830 - val_loss: 2.0590 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831\n",
      "Epoch 389/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0643 - tp: 127.0000 - fp: 216.0000 - tn: 228.0000 - fn: 141.0000 - accuracy: 0.4986 - precision: 0.3703 - recall: 0.4739 - auc: 0.4914 - val_loss: 2.0586 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831\n",
      "Epoch 390/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0586 - tp: 130.0000 - fp: 214.0000 - tn: 230.0000 - fn: 138.0000 - accuracy: 0.5056 - precision: 0.3779 - recall: 0.4851 - auc: 0.4977 - val_loss: 2.0583 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 391/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.0573 - tp: 132.0000 - fp: 205.0000 - tn: 239.0000 - fn: 136.0000 - accuracy: 0.5211 - precision: 0.3917 - recall: 0.4925 - auc: 0.5063 - val_loss: 2.0579 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 392/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0620 - tp: 125.0000 - fp: 221.0000 - tn: 223.0000 - fn: 143.0000 - accuracy: 0.4888 - precision: 0.3613 - recall: 0.4664 - auc: 0.4864 - val_loss: 2.0575 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5338\n",
      "Epoch 393/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 2.0577 - tp: 139.0000 - fp: 229.0000 - tn: 215.0000 - fn: 129.0000 - accuracy: 0.4972 - precision: 0.3777 - recall: 0.5187 - auc: 0.5101 - val_loss: 2.0571 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5743\n",
      "Epoch 394/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0432 - tp: 145.0000 - fp: 197.0000 - tn: 247.0000 - fn: 123.0000 - accuracy: 0.5506 - precision: 0.4240 - recall: 0.5410 - auc: 0.5520 - val_loss: 2.0567 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6797\n",
      "Epoch 395/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0498 - tp: 124.0000 - fp: 198.0000 - tn: 246.0000 - fn: 144.0000 - accuracy: 0.5197 - precision: 0.3851 - recall: 0.4627 - auc: 0.5166 - val_loss: 2.0562 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7036\n",
      "Epoch 396/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 2.0652 - tp: 111.0000 - fp: 223.0000 - tn: 221.0000 - fn: 157.0000 - accuracy: 0.4663 - precision: 0.3323 - recall: 0.4142 - auc: 0.4649 - val_loss: 2.0558 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7168\n",
      "Epoch 397/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0505 - tp: 136.0000 - fp: 216.0000 - tn: 228.0000 - fn: 132.0000 - accuracy: 0.5112 - precision: 0.3864 - recall: 0.5075 - auc: 0.5091 - val_loss: 2.0555 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7120\n",
      "Epoch 398/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0471 - tp: 142.0000 - fp: 196.0000 - tn: 248.0000 - fn: 126.0000 - accuracy: 0.5478 - precision: 0.4201 - recall: 0.5299 - auc: 0.5411 - val_loss: 2.0552 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6952\n",
      "Epoch 399/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0644 - tp: 105.0000 - fp: 218.0000 - tn: 226.0000 - fn: 163.0000 - accuracy: 0.4649 - precision: 0.3251 - recall: 0.3918 - auc: 0.4546 - val_loss: 2.0548 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7242\n",
      "Epoch 400/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.0574 - tp: 128.0000 - fp: 205.0000 - tn: 239.0000 - fn: 140.0000 - accuracy: 0.5154 - precision: 0.3844 - recall: 0.4776 - auc: 0.5003 - val_loss: 2.0544 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7019\n",
      "Epoch 401/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0597 - tp: 123.0000 - fp: 209.0000 - tn: 235.0000 - fn: 145.0000 - accuracy: 0.5028 - precision: 0.3705 - recall: 0.4590 - auc: 0.4892 - val_loss: 2.0540 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7242\n",
      "Epoch 402/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0552 - tp: 127.0000 - fp: 208.0000 - tn: 236.0000 - fn: 141.0000 - accuracy: 0.5098 - precision: 0.3791 - recall: 0.4739 - auc: 0.4974 - val_loss: 2.0537 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7036\n",
      "Epoch 403/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0385 - tp: 145.0000 - fp: 193.0000 - tn: 251.0000 - fn: 123.0000 - accuracy: 0.5562 - precision: 0.4290 - recall: 0.5410 - auc: 0.5552 - val_loss: 2.0533 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7019\n",
      "Epoch 404/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0546 - tp: 136.0000 - fp: 207.0000 - tn: 237.0000 - fn: 132.0000 - accuracy: 0.5239 - precision: 0.3965 - recall: 0.5075 - auc: 0.4981 - val_loss: 2.0530 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6817\n",
      "Epoch 405/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 2.0528 - tp: 133.0000 - fp: 206.0000 - tn: 238.0000 - fn: 135.0000 - accuracy: 0.5211 - precision: 0.3923 - recall: 0.4963 - auc: 0.5053 - val_loss: 2.0526 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7019\n",
      "Epoch 406/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 2.0594 - tp: 113.0000 - fp: 223.0000 - tn: 221.0000 - fn: 155.0000 - accuracy: 0.4691 - precision: 0.3363 - recall: 0.4216 - auc: 0.4775 - val_loss: 2.0522 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6662\n",
      "Epoch 407/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0551 - tp: 120.0000 - fp: 187.0000 - tn: 257.0000 - fn: 148.0000 - accuracy: 0.5295 - precision: 0.3909 - recall: 0.4478 - auc: 0.4997 - val_loss: 2.0518 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7290\n",
      "Epoch 408/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0663 - tp: 112.0000 - fp: 220.0000 - tn: 224.0000 - fn: 156.0000 - accuracy: 0.4719 - precision: 0.3373 - recall: 0.4179 - auc: 0.4590 - val_loss: 2.0514 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7386\n",
      "Epoch 409/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0481 - tp: 129.0000 - fp: 215.0000 - tn: 229.0000 - fn: 139.0000 - accuracy: 0.5028 - precision: 0.3750 - recall: 0.4813 - auc: 0.5088 - val_loss: 2.0509 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6479\n",
      "Epoch 410/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0539 - tp: 128.0000 - fp: 209.0000 - tn: 235.0000 - fn: 140.0000 - accuracy: 0.5098 - precision: 0.3798 - recall: 0.4776 - auc: 0.4981 - val_loss: 2.0506 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6245\n",
      "Epoch 411/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0440 - tp: 132.0000 - fp: 209.0000 - tn: 235.0000 - fn: 136.0000 - accuracy: 0.5154 - precision: 0.3871 - recall: 0.4925 - auc: 0.5203 - val_loss: 2.0502 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6304\n",
      "Epoch 412/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 2.0469 - tp: 133.0000 - fp: 219.0000 - tn: 225.0000 - fn: 135.0000 - accuracy: 0.5028 - precision: 0.3778 - recall: 0.4963 - auc: 0.5122 - val_loss: 2.0498 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6149\n",
      "Epoch 413/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 2.0542 - tp: 129.0000 - fp: 220.0000 - tn: 224.0000 - fn: 139.0000 - accuracy: 0.4958 - precision: 0.3696 - recall: 0.4813 - auc: 0.4903 - val_loss: 2.0494 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6479\n",
      "Epoch 414/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.0505 - tp: 130.0000 - fp: 218.0000 - tn: 226.0000 - fn: 138.0000 - accuracy: 0.5000 - precision: 0.3736 - recall: 0.4851 - auc: 0.4976 - val_loss: 2.0491 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6459\n",
      "Epoch 415/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.0441 - tp: 131.0000 - fp: 204.0000 - tn: 240.0000 - fn: 137.0000 - accuracy: 0.5211 - precision: 0.3910 - recall: 0.4888 - auc: 0.5118 - val_loss: 2.0487 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6304\n",
      "Epoch 416/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.0442 - tp: 136.0000 - fp: 200.0000 - tn: 244.0000 - fn: 132.0000 - accuracy: 0.5337 - precision: 0.4048 - recall: 0.5075 - auc: 0.5237 - val_loss: 2.0484 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6954\n",
      "Epoch 417/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0503 - tp: 128.0000 - fp: 212.0000 - tn: 232.0000 - fn: 140.0000 - accuracy: 0.5056 - precision: 0.3765 - recall: 0.4776 - auc: 0.4875 - val_loss: 2.0480 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6867\n",
      "Epoch 418/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0591 - tp: 117.0000 - fp: 214.0000 - tn: 230.0000 - fn: 151.0000 - accuracy: 0.4874 - precision: 0.3535 - recall: 0.4366 - auc: 0.4709 - val_loss: 2.0476 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7153\n",
      "Epoch 419/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.0485 - tp: 136.0000 - fp: 206.0000 - tn: 238.0000 - fn: 132.0000 - accuracy: 0.5253 - precision: 0.3977 - recall: 0.5075 - auc: 0.5067 - val_loss: 2.0472 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6304\n",
      "Epoch 420/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0435 - tp: 124.0000 - fp: 189.0000 - tn: 255.0000 - fn: 144.0000 - accuracy: 0.5323 - precision: 0.3962 - recall: 0.4627 - auc: 0.5170 - val_loss: 2.0469 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6914\n",
      "Epoch 421/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0398 - tp: 124.0000 - fp: 199.0000 - tn: 245.0000 - fn: 144.0000 - accuracy: 0.5183 - precision: 0.3839 - recall: 0.4627 - auc: 0.5152 - val_loss: 2.0465 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6372\n",
      "Epoch 422/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0481 - tp: 115.0000 - fp: 214.0000 - tn: 230.0000 - fn: 153.0000 - accuracy: 0.4846 - precision: 0.3495 - recall: 0.4291 - auc: 0.4905 - val_loss: 2.0461 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6914\n",
      "Epoch 423/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0432 - tp: 133.0000 - fp: 220.0000 - tn: 224.0000 - fn: 135.0000 - accuracy: 0.5014 - precision: 0.3768 - recall: 0.4963 - auc: 0.5086 - val_loss: 2.0458 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7085\n",
      "Epoch 424/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0454 - tp: 132.0000 - fp: 211.0000 - tn: 233.0000 - fn: 136.0000 - accuracy: 0.5126 - precision: 0.3848 - recall: 0.4925 - auc: 0.5113 - val_loss: 2.0454 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7180\n",
      "Epoch 425/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0332 - tp: 140.0000 - fp: 192.0000 - tn: 252.0000 - fn: 128.0000 - accuracy: 0.5506 - precision: 0.4217 - recall: 0.5224 - auc: 0.5460 - val_loss: 2.0451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7501\n",
      "Epoch 426/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.0362 - tp: 144.0000 - fp: 206.0000 - tn: 238.0000 - fn: 124.0000 - accuracy: 0.5365 - precision: 0.4114 - recall: 0.5373 - auc: 0.5364 - val_loss: 2.0447 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7168\n",
      "Epoch 427/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0458 - tp: 132.0000 - fp: 201.0000 - tn: 243.0000 - fn: 136.0000 - accuracy: 0.5267 - precision: 0.3964 - recall: 0.4925 - auc: 0.5101 - val_loss: 2.0444 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7346\n",
      "Epoch 428/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0447 - tp: 120.0000 - fp: 212.0000 - tn: 232.0000 - fn: 148.0000 - accuracy: 0.4944 - precision: 0.3614 - recall: 0.4478 - auc: 0.4917 - val_loss: 2.0440 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7275\n",
      "Epoch 429/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 2.0287 - tp: 135.0000 - fp: 190.0000 - tn: 254.0000 - fn: 133.0000 - accuracy: 0.5463 - precision: 0.4154 - recall: 0.5037 - auc: 0.5532 - val_loss: 2.0436 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7275\n",
      "Epoch 430/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0481 - tp: 126.0000 - fp: 217.0000 - tn: 227.0000 - fn: 142.0000 - accuracy: 0.4958 - precision: 0.3673 - recall: 0.4701 - auc: 0.4846 - val_loss: 2.0432 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7168\n",
      "Epoch 431/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0410 - tp: 126.0000 - fp: 219.0000 - tn: 225.0000 - fn: 142.0000 - accuracy: 0.4930 - precision: 0.3652 - recall: 0.4701 - auc: 0.5038 - val_loss: 2.0428 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7085\n",
      "Epoch 432/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 2.0389 - tp: 133.0000 - fp: 213.0000 - tn: 231.0000 - fn: 135.0000 - accuracy: 0.5112 - precision: 0.3844 - recall: 0.4963 - auc: 0.5142 - val_loss: 2.0424 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6042\n",
      "Epoch 433/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0354 - tp: 140.0000 - fp: 206.0000 - tn: 238.0000 - fn: 128.0000 - accuracy: 0.5309 - precision: 0.4046 - recall: 0.5224 - auc: 0.5253 - val_loss: 2.0422 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7144\n",
      "Epoch 434/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0464 - tp: 131.0000 - fp: 221.0000 - tn: 223.0000 - fn: 137.0000 - accuracy: 0.4972 - precision: 0.3722 - recall: 0.4888 - auc: 0.4883 - val_loss: 2.0418 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7019\n",
      "Epoch 435/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0482 - tp: 120.0000 - fp: 204.0000 - tn: 240.0000 - fn: 148.0000 - accuracy: 0.5056 - precision: 0.3704 - recall: 0.4478 - auc: 0.4767 - val_loss: 2.0415 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6797\n",
      "Epoch 436/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 2.0410 - tp: 131.0000 - fp: 211.0000 - tn: 233.0000 - fn: 137.0000 - accuracy: 0.5112 - precision: 0.3830 - recall: 0.4888 - auc: 0.5026 - val_loss: 2.0411 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6952\n",
      "Epoch 437/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0338 - tp: 130.0000 - fp: 215.0000 - tn: 229.0000 - fn: 138.0000 - accuracy: 0.5042 - precision: 0.3768 - recall: 0.4851 - auc: 0.5138 - val_loss: 2.0408 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831\n",
      "Epoch 438/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.0417 - tp: 128.0000 - fp: 222.0000 - tn: 222.0000 - fn: 140.0000 - accuracy: 0.4916 - precision: 0.3657 - recall: 0.4776 - auc: 0.5010 - val_loss: 2.0404 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6439\n",
      "Epoch 439/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0469 - tp: 109.0000 - fp: 197.0000 - tn: 247.0000 - fn: 159.0000 - accuracy: 0.5000 - precision: 0.3562 - recall: 0.4067 - auc: 0.4789 - val_loss: 2.0400 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7349\n",
      "Epoch 440/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0419 - tp: 132.0000 - fp: 221.0000 - tn: 223.0000 - fn: 136.0000 - accuracy: 0.4986 - precision: 0.3739 - recall: 0.4925 - auc: 0.5018 - val_loss: 2.0396 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7222\n",
      "Epoch 441/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0553 - tp: 100.0000 - fp: 216.0000 - tn: 228.0000 - fn: 168.0000 - accuracy: 0.4607 - precision: 0.3165 - recall: 0.3731 - auc: 0.4376 - val_loss: 2.0392 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7144\n",
      "Epoch 442/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0354 - tp: 126.0000 - fp: 209.0000 - tn: 235.0000 - fn: 142.0000 - accuracy: 0.5070 - precision: 0.3761 - recall: 0.4701 - auc: 0.5116 - val_loss: 2.0388 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7180\n",
      "Epoch 443/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0387 - tp: 125.0000 - fp: 207.0000 - tn: 237.0000 - fn: 143.0000 - accuracy: 0.5084 - precision: 0.3765 - recall: 0.4664 - auc: 0.4994 - val_loss: 2.0384 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7168\n",
      "Epoch 444/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0401 - tp: 112.0000 - fp: 192.0000 - tn: 252.0000 - fn: 156.0000 - accuracy: 0.5112 - precision: 0.3684 - recall: 0.4179 - auc: 0.4983 - val_loss: 2.0380 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7057\n",
      "Epoch 445/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0359 - tp: 113.0000 - fp: 204.0000 - tn: 240.0000 - fn: 155.0000 - accuracy: 0.4958 - precision: 0.3565 - recall: 0.4216 - auc: 0.4897 - val_loss: 2.0377 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7279\n",
      "Epoch 446/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0305 - tp: 127.0000 - fp: 206.0000 - tn: 238.0000 - fn: 141.0000 - accuracy: 0.5126 - precision: 0.3814 - recall: 0.4739 - auc: 0.5213 - val_loss: 2.0374 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7016\n",
      "Epoch 447/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.0354 - tp: 137.0000 - fp: 207.0000 - tn: 237.0000 - fn: 131.0000 - accuracy: 0.5253 - precision: 0.3983 - recall: 0.5112 - auc: 0.5191 - val_loss: 2.0371 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6777\n",
      "Epoch 448/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 2.0513 - tp: 118.0000 - fp: 226.0000 - tn: 218.0000 - fn: 150.0000 - accuracy: 0.4719 - precision: 0.3430 - recall: 0.4403 - auc: 0.4543 - val_loss: 2.0367 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6729\n",
      "Epoch 449/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 2.0442 - tp: 121.0000 - fp: 215.0000 - tn: 229.0000 - fn: 147.0000 - accuracy: 0.4916 - precision: 0.3601 - recall: 0.4515 - auc: 0.4742 - val_loss: 2.0363 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6729\n",
      "Epoch 450/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.0246 - tp: 141.0000 - fp: 194.0000 - tn: 250.0000 - fn: 127.0000 - accuracy: 0.5492 - precision: 0.4209 - recall: 0.5261 - auc: 0.5418 - val_loss: 2.0360 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831\n",
      "Epoch 451/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.0513 - tp: 121.0000 - fp: 217.0000 - tn: 227.0000 - fn: 147.0000 - accuracy: 0.4888 - precision: 0.3580 - recall: 0.4515 - auc: 0.4577 - val_loss: 2.0356 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6371\n",
      "Epoch 452/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.0153 - tp: 132.0000 - fp: 185.0000 - tn: 259.0000 - fn: 136.0000 - accuracy: 0.5492 - precision: 0.4164 - recall: 0.4925 - auc: 0.5596 - val_loss: 2.0352 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6729\n",
      "Epoch 453/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 2.0414 - tp: 111.0000 - fp: 207.0000 - tn: 237.0000 - fn: 157.0000 - accuracy: 0.4888 - precision: 0.3491 - recall: 0.4142 - auc: 0.4666 - val_loss: 2.0348 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7329\n",
      "Epoch 454/600\n",
      "712/712 [==============================] - 3s 4ms/sample - loss: 2.0697 - tp: 243.0000 - fp: 416.0000 - tn: 28.0000 - fn: 25.0000 - accuracy: 0.3806 - precision: 0.3687 - recall: 0.9067 - auc: 0.4122 - val_loss: 1.9797 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.2005\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 2.0130 - tp: 219.0000 - fp: 396.0000 - tn: 48.0000 - fn: 49.0000 - accuracy: 0.3750 - precision: 0.3561 - recall: 0.8172 - auc: 0.4151 - val_loss: 1.9339 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.2106\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.9700 - tp: 203.0000 - fp: 381.0000 - tn: 63.0000 - fn: 65.0000 - accuracy: 0.3736 - precision: 0.3476 - recall: 0.7575 - auc: 0.4205 - val_loss: 1.9004 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.2171\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.9230 - tp: 197.0000 - fp: 345.0000 - tn: 99.0000 - fn: 71.0000 - accuracy: 0.4157 - precision: 0.3635 - recall: 0.7351 - auc: 0.4354 - val_loss: 1.8760 - val_tp: 69.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 5.0000 - val_accuracy: 0.3855 - val_precision: 0.3966 - val_recall: 0.9324 - val_auc: 0.2231\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 1.8818 - tp: 184.0000 - fp: 320.0000 - tn: 124.0000 - fn: 84.0000 - accuracy: 0.4326 - precision: 0.3651 - recall: 0.6866 - auc: 0.4698 - val_loss: 1.8548 - val_tp: 47.0000 - val_fp: 95.0000 - val_tn: 10.0000 - val_fn: 27.0000 - val_accuracy: 0.3184 - val_precision: 0.3310 - val_recall: 0.6351 - val_auc: 0.2400\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.8699 - tp: 144.0000 - fp: 272.0000 - tn: 172.0000 - fn: 124.0000 - accuracy: 0.4438 - precision: 0.3462 - recall: 0.5373 - auc: 0.4571 - val_loss: 1.8360 - val_tp: 33.0000 - val_fp: 86.0000 - val_tn: 19.0000 - val_fn: 41.0000 - val_accuracy: 0.2905 - val_precision: 0.2773 - val_recall: 0.4459 - val_auc: 0.2541\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.8569 - tp: 143.0000 - fp: 285.0000 - tn: 159.0000 - fn: 125.0000 - accuracy: 0.4242 - precision: 0.3341 - recall: 0.5336 - auc: 0.4327 - val_loss: 1.8181 - val_tp: 18.0000 - val_fp: 71.0000 - val_tn: 34.0000 - val_fn: 56.0000 - val_accuracy: 0.2905 - val_precision: 0.2022 - val_recall: 0.2432 - val_auc: 0.2820\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.8262 - tp: 158.0000 - fp: 274.0000 - tn: 170.0000 - fn: 110.0000 - accuracy: 0.4607 - precision: 0.3657 - recall: 0.5896 - auc: 0.4594 - val_loss: 1.8001 - val_tp: 12.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 62.0000 - val_accuracy: 0.4749 - val_precision: 0.2727 - val_recall: 0.1622 - val_auc: 0.2979\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.7855 - tp: 149.0000 - fp: 256.0000 - tn: 188.0000 - fn: 119.0000 - accuracy: 0.4733 - precision: 0.3679 - recall: 0.5560 - auc: 0.5074 - val_loss: 1.7839 - val_tp: 7.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 67.0000 - val_accuracy: 0.5419 - val_precision: 0.3182 - val_recall: 0.0946 - val_auc: 0.3109\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.7928 - tp: 127.0000 - fp: 246.0000 - tn: 198.0000 - fn: 141.0000 - accuracy: 0.4565 - precision: 0.3405 - recall: 0.4739 - auc: 0.4604 - val_loss: 1.7679 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 72.0000 - val_accuracy: 0.5363 - val_precision: 0.1538 - val_recall: 0.0270 - val_auc: 0.3277\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.7626 - tp: 132.0000 - fp: 239.0000 - tn: 205.0000 - fn: 136.0000 - accuracy: 0.4733 - precision: 0.3558 - recall: 0.4925 - auc: 0.4840 - val_loss: 1.7517 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 73.0000 - val_accuracy: 0.5531 - val_precision: 0.1250 - val_recall: 0.0135 - val_auc: 0.3678\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.7448 - tp: 136.0000 - fp: 216.0000 - tn: 228.0000 - fn: 132.0000 - accuracy: 0.5112 - precision: 0.3864 - recall: 0.5075 - auc: 0.4887 - val_loss: 1.7354 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 73.0000 - val_accuracy: 0.5531 - val_precision: 0.1250 - val_recall: 0.0135 - val_auc: 0.3892\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.7558 - tp: 108.0000 - fp: 225.0000 - tn: 219.0000 - fn: 160.0000 - accuracy: 0.4593 - precision: 0.3243 - recall: 0.4030 - auc: 0.4185 - val_loss: 1.7184 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 73.0000 - val_accuracy: 0.5531 - val_precision: 0.1250 - val_recall: 0.0135 - val_auc: 0.4272\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.7143 - tp: 127.0000 - fp: 217.0000 - tn: 227.0000 - fn: 141.0000 - accuracy: 0.4972 - precision: 0.3692 - recall: 0.4739 - auc: 0.4851 - val_loss: 1.7014 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 73.0000 - val_accuracy: 0.5531 - val_precision: 0.1250 - val_recall: 0.0135 - val_auc: 0.4754\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.6976 - tp: 121.0000 - fp: 191.0000 - tn: 253.0000 - fn: 147.0000 - accuracy: 0.5253 - precision: 0.3878 - recall: 0.4515 - auc: 0.4991 - val_loss: 1.6856 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 73.0000 - val_accuracy: 0.5531 - val_precision: 0.1250 - val_recall: 0.0135 - val_auc: 0.4851\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 1.6820 - tp: 113.0000 - fp: 205.0000 - tn: 239.0000 - fn: 155.0000 - accuracy: 0.4944 - precision: 0.3553 - recall: 0.4216 - auc: 0.4881 - val_loss: 1.6686 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 73.0000 - val_accuracy: 0.5531 - val_precision: 0.1250 - val_recall: 0.0135 - val_auc: 0.5210\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.6697 - tp: 122.0000 - fp: 207.0000 - tn: 237.0000 - fn: 146.0000 - accuracy: 0.5042 - precision: 0.3708 - recall: 0.4552 - auc: 0.4860 - val_loss: 1.6529 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 73.0000 - val_accuracy: 0.5531 - val_precision: 0.1250 - val_recall: 0.0135 - val_auc: 0.5553\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.6533 - tp: 108.0000 - fp: 189.0000 - tn: 255.0000 - fn: 160.0000 - accuracy: 0.5098 - precision: 0.3636 - recall: 0.4030 - auc: 0.4940 - val_loss: 1.6358 - val_tp: 2.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 72.0000 - val_accuracy: 0.5587 - val_precision: 0.2222 - val_recall: 0.0270 - val_auc: 0.5960\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.6459 - tp: 120.0000 - fp: 207.0000 - tn: 237.0000 - fn: 148.0000 - accuracy: 0.5014 - precision: 0.3670 - recall: 0.4478 - auc: 0.4703 - val_loss: 1.6189 - val_tp: 2.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 72.0000 - val_accuracy: 0.5587 - val_precision: 0.2222 - val_recall: 0.0270 - val_auc: 0.5981\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.6157 - tp: 116.0000 - fp: 213.0000 - tn: 231.0000 - fn: 152.0000 - accuracy: 0.4874 - precision: 0.3526 - recall: 0.4328 - auc: 0.4998 - val_loss: 1.6021 - val_tp: 3.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 71.0000 - val_accuracy: 0.5587 - val_precision: 0.2727 - val_recall: 0.0405 - val_auc: 0.6339\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.5899 - tp: 119.0000 - fp: 180.0000 - tn: 264.0000 - fn: 149.0000 - accuracy: 0.5379 - precision: 0.3980 - recall: 0.4440 - auc: 0.5344 - val_loss: 1.5867 - val_tp: 3.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 71.0000 - val_accuracy: 0.5642 - val_precision: 0.3000 - val_recall: 0.0405 - val_auc: 0.6519\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.5761 - tp: 133.0000 - fp: 188.0000 - tn: 256.0000 - fn: 135.0000 - accuracy: 0.5463 - precision: 0.4143 - recall: 0.4963 - auc: 0.5287 - val_loss: 1.5699 - val_tp: 3.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 71.0000 - val_accuracy: 0.5531 - val_precision: 0.2500 - val_recall: 0.0405 - val_auc: 0.6641\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.5735 - tp: 123.0000 - fp: 195.0000 - tn: 249.0000 - fn: 145.0000 - accuracy: 0.5225 - precision: 0.3868 - recall: 0.4590 - auc: 0.5000 - val_loss: 1.5540 - val_tp: 3.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 71.0000 - val_accuracy: 0.5531 - val_precision: 0.2500 - val_recall: 0.0405 - val_auc: 0.6747\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.5539 - tp: 125.0000 - fp: 196.0000 - tn: 248.0000 - fn: 143.0000 - accuracy: 0.5239 - precision: 0.3894 - recall: 0.4664 - auc: 0.5093 - val_loss: 1.5386 - val_tp: 4.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 70.0000 - val_accuracy: 0.5587 - val_precision: 0.3077 - val_recall: 0.0541 - val_auc: 0.6824\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.5407 - tp: 110.0000 - fp: 197.0000 - tn: 247.0000 - fn: 158.0000 - accuracy: 0.5014 - precision: 0.3583 - recall: 0.4104 - auc: 0.5059 - val_loss: 1.5237 - val_tp: 3.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 71.0000 - val_accuracy: 0.5587 - val_precision: 0.2727 - val_recall: 0.0405 - val_auc: 0.6941\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.5346 - tp: 105.0000 - fp: 180.0000 - tn: 264.0000 - fn: 163.0000 - accuracy: 0.5183 - precision: 0.3684 - recall: 0.3918 - auc: 0.4897 - val_loss: 1.5084 - val_tp: 4.0000 - val_fp: 7.0000 - val_tn: 98.0000 - val_fn: 70.0000 - val_accuracy: 0.5698 - val_precision: 0.3636 - val_recall: 0.0541 - val_auc: 0.7006\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 1.4998 - tp: 110.0000 - fp: 173.0000 - tn: 271.0000 - fn: 158.0000 - accuracy: 0.5351 - precision: 0.3887 - recall: 0.4104 - auc: 0.5365 - val_loss: 1.4925 - val_tp: 4.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 70.0000 - val_accuracy: 0.5587 - val_precision: 0.3077 - val_recall: 0.0541 - val_auc: 0.7176\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.4983 - tp: 114.0000 - fp: 199.0000 - tn: 245.0000 - fn: 154.0000 - accuracy: 0.5042 - precision: 0.3642 - recall: 0.4254 - auc: 0.4993 - val_loss: 1.4768 - val_tp: 6.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 68.0000 - val_accuracy: 0.5642 - val_precision: 0.3750 - val_recall: 0.0811 - val_auc: 0.7241\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.4746 - tp: 127.0000 - fp: 202.0000 - tn: 242.0000 - fn: 141.0000 - accuracy: 0.5183 - precision: 0.3860 - recall: 0.4739 - auc: 0.5212 - val_loss: 1.4614 - val_tp: 10.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 64.0000 - val_accuracy: 0.5810 - val_precision: 0.4762 - val_recall: 0.1351 - val_auc: 0.7225\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.4709 - tp: 106.0000 - fp: 177.0000 - tn: 267.0000 - fn: 162.0000 - accuracy: 0.5239 - precision: 0.3746 - recall: 0.3955 - auc: 0.5053 - val_loss: 1.4475 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 65.0000 - val_accuracy: 0.5810 - val_precision: 0.4737 - val_recall: 0.1216 - val_auc: 0.7324\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.4504 - tp: 122.0000 - fp: 194.0000 - tn: 250.0000 - fn: 146.0000 - accuracy: 0.5225 - precision: 0.3861 - recall: 0.4552 - auc: 0.5234 - val_loss: 1.4333 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 65.0000 - val_accuracy: 0.5810 - val_precision: 0.4737 - val_recall: 0.1216 - val_auc: 0.7414\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 1.4332 - tp: 131.0000 - fp: 195.0000 - tn: 249.0000 - fn: 137.0000 - accuracy: 0.5337 - precision: 0.4018 - recall: 0.4888 - auc: 0.5229 - val_loss: 1.4184 - val_tp: 13.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 61.0000 - val_accuracy: 0.6034 - val_precision: 0.5652 - val_recall: 0.1757 - val_auc: 0.7389\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 1.4187 - tp: 119.0000 - fp: 187.0000 - tn: 257.0000 - fn: 149.0000 - accuracy: 0.5281 - precision: 0.3889 - recall: 0.4440 - auc: 0.5287 - val_loss: 1.4043 - val_tp: 13.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 61.0000 - val_accuracy: 0.6034 - val_precision: 0.5652 - val_recall: 0.1757 - val_auc: 0.7499\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.4169 - tp: 117.0000 - fp: 191.0000 - tn: 253.0000 - fn: 151.0000 - accuracy: 0.5197 - precision: 0.3799 - recall: 0.4366 - auc: 0.4987 - val_loss: 1.3913 - val_tp: 10.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 64.0000 - val_accuracy: 0.5978 - val_precision: 0.5556 - val_recall: 0.1351 - val_auc: 0.7524\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.3952 - tp: 113.0000 - fp: 189.0000 - tn: 255.0000 - fn: 155.0000 - accuracy: 0.5169 - precision: 0.3742 - recall: 0.4216 - auc: 0.5062 - val_loss: 1.3777 - val_tp: 10.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 64.0000 - val_accuracy: 0.5978 - val_precision: 0.5556 - val_recall: 0.1351 - val_auc: 0.7612\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 1.3844 - tp: 114.0000 - fp: 175.0000 - tn: 269.0000 - fn: 154.0000 - accuracy: 0.5379 - precision: 0.3945 - recall: 0.4254 - auc: 0.5136 - val_loss: 1.3625 - val_tp: 15.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 59.0000 - val_accuracy: 0.6145 - val_precision: 0.6000 - val_recall: 0.2027 - val_auc: 0.7638\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.3548 - tp: 121.0000 - fp: 167.0000 - tn: 277.0000 - fn: 147.0000 - accuracy: 0.5590 - precision: 0.4201 - recall: 0.4515 - auc: 0.5505 - val_loss: 1.3484 - val_tp: 15.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 59.0000 - val_accuracy: 0.6145 - val_precision: 0.6000 - val_recall: 0.2027 - val_auc: 0.7700\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 1.3434 - tp: 113.0000 - fp: 164.0000 - tn: 280.0000 - fn: 155.0000 - accuracy: 0.5520 - precision: 0.4079 - recall: 0.4216 - auc: 0.5498 - val_loss: 1.3349 - val_tp: 15.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 59.0000 - val_accuracy: 0.6145 - val_precision: 0.6000 - val_recall: 0.2027 - val_auc: 0.7741\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.3337 - tp: 112.0000 - fp: 171.0000 - tn: 273.0000 - fn: 156.0000 - accuracy: 0.5407 - precision: 0.3958 - recall: 0.4179 - auc: 0.5319 - val_loss: 1.3211 - val_tp: 16.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 58.0000 - val_accuracy: 0.6313 - val_precision: 0.6667 - val_recall: 0.2162 - val_auc: 0.7819\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.3207 - tp: 129.0000 - fp: 175.0000 - tn: 269.0000 - fn: 139.0000 - accuracy: 0.5590 - precision: 0.4243 - recall: 0.4813 - auc: 0.5435 - val_loss: 1.3068 - val_tp: 23.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 51.0000 - val_accuracy: 0.6536 - val_precision: 0.6765 - val_recall: 0.3108 - val_auc: 0.7844\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.3052 - tp: 134.0000 - fp: 179.0000 - tn: 265.0000 - fn: 134.0000 - accuracy: 0.5604 - precision: 0.4281 - recall: 0.5000 - auc: 0.5579 - val_loss: 1.2931 - val_tp: 24.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 50.0000 - val_accuracy: 0.6592 - val_precision: 0.6857 - val_recall: 0.3243 - val_auc: 0.7844\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 1.3074 - tp: 119.0000 - fp: 181.0000 - tn: 263.0000 - fn: 149.0000 - accuracy: 0.5365 - precision: 0.3967 - recall: 0.4440 - auc: 0.5129 - val_loss: 1.2794 - val_tp: 29.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 45.0000 - val_accuracy: 0.6704 - val_precision: 0.6744 - val_recall: 0.3919 - val_auc: 0.7875\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.2926 - tp: 123.0000 - fp: 183.0000 - tn: 261.0000 - fn: 145.0000 - accuracy: 0.5393 - precision: 0.4020 - recall: 0.4590 - auc: 0.5224 - val_loss: 1.2672 - val_tp: 26.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 48.0000 - val_accuracy: 0.6816 - val_precision: 0.7429 - val_recall: 0.3514 - val_auc: 0.7851\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 1.2708 - tp: 109.0000 - fp: 156.0000 - tn: 288.0000 - fn: 159.0000 - accuracy: 0.5576 - precision: 0.4113 - recall: 0.4067 - auc: 0.5457 - val_loss: 1.2552 - val_tp: 26.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 48.0000 - val_accuracy: 0.6872 - val_precision: 0.7647 - val_recall: 0.3514 - val_auc: 0.7898\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.2501 - tp: 117.0000 - fp: 151.0000 - tn: 293.0000 - fn: 151.0000 - accuracy: 0.5758 - precision: 0.4366 - recall: 0.4366 - auc: 0.5762 - val_loss: 1.2426 - val_tp: 29.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 45.0000 - val_accuracy: 0.6816 - val_precision: 0.7073 - val_recall: 0.3919 - val_auc: 0.7900\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.2335 - tp: 127.0000 - fp: 145.0000 - tn: 299.0000 - fn: 141.0000 - accuracy: 0.5983 - precision: 0.4669 - recall: 0.4739 - auc: 0.5942 - val_loss: 1.2299 - val_tp: 30.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 44.0000 - val_accuracy: 0.6648 - val_precision: 0.6522 - val_recall: 0.4054 - val_auc: 0.7893\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.2363 - tp: 115.0000 - fp: 162.0000 - tn: 282.0000 - fn: 153.0000 - accuracy: 0.5576 - precision: 0.4152 - recall: 0.4291 - auc: 0.5473 - val_loss: 1.2177 - val_tp: 32.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 42.0000 - val_accuracy: 0.6704 - val_precision: 0.6531 - val_recall: 0.4324 - val_auc: 0.7893\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.2130 - tp: 133.0000 - fp: 167.0000 - tn: 277.0000 - fn: 135.0000 - accuracy: 0.5758 - precision: 0.4433 - recall: 0.4963 - auc: 0.5815 - val_loss: 1.2056 - val_tp: 37.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 37.0000 - val_accuracy: 0.6760 - val_precision: 0.6379 - val_recall: 0.5000 - val_auc: 0.7882\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1997 - tp: 145.0000 - fp: 169.0000 - tn: 275.0000 - fn: 123.0000 - accuracy: 0.5899 - precision: 0.4618 - recall: 0.5410 - auc: 0.5864 - val_loss: 1.1940 - val_tp: 36.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 38.0000 - val_accuracy: 0.6760 - val_precision: 0.6429 - val_recall: 0.4865 - val_auc: 0.7929\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1953 - tp: 126.0000 - fp: 175.0000 - tn: 269.0000 - fn: 142.0000 - accuracy: 0.5548 - precision: 0.4186 - recall: 0.4701 - auc: 0.5669 - val_loss: 1.1824 - val_tp: 34.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 40.0000 - val_accuracy: 0.6760 - val_precision: 0.6538 - val_recall: 0.4595 - val_auc: 0.7900\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.1858 - tp: 119.0000 - fp: 162.0000 - tn: 282.0000 - fn: 149.0000 - accuracy: 0.5632 - precision: 0.4235 - recall: 0.4440 - auc: 0.5598 - val_loss: 1.1704 - val_tp: 35.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 39.0000 - val_accuracy: 0.6704 - val_precision: 0.6364 - val_recall: 0.4730 - val_auc: 0.7973\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1628 - tp: 136.0000 - fp: 173.0000 - tn: 271.0000 - fn: 132.0000 - accuracy: 0.5716 - precision: 0.4401 - recall: 0.5075 - auc: 0.5919 - val_loss: 1.1589 - val_tp: 35.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 39.0000 - val_accuracy: 0.6704 - val_precision: 0.6364 - val_recall: 0.4730 - val_auc: 0.7911\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1577 - tp: 134.0000 - fp: 178.0000 - tn: 266.0000 - fn: 134.0000 - accuracy: 0.5618 - precision: 0.4295 - recall: 0.5000 - auc: 0.5780 - val_loss: 1.1481 - val_tp: 35.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 39.0000 - val_accuracy: 0.6704 - val_precision: 0.6364 - val_recall: 0.4730 - val_auc: 0.7995\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.1521 - tp: 133.0000 - fp: 176.0000 - tn: 268.0000 - fn: 135.0000 - accuracy: 0.5632 - precision: 0.4304 - recall: 0.4963 - auc: 0.5670 - val_loss: 1.1373 - val_tp: 35.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 39.0000 - val_accuracy: 0.6704 - val_precision: 0.6364 - val_recall: 0.4730 - val_auc: 0.7961\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1336 - tp: 137.0000 - fp: 166.0000 - tn: 278.0000 - fn: 131.0000 - accuracy: 0.5829 - precision: 0.4521 - recall: 0.5112 - auc: 0.5905 - val_loss: 1.1268 - val_tp: 35.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 39.0000 - val_accuracy: 0.6872 - val_precision: 0.6731 - val_recall: 0.4730 - val_auc: 0.7958\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.1191 - tp: 142.0000 - fp: 161.0000 - tn: 283.0000 - fn: 126.0000 - accuracy: 0.5969 - precision: 0.4686 - recall: 0.5299 - auc: 0.6096 - val_loss: 1.1161 - val_tp: 34.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 40.0000 - val_accuracy: 0.6872 - val_precision: 0.6800 - val_recall: 0.4595 - val_auc: 0.8005\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.1219 - tp: 124.0000 - fp: 163.0000 - tn: 281.0000 - fn: 144.0000 - accuracy: 0.5688 - precision: 0.4321 - recall: 0.4627 - auc: 0.5640 - val_loss: 1.1055 - val_tp: 35.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 39.0000 - val_accuracy: 0.6872 - val_precision: 0.6731 - val_recall: 0.4730 - val_auc: 0.7950\n",
      "Epoch 58/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1078 - tp: 124.0000 - fp: 168.0000 - tn: 276.0000 - fn: 144.0000 - accuracy: 0.5618 - precision: 0.4247 - recall: 0.4627 - auc: 0.5656 - val_loss: 1.0954 - val_tp: 35.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 39.0000 - val_accuracy: 0.6927 - val_precision: 0.6863 - val_recall: 0.4730 - val_auc: 0.7988\n",
      "Epoch 59/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 1.1047 - tp: 115.0000 - fp: 179.0000 - tn: 265.0000 - fn: 153.0000 - accuracy: 0.5337 - precision: 0.3912 - recall: 0.4291 - auc: 0.5468 - val_loss: 1.0855 - val_tp: 35.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 39.0000 - val_accuracy: 0.6927 - val_precision: 0.6863 - val_recall: 0.4730 - val_auc: 0.7995\n",
      "Epoch 60/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.0834 - tp: 145.0000 - fp: 194.0000 - tn: 250.0000 - fn: 123.0000 - accuracy: 0.5548 - precision: 0.4277 - recall: 0.5410 - auc: 0.5797 - val_loss: 1.0757 - val_tp: 33.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 41.0000 - val_accuracy: 0.6983 - val_precision: 0.7174 - val_recall: 0.4459 - val_auc: 0.8030\n",
      "Epoch 61/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.0785 - tp: 131.0000 - fp: 179.0000 - tn: 265.0000 - fn: 137.0000 - accuracy: 0.5562 - precision: 0.4226 - recall: 0.4888 - auc: 0.5746 - val_loss: 1.0658 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8035\n",
      "Epoch 62/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.0731 - tp: 130.0000 - fp: 190.0000 - tn: 254.0000 - fn: 138.0000 - accuracy: 0.5393 - precision: 0.4062 - recall: 0.4851 - auc: 0.5576 - val_loss: 1.0567 - val_tp: 33.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 41.0000 - val_accuracy: 0.6983 - val_precision: 0.7174 - val_recall: 0.4459 - val_auc: 0.8018\n",
      "Epoch 63/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 1.0582 - tp: 127.0000 - fp: 157.0000 - tn: 287.0000 - fn: 141.0000 - accuracy: 0.5815 - precision: 0.4472 - recall: 0.4739 - auc: 0.5810 - val_loss: 1.0476 - val_tp: 32.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 42.0000 - val_accuracy: 0.6983 - val_precision: 0.7273 - val_recall: 0.4324 - val_auc: 0.8026\n",
      "Epoch 64/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.0540 - tp: 129.0000 - fp: 170.0000 - tn: 274.0000 - fn: 139.0000 - accuracy: 0.5660 - precision: 0.4314 - recall: 0.4813 - auc: 0.5723 - val_loss: 1.0391 - val_tp: 31.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 43.0000 - val_accuracy: 0.6983 - val_precision: 0.7381 - val_recall: 0.4189 - val_auc: 0.8053\n",
      "Epoch 65/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 1.0358 - tp: 143.0000 - fp: 179.0000 - tn: 265.0000 - fn: 125.0000 - accuracy: 0.5730 - precision: 0.4441 - recall: 0.5336 - auc: 0.5927 - val_loss: 1.0298 - val_tp: 32.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 42.0000 - val_accuracy: 0.7039 - val_precision: 0.7442 - val_recall: 0.4324 - val_auc: 0.8068\n",
      "Epoch 66/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.0314 - tp: 133.0000 - fp: 152.0000 - tn: 292.0000 - fn: 135.0000 - accuracy: 0.5969 - precision: 0.4667 - recall: 0.4963 - auc: 0.5897 - val_loss: 1.0203 - val_tp: 33.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 41.0000 - val_accuracy: 0.6983 - val_precision: 0.7174 - val_recall: 0.4459 - val_auc: 0.8029\n",
      "Epoch 67/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.0167 - tp: 134.0000 - fp: 154.0000 - tn: 290.0000 - fn: 134.0000 - accuracy: 0.5955 - precision: 0.4653 - recall: 0.5000 - auc: 0.6013 - val_loss: 1.0119 - val_tp: 32.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 42.0000 - val_accuracy: 0.7039 - val_precision: 0.7442 - val_recall: 0.4324 - val_auc: 0.8059\n",
      "Epoch 68/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.0218 - tp: 130.0000 - fp: 188.0000 - tn: 256.0000 - fn: 138.0000 - accuracy: 0.5421 - precision: 0.4088 - recall: 0.4851 - auc: 0.5560 - val_loss: 1.0036 - val_tp: 32.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 42.0000 - val_accuracy: 0.7039 - val_precision: 0.7442 - val_recall: 0.4324 - val_auc: 0.8073\n",
      "Epoch 69/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.0005 - tp: 124.0000 - fp: 175.0000 - tn: 269.0000 - fn: 144.0000 - accuracy: 0.5520 - precision: 0.4147 - recall: 0.4627 - auc: 0.5885 - val_loss: 0.9952 - val_tp: 32.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 42.0000 - val_accuracy: 0.7039 - val_precision: 0.7442 - val_recall: 0.4324 - val_auc: 0.8066\n",
      "Epoch 70/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.0020 - tp: 137.0000 - fp: 175.0000 - tn: 269.0000 - fn: 131.0000 - accuracy: 0.5702 - precision: 0.4391 - recall: 0.5112 - auc: 0.5667 - val_loss: 0.9863 - val_tp: 32.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 42.0000 - val_accuracy: 0.7039 - val_precision: 0.7442 - val_recall: 0.4324 - val_auc: 0.8073\n",
      "Epoch 71/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.9952 - tp: 133.0000 - fp: 179.0000 - tn: 265.0000 - fn: 135.0000 - accuracy: 0.5590 - precision: 0.4263 - recall: 0.4963 - auc: 0.5597 - val_loss: 0.9776 - val_tp: 32.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 42.0000 - val_accuracy: 0.7039 - val_precision: 0.7442 - val_recall: 0.4324 - val_auc: 0.8077\n",
      "Epoch 72/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.9656 - tp: 145.0000 - fp: 159.0000 - tn: 285.0000 - fn: 123.0000 - accuracy: 0.6039 - precision: 0.4770 - recall: 0.5410 - auc: 0.6272 - val_loss: 0.9694 - val_tp: 34.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 40.0000 - val_accuracy: 0.7039 - val_precision: 0.7234 - val_recall: 0.4595 - val_auc: 0.8073\n",
      "Epoch 73/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.9758 - tp: 140.0000 - fp: 183.0000 - tn: 261.0000 - fn: 128.0000 - accuracy: 0.5632 - precision: 0.4334 - recall: 0.5224 - auc: 0.5672 - val_loss: 0.9611 - val_tp: 34.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 40.0000 - val_accuracy: 0.7039 - val_precision: 0.7234 - val_recall: 0.4595 - val_auc: 0.8080\n",
      "Epoch 74/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.9566 - tp: 140.0000 - fp: 175.0000 - tn: 269.0000 - fn: 128.0000 - accuracy: 0.5744 - precision: 0.4444 - recall: 0.5224 - auc: 0.5953 - val_loss: 0.9530 - val_tp: 33.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 41.0000 - val_accuracy: 0.7095 - val_precision: 0.7500 - val_recall: 0.4459 - val_auc: 0.8053\n",
      "Epoch 75/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.9548 - tp: 134.0000 - fp: 166.0000 - tn: 278.0000 - fn: 134.0000 - accuracy: 0.5787 - precision: 0.4467 - recall: 0.5000 - auc: 0.5924 - val_loss: 0.9456 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8010\n",
      "Epoch 76/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.9484 - tp: 124.0000 - fp: 161.0000 - tn: 283.0000 - fn: 144.0000 - accuracy: 0.5716 - precision: 0.4351 - recall: 0.4627 - auc: 0.5825 - val_loss: 0.9385 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8067\n",
      "Epoch 77/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.9389 - tp: 137.0000 - fp: 155.0000 - tn: 289.0000 - fn: 131.0000 - accuracy: 0.5983 - precision: 0.4692 - recall: 0.5112 - auc: 0.5911 - val_loss: 0.9307 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8050\n",
      "Epoch 78/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.9373 - tp: 128.0000 - fp: 158.0000 - tn: 286.0000 - fn: 140.0000 - accuracy: 0.5815 - precision: 0.4476 - recall: 0.4776 - auc: 0.5768 - val_loss: 0.9233 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8061\n",
      "Epoch 79/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.9343 - tp: 134.0000 - fp: 171.0000 - tn: 273.0000 - fn: 134.0000 - accuracy: 0.5716 - precision: 0.4393 - recall: 0.5000 - auc: 0.5560 - val_loss: 0.9161 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8132\n",
      "Epoch 80/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.9177 - tp: 140.0000 - fp: 173.0000 - tn: 271.0000 - fn: 128.0000 - accuracy: 0.5772 - precision: 0.4473 - recall: 0.5224 - auc: 0.5878 - val_loss: 0.9096 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8085\n",
      "Epoch 81/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.9106 - tp: 125.0000 - fp: 153.0000 - tn: 291.0000 - fn: 143.0000 - accuracy: 0.5843 - precision: 0.4496 - recall: 0.4664 - auc: 0.5873 - val_loss: 0.9028 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8102\n",
      "Epoch 82/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.8919 - tp: 138.0000 - fp: 161.0000 - tn: 283.0000 - fn: 130.0000 - accuracy: 0.5913 - precision: 0.4615 - recall: 0.5149 - auc: 0.6266 - val_loss: 0.8960 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8082\n",
      "Epoch 83/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.9012 - tp: 129.0000 - fp: 160.0000 - tn: 284.0000 - fn: 139.0000 - accuracy: 0.5801 - precision: 0.4464 - recall: 0.4813 - auc: 0.5793 - val_loss: 0.8891 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8083\n",
      "Epoch 84/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.8766 - tp: 147.0000 - fp: 159.0000 - tn: 285.0000 - fn: 121.0000 - accuracy: 0.6067 - precision: 0.4804 - recall: 0.5485 - auc: 0.6281 - val_loss: 0.8828 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8113\n",
      "Epoch 85/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.8740 - tp: 139.0000 - fp: 160.0000 - tn: 284.0000 - fn: 129.0000 - accuracy: 0.5941 - precision: 0.4649 - recall: 0.5187 - auc: 0.6110 - val_loss: 0.8767 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8091\n",
      "Epoch 86/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.8723 - tp: 137.0000 - fp: 166.0000 - tn: 278.0000 - fn: 131.0000 - accuracy: 0.5829 - precision: 0.4521 - recall: 0.5112 - auc: 0.6054 - val_loss: 0.8702 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8065\n",
      "Epoch 87/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.8660 - tp: 152.0000 - fp: 168.0000 - tn: 276.0000 - fn: 116.0000 - accuracy: 0.6011 - precision: 0.4750 - recall: 0.5672 - auc: 0.6033 - val_loss: 0.8641 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8063\n",
      "Epoch 88/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.8668 - tp: 139.0000 - fp: 181.0000 - tn: 263.0000 - fn: 129.0000 - accuracy: 0.5646 - precision: 0.4344 - recall: 0.5187 - auc: 0.5722 - val_loss: 0.8581 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8116\n",
      "Epoch 89/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.8663 - tp: 133.0000 - fp: 176.0000 - tn: 268.0000 - fn: 135.0000 - accuracy: 0.5632 - precision: 0.4304 - recall: 0.4963 - auc: 0.5685 - val_loss: 0.8519 - val_tp: 31.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 43.0000 - val_accuracy: 0.7095 - val_precision: 0.7750 - val_recall: 0.4189 - val_auc: 0.8077\n",
      "Epoch 90/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.8562 - tp: 134.0000 - fp: 172.0000 - tn: 272.0000 - fn: 134.0000 - accuracy: 0.5702 - precision: 0.4379 - recall: 0.5000 - auc: 0.5787 - val_loss: 0.8461 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8094\n",
      "Epoch 91/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.8524 - tp: 126.0000 - fp: 174.0000 - tn: 270.0000 - fn: 142.0000 - accuracy: 0.5562 - precision: 0.4200 - recall: 0.4701 - auc: 0.5762 - val_loss: 0.8402 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8064\n",
      "Epoch 92/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.8388 - tp: 143.0000 - fp: 172.0000 - tn: 272.0000 - fn: 125.0000 - accuracy: 0.5829 - precision: 0.4540 - recall: 0.5336 - auc: 0.5955 - val_loss: 0.8346 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8095\n",
      "Epoch 93/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.8324 - tp: 139.0000 - fp: 164.0000 - tn: 280.0000 - fn: 129.0000 - accuracy: 0.5885 - precision: 0.4587 - recall: 0.5187 - auc: 0.5990 - val_loss: 0.8293 - val_tp: 31.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 43.0000 - val_accuracy: 0.7095 - val_precision: 0.7750 - val_recall: 0.4189 - val_auc: 0.8060\n",
      "Epoch 94/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.8260 - tp: 136.0000 - fp: 170.0000 - tn: 274.0000 - fn: 132.0000 - accuracy: 0.5758 - precision: 0.4444 - recall: 0.5075 - auc: 0.5964 - val_loss: 0.8233 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8033\n",
      "Epoch 95/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.8194 - tp: 153.0000 - fp: 182.0000 - tn: 262.0000 - fn: 115.0000 - accuracy: 0.5829 - precision: 0.4567 - recall: 0.5709 - auc: 0.6025 - val_loss: 0.8182 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8052\n",
      "Epoch 96/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.8114 - tp: 152.0000 - fp: 174.0000 - tn: 270.0000 - fn: 116.0000 - accuracy: 0.5927 - precision: 0.4663 - recall: 0.5672 - auc: 0.6139 - val_loss: 0.8129 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8062\n",
      "Epoch 97/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7997 - tp: 144.0000 - fp: 161.0000 - tn: 283.0000 - fn: 124.0000 - accuracy: 0.5997 - precision: 0.4721 - recall: 0.5373 - auc: 0.6349 - val_loss: 0.8078 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8093\n",
      "Epoch 98/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.8113 - tp: 132.0000 - fp: 176.0000 - tn: 268.0000 - fn: 136.0000 - accuracy: 0.5618 - precision: 0.4286 - recall: 0.4925 - auc: 0.5763 - val_loss: 0.8029 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8064\n",
      "Epoch 99/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.8036 - tp: 137.0000 - fp: 169.0000 - tn: 275.0000 - fn: 131.0000 - accuracy: 0.5787 - precision: 0.4477 - recall: 0.5112 - auc: 0.5881 - val_loss: 0.7987 - val_tp: 31.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 43.0000 - val_accuracy: 0.7095 - val_precision: 0.7750 - val_recall: 0.4189 - val_auc: 0.8054\n",
      "Epoch 100/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.8045 - tp: 126.0000 - fp: 175.0000 - tn: 269.0000 - fn: 142.0000 - accuracy: 0.5548 - precision: 0.4186 - recall: 0.4701 - auc: 0.5715 - val_loss: 0.7938 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8057\n",
      "Epoch 101/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.8029 - tp: 133.0000 - fp: 189.0000 - tn: 255.0000 - fn: 135.0000 - accuracy: 0.5449 - precision: 0.4130 - recall: 0.4963 - auc: 0.5580 - val_loss: 0.7896 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8060\n",
      "Epoch 102/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7940 - tp: 136.0000 - fp: 196.0000 - tn: 248.0000 - fn: 132.0000 - accuracy: 0.5393 - precision: 0.4096 - recall: 0.5075 - auc: 0.5728 - val_loss: 0.7857 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8055\n",
      "Epoch 103/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7942 - tp: 131.0000 - fp: 176.0000 - tn: 268.0000 - fn: 137.0000 - accuracy: 0.5604 - precision: 0.4267 - recall: 0.4888 - auc: 0.5655 - val_loss: 0.7809 - val_tp: 31.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 43.0000 - val_accuracy: 0.7095 - val_precision: 0.7750 - val_recall: 0.4189 - val_auc: 0.8065\n",
      "Epoch 104/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7876 - tp: 131.0000 - fp: 178.0000 - tn: 266.0000 - fn: 137.0000 - accuracy: 0.5576 - precision: 0.4239 - recall: 0.4888 - auc: 0.5703 - val_loss: 0.7766 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8051\n",
      "Epoch 105/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7851 - tp: 141.0000 - fp: 186.0000 - tn: 258.0000 - fn: 127.0000 - accuracy: 0.5604 - precision: 0.4312 - recall: 0.5261 - auc: 0.5660 - val_loss: 0.7721 - val_tp: 35.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 39.0000 - val_accuracy: 0.6927 - val_precision: 0.6863 - val_recall: 0.4730 - val_auc: 0.8059\n",
      "Epoch 106/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7787 - tp: 138.0000 - fp: 195.0000 - tn: 249.0000 - fn: 130.0000 - accuracy: 0.5435 - precision: 0.4144 - recall: 0.5149 - auc: 0.5655 - val_loss: 0.7681 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8024\n",
      "Epoch 107/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7772 - tp: 140.0000 - fp: 198.0000 - tn: 246.0000 - fn: 128.0000 - accuracy: 0.5421 - precision: 0.4142 - recall: 0.5224 - auc: 0.5617 - val_loss: 0.7646 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8046\n",
      "Epoch 108/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7739 - tp: 133.0000 - fp: 177.0000 - tn: 267.0000 - fn: 135.0000 - accuracy: 0.5618 - precision: 0.4290 - recall: 0.4963 - auc: 0.5638 - val_loss: 0.7611 - val_tp: 34.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 40.0000 - val_accuracy: 0.6872 - val_precision: 0.6800 - val_recall: 0.4595 - val_auc: 0.8031\n",
      "Epoch 109/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7560 - tp: 152.0000 - fp: 186.0000 - tn: 258.0000 - fn: 116.0000 - accuracy: 0.5758 - precision: 0.4497 - recall: 0.5672 - auc: 0.6075 - val_loss: 0.7577 - val_tp: 34.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 40.0000 - val_accuracy: 0.6872 - val_precision: 0.6800 - val_recall: 0.4595 - val_auc: 0.8046\n",
      "Epoch 110/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7659 - tp: 138.0000 - fp: 185.0000 - tn: 259.0000 - fn: 130.0000 - accuracy: 0.5576 - precision: 0.4272 - recall: 0.5149 - auc: 0.5715 - val_loss: 0.7541 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8038\n",
      "Epoch 111/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7514 - tp: 135.0000 - fp: 162.0000 - tn: 282.0000 - fn: 133.0000 - accuracy: 0.5857 - precision: 0.4545 - recall: 0.5037 - auc: 0.6047 - val_loss: 0.7512 - val_tp: 34.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 40.0000 - val_accuracy: 0.6872 - val_precision: 0.6800 - val_recall: 0.4595 - val_auc: 0.8033\n",
      "Epoch 112/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7417 - tp: 138.0000 - fp: 160.0000 - tn: 284.0000 - fn: 130.0000 - accuracy: 0.5927 - precision: 0.4631 - recall: 0.5149 - auc: 0.6255 - val_loss: 0.7480 - val_tp: 32.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 42.0000 - val_accuracy: 0.6872 - val_precision: 0.6957 - val_recall: 0.4324 - val_auc: 0.8067\n",
      "Epoch 113/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7532 - tp: 135.0000 - fp: 178.0000 - tn: 266.0000 - fn: 133.0000 - accuracy: 0.5632 - precision: 0.4313 - recall: 0.5037 - auc: 0.5807 - val_loss: 0.7447 - val_tp: 35.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 39.0000 - val_accuracy: 0.6927 - val_precision: 0.6863 - val_recall: 0.4730 - val_auc: 0.8033\n",
      "Epoch 114/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7505 - tp: 132.0000 - fp: 170.0000 - tn: 274.0000 - fn: 136.0000 - accuracy: 0.5702 - precision: 0.4371 - recall: 0.4925 - auc: 0.5750 - val_loss: 0.7418 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8034\n",
      "Epoch 115/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7454 - tp: 151.0000 - fp: 200.0000 - tn: 244.0000 - fn: 117.0000 - accuracy: 0.5548 - precision: 0.4302 - recall: 0.5634 - auc: 0.5844 - val_loss: 0.7386 - val_tp: 35.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 39.0000 - val_accuracy: 0.6927 - val_precision: 0.6863 - val_recall: 0.4730 - val_auc: 0.8036\n",
      "Epoch 116/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7488 - tp: 135.0000 - fp: 181.0000 - tn: 263.0000 - fn: 133.0000 - accuracy: 0.5590 - precision: 0.4272 - recall: 0.5037 - auc: 0.5684 - val_loss: 0.7367 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8047\n",
      "Epoch 117/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7482 - tp: 128.0000 - fp: 179.0000 - tn: 265.0000 - fn: 140.0000 - accuracy: 0.5520 - precision: 0.4169 - recall: 0.4776 - auc: 0.5579 - val_loss: 0.7344 - val_tp: 32.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 42.0000 - val_accuracy: 0.6872 - val_precision: 0.6957 - val_recall: 0.4324 - val_auc: 0.8051\n",
      "Epoch 118/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7369 - tp: 137.0000 - fp: 169.0000 - tn: 275.0000 - fn: 131.0000 - accuracy: 0.5787 - precision: 0.4477 - recall: 0.5112 - auc: 0.5896 - val_loss: 0.7322 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8023\n",
      "Epoch 119/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7364 - tp: 147.0000 - fp: 185.0000 - tn: 259.0000 - fn: 121.0000 - accuracy: 0.5702 - precision: 0.4428 - recall: 0.5485 - auc: 0.5823 - val_loss: 0.7291 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8029\n",
      "Epoch 120/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7499 - tp: 119.0000 - fp: 196.0000 - tn: 248.0000 - fn: 149.0000 - accuracy: 0.5154 - precision: 0.3778 - recall: 0.4440 - auc: 0.5186 - val_loss: 0.7271 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8020\n",
      "Epoch 121/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7325 - tp: 137.0000 - fp: 182.0000 - tn: 262.0000 - fn: 131.0000 - accuracy: 0.5604 - precision: 0.4295 - recall: 0.5112 - auc: 0.5845 - val_loss: 0.7245 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8031\n",
      "Epoch 122/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7236 - tp: 150.0000 - fp: 167.0000 - tn: 277.0000 - fn: 118.0000 - accuracy: 0.5997 - precision: 0.4732 - recall: 0.5597 - auc: 0.6087 - val_loss: 0.7229 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8012\n",
      "Epoch 123/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7348 - tp: 132.0000 - fp: 188.0000 - tn: 256.0000 - fn: 136.0000 - accuracy: 0.5449 - precision: 0.4125 - recall: 0.4925 - auc: 0.5594 - val_loss: 0.7210 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8043\n",
      "Epoch 124/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7295 - tp: 150.0000 - fp: 201.0000 - tn: 243.0000 - fn: 118.0000 - accuracy: 0.5520 - precision: 0.4274 - recall: 0.5597 - auc: 0.5729 - val_loss: 0.7197 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8044\n",
      "Epoch 125/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7279 - tp: 142.0000 - fp: 181.0000 - tn: 263.0000 - fn: 126.0000 - accuracy: 0.5688 - precision: 0.4396 - recall: 0.5299 - auc: 0.5707 - val_loss: 0.7186 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8039\n",
      "Epoch 126/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7231 - tp: 145.0000 - fp: 178.0000 - tn: 266.0000 - fn: 123.0000 - accuracy: 0.5772 - precision: 0.4489 - recall: 0.5410 - auc: 0.5867 - val_loss: 0.7174 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8048\n",
      "Epoch 127/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.7267 - tp: 140.0000 - fp: 184.0000 - tn: 260.0000 - fn: 128.0000 - accuracy: 0.5618 - precision: 0.4321 - recall: 0.5224 - auc: 0.5710 - val_loss: 0.7159 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8038\n",
      "Epoch 128/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7227 - tp: 132.0000 - fp: 186.0000 - tn: 258.0000 - fn: 136.0000 - accuracy: 0.5478 - precision: 0.4151 - recall: 0.4925 - auc: 0.5715 - val_loss: 0.7152 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8044\n",
      "Epoch 129/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7161 - tp: 144.0000 - fp: 174.0000 - tn: 270.0000 - fn: 124.0000 - accuracy: 0.5815 - precision: 0.4528 - recall: 0.5373 - auc: 0.6036 - val_loss: 0.7139 - val_tp: 36.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 38.0000 - val_accuracy: 0.6927 - val_precision: 0.6792 - val_recall: 0.4865 - val_auc: 0.8043\n",
      "Epoch 130/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7248 - tp: 133.0000 - fp: 181.0000 - tn: 263.0000 - fn: 135.0000 - accuracy: 0.5562 - precision: 0.4236 - recall: 0.4963 - auc: 0.5682 - val_loss: 0.7129 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8035\n",
      "Epoch 131/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7174 - tp: 136.0000 - fp: 182.0000 - tn: 262.0000 - fn: 132.0000 - accuracy: 0.5590 - precision: 0.4277 - recall: 0.5075 - auc: 0.5816 - val_loss: 0.7121 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8035\n",
      "Epoch 132/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7214 - tp: 156.0000 - fp: 194.0000 - tn: 250.0000 - fn: 112.0000 - accuracy: 0.5702 - precision: 0.4457 - recall: 0.5821 - auc: 0.5706 - val_loss: 0.7114 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8031\n",
      "Epoch 133/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7064 - tp: 153.0000 - fp: 174.0000 - tn: 270.0000 - fn: 115.0000 - accuracy: 0.5941 - precision: 0.4679 - recall: 0.5709 - auc: 0.6238 - val_loss: 0.7110 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8043\n",
      "Epoch 134/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7104 - tp: 145.0000 - fp: 153.0000 - tn: 291.0000 - fn: 123.0000 - accuracy: 0.6124 - precision: 0.4866 - recall: 0.5410 - auc: 0.6069 - val_loss: 0.7109 - val_tp: 32.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 42.0000 - val_accuracy: 0.7039 - val_precision: 0.7442 - val_recall: 0.4324 - val_auc: 0.8050\n",
      "Epoch 135/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7174 - tp: 134.0000 - fp: 173.0000 - tn: 271.0000 - fn: 134.0000 - accuracy: 0.5688 - precision: 0.4365 - recall: 0.5000 - auc: 0.5715 - val_loss: 0.7101 - val_tp: 34.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 40.0000 - val_accuracy: 0.6872 - val_precision: 0.6800 - val_recall: 0.4595 - val_auc: 0.8042\n",
      "Epoch 136/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7167 - tp: 136.0000 - fp: 165.0000 - tn: 279.0000 - fn: 132.0000 - accuracy: 0.5829 - precision: 0.4518 - recall: 0.5075 - auc: 0.5753 - val_loss: 0.7093 - val_tp: 35.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 39.0000 - val_accuracy: 0.6927 - val_precision: 0.6863 - val_recall: 0.4730 - val_auc: 0.8046\n",
      "Epoch 137/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7137 - tp: 141.0000 - fp: 177.0000 - tn: 267.0000 - fn: 127.0000 - accuracy: 0.5730 - precision: 0.4434 - recall: 0.5261 - auc: 0.5794 - val_loss: 0.7085 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8051\n",
      "Epoch 138/500\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.7129 - tp: 137.0000 - fp: 178.0000 - tn: 266.0000 - fn: 131.0000 - accuracy: 0.5660 - precision: 0.4349 - recall: 0.5112 - auc: 0.5807 - val_loss: 0.7088 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8037\n",
      "Epoch 139/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7109 - tp: 141.0000 - fp: 174.0000 - tn: 270.0000 - fn: 127.0000 - accuracy: 0.5772 - precision: 0.4476 - recall: 0.5261 - auc: 0.5825 - val_loss: 0.7087 - val_tp: 34.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 40.0000 - val_accuracy: 0.6872 - val_precision: 0.6800 - val_recall: 0.4595 - val_auc: 0.7984\n",
      "Epoch 140/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.7034 - tp: 145.0000 - fp: 151.0000 - tn: 293.0000 - fn: 123.0000 - accuracy: 0.6152 - precision: 0.4899 - recall: 0.5410 - auc: 0.6137 - val_loss: 0.7086 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8044\n",
      "Epoch 141/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7188 - tp: 129.0000 - fp: 163.0000 - tn: 281.0000 - fn: 139.0000 - accuracy: 0.5758 - precision: 0.4418 - recall: 0.4813 - auc: 0.5550 - val_loss: 0.7079 - val_tp: 30.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 44.0000 - val_accuracy: 0.6872 - val_precision: 0.7143 - val_recall: 0.4054 - val_auc: 0.8018\n",
      "Epoch 142/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7022 - tp: 149.0000 - fp: 171.0000 - tn: 273.0000 - fn: 119.0000 - accuracy: 0.5927 - precision: 0.4656 - recall: 0.5560 - auc: 0.6122 - val_loss: 0.7074 - val_tp: 30.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 44.0000 - val_accuracy: 0.6872 - val_precision: 0.7143 - val_recall: 0.4054 - val_auc: 0.8018\n",
      "Epoch 143/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7176 - tp: 123.0000 - fp: 172.0000 - tn: 272.0000 - fn: 145.0000 - accuracy: 0.5548 - precision: 0.4169 - recall: 0.4590 - auc: 0.5533 - val_loss: 0.7074 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8019\n",
      "Epoch 144/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7213 - tp: 122.0000 - fp: 184.0000 - tn: 260.0000 - fn: 146.0000 - accuracy: 0.5365 - precision: 0.3987 - recall: 0.4552 - auc: 0.5314 - val_loss: 0.7068 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8024\n",
      "Epoch 145/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7155 - tp: 129.0000 - fp: 178.0000 - tn: 266.0000 - fn: 139.0000 - accuracy: 0.5548 - precision: 0.4202 - recall: 0.4813 - auc: 0.5606 - val_loss: 0.7060 - val_tp: 34.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 40.0000 - val_accuracy: 0.6927 - val_precision: 0.6939 - val_recall: 0.4595 - val_auc: 0.8055\n",
      "Epoch 146/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7143 - tp: 140.0000 - fp: 183.0000 - tn: 261.0000 - fn: 128.0000 - accuracy: 0.5632 - precision: 0.4334 - recall: 0.5224 - auc: 0.5635 - val_loss: 0.7063 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8023\n",
      "Epoch 147/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7123 - tp: 133.0000 - fp: 164.0000 - tn: 280.0000 - fn: 135.0000 - accuracy: 0.5801 - precision: 0.4478 - recall: 0.4963 - auc: 0.5784 - val_loss: 0.7064 - val_tp: 29.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 45.0000 - val_accuracy: 0.7039 - val_precision: 0.7838 - val_recall: 0.3919 - val_auc: 0.8048\n",
      "Epoch 148/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.7130 - tp: 122.0000 - fp: 173.0000 - tn: 271.0000 - fn: 146.0000 - accuracy: 0.5520 - precision: 0.4136 - recall: 0.4552 - auc: 0.5680 - val_loss: 0.7053 - val_tp: 33.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 41.0000 - val_accuracy: 0.6872 - val_precision: 0.6875 - val_recall: 0.4459 - val_auc: 0.8045\n",
      "Epoch 149/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.7034 - tp: 126.0000 - fp: 156.0000 - tn: 288.0000 - fn: 142.0000 - accuracy: 0.5815 - precision: 0.4468 - recall: 0.4701 - auc: 0.5977 - val_loss: 0.7047 - val_tp: 34.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 40.0000 - val_accuracy: 0.6927 - val_precision: 0.6939 - val_recall: 0.4595 - val_auc: 0.8064\n",
      "Epoch 150/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7042 - tp: 135.0000 - fp: 189.0000 - tn: 255.0000 - fn: 133.0000 - accuracy: 0.5478 - precision: 0.4167 - recall: 0.5037 - auc: 0.5854 - val_loss: 0.7040 - val_tp: 35.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 39.0000 - val_accuracy: 0.6927 - val_precision: 0.6863 - val_recall: 0.4730 - val_auc: 0.8012\n",
      "Epoch 151/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7120 - tp: 135.0000 - fp: 188.0000 - tn: 256.0000 - fn: 133.0000 - accuracy: 0.5492 - precision: 0.4180 - recall: 0.5037 - auc: 0.5573 - val_loss: 0.7041 - val_tp: 34.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 40.0000 - val_accuracy: 0.6927 - val_precision: 0.6939 - val_recall: 0.4595 - val_auc: 0.8012\n",
      "Epoch 152/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6985 - tp: 134.0000 - fp: 172.0000 - tn: 272.0000 - fn: 134.0000 - accuracy: 0.5702 - precision: 0.4379 - recall: 0.5000 - auc: 0.6077 - val_loss: 0.7035 - val_tp: 35.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 39.0000 - val_accuracy: 0.6927 - val_precision: 0.6863 - val_recall: 0.4730 - val_auc: 0.7984\n",
      "Epoch 153/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7015 - tp: 145.0000 - fp: 182.0000 - tn: 262.0000 - fn: 123.0000 - accuracy: 0.5716 - precision: 0.4434 - recall: 0.5410 - auc: 0.5895 - val_loss: 0.7032 - val_tp: 34.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 40.0000 - val_accuracy: 0.6927 - val_precision: 0.6939 - val_recall: 0.4595 - val_auc: 0.8030\n",
      "Epoch 154/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7077 - tp: 134.0000 - fp: 177.0000 - tn: 267.0000 - fn: 134.0000 - accuracy: 0.5632 - precision: 0.4309 - recall: 0.5000 - auc: 0.5747 - val_loss: 0.7031 - val_tp: 34.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 40.0000 - val_accuracy: 0.6927 - val_precision: 0.6939 - val_recall: 0.4595 - val_auc: 0.8080\n",
      "Epoch 155/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.7040 - tp: 135.0000 - fp: 174.0000 - tn: 270.0000 - fn: 133.0000 - accuracy: 0.5688 - precision: 0.4369 - recall: 0.5037 - auc: 0.5877 - val_loss: 0.7025 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8033\n",
      "Epoch 156/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7072 - tp: 134.0000 - fp: 178.0000 - tn: 266.0000 - fn: 134.0000 - accuracy: 0.5618 - precision: 0.4295 - recall: 0.5000 - auc: 0.5741 - val_loss: 0.7028 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8037\n",
      "Epoch 157/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7115 - tp: 131.0000 - fp: 194.0000 - tn: 250.0000 - fn: 137.0000 - accuracy: 0.5351 - precision: 0.4031 - recall: 0.4888 - auc: 0.5499 - val_loss: 0.7028 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.7993\n",
      "Epoch 158/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.7010 - tp: 124.0000 - fp: 167.0000 - tn: 277.0000 - fn: 144.0000 - accuracy: 0.5632 - precision: 0.4261 - recall: 0.4627 - auc: 0.5816 - val_loss: 0.7025 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8054\n",
      "Epoch 159/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6989 - tp: 131.0000 - fp: 173.0000 - tn: 271.0000 - fn: 137.0000 - accuracy: 0.5646 - precision: 0.4309 - recall: 0.4888 - auc: 0.5953 - val_loss: 0.7021 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8042\n",
      "Epoch 160/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6988 - tp: 147.0000 - fp: 170.0000 - tn: 274.0000 - fn: 121.0000 - accuracy: 0.5913 - precision: 0.4637 - recall: 0.5485 - auc: 0.6013 - val_loss: 0.7018 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8028\n",
      "Epoch 161/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7047 - tp: 137.0000 - fp: 179.0000 - tn: 265.0000 - fn: 131.0000 - accuracy: 0.5646 - precision: 0.4335 - recall: 0.5112 - auc: 0.5715 - val_loss: 0.7016 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.7994\n",
      "Epoch 162/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7052 - tp: 134.0000 - fp: 181.0000 - tn: 263.0000 - fn: 134.0000 - accuracy: 0.5576 - precision: 0.4254 - recall: 0.5000 - auc: 0.5646 - val_loss: 0.7011 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8074\n",
      "Epoch 163/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7031 - tp: 127.0000 - fp: 159.0000 - tn: 285.0000 - fn: 141.0000 - accuracy: 0.5787 - precision: 0.4441 - recall: 0.4739 - auc: 0.5814 - val_loss: 0.7011 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8021\n",
      "Epoch 164/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7002 - tp: 133.0000 - fp: 166.0000 - tn: 278.0000 - fn: 135.0000 - accuracy: 0.5772 - precision: 0.4448 - recall: 0.4963 - auc: 0.5878 - val_loss: 0.7002 - val_tp: 33.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 41.0000 - val_accuracy: 0.6872 - val_precision: 0.6875 - val_recall: 0.4459 - val_auc: 0.8080\n",
      "Epoch 165/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6841 - tp: 150.0000 - fp: 164.0000 - tn: 280.0000 - fn: 118.0000 - accuracy: 0.6039 - precision: 0.4777 - recall: 0.5597 - auc: 0.6431 - val_loss: 0.6997 - val_tp: 34.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 40.0000 - val_accuracy: 0.6872 - val_precision: 0.6800 - val_recall: 0.4595 - val_auc: 0.8023\n",
      "Epoch 166/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7095 - tp: 142.0000 - fp: 184.0000 - tn: 260.0000 - fn: 126.0000 - accuracy: 0.5646 - precision: 0.4356 - recall: 0.5299 - auc: 0.5639 - val_loss: 0.6994 - val_tp: 34.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 40.0000 - val_accuracy: 0.6872 - val_precision: 0.6800 - val_recall: 0.4595 - val_auc: 0.8009\n",
      "Epoch 167/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7130 - tp: 128.0000 - fp: 191.0000 - tn: 253.0000 - fn: 140.0000 - accuracy: 0.5351 - precision: 0.4013 - recall: 0.4776 - auc: 0.5391 - val_loss: 0.6990 - val_tp: 35.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 39.0000 - val_accuracy: 0.6927 - val_precision: 0.6863 - val_recall: 0.4730 - val_auc: 0.8022\n",
      "Epoch 168/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7015 - tp: 136.0000 - fp: 163.0000 - tn: 281.0000 - fn: 132.0000 - accuracy: 0.5857 - precision: 0.4548 - recall: 0.5075 - auc: 0.5847 - val_loss: 0.6990 - val_tp: 33.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 41.0000 - val_accuracy: 0.6816 - val_precision: 0.6735 - val_recall: 0.4459 - val_auc: 0.8058\n",
      "Epoch 169/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.7021 - tp: 143.0000 - fp: 178.0000 - tn: 266.0000 - fn: 125.0000 - accuracy: 0.5744 - precision: 0.4455 - recall: 0.5336 - auc: 0.5860 - val_loss: 0.6988 - val_tp: 33.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 41.0000 - val_accuracy: 0.6816 - val_precision: 0.6735 - val_recall: 0.4459 - val_auc: 0.8059\n",
      "Epoch 170/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7016 - tp: 134.0000 - fp: 163.0000 - tn: 281.0000 - fn: 134.0000 - accuracy: 0.5829 - precision: 0.4512 - recall: 0.5000 - auc: 0.5826 - val_loss: 0.6989 - val_tp: 32.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 42.0000 - val_accuracy: 0.7151 - val_precision: 0.7805 - val_recall: 0.4324 - val_auc: 0.8076\n",
      "Epoch 171/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.7000 - tp: 133.0000 - fp: 170.0000 - tn: 274.0000 - fn: 135.0000 - accuracy: 0.5716 - precision: 0.4389 - recall: 0.4963 - auc: 0.5895 - val_loss: 0.6988 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8071\n",
      "Epoch 172/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7099 - tp: 129.0000 - fp: 178.0000 - tn: 266.0000 - fn: 139.0000 - accuracy: 0.5548 - precision: 0.4202 - recall: 0.4813 - auc: 0.5510 - val_loss: 0.6989 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8058\n",
      "Epoch 173/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.6968 - tp: 141.0000 - fp: 170.0000 - tn: 274.0000 - fn: 127.0000 - accuracy: 0.5829 - precision: 0.4534 - recall: 0.5261 - auc: 0.5951 - val_loss: 0.6989 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8058\n",
      "Epoch 174/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.6936 - tp: 137.0000 - fp: 165.0000 - tn: 279.0000 - fn: 131.0000 - accuracy: 0.5843 - precision: 0.4536 - recall: 0.5112 - auc: 0.6014 - val_loss: 0.6988 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8067\n",
      "Epoch 175/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7058 - tp: 123.0000 - fp: 173.0000 - tn: 271.0000 - fn: 145.0000 - accuracy: 0.5534 - precision: 0.4155 - recall: 0.4590 - auc: 0.5649 - val_loss: 0.6987 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8069\n",
      "Epoch 176/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7023 - tp: 112.0000 - fp: 159.0000 - tn: 285.0000 - fn: 156.0000 - accuracy: 0.5576 - precision: 0.4133 - recall: 0.4179 - auc: 0.5715 - val_loss: 0.6981 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8037\n",
      "Epoch 177/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7060 - tp: 134.0000 - fp: 164.0000 - tn: 280.0000 - fn: 134.0000 - accuracy: 0.5815 - precision: 0.4497 - recall: 0.5000 - auc: 0.5671 - val_loss: 0.6979 - val_tp: 32.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 42.0000 - val_accuracy: 0.7151 - val_precision: 0.7805 - val_recall: 0.4324 - val_auc: 0.8029\n",
      "Epoch 178/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.6934 - tp: 149.0000 - fp: 160.0000 - tn: 284.0000 - fn: 119.0000 - accuracy: 0.6081 - precision: 0.4822 - recall: 0.5560 - auc: 0.6141 - val_loss: 0.6980 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8071\n",
      "Epoch 179/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6929 - tp: 135.0000 - fp: 158.0000 - tn: 286.0000 - fn: 133.0000 - accuracy: 0.5913 - precision: 0.4608 - recall: 0.5037 - auc: 0.6104 - val_loss: 0.6977 - val_tp: 31.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 43.0000 - val_accuracy: 0.7151 - val_precision: 0.7949 - val_recall: 0.4189 - val_auc: 0.8066\n",
      "Epoch 180/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.6992 - tp: 132.0000 - fp: 165.0000 - tn: 279.0000 - fn: 136.0000 - accuracy: 0.5772 - precision: 0.4444 - recall: 0.4925 - auc: 0.5813 - val_loss: 0.6972 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8066\n",
      "Epoch 181/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7041 - tp: 141.0000 - fp: 193.0000 - tn: 251.0000 - fn: 127.0000 - accuracy: 0.5506 - precision: 0.4222 - recall: 0.5261 - auc: 0.5685 - val_loss: 0.6972 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8065\n",
      "Epoch 182/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7016 - tp: 143.0000 - fp: 173.0000 - tn: 271.0000 - fn: 125.0000 - accuracy: 0.5815 - precision: 0.4525 - recall: 0.5336 - auc: 0.5770 - val_loss: 0.6967 - val_tp: 34.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 40.0000 - val_accuracy: 0.6872 - val_precision: 0.6800 - val_recall: 0.4595 - val_auc: 0.8066\n",
      "Epoch 183/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6977 - tp: 136.0000 - fp: 165.0000 - tn: 279.0000 - fn: 132.0000 - accuracy: 0.5829 - precision: 0.4518 - recall: 0.5075 - auc: 0.5913 - val_loss: 0.6964 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8081\n",
      "Epoch 184/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6996 - tp: 140.0000 - fp: 179.0000 - tn: 265.0000 - fn: 128.0000 - accuracy: 0.5688 - precision: 0.4389 - recall: 0.5224 - auc: 0.5786 - val_loss: 0.6969 - val_tp: 32.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 42.0000 - val_accuracy: 0.6872 - val_precision: 0.6957 - val_recall: 0.4324 - val_auc: 0.8082\n",
      "Epoch 185/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7005 - tp: 129.0000 - fp: 166.0000 - tn: 278.0000 - fn: 139.0000 - accuracy: 0.5716 - precision: 0.4373 - recall: 0.4813 - auc: 0.5824 - val_loss: 0.6968 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8071\n",
      "Epoch 186/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7102 - tp: 118.0000 - fp: 177.0000 - tn: 267.0000 - fn: 150.0000 - accuracy: 0.5407 - precision: 0.4000 - recall: 0.4403 - auc: 0.5427 - val_loss: 0.6967 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.7976\n",
      "Epoch 187/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6942 - tp: 143.0000 - fp: 164.0000 - tn: 280.0000 - fn: 125.0000 - accuracy: 0.5941 - precision: 0.4658 - recall: 0.5336 - auc: 0.6030 - val_loss: 0.6966 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8028\n",
      "Epoch 188/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.6935 - tp: 126.0000 - fp: 155.0000 - tn: 289.0000 - fn: 142.0000 - accuracy: 0.5829 - precision: 0.4484 - recall: 0.4701 - auc: 0.5986 - val_loss: 0.6963 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8055\n",
      "Epoch 189/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.6937 - tp: 145.0000 - fp: 171.0000 - tn: 273.0000 - fn: 123.0000 - accuracy: 0.5871 - precision: 0.4589 - recall: 0.5410 - auc: 0.5950 - val_loss: 0.6954 - val_tp: 35.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 39.0000 - val_accuracy: 0.6927 - val_precision: 0.6863 - val_recall: 0.4730 - val_auc: 0.8073\n",
      "Epoch 190/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6989 - tp: 130.0000 - fp: 173.0000 - tn: 271.0000 - fn: 138.0000 - accuracy: 0.5632 - precision: 0.4290 - recall: 0.4851 - auc: 0.5765 - val_loss: 0.6948 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8116\n",
      "Epoch 191/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.7074 - tp: 135.0000 - fp: 200.0000 - tn: 244.0000 - fn: 133.0000 - accuracy: 0.5323 - precision: 0.4030 - recall: 0.5037 - auc: 0.5500 - val_loss: 0.6947 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8100\n",
      "Epoch 192/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.7063 - tp: 144.0000 - fp: 184.0000 - tn: 260.0000 - fn: 124.0000 - accuracy: 0.5674 - precision: 0.4390 - recall: 0.5373 - auc: 0.5600 - val_loss: 0.6946 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8083\n",
      "Epoch 193/500\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 0.7020 - tp: 139.0000 - fp: 185.0000 - tn: 259.0000 - fn: 129.0000 - accuracy: 0.5590 - precision: 0.4290 - recall: 0.5187 - auc: 0.5717 - val_loss: 0.6943 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8089\n",
      "Epoch 194/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7063 - tp: 128.0000 - fp: 185.0000 - tn: 259.0000 - fn: 140.0000 - accuracy: 0.5435 - precision: 0.4089 - recall: 0.4776 - auc: 0.5485 - val_loss: 0.6945 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8073\n",
      "Epoch 195/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.7004 - tp: 131.0000 - fp: 172.0000 - tn: 272.0000 - fn: 137.0000 - accuracy: 0.5660 - precision: 0.4323 - recall: 0.4888 - auc: 0.5697 - val_loss: 0.6945 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8073\n",
      "Epoch 196/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7030 - tp: 140.0000 - fp: 188.0000 - tn: 256.0000 - fn: 128.0000 - accuracy: 0.5562 - precision: 0.4268 - recall: 0.5224 - auc: 0.5675 - val_loss: 0.6943 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8068\n",
      "Epoch 197/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.7026 - tp: 138.0000 - fp: 181.0000 - tn: 263.0000 - fn: 130.0000 - accuracy: 0.5632 - precision: 0.4326 - recall: 0.5149 - auc: 0.5715 - val_loss: 0.6949 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8055\n",
      "Epoch 198/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7024 - tp: 128.0000 - fp: 185.0000 - tn: 259.0000 - fn: 140.0000 - accuracy: 0.5435 - precision: 0.4089 - recall: 0.4776 - auc: 0.5617 - val_loss: 0.6953 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8101\n",
      "Epoch 199/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.7045 - tp: 119.0000 - fp: 167.0000 - tn: 277.0000 - fn: 149.0000 - accuracy: 0.5562 - precision: 0.4161 - recall: 0.4440 - auc: 0.5541 - val_loss: 0.6953 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8101\n",
      "Epoch 200/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7025 - tp: 119.0000 - fp: 164.0000 - tn: 280.0000 - fn: 149.0000 - accuracy: 0.5604 - precision: 0.4205 - recall: 0.4440 - auc: 0.5555 - val_loss: 0.6950 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8068\n",
      "Epoch 201/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7001 - tp: 125.0000 - fp: 178.0000 - tn: 266.0000 - fn: 143.0000 - accuracy: 0.5492 - precision: 0.4125 - recall: 0.4664 - auc: 0.5665 - val_loss: 0.6949 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8068\n",
      "Epoch 202/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6980 - tp: 148.0000 - fp: 184.0000 - tn: 260.0000 - fn: 120.0000 - accuracy: 0.5730 - precision: 0.4458 - recall: 0.5522 - auc: 0.5848 - val_loss: 0.6944 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8085\n",
      "Epoch 203/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6912 - tp: 156.0000 - fp: 172.0000 - tn: 272.0000 - fn: 112.0000 - accuracy: 0.6011 - precision: 0.4756 - recall: 0.5821 - auc: 0.6163 - val_loss: 0.6942 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8099\n",
      "Epoch 204/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.6930 - tp: 137.0000 - fp: 183.0000 - tn: 261.0000 - fn: 131.0000 - accuracy: 0.5590 - precision: 0.4281 - recall: 0.5112 - auc: 0.5947 - val_loss: 0.6943 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8075\n",
      "Epoch 205/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6923 - tp: 144.0000 - fp: 178.0000 - tn: 266.0000 - fn: 124.0000 - accuracy: 0.5758 - precision: 0.4472 - recall: 0.5373 - auc: 0.6021 - val_loss: 0.6940 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8107\n",
      "Epoch 206/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.7000 - tp: 139.0000 - fp: 183.0000 - tn: 261.0000 - fn: 129.0000 - accuracy: 0.5618 - precision: 0.4317 - recall: 0.5187 - auc: 0.5742 - val_loss: 0.6938 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8148\n",
      "Epoch 207/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7087 - tp: 127.0000 - fp: 195.0000 - tn: 249.0000 - fn: 141.0000 - accuracy: 0.5281 - precision: 0.3944 - recall: 0.4739 - auc: 0.5354 - val_loss: 0.6939 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8111\n",
      "Epoch 208/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7001 - tp: 143.0000 - fp: 176.0000 - tn: 268.0000 - fn: 125.0000 - accuracy: 0.5772 - precision: 0.4483 - recall: 0.5336 - auc: 0.5807 - val_loss: 0.6937 - val_tp: 41.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 33.0000 - val_accuracy: 0.7151 - val_precision: 0.6949 - val_recall: 0.5541 - val_auc: 0.8099\n",
      "Epoch 209/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7046 - tp: 131.0000 - fp: 172.0000 - tn: 272.0000 - fn: 137.0000 - accuracy: 0.5660 - precision: 0.4323 - recall: 0.4888 - auc: 0.5646 - val_loss: 0.6943 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8073\n",
      "Epoch 210/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6956 - tp: 133.0000 - fp: 174.0000 - tn: 270.0000 - fn: 135.0000 - accuracy: 0.5660 - precision: 0.4332 - recall: 0.4963 - auc: 0.5798 - val_loss: 0.6941 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8105\n",
      "Epoch 211/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7050 - tp: 136.0000 - fp: 187.0000 - tn: 257.0000 - fn: 132.0000 - accuracy: 0.5520 - precision: 0.4211 - recall: 0.5075 - auc: 0.5549 - val_loss: 0.6940 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8153\n",
      "Epoch 212/500\n",
      "712/712 [==============================] - 0s 105us/sample - loss: 0.6882 - tp: 142.0000 - fp: 174.0000 - tn: 270.0000 - fn: 126.0000 - accuracy: 0.5787 - precision: 0.4494 - recall: 0.5299 - auc: 0.6153 - val_loss: 0.6937 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8137\n",
      "Epoch 213/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.6891 - tp: 143.0000 - fp: 170.0000 - tn: 274.0000 - fn: 125.0000 - accuracy: 0.5857 - precision: 0.4569 - recall: 0.5336 - auc: 0.6082 - val_loss: 0.6935 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8143\n",
      "Epoch 214/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6932 - tp: 140.0000 - fp: 181.0000 - tn: 263.0000 - fn: 128.0000 - accuracy: 0.5660 - precision: 0.4361 - recall: 0.5224 - auc: 0.5913 - val_loss: 0.6931 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8099\n",
      "Epoch 215/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.7038 - tp: 141.0000 - fp: 178.0000 - tn: 266.0000 - fn: 127.0000 - accuracy: 0.5716 - precision: 0.4420 - recall: 0.5261 - auc: 0.5650 - val_loss: 0.6931 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8142\n",
      "Epoch 216/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.7087 - tp: 128.0000 - fp: 195.0000 - tn: 249.0000 - fn: 140.0000 - accuracy: 0.5295 - precision: 0.3963 - recall: 0.4776 - auc: 0.5349 - val_loss: 0.6932 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8078\n",
      "Epoch 217/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.6942 - tp: 138.0000 - fp: 174.0000 - tn: 270.0000 - fn: 130.0000 - accuracy: 0.5730 - precision: 0.4423 - recall: 0.5149 - auc: 0.5896 - val_loss: 0.6935 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8086\n",
      "Epoch 218/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.7007 - tp: 135.0000 - fp: 191.0000 - tn: 253.0000 - fn: 133.0000 - accuracy: 0.5449 - precision: 0.4141 - recall: 0.5037 - auc: 0.5640 - val_loss: 0.6933 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8096\n",
      "Epoch 219/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7044 - tp: 127.0000 - fp: 180.0000 - tn: 264.0000 - fn: 141.0000 - accuracy: 0.5492 - precision: 0.4137 - recall: 0.4739 - auc: 0.5542 - val_loss: 0.6933 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8073\n",
      "Epoch 220/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.6929 - tp: 125.0000 - fp: 145.0000 - tn: 299.0000 - fn: 143.0000 - accuracy: 0.5955 - precision: 0.4630 - recall: 0.4664 - auc: 0.5923 - val_loss: 0.6941 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8103\n",
      "Epoch 221/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6974 - tp: 135.0000 - fp: 180.0000 - tn: 264.0000 - fn: 133.0000 - accuracy: 0.5604 - precision: 0.4286 - recall: 0.5037 - auc: 0.5820 - val_loss: 0.6944 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8073\n",
      "Epoch 222/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.7005 - tp: 137.0000 - fp: 182.0000 - tn: 262.0000 - fn: 131.0000 - accuracy: 0.5604 - precision: 0.4295 - recall: 0.5112 - auc: 0.5667 - val_loss: 0.6938 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8103\n",
      "Epoch 223/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.6982 - tp: 129.0000 - fp: 168.0000 - tn: 276.0000 - fn: 139.0000 - accuracy: 0.5688 - precision: 0.4343 - recall: 0.4813 - auc: 0.5755 - val_loss: 0.6938 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8113\n",
      "Epoch 224/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6983 - tp: 134.0000 - fp: 178.0000 - tn: 266.0000 - fn: 134.0000 - accuracy: 0.5618 - precision: 0.4295 - recall: 0.5000 - auc: 0.5770 - val_loss: 0.6939 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8102\n",
      "Epoch 225/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6982 - tp: 139.0000 - fp: 179.0000 - tn: 265.0000 - fn: 129.0000 - accuracy: 0.5674 - precision: 0.4371 - recall: 0.5187 - auc: 0.5770 - val_loss: 0.6939 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8063\n",
      "Epoch 226/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6985 - tp: 142.0000 - fp: 184.0000 - tn: 260.0000 - fn: 126.0000 - accuracy: 0.5646 - precision: 0.4356 - recall: 0.5299 - auc: 0.5746 - val_loss: 0.6941 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8112\n",
      "Epoch 227/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6964 - tp: 135.0000 - fp: 189.0000 - tn: 255.0000 - fn: 133.0000 - accuracy: 0.5478 - precision: 0.4167 - recall: 0.5037 - auc: 0.5766 - val_loss: 0.6941 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8131\n",
      "Epoch 228/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.7002 - tp: 128.0000 - fp: 174.0000 - tn: 270.0000 - fn: 140.0000 - accuracy: 0.5590 - precision: 0.4238 - recall: 0.4776 - auc: 0.5762 - val_loss: 0.6931 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8172\n",
      "Epoch 229/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.6896 - tp: 152.0000 - fp: 180.0000 - tn: 264.0000 - fn: 116.0000 - accuracy: 0.5843 - precision: 0.4578 - recall: 0.5672 - auc: 0.6123 - val_loss: 0.6934 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8102\n",
      "Epoch 230/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6958 - tp: 140.0000 - fp: 183.0000 - tn: 261.0000 - fn: 128.0000 - accuracy: 0.5632 - precision: 0.4334 - recall: 0.5224 - auc: 0.5871 - val_loss: 0.6930 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8133\n",
      "Epoch 231/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6963 - tp: 134.0000 - fp: 170.0000 - tn: 274.0000 - fn: 134.0000 - accuracy: 0.5730 - precision: 0.4408 - recall: 0.5000 - auc: 0.5885 - val_loss: 0.6929 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8143\n",
      "Epoch 232/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6894 - tp: 146.0000 - fp: 175.0000 - tn: 269.0000 - fn: 122.0000 - accuracy: 0.5829 - precision: 0.4548 - recall: 0.5448 - auc: 0.6096 - val_loss: 0.6923 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8172\n",
      "Epoch 233/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6914 - tp: 142.0000 - fp: 168.0000 - tn: 276.0000 - fn: 126.0000 - accuracy: 0.5871 - precision: 0.4581 - recall: 0.5299 - auc: 0.6014 - val_loss: 0.6925 - val_tp: 36.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 38.0000 - val_accuracy: 0.6983 - val_precision: 0.6923 - val_recall: 0.4865 - val_auc: 0.8083\n",
      "Epoch 234/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6919 - tp: 131.0000 - fp: 167.0000 - tn: 277.0000 - fn: 137.0000 - accuracy: 0.5730 - precision: 0.4396 - recall: 0.4888 - auc: 0.6018 - val_loss: 0.6925 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8143\n",
      "Epoch 235/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.6944 - tp: 138.0000 - fp: 190.0000 - tn: 254.0000 - fn: 130.0000 - accuracy: 0.5506 - precision: 0.4207 - recall: 0.5149 - auc: 0.5898 - val_loss: 0.6927 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8086\n",
      "Epoch 236/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6989 - tp: 133.0000 - fp: 171.0000 - tn: 273.0000 - fn: 135.0000 - accuracy: 0.5702 - precision: 0.4375 - recall: 0.4963 - auc: 0.5832 - val_loss: 0.6931 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8129\n",
      "Epoch 237/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6943 - tp: 134.0000 - fp: 156.0000 - tn: 288.0000 - fn: 134.0000 - accuracy: 0.5927 - precision: 0.4621 - recall: 0.5000 - auc: 0.5846 - val_loss: 0.6933 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8129\n",
      "Epoch 238/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6903 - tp: 145.0000 - fp: 168.0000 - tn: 276.0000 - fn: 123.0000 - accuracy: 0.5913 - precision: 0.4633 - recall: 0.5410 - auc: 0.6099 - val_loss: 0.6946 - val_tp: 27.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 47.0000 - val_accuracy: 0.6927 - val_precision: 0.7714 - val_recall: 0.3649 - val_auc: 0.8115\n",
      "Epoch 239/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6928 - tp: 127.0000 - fp: 173.0000 - tn: 271.0000 - fn: 141.0000 - accuracy: 0.5590 - precision: 0.4233 - recall: 0.4739 - auc: 0.5872 - val_loss: 0.6937 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8126\n",
      "Epoch 240/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6970 - tp: 126.0000 - fp: 156.0000 - tn: 288.0000 - fn: 142.0000 - accuracy: 0.5815 - precision: 0.4468 - recall: 0.4701 - auc: 0.5869 - val_loss: 0.6937 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8161\n",
      "Epoch 241/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6938 - tp: 137.0000 - fp: 170.0000 - tn: 274.0000 - fn: 131.0000 - accuracy: 0.5772 - precision: 0.4463 - recall: 0.5112 - auc: 0.5852 - val_loss: 0.6934 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8129\n",
      "Epoch 242/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6935 - tp: 131.0000 - fp: 159.0000 - tn: 285.0000 - fn: 137.0000 - accuracy: 0.5843 - precision: 0.4517 - recall: 0.4888 - auc: 0.5926 - val_loss: 0.6933 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8126\n",
      "Epoch 243/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7036 - tp: 136.0000 - fp: 179.0000 - tn: 265.0000 - fn: 132.0000 - accuracy: 0.5632 - precision: 0.4317 - recall: 0.5075 - auc: 0.5661 - val_loss: 0.6928 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8165\n",
      "Epoch 244/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6888 - tp: 134.0000 - fp: 155.0000 - tn: 289.0000 - fn: 134.0000 - accuracy: 0.5941 - precision: 0.4637 - recall: 0.5000 - auc: 0.6089 - val_loss: 0.6921 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8166\n",
      "Epoch 245/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.6920 - tp: 146.0000 - fp: 188.0000 - tn: 256.0000 - fn: 122.0000 - accuracy: 0.5646 - precision: 0.4371 - recall: 0.5448 - auc: 0.5971 - val_loss: 0.6917 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8128\n",
      "Epoch 246/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.7046 - tp: 125.0000 - fp: 193.0000 - tn: 251.0000 - fn: 143.0000 - accuracy: 0.5281 - precision: 0.3931 - recall: 0.4664 - auc: 0.5513 - val_loss: 0.6920 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8166\n",
      "Epoch 247/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.6948 - tp: 148.0000 - fp: 181.0000 - tn: 263.0000 - fn: 120.0000 - accuracy: 0.5772 - precision: 0.4498 - recall: 0.5522 - auc: 0.5947 - val_loss: 0.6917 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8166\n",
      "Epoch 248/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.6951 - tp: 139.0000 - fp: 173.0000 - tn: 271.0000 - fn: 129.0000 - accuracy: 0.5758 - precision: 0.4455 - recall: 0.5187 - auc: 0.5793 - val_loss: 0.6914 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8164\n",
      "Epoch 249/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.7040 - tp: 131.0000 - fp: 181.0000 - tn: 263.0000 - fn: 137.0000 - accuracy: 0.5534 - precision: 0.4199 - recall: 0.4888 - auc: 0.5628 - val_loss: 0.6916 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8164\n",
      "Epoch 250/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6952 - tp: 135.0000 - fp: 177.0000 - tn: 267.0000 - fn: 133.0000 - accuracy: 0.5646 - precision: 0.4327 - recall: 0.5037 - auc: 0.5848 - val_loss: 0.6911 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8145\n",
      "Epoch 251/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6926 - tp: 143.0000 - fp: 179.0000 - tn: 265.0000 - fn: 125.0000 - accuracy: 0.5730 - precision: 0.4441 - recall: 0.5336 - auc: 0.5977 - val_loss: 0.6910 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8161\n",
      "Epoch 252/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6957 - tp: 156.0000 - fp: 178.0000 - tn: 266.0000 - fn: 112.0000 - accuracy: 0.5927 - precision: 0.4671 - recall: 0.5821 - auc: 0.5952 - val_loss: 0.6908 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8172\n",
      "Epoch 253/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6909 - tp: 142.0000 - fp: 154.0000 - tn: 290.0000 - fn: 126.0000 - accuracy: 0.6067 - precision: 0.4797 - recall: 0.5299 - auc: 0.6137 - val_loss: 0.6907 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8172\n",
      "Epoch 254/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.6885 - tp: 142.0000 - fp: 168.0000 - tn: 276.0000 - fn: 126.0000 - accuracy: 0.5871 - precision: 0.4581 - recall: 0.5299 - auc: 0.6124 - val_loss: 0.6904 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8172\n",
      "Epoch 255/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6989 - tp: 131.0000 - fp: 174.0000 - tn: 270.0000 - fn: 137.0000 - accuracy: 0.5632 - precision: 0.4295 - recall: 0.4888 - auc: 0.5795 - val_loss: 0.6905 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8174\n",
      "Epoch 256/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6881 - tp: 139.0000 - fp: 165.0000 - tn: 279.0000 - fn: 129.0000 - accuracy: 0.5871 - precision: 0.4572 - recall: 0.5187 - auc: 0.6153 - val_loss: 0.6905 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8181\n",
      "Epoch 257/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6901 - tp: 129.0000 - fp: 173.0000 - tn: 271.0000 - fn: 139.0000 - accuracy: 0.5618 - precision: 0.4272 - recall: 0.4813 - auc: 0.6011 - val_loss: 0.6909 - val_tp: 30.0000 - val_fp: 8.0000 - val_tn: 97.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.7895 - val_recall: 0.4054 - val_auc: 0.8192\n",
      "Epoch 258/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.6919 - tp: 147.0000 - fp: 182.0000 - tn: 262.0000 - fn: 121.0000 - accuracy: 0.5744 - precision: 0.4468 - recall: 0.5485 - auc: 0.6066 - val_loss: 0.6902 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8176\n",
      "Epoch 259/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6988 - tp: 124.0000 - fp: 166.0000 - tn: 278.0000 - fn: 144.0000 - accuracy: 0.5646 - precision: 0.4276 - recall: 0.4627 - auc: 0.5782 - val_loss: 0.6897 - val_tp: 32.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.7619 - val_recall: 0.4324 - val_auc: 0.8167\n",
      "Epoch 260/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7001 - tp: 135.0000 - fp: 183.0000 - tn: 261.0000 - fn: 133.0000 - accuracy: 0.5562 - precision: 0.4245 - recall: 0.5037 - auc: 0.5687 - val_loss: 0.6902 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8188\n",
      "Epoch 261/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.6880 - tp: 135.0000 - fp: 161.0000 - tn: 283.0000 - fn: 133.0000 - accuracy: 0.5871 - precision: 0.4561 - recall: 0.5037 - auc: 0.6100 - val_loss: 0.6904 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8191\n",
      "Epoch 262/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6896 - tp: 146.0000 - fp: 175.0000 - tn: 269.0000 - fn: 122.0000 - accuracy: 0.5829 - precision: 0.4548 - recall: 0.5448 - auc: 0.6063 - val_loss: 0.6902 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8182\n",
      "Epoch 263/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6938 - tp: 130.0000 - fp: 154.0000 - tn: 290.0000 - fn: 138.0000 - accuracy: 0.5899 - precision: 0.4577 - recall: 0.4851 - auc: 0.5939 - val_loss: 0.6893 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8191\n",
      "Epoch 264/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6899 - tp: 144.0000 - fp: 172.0000 - tn: 272.0000 - fn: 124.0000 - accuracy: 0.5843 - precision: 0.4557 - recall: 0.5373 - auc: 0.6092 - val_loss: 0.6892 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8186\n",
      "Epoch 265/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6985 - tp: 147.0000 - fp: 184.0000 - tn: 260.0000 - fn: 121.0000 - accuracy: 0.5716 - precision: 0.4441 - recall: 0.5485 - auc: 0.5855 - val_loss: 0.6894 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8191\n",
      "Epoch 266/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6867 - tp: 141.0000 - fp: 166.0000 - tn: 278.0000 - fn: 127.0000 - accuracy: 0.5885 - precision: 0.4593 - recall: 0.5261 - auc: 0.6185 - val_loss: 0.6886 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8205\n",
      "Epoch 267/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6959 - tp: 148.0000 - fp: 173.0000 - tn: 271.0000 - fn: 120.0000 - accuracy: 0.5885 - precision: 0.4611 - recall: 0.5522 - auc: 0.5963 - val_loss: 0.6884 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8205\n",
      "Epoch 268/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.6939 - tp: 149.0000 - fp: 174.0000 - tn: 270.0000 - fn: 119.0000 - accuracy: 0.5885 - precision: 0.4613 - recall: 0.5560 - auc: 0.6039 - val_loss: 0.6880 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8180\n",
      "Epoch 269/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6891 - tp: 139.0000 - fp: 176.0000 - tn: 268.0000 - fn: 129.0000 - accuracy: 0.5716 - precision: 0.4413 - recall: 0.5187 - auc: 0.6091 - val_loss: 0.6885 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8208\n",
      "Epoch 270/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6867 - tp: 138.0000 - fp: 156.0000 - tn: 288.0000 - fn: 130.0000 - accuracy: 0.5983 - precision: 0.4694 - recall: 0.5149 - auc: 0.6176 - val_loss: 0.6878 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8203\n",
      "Epoch 271/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6941 - tp: 134.0000 - fp: 171.0000 - tn: 273.0000 - fn: 134.0000 - accuracy: 0.5716 - precision: 0.4393 - recall: 0.5000 - auc: 0.5934 - val_loss: 0.6872 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8212\n",
      "Epoch 272/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6918 - tp: 157.0000 - fp: 175.0000 - tn: 269.0000 - fn: 111.0000 - accuracy: 0.5983 - precision: 0.4729 - recall: 0.5858 - auc: 0.6094 - val_loss: 0.6870 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8205\n",
      "Epoch 273/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.7020 - tp: 135.0000 - fp: 188.0000 - tn: 256.0000 - fn: 133.0000 - accuracy: 0.5492 - precision: 0.4180 - recall: 0.5037 - auc: 0.5682 - val_loss: 0.6871 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8205\n",
      "Epoch 274/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6838 - tp: 153.0000 - fp: 174.0000 - tn: 270.0000 - fn: 115.0000 - accuracy: 0.5941 - precision: 0.4679 - recall: 0.5709 - auc: 0.6259 - val_loss: 0.6874 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8193\n",
      "Epoch 275/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7027 - tp: 147.0000 - fp: 193.0000 - tn: 251.0000 - fn: 121.0000 - accuracy: 0.5590 - precision: 0.4324 - recall: 0.5485 - auc: 0.5676 - val_loss: 0.6872 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8195\n",
      "Epoch 276/500\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 0.7004 - tp: 139.0000 - fp: 186.0000 - tn: 258.0000 - fn: 129.0000 - accuracy: 0.5576 - precision: 0.4277 - recall: 0.5187 - auc: 0.5811 - val_loss: 0.6872 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8185\n",
      "Epoch 277/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6921 - tp: 155.0000 - fp: 200.0000 - tn: 244.0000 - fn: 113.0000 - accuracy: 0.5604 - precision: 0.4366 - recall: 0.5784 - auc: 0.6029 - val_loss: 0.6871 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8205\n",
      "Epoch 278/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.6978 - tp: 136.0000 - fp: 179.0000 - tn: 265.0000 - fn: 132.0000 - accuracy: 0.5632 - precision: 0.4317 - recall: 0.5075 - auc: 0.5794 - val_loss: 0.6879 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8205\n",
      "Epoch 279/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6896 - tp: 147.0000 - fp: 175.0000 - tn: 269.0000 - fn: 121.0000 - accuracy: 0.5843 - precision: 0.4565 - recall: 0.5485 - auc: 0.6077 - val_loss: 0.6874 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8189\n",
      "Epoch 280/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.6899 - tp: 143.0000 - fp: 156.0000 - tn: 288.0000 - fn: 125.0000 - accuracy: 0.6053 - precision: 0.4783 - recall: 0.5336 - auc: 0.6153 - val_loss: 0.6881 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8208\n",
      "Epoch 281/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6919 - tp: 142.0000 - fp: 178.0000 - tn: 266.0000 - fn: 126.0000 - accuracy: 0.5730 - precision: 0.4437 - recall: 0.5299 - auc: 0.6001 - val_loss: 0.6867 - val_tp: 39.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 35.0000 - val_accuracy: 0.7374 - val_precision: 0.7647 - val_recall: 0.5270 - val_auc: 0.8219\n",
      "Epoch 282/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6916 - tp: 147.0000 - fp: 184.0000 - tn: 260.0000 - fn: 121.0000 - accuracy: 0.5716 - precision: 0.4441 - recall: 0.5485 - auc: 0.6070 - val_loss: 0.6865 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8216\n",
      "Epoch 283/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6884 - tp: 135.0000 - fp: 170.0000 - tn: 274.0000 - fn: 133.0000 - accuracy: 0.5744 - precision: 0.4426 - recall: 0.5037 - auc: 0.6106 - val_loss: 0.6858 - val_tp: 39.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 35.0000 - val_accuracy: 0.7374 - val_precision: 0.7647 - val_recall: 0.5270 - val_auc: 0.8202\n",
      "Epoch 284/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.6939 - tp: 138.0000 - fp: 165.0000 - tn: 279.0000 - fn: 130.0000 - accuracy: 0.5857 - precision: 0.4554 - recall: 0.5149 - auc: 0.6022 - val_loss: 0.6861 - val_tp: 33.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 41.0000 - val_accuracy: 0.7151 - val_precision: 0.7674 - val_recall: 0.4459 - val_auc: 0.8223\n",
      "Epoch 285/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.6917 - tp: 141.0000 - fp: 170.0000 - tn: 274.0000 - fn: 127.0000 - accuracy: 0.5829 - precision: 0.4534 - recall: 0.5261 - auc: 0.6090 - val_loss: 0.6867 - val_tp: 31.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 43.0000 - val_accuracy: 0.7039 - val_precision: 0.7561 - val_recall: 0.4189 - val_auc: 0.8216\n",
      "Epoch 286/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.6836 - tp: 150.0000 - fp: 177.0000 - tn: 267.0000 - fn: 118.0000 - accuracy: 0.5857 - precision: 0.4587 - recall: 0.5597 - auc: 0.6295 - val_loss: 0.6864 - val_tp: 33.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 41.0000 - val_accuracy: 0.7151 - val_precision: 0.7674 - val_recall: 0.4459 - val_auc: 0.8214\n",
      "Epoch 287/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6930 - tp: 142.0000 - fp: 179.0000 - tn: 265.0000 - fn: 126.0000 - accuracy: 0.5716 - precision: 0.4424 - recall: 0.5299 - auc: 0.6022 - val_loss: 0.6858 - val_tp: 33.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 41.0000 - val_accuracy: 0.7151 - val_precision: 0.7674 - val_recall: 0.4459 - val_auc: 0.8223\n",
      "Epoch 288/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6900 - tp: 163.0000 - fp: 189.0000 - tn: 255.0000 - fn: 105.0000 - accuracy: 0.5871 - precision: 0.4631 - recall: 0.6082 - auc: 0.6165 - val_loss: 0.6856 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8229\n",
      "Epoch 289/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6952 - tp: 152.0000 - fp: 176.0000 - tn: 268.0000 - fn: 116.0000 - accuracy: 0.5899 - precision: 0.4634 - recall: 0.5672 - auc: 0.5981 - val_loss: 0.6858 - val_tp: 33.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 41.0000 - val_accuracy: 0.7151 - val_precision: 0.7674 - val_recall: 0.4459 - val_auc: 0.8223\n",
      "Epoch 290/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6875 - tp: 151.0000 - fp: 181.0000 - tn: 263.0000 - fn: 117.0000 - accuracy: 0.5815 - precision: 0.4548 - recall: 0.5634 - auc: 0.6154 - val_loss: 0.6857 - val_tp: 33.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 41.0000 - val_accuracy: 0.7151 - val_precision: 0.7674 - val_recall: 0.4459 - val_auc: 0.8223\n",
      "Epoch 291/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.7058 - tp: 128.0000 - fp: 199.0000 - tn: 245.0000 - fn: 140.0000 - accuracy: 0.5239 - precision: 0.3914 - recall: 0.4776 - auc: 0.5594 - val_loss: 0.6846 - val_tp: 39.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 35.0000 - val_accuracy: 0.7374 - val_precision: 0.7647 - val_recall: 0.5270 - val_auc: 0.8227\n",
      "Epoch 292/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.6920 - tp: 152.0000 - fp: 181.0000 - tn: 263.0000 - fn: 116.0000 - accuracy: 0.5829 - precision: 0.4565 - recall: 0.5672 - auc: 0.6069 - val_loss: 0.6843 - val_tp: 39.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 35.0000 - val_accuracy: 0.7374 - val_precision: 0.7647 - val_recall: 0.5270 - val_auc: 0.8221\n",
      "Epoch 293/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6900 - tp: 156.0000 - fp: 192.0000 - tn: 252.0000 - fn: 112.0000 - accuracy: 0.5730 - precision: 0.4483 - recall: 0.5821 - auc: 0.6083 - val_loss: 0.6845 - val_tp: 39.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 35.0000 - val_accuracy: 0.7374 - val_precision: 0.7647 - val_recall: 0.5270 - val_auc: 0.8227\n",
      "Epoch 294/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6996 - tp: 146.0000 - fp: 176.0000 - tn: 268.0000 - fn: 122.0000 - accuracy: 0.5815 - precision: 0.4534 - recall: 0.5448 - auc: 0.5880 - val_loss: 0.6848 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8229\n",
      "Epoch 295/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.6869 - tp: 146.0000 - fp: 165.0000 - tn: 279.0000 - fn: 122.0000 - accuracy: 0.5969 - precision: 0.4695 - recall: 0.5448 - auc: 0.6190 - val_loss: 0.6843 - val_tp: 39.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 35.0000 - val_accuracy: 0.7374 - val_precision: 0.7647 - val_recall: 0.5270 - val_auc: 0.8216\n",
      "Epoch 296/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.6983 - tp: 146.0000 - fp: 184.0000 - tn: 260.0000 - fn: 122.0000 - accuracy: 0.5702 - precision: 0.4424 - recall: 0.5448 - auc: 0.5903 - val_loss: 0.6846 - val_tp: 33.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 41.0000 - val_accuracy: 0.7151 - val_precision: 0.7674 - val_recall: 0.4459 - val_auc: 0.8221\n",
      "Epoch 297/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6814 - tp: 152.0000 - fp: 170.0000 - tn: 274.0000 - fn: 116.0000 - accuracy: 0.5983 - precision: 0.4720 - recall: 0.5672 - auc: 0.6347 - val_loss: 0.6849 - val_tp: 33.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 41.0000 - val_accuracy: 0.7151 - val_precision: 0.7674 - val_recall: 0.4459 - val_auc: 0.8227\n",
      "Epoch 298/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.6938 - tp: 140.0000 - fp: 176.0000 - tn: 268.0000 - fn: 128.0000 - accuracy: 0.5730 - precision: 0.4430 - recall: 0.5224 - auc: 0.5980 - val_loss: 0.6843 - val_tp: 34.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 40.0000 - val_accuracy: 0.7207 - val_precision: 0.7727 - val_recall: 0.4595 - val_auc: 0.8221\n",
      "Epoch 299/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6902 - tp: 137.0000 - fp: 173.0000 - tn: 271.0000 - fn: 131.0000 - accuracy: 0.5730 - precision: 0.4419 - recall: 0.5112 - auc: 0.6078 - val_loss: 0.6848 - val_tp: 33.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 41.0000 - val_accuracy: 0.7151 - val_precision: 0.7674 - val_recall: 0.4459 - val_auc: 0.8227\n",
      "Epoch 300/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6842 - tp: 135.0000 - fp: 149.0000 - tn: 295.0000 - fn: 133.0000 - accuracy: 0.6039 - precision: 0.4754 - recall: 0.5037 - auc: 0.6268 - val_loss: 0.6841 - val_tp: 33.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 41.0000 - val_accuracy: 0.7151 - val_precision: 0.7674 - val_recall: 0.4459 - val_auc: 0.8221\n",
      "Epoch 301/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.6978 - tp: 134.0000 - fp: 174.0000 - tn: 270.0000 - fn: 134.0000 - accuracy: 0.5674 - precision: 0.4351 - recall: 0.5000 - auc: 0.5869 - val_loss: 0.6836 - val_tp: 39.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 35.0000 - val_accuracy: 0.7374 - val_precision: 0.7647 - val_recall: 0.5270 - val_auc: 0.8227\n",
      "Epoch 302/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.6953 - tp: 147.0000 - fp: 186.0000 - tn: 258.0000 - fn: 121.0000 - accuracy: 0.5688 - precision: 0.4414 - recall: 0.5485 - auc: 0.5963 - val_loss: 0.6836 - val_tp: 39.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 35.0000 - val_accuracy: 0.7374 - val_precision: 0.7647 - val_recall: 0.5270 - val_auc: 0.8230\n",
      "Epoch 303/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.6932 - tp: 151.0000 - fp: 175.0000 - tn: 269.0000 - fn: 117.0000 - accuracy: 0.5899 - precision: 0.4632 - recall: 0.5634 - auc: 0.6064 - val_loss: 0.6837 - val_tp: 39.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 35.0000 - val_accuracy: 0.7374 - val_precision: 0.7647 - val_recall: 0.5270 - val_auc: 0.8223\n",
      "Epoch 304/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.6974 - tp: 133.0000 - fp: 173.0000 - tn: 271.0000 - fn: 135.0000 - accuracy: 0.5674 - precision: 0.4346 - recall: 0.4963 - auc: 0.5904 - val_loss: 0.6837 - val_tp: 39.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 35.0000 - val_accuracy: 0.7374 - val_precision: 0.7647 - val_recall: 0.5270 - val_auc: 0.8223\n",
      "Epoch 305/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.6866 - tp: 149.0000 - fp: 185.0000 - tn: 259.0000 - fn: 119.0000 - accuracy: 0.5730 - precision: 0.4461 - recall: 0.5560 - auc: 0.6148 - val_loss: 0.6835 - val_tp: 39.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 35.0000 - val_accuracy: 0.7374 - val_precision: 0.7647 - val_recall: 0.5270 - val_auc: 0.8225\n",
      "Epoch 306/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.6994 - tp: 136.0000 - fp: 173.0000 - tn: 271.0000 - fn: 132.0000 - accuracy: 0.5716 - precision: 0.4401 - recall: 0.5075 - auc: 0.5840 - val_loss: 0.6829 - val_tp: 39.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 35.0000 - val_accuracy: 0.7374 - val_precision: 0.7647 - val_recall: 0.5270 - val_auc: 0.8253\n",
      "Epoch 307/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.6855 - tp: 151.0000 - fp: 158.0000 - tn: 286.0000 - fn: 117.0000 - accuracy: 0.6138 - precision: 0.4887 - recall: 0.5634 - auc: 0.6308 - val_loss: 0.6836 - val_tp: 33.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 41.0000 - val_accuracy: 0.7151 - val_precision: 0.7674 - val_recall: 0.4459 - val_auc: 0.8227\n",
      "Epoch 308/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4351 - tp: 197.0000 - fp: 40.0000 - tn: 404.0000 - fn: 71.0000 - accuracy: 0.8441 - precision: 0.8312 - recall: 0.7351 - auc: 0.8726 - val_loss: 0.4688 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8934\n",
      "Epoch 371/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4219 - tp: 190.0000 - fp: 37.0000 - tn: 407.0000 - fn: 78.0000 - accuracy: 0.8385 - precision: 0.8370 - recall: 0.7090 - auc: 0.8822 - val_loss: 0.4659 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8955\n",
      "Epoch 372/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4365 - tp: 190.0000 - fp: 39.0000 - tn: 405.0000 - fn: 78.0000 - accuracy: 0.8357 - precision: 0.8297 - recall: 0.7090 - auc: 0.8727 - val_loss: 0.4713 - val_tp: 52.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 22.0000 - val_accuracy: 0.8156 - val_precision: 0.8254 - val_recall: 0.7027 - val_auc: 0.8937\n",
      "Epoch 373/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4265 - tp: 193.0000 - fp: 35.0000 - tn: 409.0000 - fn: 75.0000 - accuracy: 0.8455 - precision: 0.8465 - recall: 0.7201 - auc: 0.8813 - val_loss: 0.4777 - val_tp: 57.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 17.0000 - val_accuracy: 0.8324 - val_precision: 0.8143 - val_recall: 0.7703 - val_auc: 0.8954\n",
      "Epoch 374/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4366 - tp: 193.0000 - fp: 46.0000 - tn: 398.0000 - fn: 75.0000 - accuracy: 0.8301 - precision: 0.8075 - recall: 0.7201 - auc: 0.8785 - val_loss: 0.4555 - val_tp: 54.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 20.0000 - val_accuracy: 0.8156 - val_precision: 0.8060 - val_recall: 0.7297 - val_auc: 0.8952\n",
      "Epoch 375/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4135 - tp: 189.0000 - fp: 33.0000 - tn: 411.0000 - fn: 79.0000 - accuracy: 0.8427 - precision: 0.8514 - recall: 0.7052 - auc: 0.8953 - val_loss: 0.4550 - val_tp: 54.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 20.0000 - val_accuracy: 0.8212 - val_precision: 0.8182 - val_recall: 0.7297 - val_auc: 0.8950\n",
      "Epoch 376/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4330 - tp: 197.0000 - fp: 45.0000 - tn: 399.0000 - fn: 71.0000 - accuracy: 0.8371 - precision: 0.8140 - recall: 0.7351 - auc: 0.8773 - val_loss: 0.4622 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8999\n",
      "Epoch 377/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4245 - tp: 195.0000 - fp: 43.0000 - tn: 401.0000 - fn: 73.0000 - accuracy: 0.8371 - precision: 0.8193 - recall: 0.7276 - auc: 0.8856 - val_loss: 0.4482 - val_tp: 54.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 20.0000 - val_accuracy: 0.8212 - val_precision: 0.8182 - val_recall: 0.7297 - val_auc: 0.8911\n",
      "Epoch 378/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4352 - tp: 186.0000 - fp: 42.0000 - tn: 402.0000 - fn: 82.0000 - accuracy: 0.8258 - precision: 0.8158 - recall: 0.6940 - auc: 0.8734 - val_loss: 0.4613 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8925\n",
      "Epoch 379/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4170 - tp: 204.0000 - fp: 51.0000 - tn: 393.0000 - fn: 64.0000 - accuracy: 0.8385 - precision: 0.8000 - recall: 0.7612 - auc: 0.8848 - val_loss: 0.4621 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8954\n",
      "Epoch 380/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4235 - tp: 190.0000 - fp: 43.0000 - tn: 401.0000 - fn: 78.0000 - accuracy: 0.8301 - precision: 0.8155 - recall: 0.7090 - auc: 0.8777 - val_loss: 0.4626 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8892\n",
      "Epoch 381/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4238 - tp: 188.0000 - fp: 37.0000 - tn: 407.0000 - fn: 80.0000 - accuracy: 0.8357 - precision: 0.8356 - recall: 0.7015 - auc: 0.8809 - val_loss: 0.4574 - val_tp: 54.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 20.0000 - val_accuracy: 0.8212 - val_precision: 0.8182 - val_recall: 0.7297 - val_auc: 0.8971\n",
      "Epoch 382/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4394 - tp: 186.0000 - fp: 35.0000 - tn: 409.0000 - fn: 82.0000 - accuracy: 0.8357 - precision: 0.8416 - recall: 0.6940 - auc: 0.8706 - val_loss: 0.4595 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8988\n",
      "Epoch 383/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4205 - tp: 198.0000 - fp: 42.0000 - tn: 402.0000 - fn: 70.0000 - accuracy: 0.8427 - precision: 0.8250 - recall: 0.7388 - auc: 0.8944 - val_loss: 0.4661 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8968\n",
      "Epoch 384/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4332 - tp: 203.0000 - fp: 47.0000 - tn: 397.0000 - fn: 65.0000 - accuracy: 0.8427 - precision: 0.8120 - recall: 0.7575 - auc: 0.8750 - val_loss: 0.4633 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8950\n",
      "Epoch 385/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4328 - tp: 200.0000 - fp: 42.0000 - tn: 402.0000 - fn: 68.0000 - accuracy: 0.8455 - precision: 0.8264 - recall: 0.7463 - auc: 0.8750 - val_loss: 0.4660 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8921\n",
      "Epoch 386/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4228 - tp: 199.0000 - fp: 37.0000 - tn: 407.0000 - fn: 69.0000 - accuracy: 0.8511 - precision: 0.8432 - recall: 0.7425 - auc: 0.8818 - val_loss: 0.4733 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.8933\n",
      "Epoch 387/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4392 - tp: 204.0000 - fp: 42.0000 - tn: 402.0000 - fn: 64.0000 - accuracy: 0.8511 - precision: 0.8293 - recall: 0.7612 - auc: 0.8693 - val_loss: 0.4771 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8931\n",
      "Epoch 388/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4334 - tp: 192.0000 - fp: 43.0000 - tn: 401.0000 - fn: 76.0000 - accuracy: 0.8329 - precision: 0.8170 - recall: 0.7164 - auc: 0.8779 - val_loss: 0.4750 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8892\n",
      "Epoch 389/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4244 - tp: 189.0000 - fp: 38.0000 - tn: 406.0000 - fn: 79.0000 - accuracy: 0.8357 - precision: 0.8326 - recall: 0.7052 - auc: 0.8817 - val_loss: 0.4662 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8958\n",
      "Epoch 390/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4219 - tp: 199.0000 - fp: 46.0000 - tn: 398.0000 - fn: 69.0000 - accuracy: 0.8385 - precision: 0.8122 - recall: 0.7425 - auc: 0.8882 - val_loss: 0.4623 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8931\n",
      "Epoch 391/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4278 - tp: 199.0000 - fp: 51.0000 - tn: 393.0000 - fn: 69.0000 - accuracy: 0.8315 - precision: 0.7960 - recall: 0.7425 - auc: 0.8825 - val_loss: 0.4647 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8925\n",
      "Epoch 392/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4379 - tp: 204.0000 - fp: 49.0000 - tn: 395.0000 - fn: 64.0000 - accuracy: 0.8413 - precision: 0.8063 - recall: 0.7612 - auc: 0.8737 - val_loss: 0.4560 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8898\n",
      "Epoch 393/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4357 - tp: 207.0000 - fp: 58.0000 - tn: 386.0000 - fn: 61.0000 - accuracy: 0.8329 - precision: 0.7811 - recall: 0.7724 - auc: 0.8755 - val_loss: 0.4575 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8959\n",
      "Epoch 394/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4267 - tp: 210.0000 - fp: 62.0000 - tn: 382.0000 - fn: 58.0000 - accuracy: 0.8315 - precision: 0.7721 - recall: 0.7836 - auc: 0.8802 - val_loss: 0.4688 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.8850\n",
      "Epoch 395/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4354 - tp: 195.0000 - fp: 47.0000 - tn: 397.0000 - fn: 73.0000 - accuracy: 0.8315 - precision: 0.8058 - recall: 0.7276 - auc: 0.8787 - val_loss: 0.4584 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8860\n",
      "Epoch 396/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4294 - tp: 201.0000 - fp: 48.0000 - tn: 396.0000 - fn: 67.0000 - accuracy: 0.8385 - precision: 0.8072 - recall: 0.7500 - auc: 0.8792 - val_loss: 0.4506 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8938\n",
      "Epoch 397/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4233 - tp: 204.0000 - fp: 58.0000 - tn: 386.0000 - fn: 64.0000 - accuracy: 0.8287 - precision: 0.7786 - recall: 0.7612 - auc: 0.8832 - val_loss: 0.4448 - val_tp: 60.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 14.0000 - val_accuracy: 0.8212 - val_precision: 0.7692 - val_recall: 0.8108 - val_auc: 0.8959\n",
      "Epoch 398/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4179 - tp: 205.0000 - fp: 57.0000 - tn: 387.0000 - fn: 63.0000 - accuracy: 0.8315 - precision: 0.7824 - recall: 0.7649 - auc: 0.8896 - val_loss: 0.4562 - val_tp: 62.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 12.0000 - val_accuracy: 0.7821 - val_precision: 0.6966 - val_recall: 0.8378 - val_auc: 0.8955\n",
      "Epoch 399/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.4187 - tp: 211.0000 - fp: 64.0000 - tn: 380.0000 - fn: 57.0000 - accuracy: 0.8301 - precision: 0.7673 - recall: 0.7873 - auc: 0.8842 - val_loss: 0.4600 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8928\n",
      "Epoch 400/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4272 - tp: 201.0000 - fp: 45.0000 - tn: 399.0000 - fn: 67.0000 - accuracy: 0.8427 - precision: 0.8171 - recall: 0.7500 - auc: 0.8777 - val_loss: 0.4676 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8959\n",
      "Epoch 401/500\n",
      "712/712 [==============================] - 0s 213us/sample - loss: 0.4327 - tp: 193.0000 - fp: 47.0000 - tn: 397.0000 - fn: 75.0000 - accuracy: 0.8287 - precision: 0.8042 - recall: 0.7201 - auc: 0.8783 - val_loss: 0.4533 - val_tp: 54.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 20.0000 - val_accuracy: 0.8156 - val_precision: 0.8060 - val_recall: 0.7297 - val_auc: 0.8981\n",
      "Epoch 402/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.4120 - tp: 200.0000 - fp: 45.0000 - tn: 399.0000 - fn: 68.0000 - accuracy: 0.8413 - precision: 0.8163 - recall: 0.7463 - auc: 0.8894 - val_loss: 0.4730 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8932\n",
      "Epoch 403/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.4312 - tp: 190.0000 - fp: 36.0000 - tn: 408.0000 - fn: 78.0000 - accuracy: 0.8399 - precision: 0.8407 - recall: 0.7090 - auc: 0.8767 - val_loss: 0.4626 - val_tp: 53.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 21.0000 - val_accuracy: 0.8212 - val_precision: 0.8281 - val_recall: 0.7162 - val_auc: 0.8977\n",
      "Epoch 404/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.4179 - tp: 184.0000 - fp: 31.0000 - tn: 413.0000 - fn: 84.0000 - accuracy: 0.8385 - precision: 0.8558 - recall: 0.6866 - auc: 0.8891 - val_loss: 0.4694 - val_tp: 55.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 19.0000 - val_accuracy: 0.8156 - val_precision: 0.7971 - val_recall: 0.7432 - val_auc: 0.8975\n",
      "Epoch 405/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.4288 - tp: 191.0000 - fp: 40.0000 - tn: 404.0000 - fn: 77.0000 - accuracy: 0.8357 - precision: 0.8268 - recall: 0.7127 - auc: 0.8780 - val_loss: 0.4653 - val_tp: 54.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 20.0000 - val_accuracy: 0.8268 - val_precision: 0.8308 - val_recall: 0.7297 - val_auc: 0.8965\n",
      "Epoch 406/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4371 - tp: 195.0000 - fp: 47.0000 - tn: 397.0000 - fn: 73.0000 - accuracy: 0.8315 - precision: 0.8058 - recall: 0.7276 - auc: 0.8707 - val_loss: 0.4649 - val_tp: 54.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 20.0000 - val_accuracy: 0.8268 - val_precision: 0.8308 - val_recall: 0.7297 - val_auc: 0.8914\n",
      "Epoch 407/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4323 - tp: 186.0000 - fp: 32.0000 - tn: 412.0000 - fn: 82.0000 - accuracy: 0.8399 - precision: 0.8532 - recall: 0.6940 - auc: 0.8753 - val_loss: 0.4668 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 19.0000 - val_accuracy: 0.8212 - val_precision: 0.8088 - val_recall: 0.7432 - val_auc: 0.8961\n",
      "Epoch 408/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 4.2330 - tp: 112.0000 - fp: 171.0000 - tn: 273.0000 - fn: 156.0000 - accuracy: 0.5407 - precision: 0.3958 - recall: 0.4179 - auc: 0.5056 - val_loss: 4.2273 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.4952\n",
      "Epoch 241/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 4.2269 - tp: 108.0000 - fp: 190.0000 - tn: 254.0000 - fn: 160.0000 - accuracy: 0.5084 - precision: 0.3624 - recall: 0.4030 - auc: 0.4991 - val_loss: 4.2208 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 242/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 4.2191 - tp: 127.0000 - fp: 191.0000 - tn: 253.0000 - fn: 141.0000 - accuracy: 0.5337 - precision: 0.3994 - recall: 0.4739 - auc: 0.5115 - val_loss: 4.2143 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 243/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 4.2144 - tp: 101.0000 - fp: 188.0000 - tn: 256.0000 - fn: 167.0000 - accuracy: 0.5014 - precision: 0.3495 - recall: 0.3769 - auc: 0.4815 - val_loss: 4.2078 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 244/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 4.2036 - tp: 127.0000 - fp: 184.0000 - tn: 260.0000 - fn: 141.0000 - accuracy: 0.5435 - precision: 0.4084 - recall: 0.4739 - auc: 0.5335 - val_loss: 4.2014 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 245/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 4.2077 - tp: 113.0000 - fp: 212.0000 - tn: 232.0000 - fn: 155.0000 - accuracy: 0.4846 - precision: 0.3477 - recall: 0.4216 - auc: 0.4772 - val_loss: 4.1949 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 246/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 4.1891 - tp: 121.0000 - fp: 187.0000 - tn: 257.0000 - fn: 147.0000 - accuracy: 0.5309 - precision: 0.3929 - recall: 0.4515 - auc: 0.5196 - val_loss: 4.1884 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 247/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 4.1862 - tp: 112.0000 - fp: 193.0000 - tn: 251.0000 - fn: 156.0000 - accuracy: 0.5098 - precision: 0.3672 - recall: 0.4179 - auc: 0.4997 - val_loss: 4.1819 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 248/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 4.1734 - tp: 116.0000 - fp: 187.0000 - tn: 257.0000 - fn: 152.0000 - accuracy: 0.5239 - precision: 0.3828 - recall: 0.4328 - auc: 0.5246 - val_loss: 4.1755 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 249/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 4.1733 - tp: 111.0000 - fp: 189.0000 - tn: 255.0000 - fn: 157.0000 - accuracy: 0.5140 - precision: 0.3700 - recall: 0.4142 - auc: 0.4952 - val_loss: 4.1690 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 250/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 4.1595 - tp: 117.0000 - fp: 179.0000 - tn: 265.0000 - fn: 151.0000 - accuracy: 0.5365 - precision: 0.3953 - recall: 0.4366 - auc: 0.5328 - val_loss: 4.1625 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 251/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 4.1728 - tp: 100.0000 - fp: 195.0000 - tn: 249.0000 - fn: 168.0000 - accuracy: 0.4902 - precision: 0.3390 - recall: 0.3731 - auc: 0.4601 - val_loss: 4.1560 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 252/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 4.1598 - tp: 112.0000 - fp: 173.0000 - tn: 271.0000 - fn: 156.0000 - accuracy: 0.5379 - precision: 0.3930 - recall: 0.4179 - auc: 0.4813 - val_loss: 4.1496 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 253/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 4.1505 - tp: 112.0000 - fp: 192.0000 - tn: 252.0000 - fn: 156.0000 - accuracy: 0.5112 - precision: 0.3684 - recall: 0.4179 - auc: 0.4948 - val_loss: 4.1431 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 254/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 4.1413 - tp: 125.0000 - fp: 203.0000 - tn: 241.0000 - fn: 143.0000 - accuracy: 0.5140 - precision: 0.3811 - recall: 0.4664 - auc: 0.5039 - val_loss: 4.1367 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 255/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 4.1411 - tp: 106.0000 - fp: 190.0000 - tn: 254.0000 - fn: 162.0000 - accuracy: 0.5056 - precision: 0.3581 - recall: 0.3955 - auc: 0.4817 - val_loss: 4.1303 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 256/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 4.1286 - tp: 109.0000 - fp: 188.0000 - tn: 256.0000 - fn: 159.0000 - accuracy: 0.5126 - precision: 0.3670 - recall: 0.4067 - auc: 0.4976 - val_loss: 4.1239 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 257/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 4.1226 - tp: 119.0000 - fp: 194.0000 - tn: 250.0000 - fn: 149.0000 - accuracy: 0.5183 - precision: 0.3802 - recall: 0.4440 - auc: 0.4991 - val_loss: 4.1175 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 258/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 4.0999 - tp: 136.0000 - fp: 177.0000 - tn: 267.0000 - fn: 132.0000 - accuracy: 0.5660 - precision: 0.4345 - recall: 0.5075 - auc: 0.5554 - val_loss: 4.1111 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 259/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 4.1114 - tp: 136.0000 - fp: 208.0000 - tn: 236.0000 - fn: 132.0000 - accuracy: 0.5225 - precision: 0.3953 - recall: 0.5075 - auc: 0.5053 - val_loss: 4.1047 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 260/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 4.1071 - tp: 104.0000 - fp: 181.0000 - tn: 263.0000 - fn: 164.0000 - accuracy: 0.5154 - precision: 0.3649 - recall: 0.3881 - auc: 0.4779 - val_loss: 4.0984 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5048\n",
      "Epoch 261/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 4.0917 - tp: 109.0000 - fp: 206.0000 - tn: 238.0000 - fn: 159.0000 - accuracy: 0.4874 - precision: 0.3460 - recall: 0.4067 - auc: 0.4922 - val_loss: 4.0920 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5048\n",
      "Epoch 262/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 4.0887 - tp: 116.0000 - fp: 177.0000 - tn: 267.0000 - fn: 152.0000 - accuracy: 0.5379 - precision: 0.3959 - recall: 0.4328 - auc: 0.5069 - val_loss: 4.0855 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5048\n",
      "Epoch 263/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 4.0810 - tp: 119.0000 - fp: 197.0000 - tn: 247.0000 - fn: 149.0000 - accuracy: 0.5140 - precision: 0.3766 - recall: 0.4440 - auc: 0.5059 - val_loss: 4.0792 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 264/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 4.0725 - tp: 123.0000 - fp: 195.0000 - tn: 249.0000 - fn: 145.0000 - accuracy: 0.5225 - precision: 0.3868 - recall: 0.4590 - auc: 0.5212 - val_loss: 4.0728 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 265/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 4.0627 - tp: 114.0000 - fp: 167.0000 - tn: 277.0000 - fn: 154.0000 - accuracy: 0.5492 - precision: 0.4057 - recall: 0.4254 - auc: 0.5244 - val_loss: 4.0664 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 266/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 4.0591 - tp: 112.0000 - fp: 188.0000 - tn: 256.0000 - fn: 156.0000 - accuracy: 0.5169 - precision: 0.3733 - recall: 0.4179 - auc: 0.5144 - val_loss: 4.0600 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 267/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 4.0603 - tp: 118.0000 - fp: 197.0000 - tn: 247.0000 - fn: 150.0000 - accuracy: 0.5126 - precision: 0.3746 - recall: 0.4403 - auc: 0.4935 - val_loss: 4.0537 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 268/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 4.0528 - tp: 139.0000 - fp: 207.0000 - tn: 237.0000 - fn: 129.0000 - accuracy: 0.5281 - precision: 0.4017 - recall: 0.5187 - auc: 0.5022 - val_loss: 4.0474 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 269/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 4.0421 - tp: 134.0000 - fp: 188.0000 - tn: 256.0000 - fn: 134.0000 - accuracy: 0.5478 - precision: 0.4161 - recall: 0.5000 - auc: 0.5149 - val_loss: 4.0411 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 270/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 4.0297 - tp: 134.0000 - fp: 206.0000 - tn: 238.0000 - fn: 134.0000 - accuracy: 0.5225 - precision: 0.3941 - recall: 0.5000 - auc: 0.5323 - val_loss: 4.0348 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 271/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 4.0347 - tp: 121.0000 - fp: 195.0000 - tn: 249.0000 - fn: 147.0000 - accuracy: 0.5197 - precision: 0.3829 - recall: 0.4515 - auc: 0.4994 - val_loss: 4.0285 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 272/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 4.0112 - tp: 123.0000 - fp: 168.0000 - tn: 276.0000 - fn: 145.0000 - accuracy: 0.5604 - precision: 0.4227 - recall: 0.4590 - auc: 0.5488 - val_loss: 4.0222 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 273/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 4.0167 - tp: 115.0000 - fp: 202.0000 - tn: 242.0000 - fn: 153.0000 - accuracy: 0.5014 - precision: 0.3628 - recall: 0.4291 - auc: 0.5110 - val_loss: 4.0159 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 274/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 4.0265 - tp: 105.0000 - fp: 199.0000 - tn: 245.0000 - fn: 163.0000 - accuracy: 0.4916 - precision: 0.3454 - recall: 0.3918 - auc: 0.4520 - val_loss: 4.0095 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5048\n",
      "Epoch 275/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 4.0078 - tp: 124.0000 - fp: 194.0000 - tn: 250.0000 - fn: 144.0000 - accuracy: 0.5253 - precision: 0.3899 - recall: 0.4627 - auc: 0.5046 - val_loss: 4.0032 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5286\n",
      "Epoch 276/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 3.9989 - tp: 110.0000 - fp: 167.0000 - tn: 277.0000 - fn: 158.0000 - accuracy: 0.5435 - precision: 0.3971 - recall: 0.4104 - auc: 0.5053 - val_loss: 3.9969 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5048\n",
      "Epoch 277/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 3.9875 - tp: 115.0000 - fp: 175.0000 - tn: 269.0000 - fn: 153.0000 - accuracy: 0.5393 - precision: 0.3966 - recall: 0.4291 - auc: 0.5250 - val_loss: 3.9906 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 278/500\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 3s 4ms/sample - loss: 1.9895 - tp: 14.0000 - fp: 24.0000 - tn: 420.0000 - fn: 254.0000 - accuracy: 0.6096 - precision: 0.3684 - recall: 0.0522 - auc: 0.5337 - val_loss: 2.0149 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3025\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.9766 - tp: 21.0000 - fp: 25.0000 - tn: 419.0000 - fn: 247.0000 - accuracy: 0.6180 - precision: 0.4565 - recall: 0.0784 - auc: 0.4926 - val_loss: 1.9864 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3476\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.9579 - tp: 16.0000 - fp: 38.0000 - tn: 406.0000 - fn: 252.0000 - accuracy: 0.5927 - precision: 0.2963 - recall: 0.0597 - auc: 0.4759 - val_loss: 1.9594 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3600\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.9316 - tp: 25.0000 - fp: 42.0000 - tn: 402.0000 - fn: 243.0000 - accuracy: 0.5997 - precision: 0.3731 - recall: 0.0933 - auc: 0.4936 - val_loss: 1.9327 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3680\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.9162 - tp: 26.0000 - fp: 49.0000 - tn: 395.0000 - fn: 242.0000 - accuracy: 0.5913 - precision: 0.3467 - recall: 0.0970 - auc: 0.4514 - val_loss: 1.9083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3369\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.8840 - tp: 32.0000 - fp: 51.0000 - tn: 393.0000 - fn: 236.0000 - accuracy: 0.5969 - precision: 0.3855 - recall: 0.1194 - auc: 0.4860 - val_loss: 1.8838 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3793\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.8656 - tp: 39.0000 - fp: 75.0000 - tn: 369.0000 - fn: 229.0000 - accuracy: 0.5730 - precision: 0.3421 - recall: 0.1455 - auc: 0.4817 - val_loss: 1.8616 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3447\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.8449 - tp: 36.0000 - fp: 76.0000 - tn: 368.0000 - fn: 232.0000 - accuracy: 0.5674 - precision: 0.3214 - recall: 0.1343 - auc: 0.4701 - val_loss: 1.8392 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3946\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.8168 - tp: 50.0000 - fp: 75.0000 - tn: 369.0000 - fn: 218.0000 - accuracy: 0.5885 - precision: 0.4000 - recall: 0.1866 - auc: 0.5073 - val_loss: 1.8189 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3953\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.7893 - tp: 63.0000 - fp: 96.0000 - tn: 348.0000 - fn: 205.0000 - accuracy: 0.5772 - precision: 0.3962 - recall: 0.2351 - auc: 0.5224 - val_loss: 1.7985 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4349\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.7789 - tp: 60.0000 - fp: 99.0000 - tn: 345.0000 - fn: 208.0000 - accuracy: 0.5688 - precision: 0.3774 - recall: 0.2239 - auc: 0.5001 - val_loss: 1.7781 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3897\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.7582 - tp: 61.0000 - fp: 106.0000 - tn: 338.0000 - fn: 207.0000 - accuracy: 0.5604 - precision: 0.3653 - recall: 0.2276 - auc: 0.5092 - val_loss: 1.7585 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4107\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.7513 - tp: 59.0000 - fp: 133.0000 - tn: 311.0000 - fn: 209.0000 - accuracy: 0.5197 - precision: 0.3073 - recall: 0.2201 - auc: 0.4537 - val_loss: 1.7396 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4253\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.7296 - tp: 79.0000 - fp: 130.0000 - tn: 314.0000 - fn: 189.0000 - accuracy: 0.5520 - precision: 0.3780 - recall: 0.2948 - auc: 0.4784 - val_loss: 1.7208 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4234\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.6943 - tp: 73.0000 - fp: 109.0000 - tn: 335.0000 - fn: 195.0000 - accuracy: 0.5730 - precision: 0.4011 - recall: 0.2724 - auc: 0.5417 - val_loss: 1.7029 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4479\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.6866 - tp: 71.0000 - fp: 135.0000 - tn: 309.0000 - fn: 197.0000 - accuracy: 0.5337 - precision: 0.3447 - recall: 0.2649 - auc: 0.5076 - val_loss: 1.6851 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4398\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.6786 - tp: 87.0000 - fp: 159.0000 - tn: 285.0000 - fn: 181.0000 - accuracy: 0.5225 - precision: 0.3537 - recall: 0.3246 - auc: 0.4612 - val_loss: 1.6681 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4526\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.6521 - tp: 83.0000 - fp: 119.0000 - tn: 325.0000 - fn: 185.0000 - accuracy: 0.5730 - precision: 0.4109 - recall: 0.3097 - auc: 0.5060 - val_loss: 1.6506 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4663\n",
      "Epoch 19/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.6412 - tp: 88.0000 - fp: 155.0000 - tn: 289.0000 - fn: 180.0000 - accuracy: 0.5295 - precision: 0.3621 - recall: 0.3284 - auc: 0.4768 - val_loss: 1.6334 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4633\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.6150 - tp: 106.0000 - fp: 157.0000 - tn: 287.0000 - fn: 162.0000 - accuracy: 0.5520 - precision: 0.4030 - recall: 0.3955 - auc: 0.5154 - val_loss: 1.6165 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5136\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.6011 - tp: 104.0000 - fp: 171.0000 - tn: 273.0000 - fn: 164.0000 - accuracy: 0.5295 - precision: 0.3782 - recall: 0.3881 - auc: 0.5076 - val_loss: 1.6005 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5274\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.5823 - tp: 93.0000 - fp: 147.0000 - tn: 297.0000 - fn: 175.0000 - accuracy: 0.5478 - precision: 0.3875 - recall: 0.3470 - auc: 0.5229 - val_loss: 1.5840 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5058\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.5750 - tp: 109.0000 - fp: 167.0000 - tn: 277.0000 - fn: 159.0000 - accuracy: 0.5421 - precision: 0.3949 - recall: 0.4067 - auc: 0.4923 - val_loss: 1.5680 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5050\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.5553 - tp: 104.0000 - fp: 157.0000 - tn: 287.0000 - fn: 164.0000 - accuracy: 0.5492 - precision: 0.3985 - recall: 0.3881 - auc: 0.5047 - val_loss: 1.5524 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5999\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.5353 - tp: 116.0000 - fp: 167.0000 - tn: 277.0000 - fn: 152.0000 - accuracy: 0.5520 - precision: 0.4099 - recall: 0.4328 - auc: 0.5230 - val_loss: 1.5371 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5908\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 1.5308 - tp: 102.0000 - fp: 175.0000 - tn: 269.0000 - fn: 166.0000 - accuracy: 0.5211 - precision: 0.3682 - recall: 0.3806 - auc: 0.4854 - val_loss: 1.5220 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5377\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 1.5162 - tp: 102.0000 - fp: 176.0000 - tn: 268.0000 - fn: 166.0000 - accuracy: 0.5197 - precision: 0.3669 - recall: 0.3806 - auc: 0.4857 - val_loss: 1.5069 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6243\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.4934 - tp: 107.0000 - fp: 175.0000 - tn: 269.0000 - fn: 161.0000 - accuracy: 0.5281 - precision: 0.3794 - recall: 0.3993 - auc: 0.5150 - val_loss: 1.4922 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6086\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.4740 - tp: 108.0000 - fp: 161.0000 - tn: 283.0000 - fn: 160.0000 - accuracy: 0.5492 - precision: 0.4015 - recall: 0.4030 - auc: 0.5258 - val_loss: 1.4772 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6652\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.4615 - tp: 120.0000 - fp: 194.0000 - tn: 250.0000 - fn: 148.0000 - accuracy: 0.5197 - precision: 0.3822 - recall: 0.4478 - auc: 0.5249 - val_loss: 1.4633 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6019\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.4666 - tp: 105.0000 - fp: 204.0000 - tn: 240.0000 - fn: 163.0000 - accuracy: 0.4846 - precision: 0.3398 - recall: 0.3918 - auc: 0.4566 - val_loss: 1.4495 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6067\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.4401 - tp: 111.0000 - fp: 191.0000 - tn: 253.0000 - fn: 157.0000 - accuracy: 0.5112 - precision: 0.3675 - recall: 0.4142 - auc: 0.5022 - val_loss: 1.4355 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6808\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.4246 - tp: 107.0000 - fp: 180.0000 - tn: 264.0000 - fn: 161.0000 - accuracy: 0.5211 - precision: 0.3728 - recall: 0.3993 - auc: 0.5060 - val_loss: 1.4220 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7166\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.4077 - tp: 116.0000 - fp: 175.0000 - tn: 269.0000 - fn: 152.0000 - accuracy: 0.5407 - precision: 0.3986 - recall: 0.4328 - auc: 0.5261 - val_loss: 1.4090 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6914\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.4021 - tp: 116.0000 - fp: 203.0000 - tn: 241.0000 - fn: 152.0000 - accuracy: 0.5014 - precision: 0.3636 - recall: 0.4328 - auc: 0.4855 - val_loss: 1.3957 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6297\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.3822 - tp: 116.0000 - fp: 185.0000 - tn: 259.0000 - fn: 152.0000 - accuracy: 0.5267 - precision: 0.3854 - recall: 0.4328 - auc: 0.5152 - val_loss: 1.3827 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6233\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3705 - tp: 123.0000 - fp: 191.0000 - tn: 253.0000 - fn: 145.0000 - accuracy: 0.5281 - precision: 0.3917 - recall: 0.4590 - auc: 0.5127 - val_loss: 1.3701 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5835\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.3625 - tp: 113.0000 - fp: 183.0000 - tn: 261.0000 - fn: 155.0000 - accuracy: 0.5253 - precision: 0.3818 - recall: 0.4216 - auc: 0.4999 - val_loss: 1.3578 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6168\n",
      "Epoch 39/500\n",
      " 32/712 [>.............................]Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/400\n",
      "712/712 [==============================] - 4s 5ms/sample - loss: 4.8494 - tp: 230.0000 - fp: 362.0000 - tn: 82.0000 - fn: 38.0000 - accuracy: 0.4382 - precision: 0.3885 - recall: 0.8582 - auc: 0.5219 - val_loss: 4.4182 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.6379\n",
      "Epoch 2/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 4.1218 - tp: 183.0000 - fp: 291.0000 - tn: 153.0000 - fn: 85.0000 - accuracy: 0.4719 - precision: 0.3861 - recall: 0.6828 - auc: 0.5053 - val_loss: 3.7844 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 73.0000 - val_accuracy: 0.5922 - val_precision: 1.0000 - val_recall: 0.0135 - val_auc: 0.6754\n",
      "Epoch 3/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 3.4924 - tp: 140.0000 - fp: 216.0000 - tn: 228.0000 - fn: 128.0000 - accuracy: 0.5169 - precision: 0.3933 - recall: 0.5224 - auc: 0.5249 - val_loss: 3.1897 - val_tp: 13.0000 - val_fp: 1.0000 - val_tn: 104.0000 - val_fn: 61.0000 - val_accuracy: 0.6536 - val_precision: 0.9286 - val_recall: 0.1757 - val_auc: 0.7992\n",
      "Epoch 4/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 2.9266 - tp: 95.0000 - fp: 183.0000 - tn: 261.0000 - fn: 173.0000 - accuracy: 0.5000 - precision: 0.3417 - recall: 0.3545 - auc: 0.4817 - val_loss: 2.6542 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 5/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 2.4152 - tp: 49.0000 - fp: 91.0000 - tn: 353.0000 - fn: 219.0000 - accuracy: 0.5646 - precision: 0.3500 - recall: 0.1828 - auc: 0.4738 - val_loss: 2.1765 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 6/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 1.9657 - tp: 37.0000 - fp: 39.0000 - tn: 405.0000 - fn: 231.0000 - accuracy: 0.6208 - precision: 0.4868 - recall: 0.1381 - auc: 0.5111 - val_loss: 1.7663 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 7/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.5874 - tp: 8.0000 - fp: 8.0000 - tn: 436.0000 - fn: 260.0000 - accuracy: 0.6236 - precision: 0.5000 - recall: 0.0299 - auc: 0.5101 - val_loss: 1.4229 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 8/400\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 1.2785 - tp: 0.0000e+00 - fp: 2.0000 - tn: 442.0000 - fn: 268.0000 - accuracy: 0.6208 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5046 - val_loss: 1.1553 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 9/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 1.0472 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4989 - val_loss: 0.9661 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 10/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.8925 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4966 - val_loss: 0.8504 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 11/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.8068 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4924 - val_loss: 0.7925 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 12/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7610 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4874 - val_loss: 0.7574 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 13/400\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.7334 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4674 - val_loss: 0.7372 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 14/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7188 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4960 - val_loss: 0.7284 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 15/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7131 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4886 - val_loss: 0.7249 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 16/400\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7112 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4886 - val_loss: 0.7244 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 17/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.7098 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4911 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 18/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7093 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4833 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 19/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4701 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 20/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5084 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 21/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4952 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 22/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 23/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5053 - val_loss: 0.7222 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 24/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4922 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 25/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5002 - val_loss: 0.7221 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 26/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4612 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 27/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4636 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 28/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4662 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 29/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4897 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 30/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4736 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 31/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4840 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 32/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4948 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 33/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4884 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 34/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4951 - val_loss: 0.7229 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 35/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4950 - val_loss: 0.7223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 36/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4953 - val_loss: 0.7229 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 37/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4640 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 38/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4895 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 39/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4996 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 40/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4832 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 41/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4839 - val_loss: 0.7223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 42/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4729 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 43/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4566 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 44/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7233 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 45/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 46/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7232 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 47/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 48/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4752 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 49/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4888 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 50/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7088 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5271 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 51/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4866 - val_loss: 0.7221 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 52/400\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4784 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 53/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4983 - val_loss: 0.7221 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 54/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5018 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 55/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4868 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 56/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4868 - val_loss: 0.7229 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 57/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5052 - val_loss: 0.7223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 58/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4855 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 59/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7088 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5234 - val_loss: 0.7222 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 60/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4895 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 61/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4837 - val_loss: 0.7222 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 62/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4826 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 63/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5129 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 64/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4963 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 65/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4598 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 66/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4746 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 67/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 68/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4882 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 69/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4696 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 70/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4835 - val_loss: 0.7229 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 71/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4800 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 72/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4848 - val_loss: 0.7229 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 73/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4934 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 74/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4808 - val_loss: 0.7232 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 75/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4927 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 76/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 77/400\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4777 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 78/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4995 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 79/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4839 - val_loss: 0.7229 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 80/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7232 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 81/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4905 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 82/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5034 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 83/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4840 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 84/400\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4801 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 85/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7088 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 86/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4881 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 87/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 88/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4857 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 89/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5079 - val_loss: 0.7223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 90/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5022 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 91/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7092 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4728 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 92/400\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5054 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 93/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7088 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5226 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 94/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4951 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 95/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5042 - val_loss: 0.7222 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 96/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4878 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 97/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4968 - val_loss: 0.7222 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 98/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5091 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 99/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4962 - val_loss: 0.7223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 100/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4955 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 101/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7088 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4916 - val_loss: 0.7223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 102/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4851 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 103/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4979 - val_loss: 0.7223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 104/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4829 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 105/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4783 - val_loss: 0.7222 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 106/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4919 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 107/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4974 - val_loss: 0.7223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 108/400\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4688 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 109/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5048 - val_loss: 0.7222 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 110/400\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4966 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 111/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7088 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5101 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 112/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4781 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 113/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5021 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 114/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5015 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 115/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4692 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 116/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4824 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 117/400\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4871 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 118/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4944 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 119/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7088 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5219 - val_loss: 0.7223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 120/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7092 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4796 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 121/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4687 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 122/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4992 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 123/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 124/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4697 - val_loss: 0.7233 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 125/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 126/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7234 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 127/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7229 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 128/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 129/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4977 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 130/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 131/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 132/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4655 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 133/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4632 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 134/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 135/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 136/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4732 - val_loss: 0.7229 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 137/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4888 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 138/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4995 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 139/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5083 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 140/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 141/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 142/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4905 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 143/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4981 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 144/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4927 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 145/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4765 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 146/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4940 - val_loss: 0.7232 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 147/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 148/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4750 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 149/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 150/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4945 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 151/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 152/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4890 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 153/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4883 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 154/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 155/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 156/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 157/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 158/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4936 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 159/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4876 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 160/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7088 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5295 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 161/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4957 - val_loss: 0.7222 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 162/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7088 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5198 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 163/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4484 - val_loss: 0.7224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 164/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4952 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 165/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4721 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 166/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4779 - val_loss: 0.7229 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 167/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4614 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 168/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4837 - val_loss: 0.7232 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 169/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4935 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 170/400\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 171/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4832 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 172/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7088 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4945 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 173/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4884 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 174/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4866 - val_loss: 0.7233 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 175/400\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4916 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 176/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 177/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 178/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7232 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 179/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 180/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7232 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 181/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 182/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 183/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5076 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 184/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4757 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 185/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4937 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 186/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4658 - val_loss: 0.7230 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 187/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4588 - val_loss: 0.7226 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 188/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4807 - val_loss: 0.7229 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 189/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4976 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 190/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4931 - val_loss: 0.7228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 191/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4756 - val_loss: 0.7225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 192/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4790 - val_loss: 0.7229 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 193/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 5.6303 - tp: 128.0000 - fp: 197.0000 - tn: 247.0000 - fn: 140.0000 - accuracy: 0.5267 - precision: 0.3938 - recall: 0.4776 - auc: 0.5183 - val_loss: 5.6351 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4181\n",
      "Epoch 403/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 5.6286 - tp: 132.0000 - fp: 220.0000 - tn: 224.0000 - fn: 136.0000 - accuracy: 0.5000 - precision: 0.3750 - recall: 0.4925 - auc: 0.5139 - val_loss: 5.6350 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4181\n",
      "Epoch 404/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 5.6453 - tp: 114.0000 - fp: 226.0000 - tn: 218.0000 - fn: 154.0000 - accuracy: 0.4663 - precision: 0.3353 - recall: 0.4254 - auc: 0.4549 - val_loss: 5.6349 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4181\n",
      "Epoch 405/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 5.6434 - tp: 121.0000 - fp: 213.0000 - tn: 231.0000 - fn: 147.0000 - accuracy: 0.4944 - precision: 0.3623 - recall: 0.4515 - auc: 0.4798 - val_loss: 5.6348 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4181\n",
      "Epoch 406/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 5.6312 - tp: 145.0000 - fp: 223.0000 - tn: 221.0000 - fn: 123.0000 - accuracy: 0.5140 - precision: 0.3940 - recall: 0.5410 - auc: 0.5180 - val_loss: 5.6348 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4181\n",
      "Epoch 407/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 5.6363 - tp: 124.0000 - fp: 214.0000 - tn: 230.0000 - fn: 144.0000 - accuracy: 0.4972 - precision: 0.3669 - recall: 0.4627 - auc: 0.4912 - val_loss: 5.6347 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4198\n",
      "Epoch 408/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 5.6360 - tp: 143.0000 - fp: 222.0000 - tn: 222.0000 - fn: 125.0000 - accuracy: 0.5126 - precision: 0.3918 - recall: 0.5336 - auc: 0.5039 - val_loss: 5.6346 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4198\n",
      "Epoch 409/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 5.6418 - tp: 126.0000 - fp: 219.0000 - tn: 225.0000 - fn: 142.0000 - accuracy: 0.4930 - precision: 0.3652 - recall: 0.4701 - auc: 0.4672 - val_loss: 5.6345 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4198\n",
      "Epoch 410/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 5.6437 - tp: 116.0000 - fp: 216.0000 - tn: 228.0000 - fn: 152.0000 - accuracy: 0.4831 - precision: 0.3494 - recall: 0.4328 - auc: 0.4524 - val_loss: 5.6345 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4198\n",
      "Epoch 411/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 5.6454 - tp: 134.0000 - fp: 234.0000 - tn: 210.0000 - fn: 134.0000 - accuracy: 0.4831 - precision: 0.3641 - recall: 0.5000 - auc: 0.4684 - val_loss: 5.6344 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 412/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 5.6300 - tp: 134.0000 - fp: 214.0000 - tn: 230.0000 - fn: 134.0000 - accuracy: 0.5112 - precision: 0.3851 - recall: 0.5000 - auc: 0.5128 - val_loss: 5.6343 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 413/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 5.6284 - tp: 144.0000 - fp: 214.0000 - tn: 230.0000 - fn: 124.0000 - accuracy: 0.5253 - precision: 0.4022 - recall: 0.5373 - auc: 0.5144 - val_loss: 5.6342 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 414/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 5.6383 - tp: 126.0000 - fp: 218.0000 - tn: 226.0000 - fn: 142.0000 - accuracy: 0.4944 - precision: 0.3663 - recall: 0.4701 - auc: 0.4849 - val_loss: 5.6342 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 415/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 5.6438 - tp: 123.0000 - fp: 218.0000 - tn: 226.0000 - fn: 145.0000 - accuracy: 0.4902 - precision: 0.3607 - recall: 0.4590 - auc: 0.4658 - val_loss: 5.6341 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 416/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 5.6370 - tp: 121.0000 - fp: 231.0000 - tn: 213.0000 - fn: 147.0000 - accuracy: 0.4691 - precision: 0.3438 - recall: 0.4515 - auc: 0.4728 - val_loss: 5.6340 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 417/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 5.6324 - tp: 130.0000 - fp: 232.0000 - tn: 212.0000 - fn: 138.0000 - accuracy: 0.4803 - precision: 0.3591 - recall: 0.4851 - auc: 0.4873 - val_loss: 5.6339 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 418/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 5.6308 - tp: 138.0000 - fp: 213.0000 - tn: 231.0000 - fn: 130.0000 - accuracy: 0.5183 - precision: 0.3932 - recall: 0.5149 - auc: 0.5090 - val_loss: 5.6338 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 419/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 5.6255 - tp: 150.0000 - fp: 218.0000 - tn: 226.0000 - fn: 118.0000 - accuracy: 0.5281 - precision: 0.4076 - recall: 0.5597 - auc: 0.5225 - val_loss: 5.6338 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 420/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 5.6326 - tp: 130.0000 - fp: 231.0000 - tn: 213.0000 - fn: 138.0000 - accuracy: 0.4817 - precision: 0.3601 - recall: 0.4851 - auc: 0.4995 - val_loss: 5.6337 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 421/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 5.6311 - tp: 131.0000 - fp: 219.0000 - tn: 225.0000 - fn: 137.0000 - accuracy: 0.5000 - precision: 0.3743 - recall: 0.4888 - auc: 0.5045 - val_loss: 5.6336 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 422/500\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 5.6315 - tp: 129.0000 - fp: 226.0000 - tn: 218.0000 - fn: 139.0000 - accuracy: 0.4874 - precision: 0.3634 - recall: 0.4813 - auc: 0.4988 - val_loss: 5.6335 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 423/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 5.6289 - tp: 133.0000 - fp: 214.0000 - tn: 230.0000 - fn: 135.0000 - accuracy: 0.5098 - precision: 0.3833 - recall: 0.4963 - auc: 0.4990 - val_loss: 5.6335 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 424/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 5.6391 - tp: 133.0000 - fp: 211.0000 - tn: 233.0000 - fn: 135.0000 - accuracy: 0.5140 - precision: 0.3866 - recall: 0.4963 - auc: 0.4814 - val_loss: 5.6334 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 425/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 5.6407 - tp: 119.0000 - fp: 231.0000 - tn: 213.0000 - fn: 149.0000 - accuracy: 0.4663 - precision: 0.3400 - recall: 0.4440 - auc: 0.4730 - val_loss: 5.6333 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 426/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 5.6316 - tp: 134.0000 - fp: 224.0000 - tn: 220.0000 - fn: 134.0000 - accuracy: 0.4972 - precision: 0.3743 - recall: 0.5000 - auc: 0.5014 - val_loss: 5.6332 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 427/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 5.6425 - tp: 127.0000 - fp: 234.0000 - tn: 210.0000 - fn: 141.0000 - accuracy: 0.4733 - precision: 0.3518 - recall: 0.4739 - auc: 0.4605 - val_loss: 5.6332 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 428/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 5.6422 - tp: 126.0000 - fp: 234.0000 - tn: 210.0000 - fn: 142.0000 - accuracy: 0.4719 - precision: 0.3500 - recall: 0.4701 - auc: 0.4594 - val_loss: 5.6331 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 429/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 5.6363 - tp: 138.0000 - fp: 215.0000 - tn: 229.0000 - fn: 130.0000 - accuracy: 0.5154 - precision: 0.3909 - recall: 0.5149 - auc: 0.4814 - val_loss: 5.6330 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 430/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 5.6370 - tp: 128.0000 - fp: 224.0000 - tn: 220.0000 - fn: 140.0000 - accuracy: 0.4888 - precision: 0.3636 - recall: 0.4776 - auc: 0.4784 - val_loss: 5.6329 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 431/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 5.6297 - tp: 125.0000 - fp: 213.0000 - tn: 231.0000 - fn: 143.0000 - accuracy: 0.5000 - precision: 0.3698 - recall: 0.4664 - auc: 0.4993 - val_loss: 5.6329 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 432/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 5.6349 - tp: 132.0000 - fp: 239.0000 - tn: 205.0000 - fn: 136.0000 - accuracy: 0.4733 - precision: 0.3558 - recall: 0.4925 - auc: 0.4874 - val_loss: 5.6328 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 433/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 5.6379 - tp: 138.0000 - fp: 251.0000 - tn: 193.0000 - fn: 130.0000 - accuracy: 0.4649 - precision: 0.3548 - recall: 0.5149 - auc: 0.4724 - val_loss: 5.6327 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 434/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 5.6364 - tp: 126.0000 - fp: 224.0000 - tn: 220.0000 - fn: 142.0000 - accuracy: 0.4860 - precision: 0.3600 - recall: 0.4701 - auc: 0.4796 - val_loss: 5.6326 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 435/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 5.6351 - tp: 127.0000 - fp: 237.0000 - tn: 207.0000 - fn: 141.0000 - accuracy: 0.4691 - precision: 0.3489 - recall: 0.4739 - auc: 0.4782 - val_loss: 5.6325 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 436/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 5.6214 - tp: 146.0000 - fp: 220.0000 - tn: 224.0000 - fn: 122.0000 - accuracy: 0.5197 - precision: 0.3989 - recall: 0.5448 - auc: 0.5344 - val_loss: 5.6325 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 437/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 5.6343 - tp: 133.0000 - fp: 251.0000 - tn: 193.0000 - fn: 135.0000 - accuracy: 0.4579 - precision: 0.3464 - recall: 0.4963 - auc: 0.4755 - val_loss: 5.6324 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 438/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 5.6203 - tp: 144.0000 - fp: 229.0000 - tn: 215.0000 - fn: 124.0000 - accuracy: 0.5042 - precision: 0.3861 - recall: 0.5373 - auc: 0.5332 - val_loss: 5.6323 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 439/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 5.6369 - tp: 124.0000 - fp: 241.0000 - tn: 203.0000 - fn: 144.0000 - accuracy: 0.4593 - precision: 0.3397 - recall: 0.4627 - auc: 0.4787 - val_loss: 5.6322 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 440/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 5.6402 - tp: 123.0000 - fp: 234.0000 - tn: 210.0000 - fn: 145.0000 - accuracy: 0.4677 - precision: 0.3445 - recall: 0.4590 - auc: 0.4677 - val_loss: 5.6322 - val_tp: 67.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.4358 - val_precision: 0.4161 - val_recall: 0.9054 - val_auc: 0.4191\n",
      "Epoch 441/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6947 - tp: 109.0000 - fp: 196.0000 - tn: 248.0000 - fn: 159.0000 - accuracy: 0.5014 - precision: 0.3574 - recall: 0.4067 - auc: 0.4813 - val_loss: 0.7043 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 368/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6898 - tp: 122.0000 - fp: 189.0000 - tn: 255.0000 - fn: 146.0000 - accuracy: 0.5295 - precision: 0.3923 - recall: 0.4552 - auc: 0.5275 - val_loss: 0.7043 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 369/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6907 - tp: 133.0000 - fp: 216.0000 - tn: 228.0000 - fn: 135.0000 - accuracy: 0.5070 - precision: 0.3811 - recall: 0.4963 - auc: 0.5209 - val_loss: 0.7044 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 370/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6912 - tp: 128.0000 - fp: 184.0000 - tn: 260.0000 - fn: 140.0000 - accuracy: 0.5449 - precision: 0.4103 - recall: 0.4776 - auc: 0.5267 - val_loss: 0.7044 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 371/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6892 - tp: 123.0000 - fp: 180.0000 - tn: 264.0000 - fn: 145.0000 - accuracy: 0.5435 - precision: 0.4059 - recall: 0.4590 - auc: 0.5332 - val_loss: 0.7044 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 372/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6910 - tp: 126.0000 - fp: 191.0000 - tn: 253.0000 - fn: 142.0000 - accuracy: 0.5323 - precision: 0.3975 - recall: 0.4701 - auc: 0.5188 - val_loss: 0.7043 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 373/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6899 - tp: 127.0000 - fp: 173.0000 - tn: 271.0000 - fn: 141.0000 - accuracy: 0.5590 - precision: 0.4233 - recall: 0.4739 - auc: 0.5342 - val_loss: 0.7043 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 374/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6955 - tp: 123.0000 - fp: 207.0000 - tn: 237.0000 - fn: 145.0000 - accuracy: 0.5056 - precision: 0.3727 - recall: 0.4590 - auc: 0.4695 - val_loss: 0.7043 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 375/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6914 - tp: 122.0000 - fp: 187.0000 - tn: 257.0000 - fn: 146.0000 - accuracy: 0.5323 - precision: 0.3948 - recall: 0.4552 - auc: 0.5255 - val_loss: 0.7044 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 376/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6953 - tp: 113.0000 - fp: 204.0000 - tn: 240.0000 - fn: 155.0000 - accuracy: 0.4958 - precision: 0.3565 - recall: 0.4216 - auc: 0.4800 - val_loss: 0.7043 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 377/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6923 - tp: 115.0000 - fp: 192.0000 - tn: 252.0000 - fn: 153.0000 - accuracy: 0.5154 - precision: 0.3746 - recall: 0.4291 - auc: 0.5040 - val_loss: 0.7043 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 378/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6923 - tp: 122.0000 - fp: 189.0000 - tn: 255.0000 - fn: 146.0000 - accuracy: 0.5295 - precision: 0.3923 - recall: 0.4552 - auc: 0.5103 - val_loss: 0.7043 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 379/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6910 - tp: 120.0000 - fp: 203.0000 - tn: 241.0000 - fn: 148.0000 - accuracy: 0.5070 - precision: 0.3715 - recall: 0.4478 - auc: 0.5098 - val_loss: 0.7044 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 380/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6940 - tp: 111.0000 - fp: 177.0000 - tn: 267.0000 - fn: 157.0000 - accuracy: 0.5309 - precision: 0.3854 - recall: 0.4142 - auc: 0.4934 - val_loss: 0.7044 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 381/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6910 - tp: 123.0000 - fp: 186.0000 - tn: 258.0000 - fn: 145.0000 - accuracy: 0.5351 - precision: 0.3981 - recall: 0.4590 - auc: 0.5214 - val_loss: 0.7044 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 382/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6934 - tp: 112.0000 - fp: 187.0000 - tn: 257.0000 - fn: 156.0000 - accuracy: 0.5183 - precision: 0.3746 - recall: 0.4179 - auc: 0.4965 - val_loss: 0.7044 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 383/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6953 - tp: 121.0000 - fp: 215.0000 - tn: 229.0000 - fn: 147.0000 - accuracy: 0.4916 - precision: 0.3601 - recall: 0.4515 - auc: 0.4691 - val_loss: 0.7042 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 384/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6910 - tp: 125.0000 - fp: 196.0000 - tn: 248.0000 - fn: 143.0000 - accuracy: 0.5239 - precision: 0.3894 - recall: 0.4664 - auc: 0.5121 - val_loss: 0.7042 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 385/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6959 - tp: 108.0000 - fp: 191.0000 - tn: 253.0000 - fn: 160.0000 - accuracy: 0.5070 - precision: 0.3612 - recall: 0.4030 - auc: 0.4668 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 386/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6941 - tp: 137.0000 - fp: 227.0000 - tn: 217.0000 - fn: 131.0000 - accuracy: 0.4972 - precision: 0.3764 - recall: 0.5112 - auc: 0.4943 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 387/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6913 - tp: 127.0000 - fp: 220.0000 - tn: 224.0000 - fn: 141.0000 - accuracy: 0.4930 - precision: 0.3660 - recall: 0.4739 - auc: 0.5233 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 388/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6960 - tp: 118.0000 - fp: 226.0000 - tn: 218.0000 - fn: 150.0000 - accuracy: 0.4719 - precision: 0.3430 - recall: 0.4403 - auc: 0.4608 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 389/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6927 - tp: 142.0000 - fp: 213.0000 - tn: 231.0000 - fn: 126.0000 - accuracy: 0.5239 - precision: 0.4000 - recall: 0.5299 - auc: 0.5124 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 390/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.6935 - tp: 130.0000 - fp: 221.0000 - tn: 223.0000 - fn: 138.0000 - accuracy: 0.4958 - precision: 0.3704 - recall: 0.4851 - auc: 0.5036 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 391/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6916 - tp: 125.0000 - fp: 210.0000 - tn: 234.0000 - fn: 143.0000 - accuracy: 0.5042 - precision: 0.3731 - recall: 0.4664 - auc: 0.5030 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 392/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6898 - tp: 144.0000 - fp: 207.0000 - tn: 237.0000 - fn: 124.0000 - accuracy: 0.5351 - precision: 0.4103 - recall: 0.5373 - auc: 0.5320 - val_loss: 0.7042 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 393/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6951 - tp: 119.0000 - fp: 214.0000 - tn: 230.0000 - fn: 149.0000 - accuracy: 0.4902 - precision: 0.3574 - recall: 0.4440 - auc: 0.4754 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 394/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6916 - tp: 139.0000 - fp: 204.0000 - tn: 240.0000 - fn: 129.0000 - accuracy: 0.5323 - precision: 0.4052 - recall: 0.5187 - auc: 0.5153 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 395/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6952 - tp: 115.0000 - fp: 208.0000 - tn: 236.0000 - fn: 153.0000 - accuracy: 0.4930 - precision: 0.3560 - recall: 0.4291 - auc: 0.4777 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 396/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.6932 - tp: 132.0000 - fp: 204.0000 - tn: 240.0000 - fn: 136.0000 - accuracy: 0.5225 - precision: 0.3929 - recall: 0.4925 - auc: 0.4970 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 397/500\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.6922 - tp: 131.0000 - fp: 230.0000 - tn: 214.0000 - fn: 137.0000 - accuracy: 0.4846 - precision: 0.3629 - recall: 0.4888 - auc: 0.4990 - val_loss: 0.7040 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 398/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6933 - tp: 124.0000 - fp: 227.0000 - tn: 217.0000 - fn: 144.0000 - accuracy: 0.4789 - precision: 0.3533 - recall: 0.4627 - auc: 0.4850 - val_loss: 0.7040 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 399/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6891 - tp: 126.0000 - fp: 186.0000 - tn: 258.0000 - fn: 142.0000 - accuracy: 0.5393 - precision: 0.4038 - recall: 0.4701 - auc: 0.5370 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 400/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6911 - tp: 139.0000 - fp: 217.0000 - tn: 227.0000 - fn: 129.0000 - accuracy: 0.5140 - precision: 0.3904 - recall: 0.5187 - auc: 0.5251 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 401/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6927 - tp: 126.0000 - fp: 205.0000 - tn: 239.0000 - fn: 142.0000 - accuracy: 0.5126 - precision: 0.3807 - recall: 0.4701 - auc: 0.5010 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 402/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6902 - tp: 135.0000 - fp: 201.0000 - tn: 243.0000 - fn: 133.0000 - accuracy: 0.5309 - precision: 0.4018 - recall: 0.5037 - auc: 0.5271 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 403/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6923 - tp: 134.0000 - fp: 209.0000 - tn: 235.0000 - fn: 134.0000 - accuracy: 0.5183 - precision: 0.3907 - recall: 0.5000 - auc: 0.5145 - val_loss: 0.7041 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 404/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6899 - tp: 120.0000 - fp: 185.0000 - tn: 259.0000 - fn: 148.0000 - accuracy: 0.5323 - precision: 0.3934 - recall: 0.4478 - auc: 0.5364 - val_loss: 0.7043 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 405/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6919 - tp: 124.0000 - fp: 189.0000 - tn: 255.0000 - fn: 144.0000 - accuracy: 0.5323 - precision: 0.3962 - recall: 0.4627 - auc: 0.5036 - val_loss: 0.7042 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 406/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 547/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4761 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 548/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4587 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 549/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4909 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 550/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4808 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 551/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 552/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 553/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 554/600\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4949 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 555/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 556/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4949 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 557/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6911 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4902 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 558/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4974 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 559/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 560/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 561/600\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4713 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 562/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4856 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 563/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4953 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 564/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4879 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 565/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6911 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4798 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 566/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4982 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 567/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4804 - val_loss: 0.7047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 568/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4733 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 569/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4750 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 570/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 571/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4838 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 572/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4819 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 573/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4529 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 574/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 575/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 576/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 577/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4735 - val_loss: 0.7049 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 578/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4792 - val_loss: 0.7049 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 579/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 580/600\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 581/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7049 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 582/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 583/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7048 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 584/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6368 - tp: 190.0000 - fp: 92.0000 - tn: 352.0000 - fn: 78.0000 - accuracy: 0.7612 - precision: 0.6738 - recall: 0.7090 - auc: 0.8105 - val_loss: 0.5738 - val_tp: 56.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 18.0000 - val_accuracy: 0.7654 - val_precision: 0.7000 - val_recall: 0.7568 - val_auc: 0.8811\n",
      "Epoch 274/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6468 - tp: 191.0000 - fp: 100.0000 - tn: 344.0000 - fn: 77.0000 - accuracy: 0.7514 - precision: 0.6564 - recall: 0.7127 - auc: 0.8028 - val_loss: 0.5739 - val_tp: 56.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 18.0000 - val_accuracy: 0.7654 - val_precision: 0.7000 - val_recall: 0.7568 - val_auc: 0.8807\n",
      "Epoch 275/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6376 - tp: 188.0000 - fp: 88.0000 - tn: 356.0000 - fn: 80.0000 - accuracy: 0.7640 - precision: 0.6812 - recall: 0.7015 - auc: 0.8086 - val_loss: 0.5736 - val_tp: 57.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 17.0000 - val_accuracy: 0.7709 - val_precision: 0.7037 - val_recall: 0.7703 - val_auc: 0.8806\n",
      "Epoch 276/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6212 - tp: 189.0000 - fp: 92.0000 - tn: 352.0000 - fn: 79.0000 - accuracy: 0.7598 - precision: 0.6726 - recall: 0.7052 - auc: 0.8227 - val_loss: 0.5731 - val_tp: 57.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 17.0000 - val_accuracy: 0.7709 - val_precision: 0.7037 - val_recall: 0.7703 - val_auc: 0.8804\n",
      "Epoch 277/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6261 - tp: 194.0000 - fp: 90.0000 - tn: 354.0000 - fn: 74.0000 - accuracy: 0.7697 - precision: 0.6831 - recall: 0.7239 - auc: 0.8213 - val_loss: 0.5723 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8808\n",
      "Epoch 278/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6293 - tp: 192.0000 - fp: 97.0000 - tn: 347.0000 - fn: 76.0000 - accuracy: 0.7570 - precision: 0.6644 - recall: 0.7164 - auc: 0.8116 - val_loss: 0.5732 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8816\n",
      "Epoch 279/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6274 - tp: 199.0000 - fp: 95.0000 - tn: 349.0000 - fn: 69.0000 - accuracy: 0.7697 - precision: 0.6769 - recall: 0.7425 - auc: 0.8135 - val_loss: 0.5738 - val_tp: 54.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 20.0000 - val_accuracy: 0.7654 - val_precision: 0.7105 - val_recall: 0.7297 - val_auc: 0.8810\n",
      "Epoch 280/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6487 - tp: 182.0000 - fp: 89.0000 - tn: 355.0000 - fn: 86.0000 - accuracy: 0.7542 - precision: 0.6716 - recall: 0.6791 - auc: 0.7983 - val_loss: 0.5735 - val_tp: 57.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 17.0000 - val_accuracy: 0.7709 - val_precision: 0.7037 - val_recall: 0.7703 - val_auc: 0.8816\n",
      "Epoch 281/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.6424 - tp: 192.0000 - fp: 104.0000 - tn: 340.0000 - fn: 76.0000 - accuracy: 0.7472 - precision: 0.6486 - recall: 0.7164 - auc: 0.8016 - val_loss: 0.5746 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8808\n",
      "Epoch 282/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.6433 - tp: 185.0000 - fp: 93.0000 - tn: 351.0000 - fn: 83.0000 - accuracy: 0.7528 - precision: 0.6655 - recall: 0.6903 - auc: 0.8038 - val_loss: 0.5752 - val_tp: 58.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 16.0000 - val_accuracy: 0.7765 - val_precision: 0.7073 - val_recall: 0.7838 - val_auc: 0.8808\n",
      "Epoch 283/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.6295 - tp: 196.0000 - fp: 102.0000 - tn: 342.0000 - fn: 72.0000 - accuracy: 0.7556 - precision: 0.6577 - recall: 0.7313 - auc: 0.8172 - val_loss: 0.5753 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8815\n",
      "Epoch 284/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6207 - tp: 187.0000 - fp: 85.0000 - tn: 359.0000 - fn: 81.0000 - accuracy: 0.7669 - precision: 0.6875 - recall: 0.6978 - auc: 0.8221 - val_loss: 0.5749 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8817\n",
      "Epoch 285/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6330 - tp: 186.0000 - fp: 96.0000 - tn: 348.0000 - fn: 82.0000 - accuracy: 0.7500 - precision: 0.6596 - recall: 0.6940 - auc: 0.8045 - val_loss: 0.5739 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8818\n",
      "Epoch 286/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6145 - tp: 192.0000 - fp: 99.0000 - tn: 345.0000 - fn: 76.0000 - accuracy: 0.7542 - precision: 0.6598 - recall: 0.7164 - auc: 0.8300 - val_loss: 0.5725 - val_tp: 57.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 17.0000 - val_accuracy: 0.7709 - val_precision: 0.7037 - val_recall: 0.7703 - val_auc: 0.8812\n",
      "Epoch 287/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6229 - tp: 194.0000 - fp: 89.0000 - tn: 355.0000 - fn: 74.0000 - accuracy: 0.7711 - precision: 0.6855 - recall: 0.7239 - auc: 0.8184 - val_loss: 0.5721 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8813\n",
      "Epoch 288/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.6213 - tp: 193.0000 - fp: 89.0000 - tn: 355.0000 - fn: 75.0000 - accuracy: 0.7697 - precision: 0.6844 - recall: 0.7201 - auc: 0.8233 - val_loss: 0.5716 - val_tp: 56.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 18.0000 - val_accuracy: 0.7654 - val_precision: 0.7000 - val_recall: 0.7568 - val_auc: 0.8815\n",
      "Epoch 289/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6219 - tp: 192.0000 - fp: 92.0000 - tn: 352.0000 - fn: 76.0000 - accuracy: 0.7640 - precision: 0.6761 - recall: 0.7164 - auc: 0.8172 - val_loss: 0.5714 - val_tp: 55.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 19.0000 - val_accuracy: 0.7654 - val_precision: 0.7051 - val_recall: 0.7432 - val_auc: 0.8821\n",
      "Epoch 290/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6564 - tp: 186.0000 - fp: 101.0000 - tn: 343.0000 - fn: 82.0000 - accuracy: 0.7430 - precision: 0.6481 - recall: 0.6940 - auc: 0.7843 - val_loss: 0.5721 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8819\n",
      "Epoch 291/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6232 - tp: 195.0000 - fp: 83.0000 - tn: 361.0000 - fn: 73.0000 - accuracy: 0.7809 - precision: 0.7014 - recall: 0.7276 - auc: 0.8221 - val_loss: 0.5713 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8819\n",
      "Epoch 292/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6243 - tp: 191.0000 - fp: 93.0000 - tn: 351.0000 - fn: 77.0000 - accuracy: 0.7612 - precision: 0.6725 - recall: 0.7127 - auc: 0.8168 - val_loss: 0.5711 - val_tp: 54.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 20.0000 - val_accuracy: 0.7654 - val_precision: 0.7105 - val_recall: 0.7297 - val_auc: 0.8818\n",
      "Epoch 293/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6208 - tp: 190.0000 - fp: 97.0000 - tn: 347.0000 - fn: 78.0000 - accuracy: 0.7542 - precision: 0.6620 - recall: 0.7090 - auc: 0.8212 - val_loss: 0.5716 - val_tp: 54.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 20.0000 - val_accuracy: 0.7709 - val_precision: 0.7200 - val_recall: 0.7297 - val_auc: 0.8820\n",
      "Epoch 294/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6495 - tp: 177.0000 - fp: 92.0000 - tn: 352.0000 - fn: 91.0000 - accuracy: 0.7430 - precision: 0.6580 - recall: 0.6604 - auc: 0.7956 - val_loss: 0.5710 - val_tp: 54.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 20.0000 - val_accuracy: 0.7654 - val_precision: 0.7105 - val_recall: 0.7297 - val_auc: 0.8818\n",
      "Epoch 295/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6308 - tp: 188.0000 - fp: 85.0000 - tn: 359.0000 - fn: 80.0000 - accuracy: 0.7683 - precision: 0.6886 - recall: 0.7015 - auc: 0.8134 - val_loss: 0.5706 - val_tp: 54.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 20.0000 - val_accuracy: 0.7654 - val_precision: 0.7105 - val_recall: 0.7297 - val_auc: 0.8825\n",
      "Epoch 296/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6352 - tp: 183.0000 - fp: 84.0000 - tn: 360.0000 - fn: 85.0000 - accuracy: 0.7626 - precision: 0.6854 - recall: 0.6828 - auc: 0.8071 - val_loss: 0.5707 - val_tp: 54.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 20.0000 - val_accuracy: 0.7654 - val_precision: 0.7105 - val_recall: 0.7297 - val_auc: 0.8820\n",
      "Epoch 297/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6171 - tp: 187.0000 - fp: 74.0000 - tn: 370.0000 - fn: 81.0000 - accuracy: 0.7823 - precision: 0.7165 - recall: 0.6978 - auc: 0.8145 - val_loss: 0.5697 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8819\n",
      "Epoch 298/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.6164 - tp: 195.0000 - fp: 95.0000 - tn: 349.0000 - fn: 73.0000 - accuracy: 0.7640 - precision: 0.6724 - recall: 0.7276 - auc: 0.8245 - val_loss: 0.5692 - val_tp: 54.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 20.0000 - val_accuracy: 0.7654 - val_precision: 0.7105 - val_recall: 0.7297 - val_auc: 0.8812\n",
      "Epoch 299/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6302 - tp: 189.0000 - fp: 92.0000 - tn: 352.0000 - fn: 79.0000 - accuracy: 0.7598 - precision: 0.6726 - recall: 0.7052 - auc: 0.8111 - val_loss: 0.5693 - val_tp: 54.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 20.0000 - val_accuracy: 0.7654 - val_precision: 0.7105 - val_recall: 0.7297 - val_auc: 0.8827\n",
      "Epoch 300/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6245 - tp: 192.0000 - fp: 84.0000 - tn: 360.0000 - fn: 76.0000 - accuracy: 0.7753 - precision: 0.6957 - recall: 0.7164 - auc: 0.8143 - val_loss: 0.5690 - val_tp: 54.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 20.0000 - val_accuracy: 0.7654 - val_precision: 0.7105 - val_recall: 0.7297 - val_auc: 0.8817\n",
      "Epoch 301/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.6294 - tp: 184.0000 - fp: 90.0000 - tn: 354.0000 - fn: 84.0000 - accuracy: 0.7556 - precision: 0.6715 - recall: 0.6866 - auc: 0.8141 - val_loss: 0.5680 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8815\n",
      "Epoch 302/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.6262 - tp: 186.0000 - fp: 84.0000 - tn: 360.0000 - fn: 82.0000 - accuracy: 0.7669 - precision: 0.6889 - recall: 0.6940 - auc: 0.8140 - val_loss: 0.5672 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8826\n",
      "Epoch 303/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6168 - tp: 191.0000 - fp: 91.0000 - tn: 353.0000 - fn: 77.0000 - accuracy: 0.7640 - precision: 0.6773 - recall: 0.7127 - auc: 0.8200 - val_loss: 0.5672 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8827\n",
      "Epoch 304/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5984 - tp: 192.0000 - fp: 79.0000 - tn: 365.0000 - fn: 76.0000 - accuracy: 0.7823 - precision: 0.7085 - recall: 0.7164 - auc: 0.8322 - val_loss: 0.5658 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8821\n",
      "Epoch 305/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6262 - tp: 196.0000 - fp: 91.0000 - tn: 353.0000 - fn: 72.0000 - accuracy: 0.7711 - precision: 0.6829 - recall: 0.7313 - auc: 0.8122 - val_loss: 0.5652 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8820\n",
      "Epoch 306/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6247 - tp: 193.0000 - fp: 95.0000 - tn: 349.0000 - fn: 75.0000 - accuracy: 0.7612 - precision: 0.6701 - recall: 0.7201 - auc: 0.8149 - val_loss: 0.5651 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8822\n",
      "Epoch 307/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6295 - tp: 192.0000 - fp: 87.0000 - tn: 357.0000 - fn: 76.0000 - accuracy: 0.7711 - precision: 0.6882 - recall: 0.7164 - auc: 0.8058 - val_loss: 0.5657 - val_tp: 58.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 16.0000 - val_accuracy: 0.7765 - val_precision: 0.7073 - val_recall: 0.7838 - val_auc: 0.8826\n",
      "Epoch 308/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.6244 - tp: 190.0000 - fp: 97.0000 - tn: 347.0000 - fn: 78.0000 - accuracy: 0.7542 - precision: 0.6620 - recall: 0.7090 - auc: 0.8154 - val_loss: 0.5657 - val_tp: 58.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 16.0000 - val_accuracy: 0.7765 - val_precision: 0.7073 - val_recall: 0.7838 - val_auc: 0.8810\n",
      "Epoch 309/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.6073 - tp: 196.0000 - fp: 87.0000 - tn: 357.0000 - fn: 72.0000 - accuracy: 0.7767 - precision: 0.6926 - recall: 0.7313 - auc: 0.8282 - val_loss: 0.5651 - val_tp: 56.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.7709 - val_precision: 0.7089 - val_recall: 0.7568 - val_auc: 0.8826\n",
      "Epoch 310/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.6232 - tp: 192.0000 - fp: 96.0000 - tn: 348.0000 - fn: 76.0000 - accuracy: 0.7584 - precision: 0.6667 - recall: 0.7164 - auc: 0.8127 - val_loss: 0.5650 - val_tp: 58.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 16.0000 - val_accuracy: 0.7765 - val_precision: 0.7073 - val_recall: 0.7838 - val_auc: 0.8821\n",
      "Epoch 311/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.7049 - tp: 125.0000 - fp: 192.0000 - tn: 252.0000 - fn: 143.0000 - accuracy: 0.5295 - precision: 0.3943 - recall: 0.4664 - auc: 0.5075 - val_loss: 0.7203 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 380/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7053 - tp: 32.0000 - fp: 69.0000 - tn: 375.0000 - fn: 236.0000 - accuracy: 0.5716 - precision: 0.3168 - recall: 0.1194 - auc: 0.5038 - val_loss: 0.7182 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 381/600\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.7043 - tp: 58.0000 - fp: 88.0000 - tn: 356.0000 - fn: 210.0000 - accuracy: 0.5815 - precision: 0.3973 - recall: 0.2164 - auc: 0.5202 - val_loss: 0.7160 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 382/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7058 - tp: 113.0000 - fp: 200.0000 - tn: 244.0000 - fn: 155.0000 - accuracy: 0.5014 - precision: 0.3610 - recall: 0.4216 - auc: 0.4812 - val_loss: 0.7161 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 383/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.7060 - tp: 127.0000 - fp: 207.0000 - tn: 237.0000 - fn: 141.0000 - accuracy: 0.5112 - precision: 0.3802 - recall: 0.4739 - auc: 0.4862 - val_loss: 0.7172 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 384/600\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.7060 - tp: 101.0000 - fp: 156.0000 - tn: 288.0000 - fn: 167.0000 - accuracy: 0.5463 - precision: 0.3930 - recall: 0.3769 - auc: 0.4865 - val_loss: 0.7164 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 385/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.7065 - tp: 132.0000 - fp: 228.0000 - tn: 216.0000 - fn: 136.0000 - accuracy: 0.4888 - precision: 0.3667 - recall: 0.4925 - auc: 0.4720 - val_loss: 0.7169 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 386/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7049 - tp: 99.0000 - fp: 161.0000 - tn: 283.0000 - fn: 169.0000 - accuracy: 0.5365 - precision: 0.3808 - recall: 0.3694 - auc: 0.5064 - val_loss: 0.7166 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 387/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7063 - tp: 116.0000 - fp: 211.0000 - tn: 233.0000 - fn: 152.0000 - accuracy: 0.4902 - precision: 0.3547 - recall: 0.4328 - auc: 0.4695 - val_loss: 0.7196 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 388/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7050 - tp: 80.0000 - fp: 130.0000 - tn: 314.0000 - fn: 188.0000 - accuracy: 0.5534 - precision: 0.3810 - recall: 0.2985 - auc: 0.5027 - val_loss: 0.7197 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 389/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7044 - tp: 44.0000 - fp: 75.0000 - tn: 369.0000 - fn: 224.0000 - accuracy: 0.5801 - precision: 0.3697 - recall: 0.1642 - auc: 0.5137 - val_loss: 0.7180 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 390/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7062 - tp: 75.0000 - fp: 147.0000 - tn: 297.0000 - fn: 193.0000 - accuracy: 0.5225 - precision: 0.3378 - recall: 0.2799 - auc: 0.4766 - val_loss: 0.7186 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 391/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7057 - tp: 102.0000 - fp: 165.0000 - tn: 279.0000 - fn: 166.0000 - accuracy: 0.5351 - precision: 0.3820 - recall: 0.3806 - auc: 0.4912 - val_loss: 0.7187 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 392/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.7067 - tp: 75.0000 - fp: 132.0000 - tn: 312.0000 - fn: 193.0000 - accuracy: 0.5435 - precision: 0.3623 - recall: 0.2799 - auc: 0.4720 - val_loss: 0.7162 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 393/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.7043 - tp: 132.0000 - fp: 212.0000 - tn: 232.0000 - fn: 136.0000 - accuracy: 0.5112 - precision: 0.3837 - recall: 0.4925 - auc: 0.5093 - val_loss: 0.7174 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 394/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7056 - tp: 130.0000 - fp: 215.0000 - tn: 229.0000 - fn: 138.0000 - accuracy: 0.5042 - precision: 0.3768 - recall: 0.4851 - auc: 0.4908 - val_loss: 0.7182 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 395/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7050 - tp: 112.0000 - fp: 182.0000 - tn: 262.0000 - fn: 156.0000 - accuracy: 0.5253 - precision: 0.3810 - recall: 0.4179 - auc: 0.5041 - val_loss: 0.7182 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 396/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7041 - tp: 68.0000 - fp: 110.0000 - tn: 334.0000 - fn: 200.0000 - accuracy: 0.5646 - precision: 0.3820 - recall: 0.2537 - auc: 0.5100 - val_loss: 0.7171 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 397/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7066 - tp: 142.0000 - fp: 242.0000 - tn: 202.0000 - fn: 126.0000 - accuracy: 0.4831 - precision: 0.3698 - recall: 0.5299 - auc: 0.4805 - val_loss: 0.7183 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 398/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7060 - tp: 82.0000 - fp: 134.0000 - tn: 310.0000 - fn: 186.0000 - accuracy: 0.5506 - precision: 0.3796 - recall: 0.3060 - auc: 0.4776 - val_loss: 0.7213 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 399/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7041 - tp: 49.0000 - fp: 59.0000 - tn: 385.0000 - fn: 219.0000 - accuracy: 0.6096 - precision: 0.4537 - recall: 0.1828 - auc: 0.5091 - val_loss: 0.7172 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 400/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7050 - tp: 143.0000 - fp: 237.0000 - tn: 207.0000 - fn: 125.0000 - accuracy: 0.4916 - precision: 0.3763 - recall: 0.5336 - auc: 0.5067 - val_loss: 0.7194 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 401/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.7066 - tp: 56.0000 - fp: 100.0000 - tn: 344.0000 - fn: 212.0000 - accuracy: 0.5618 - precision: 0.3590 - recall: 0.2090 - auc: 0.4884 - val_loss: 0.7172 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 402/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7074 - tp: 138.0000 - fp: 251.0000 - tn: 193.0000 - fn: 130.0000 - accuracy: 0.4649 - precision: 0.3548 - recall: 0.5149 - auc: 0.4648 - val_loss: 0.7181 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 403/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7040 - tp: 82.0000 - fp: 121.0000 - tn: 323.0000 - fn: 186.0000 - accuracy: 0.5688 - precision: 0.4039 - recall: 0.3060 - auc: 0.5118 - val_loss: 0.7193 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 404/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.7036 - tp: 30.0000 - fp: 29.0000 - tn: 415.0000 - fn: 238.0000 - accuracy: 0.6250 - precision: 0.5085 - recall: 0.1119 - auc: 0.5305 - val_loss: 0.7168 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 405/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.7070 - tp: 117.0000 - fp: 218.0000 - tn: 226.0000 - fn: 151.0000 - accuracy: 0.4817 - precision: 0.3493 - recall: 0.4366 - auc: 0.4572 - val_loss: 0.7178 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 406/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.7073 - tp: 126.0000 - fp: 239.0000 - tn: 205.0000 - fn: 142.0000 - accuracy: 0.4649 - precision: 0.3452 - recall: 0.4701 - auc: 0.4708 - val_loss: 0.7220 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 407/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7045 - tp: 77.0000 - fp: 131.0000 - tn: 313.0000 - fn: 191.0000 - accuracy: 0.5478 - precision: 0.3702 - recall: 0.2873 - auc: 0.5084 - val_loss: 0.7191 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 408/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7051 - tp: 97.0000 - fp: 169.0000 - tn: 275.0000 - fn: 171.0000 - accuracy: 0.5225 - precision: 0.3647 - recall: 0.3619 - auc: 0.4935 - val_loss: 0.7204 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 409/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7068 - tp: 46.0000 - fp: 84.0000 - tn: 360.0000 - fn: 222.0000 - accuracy: 0.5702 - precision: 0.3538 - recall: 0.1716 - auc: 0.4714 - val_loss: 0.7169 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 410/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7072 - tp: 116.0000 - fp: 211.0000 - tn: 233.0000 - fn: 152.0000 - accuracy: 0.4902 - precision: 0.3547 - recall: 0.4328 - auc: 0.4613 - val_loss: 0.7179 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 411/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7062 - tp: 81.0000 - fp: 144.0000 - tn: 300.0000 - fn: 187.0000 - accuracy: 0.5351 - precision: 0.3600 - recall: 0.3022 - auc: 0.4852 - val_loss: 0.7172 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 412/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7068 - tp: 141.0000 - fp: 241.0000 - tn: 203.0000 - fn: 127.0000 - accuracy: 0.4831 - precision: 0.3691 - recall: 0.5261 - auc: 0.4779 - val_loss: 0.7175 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 413/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7062 - tp: 146.0000 - fp: 268.0000 - tn: 176.0000 - fn: 122.0000 - accuracy: 0.4522 - precision: 0.3527 - recall: 0.5448 - auc: 0.4838 - val_loss: 0.7199 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 414/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.7050 - tp: 47.0000 - fp: 87.0000 - tn: 357.0000 - fn: 221.0000 - accuracy: 0.5674 - precision: 0.3507 - recall: 0.1754 - auc: 0.5098 - val_loss: 0.7171 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 415/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.7066 - tp: 91.0000 - fp: 155.0000 - tn: 289.0000 - fn: 177.0000 - accuracy: 0.5337 - precision: 0.3699 - recall: 0.3396 - auc: 0.4750 - val_loss: 0.7168 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 416/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.7060 - tp: 142.0000 - fp: 258.0000 - tn: 186.0000 - fn: 126.0000 - accuracy: 0.4607 - precision: 0.3550 - recall: 0.5299 - auc: 0.4833 - val_loss: 0.7186 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 417/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7040 - tp: 96.0000 - fp: 138.0000 - tn: 306.0000 - fn: 172.0000 - accuracy: 0.5646 - precision: 0.4103 - recall: 0.3582 - auc: 0.5243 - val_loss: 0.7209 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 418/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 1.9697 - tp: 182.0000 - fp: 276.0000 - tn: 168.0000 - fn: 86.0000 - accuracy: 0.4916 - precision: 0.3974 - recall: 0.6791 - auc: 0.5270 - val_loss: 1.9730 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8197\n",
      "Epoch 241/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.9657 - tp: 184.0000 - fp: 285.0000 - tn: 159.0000 - fn: 84.0000 - accuracy: 0.4817 - precision: 0.3923 - recall: 0.6866 - auc: 0.5444 - val_loss: 1.9705 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8227\n",
      "Epoch 242/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.9678 - tp: 184.0000 - fp: 299.0000 - tn: 145.0000 - fn: 84.0000 - accuracy: 0.4621 - precision: 0.3810 - recall: 0.6866 - auc: 0.5200 - val_loss: 1.9681 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8197\n",
      "Epoch 243/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.9653 - tp: 182.0000 - fp: 278.0000 - tn: 166.0000 - fn: 86.0000 - accuracy: 0.4888 - precision: 0.3957 - recall: 0.6791 - auc: 0.5194 - val_loss: 1.9657 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8197\n",
      "Epoch 244/600\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 1.9674 - tp: 179.0000 - fp: 306.0000 - tn: 138.0000 - fn: 89.0000 - accuracy: 0.4452 - precision: 0.3691 - recall: 0.6679 - auc: 0.4844 - val_loss: 1.9632 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8200\n",
      "Epoch 245/600\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 1.9593 - tp: 177.0000 - fp: 285.0000 - tn: 159.0000 - fn: 91.0000 - accuracy: 0.4719 - precision: 0.3831 - recall: 0.6604 - auc: 0.5245 - val_loss: 1.9608 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8196\n",
      "Epoch 246/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.9540 - tp: 183.0000 - fp: 269.0000 - tn: 175.0000 - fn: 85.0000 - accuracy: 0.5028 - precision: 0.4049 - recall: 0.6828 - auc: 0.5546 - val_loss: 1.9584 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8221\n",
      "Epoch 247/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.9547 - tp: 185.0000 - fp: 281.0000 - tn: 163.0000 - fn: 83.0000 - accuracy: 0.4888 - precision: 0.3970 - recall: 0.6903 - auc: 0.5243 - val_loss: 1.9560 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8103\n",
      "Epoch 248/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.9531 - tp: 189.0000 - fp: 288.0000 - tn: 156.0000 - fn: 79.0000 - accuracy: 0.4846 - precision: 0.3962 - recall: 0.7052 - auc: 0.5153 - val_loss: 1.9536 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8145\n",
      "Epoch 249/600\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 1.9526 - tp: 174.0000 - fp: 283.0000 - tn: 161.0000 - fn: 94.0000 - accuracy: 0.4705 - precision: 0.3807 - recall: 0.6493 - auc: 0.5108 - val_loss: 1.9512 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8165\n",
      "Epoch 250/600\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 1.9528 - tp: 168.0000 - fp: 278.0000 - tn: 166.0000 - fn: 100.0000 - accuracy: 0.4691 - precision: 0.3767 - recall: 0.6269 - auc: 0.4843 - val_loss: 1.9487 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8165\n",
      "Epoch 251/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.9424 - tp: 181.0000 - fp: 273.0000 - tn: 171.0000 - fn: 87.0000 - accuracy: 0.4944 - precision: 0.3987 - recall: 0.6754 - auc: 0.5437 - val_loss: 1.9463 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8216\n",
      "Epoch 252/600\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 1.9439 - tp: 180.0000 - fp: 290.0000 - tn: 154.0000 - fn: 88.0000 - accuracy: 0.4691 - precision: 0.3830 - recall: 0.6716 - auc: 0.5148 - val_loss: 1.9439 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8234\n",
      "Epoch 253/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.9396 - tp: 186.0000 - fp: 304.0000 - tn: 140.0000 - fn: 82.0000 - accuracy: 0.4579 - precision: 0.3796 - recall: 0.6940 - auc: 0.5274 - val_loss: 1.9415 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8214\n",
      "Epoch 254/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.9347 - tp: 191.0000 - fp: 280.0000 - tn: 164.0000 - fn: 77.0000 - accuracy: 0.4986 - precision: 0.4055 - recall: 0.7127 - auc: 0.5487 - val_loss: 1.9392 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8207\n",
      "Epoch 255/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.9311 - tp: 192.0000 - fp: 274.0000 - tn: 170.0000 - fn: 76.0000 - accuracy: 0.5084 - precision: 0.4120 - recall: 0.7164 - auc: 0.5547 - val_loss: 1.9368 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8173\n",
      "Epoch 256/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.9337 - tp: 180.0000 - fp: 286.0000 - tn: 158.0000 - fn: 88.0000 - accuracy: 0.4747 - precision: 0.3863 - recall: 0.6716 - auc: 0.5197 - val_loss: 1.9344 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8184\n",
      "Epoch 257/600\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 1.9232 - tp: 184.0000 - fp: 264.0000 - tn: 180.0000 - fn: 84.0000 - accuracy: 0.5112 - precision: 0.4107 - recall: 0.6866 - auc: 0.5680 - val_loss: 1.9320 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8218\n",
      "Epoch 258/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.9269 - tp: 180.0000 - fp: 280.0000 - tn: 164.0000 - fn: 88.0000 - accuracy: 0.4831 - precision: 0.3913 - recall: 0.6716 - auc: 0.5346 - val_loss: 1.9296 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8218\n",
      "Epoch 259/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.9240 - tp: 186.0000 - fp: 278.0000 - tn: 166.0000 - fn: 82.0000 - accuracy: 0.4944 - precision: 0.4009 - recall: 0.6940 - auc: 0.5385 - val_loss: 1.9273 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8194\n",
      "Epoch 260/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.9240 - tp: 178.0000 - fp: 271.0000 - tn: 173.0000 - fn: 90.0000 - accuracy: 0.4930 - precision: 0.3964 - recall: 0.6642 - auc: 0.5216 - val_loss: 1.9249 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7923\n",
      "Epoch 261/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.9213 - tp: 167.0000 - fp: 273.0000 - tn: 171.0000 - fn: 101.0000 - accuracy: 0.4747 - precision: 0.3795 - recall: 0.6231 - auc: 0.5203 - val_loss: 1.9225 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7914\n",
      "Epoch 262/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.9136 - tp: 188.0000 - fp: 265.0000 - tn: 179.0000 - fn: 80.0000 - accuracy: 0.5154 - precision: 0.4150 - recall: 0.7015 - auc: 0.5519 - val_loss: 1.9201 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8011\n",
      "Epoch 263/600\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 1.9107 - tp: 193.0000 - fp: 267.0000 - tn: 177.0000 - fn: 75.0000 - accuracy: 0.5197 - precision: 0.4196 - recall: 0.7201 - auc: 0.5674 - val_loss: 1.9178 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8011\n",
      "Epoch 264/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.9135 - tp: 166.0000 - fp: 261.0000 - tn: 183.0000 - fn: 102.0000 - accuracy: 0.4902 - precision: 0.3888 - recall: 0.6194 - auc: 0.5252 - val_loss: 1.9154 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8011\n",
      "Epoch 265/600\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 1.9113 - tp: 177.0000 - fp: 281.0000 - tn: 163.0000 - fn: 91.0000 - accuracy: 0.4775 - precision: 0.3865 - recall: 0.6604 - auc: 0.5191 - val_loss: 1.9130 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8011\n",
      "Epoch 266/600\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 1.9094 - tp: 182.0000 - fp: 288.0000 - tn: 156.0000 - fn: 86.0000 - accuracy: 0.4747 - precision: 0.3872 - recall: 0.6791 - auc: 0.5174 - val_loss: 1.9107 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7949\n",
      "Epoch 267/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.8994 - tp: 181.0000 - fp: 255.0000 - tn: 189.0000 - fn: 87.0000 - accuracy: 0.5197 - precision: 0.4151 - recall: 0.6754 - auc: 0.5793 - val_loss: 1.9083 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7949\n",
      "Epoch 268/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.9007 - tp: 179.0000 - fp: 246.0000 - tn: 198.0000 - fn: 89.0000 - accuracy: 0.5295 - precision: 0.4212 - recall: 0.6679 - auc: 0.5629 - val_loss: 1.9060 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7972\n",
      "Epoch 269/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.8972 - tp: 174.0000 - fp: 276.0000 - tn: 168.0000 - fn: 94.0000 - accuracy: 0.4803 - precision: 0.3867 - recall: 0.6493 - auc: 0.5453 - val_loss: 1.9036 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7993\n",
      "Epoch 270/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.8940 - tp: 183.0000 - fp: 270.0000 - tn: 174.0000 - fn: 85.0000 - accuracy: 0.5014 - precision: 0.4040 - recall: 0.6828 - auc: 0.5526 - val_loss: 1.9013 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7912\n",
      "Epoch 271/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.8945 - tp: 180.0000 - fp: 276.0000 - tn: 168.0000 - fn: 88.0000 - accuracy: 0.4888 - precision: 0.3947 - recall: 0.6716 - auc: 0.5498 - val_loss: 1.8990 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7909\n",
      "Epoch 272/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.8953 - tp: 171.0000 - fp: 274.0000 - tn: 170.0000 - fn: 97.0000 - accuracy: 0.4789 - precision: 0.3843 - recall: 0.6381 - auc: 0.5144 - val_loss: 1.8966 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7901\n",
      "Epoch 273/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.8844 - tp: 177.0000 - fp: 244.0000 - tn: 200.0000 - fn: 91.0000 - accuracy: 0.5295 - precision: 0.4204 - recall: 0.6604 - auc: 0.5780 - val_loss: 1.8943 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7943\n",
      "Epoch 274/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.8880 - tp: 182.0000 - fp: 270.0000 - tn: 174.0000 - fn: 86.0000 - accuracy: 0.5000 - precision: 0.4027 - recall: 0.6791 - auc: 0.5344 - val_loss: 1.8920 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7961\n",
      "Epoch 275/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 1.8880 - tp: 162.0000 - fp: 248.0000 - tn: 196.0000 - fn: 106.0000 - accuracy: 0.5028 - precision: 0.3951 - recall: 0.6045 - auc: 0.5191 - val_loss: 1.8896 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8018\n",
      "Epoch 276/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.8899 - tp: 157.0000 - fp: 269.0000 - tn: 175.0000 - fn: 111.0000 - accuracy: 0.4663 - precision: 0.3685 - recall: 0.5858 - auc: 0.4946 - val_loss: 1.8873 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8086\n",
      "Epoch 277/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.8819 - tp: 187.0000 - fp: 286.0000 - tn: 158.0000 - fn: 81.0000 - accuracy: 0.4846 - precision: 0.3953 - recall: 0.6978 - auc: 0.5279 - val_loss: 1.8850 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8086\n",
      "Epoch 278/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.8785 - tp: 176.0000 - fp: 267.0000 - tn: 177.0000 - fn: 92.0000 - accuracy: 0.4958 - precision: 0.3973 - recall: 0.6567 - auc: 0.5544 - val_loss: 1.8827 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.8263\n",
      "Epoch 279/600\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 1.0602 - tp: 165.0000 - fp: 137.0000 - tn: 307.0000 - fn: 103.0000 - accuracy: 0.6629 - precision: 0.5464 - recall: 0.6157 - auc: 0.7089 - val_loss: 0.9989 - val_tp: 59.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 15.0000 - val_accuracy: 0.7374 - val_precision: 0.6484 - val_recall: 0.7973 - val_auc: 0.8414\n",
      "Epoch 20/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.0348 - tp: 185.0000 - fp: 148.0000 - tn: 296.0000 - fn: 83.0000 - accuracy: 0.6756 - precision: 0.5556 - recall: 0.6903 - auc: 0.7244 - val_loss: 0.9688 - val_tp: 57.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 17.0000 - val_accuracy: 0.7374 - val_precision: 0.6552 - val_recall: 0.7703 - val_auc: 0.8474\n",
      "Epoch 21/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 1.0182 - tp: 172.0000 - fp: 125.0000 - tn: 319.0000 - fn: 96.0000 - accuracy: 0.6896 - precision: 0.5791 - recall: 0.6418 - auc: 0.7243 - val_loss: 0.9406 - val_tp: 62.0000 - val_fp: 33.0000 - val_tn: 72.0000 - val_fn: 12.0000 - val_accuracy: 0.7486 - val_precision: 0.6526 - val_recall: 0.8378 - val_auc: 0.8501\n",
      "Epoch 22/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.9764 - tp: 183.0000 - fp: 131.0000 - tn: 313.0000 - fn: 85.0000 - accuracy: 0.6966 - precision: 0.5828 - recall: 0.6828 - auc: 0.7605 - val_loss: 0.9136 - val_tp: 58.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 16.0000 - val_accuracy: 0.7430 - val_precision: 0.6591 - val_recall: 0.7838 - val_auc: 0.8573\n",
      "Epoch 23/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.9740 - tp: 183.0000 - fp: 128.0000 - tn: 316.0000 - fn: 85.0000 - accuracy: 0.7008 - precision: 0.5884 - recall: 0.6828 - auc: 0.7479 - val_loss: 0.8973 - val_tp: 55.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 19.0000 - val_accuracy: 0.7598 - val_precision: 0.6962 - val_recall: 0.7432 - val_auc: 0.8597\n",
      "Epoch 24/500\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.9206 - tp: 189.0000 - fp: 110.0000 - tn: 334.0000 - fn: 79.0000 - accuracy: 0.7346 - precision: 0.6321 - recall: 0.7052 - auc: 0.7918 - val_loss: 0.8709 - val_tp: 57.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 17.0000 - val_accuracy: 0.7598 - val_precision: 0.6867 - val_recall: 0.7703 - val_auc: 0.8614\n",
      "Epoch 25/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.9320 - tp: 187.0000 - fp: 116.0000 - tn: 328.0000 - fn: 81.0000 - accuracy: 0.7233 - precision: 0.6172 - recall: 0.6978 - auc: 0.7694 - val_loss: 0.8584 - val_tp: 55.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 19.0000 - val_accuracy: 0.7654 - val_precision: 0.7051 - val_recall: 0.7432 - val_auc: 0.8657\n",
      "Epoch 26/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.9038 - tp: 190.0000 - fp: 106.0000 - tn: 338.0000 - fn: 78.0000 - accuracy: 0.7416 - precision: 0.6419 - recall: 0.7090 - auc: 0.7865 - val_loss: 0.8410 - val_tp: 55.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 19.0000 - val_accuracy: 0.7598 - val_precision: 0.6962 - val_recall: 0.7432 - val_auc: 0.8662\n",
      "Epoch 27/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.8938 - tp: 189.0000 - fp: 109.0000 - tn: 335.0000 - fn: 79.0000 - accuracy: 0.7360 - precision: 0.6342 - recall: 0.7052 - auc: 0.7815 - val_loss: 0.8259 - val_tp: 55.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 19.0000 - val_accuracy: 0.7709 - val_precision: 0.7143 - val_recall: 0.7432 - val_auc: 0.8725\n",
      "Epoch 28/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.8604 - tp: 196.0000 - fp: 97.0000 - tn: 347.0000 - fn: 72.0000 - accuracy: 0.7626 - precision: 0.6689 - recall: 0.7313 - auc: 0.8035 - val_loss: 0.8125 - val_tp: 55.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 19.0000 - val_accuracy: 0.7598 - val_precision: 0.6962 - val_recall: 0.7432 - val_auc: 0.8707\n",
      "Epoch 29/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.8458 - tp: 203.0000 - fp: 105.0000 - tn: 339.0000 - fn: 65.0000 - accuracy: 0.7612 - precision: 0.6591 - recall: 0.7575 - auc: 0.8067 - val_loss: 0.8146 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8752\n",
      "Epoch 30/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.8405 - tp: 184.0000 - fp: 98.0000 - tn: 346.0000 - fn: 84.0000 - accuracy: 0.7444 - precision: 0.6525 - recall: 0.6866 - auc: 0.8004 - val_loss: 0.7881 - val_tp: 55.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 19.0000 - val_accuracy: 0.7654 - val_precision: 0.7051 - val_recall: 0.7432 - val_auc: 0.8705\n",
      "Epoch 31/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.8532 - tp: 194.0000 - fp: 102.0000 - tn: 342.0000 - fn: 74.0000 - accuracy: 0.7528 - precision: 0.6554 - recall: 0.7239 - auc: 0.7813 - val_loss: 0.7789 - val_tp: 55.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 19.0000 - val_accuracy: 0.7598 - val_precision: 0.6962 - val_recall: 0.7432 - val_auc: 0.8710\n",
      "Epoch 32/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.8060 - tp: 198.0000 - fp: 104.0000 - tn: 340.0000 - fn: 70.0000 - accuracy: 0.7556 - precision: 0.6556 - recall: 0.7388 - auc: 0.8158 - val_loss: 0.7668 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8713\n",
      "Epoch 33/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.7953 - tp: 194.0000 - fp: 92.0000 - tn: 352.0000 - fn: 74.0000 - accuracy: 0.7669 - precision: 0.6783 - recall: 0.7239 - auc: 0.8115 - val_loss: 0.7623 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8747\n",
      "Epoch 34/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.7906 - tp: 191.0000 - fp: 83.0000 - tn: 361.0000 - fn: 77.0000 - accuracy: 0.7753 - precision: 0.6971 - recall: 0.7127 - auc: 0.8088 - val_loss: 0.7476 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8743\n",
      "Epoch 35/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7882 - tp: 203.0000 - fp: 81.0000 - tn: 363.0000 - fn: 65.0000 - accuracy: 0.7949 - precision: 0.7148 - recall: 0.7575 - auc: 0.8077 - val_loss: 0.7374 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8730\n",
      "Epoch 36/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.7775 - tp: 195.0000 - fp: 85.0000 - tn: 359.0000 - fn: 73.0000 - accuracy: 0.7781 - precision: 0.6964 - recall: 0.7276 - auc: 0.8116 - val_loss: 0.7347 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8725\n",
      "Epoch 37/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.7646 - tp: 192.0000 - fp: 87.0000 - tn: 357.0000 - fn: 76.0000 - accuracy: 0.7711 - precision: 0.6882 - recall: 0.7164 - auc: 0.8163 - val_loss: 0.7328 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8747\n",
      "Epoch 38/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.7677 - tp: 186.0000 - fp: 83.0000 - tn: 361.0000 - fn: 82.0000 - accuracy: 0.7683 - precision: 0.6914 - recall: 0.6940 - auc: 0.8049 - val_loss: 0.7153 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8734\n",
      "Epoch 39/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.7458 - tp: 194.0000 - fp: 87.0000 - tn: 357.0000 - fn: 74.0000 - accuracy: 0.7739 - precision: 0.6904 - recall: 0.7239 - auc: 0.8185 - val_loss: 0.7101 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8745\n",
      "Epoch 40/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.7498 - tp: 190.0000 - fp: 79.0000 - tn: 365.0000 - fn: 78.0000 - accuracy: 0.7795 - precision: 0.7063 - recall: 0.7090 - auc: 0.8040 - val_loss: 0.7025 - val_tp: 53.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 21.0000 - val_accuracy: 0.7765 - val_precision: 0.7361 - val_recall: 0.7162 - val_auc: 0.8730\n",
      "Epoch 41/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.7313 - tp: 191.0000 - fp: 80.0000 - tn: 364.0000 - fn: 77.0000 - accuracy: 0.7795 - precision: 0.7048 - recall: 0.7127 - auc: 0.8184 - val_loss: 0.6927 - val_tp: 54.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 20.0000 - val_accuracy: 0.7821 - val_precision: 0.7397 - val_recall: 0.7297 - val_auc: 0.8743\n",
      "Epoch 42/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.7293 - tp: 198.0000 - fp: 87.0000 - tn: 357.0000 - fn: 70.0000 - accuracy: 0.7795 - precision: 0.6947 - recall: 0.7388 - auc: 0.8115 - val_loss: 0.6926 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8740\n",
      "Epoch 43/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.7187 - tp: 193.0000 - fp: 88.0000 - tn: 356.0000 - fn: 75.0000 - accuracy: 0.7711 - precision: 0.6868 - recall: 0.7201 - auc: 0.8180 - val_loss: 0.6936 - val_tp: 53.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 21.0000 - val_accuracy: 0.7877 - val_precision: 0.7571 - val_recall: 0.7162 - val_auc: 0.8764\n",
      "Epoch 44/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6968 - tp: 193.0000 - fp: 67.0000 - tn: 377.0000 - fn: 75.0000 - accuracy: 0.8006 - precision: 0.7423 - recall: 0.7201 - auc: 0.8305 - val_loss: 0.6788 - val_tp: 54.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 20.0000 - val_accuracy: 0.7765 - val_precision: 0.7297 - val_recall: 0.7297 - val_auc: 0.8745\n",
      "Epoch 45/500\n",
      "712/712 [==============================] - 0s 158us/sample - loss: 0.7057 - tp: 193.0000 - fp: 72.0000 - tn: 372.0000 - fn: 75.0000 - accuracy: 0.7935 - precision: 0.7283 - recall: 0.7201 - auc: 0.8182 - val_loss: 0.6711 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8745\n",
      "Epoch 46/500\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.7048 - tp: 198.0000 - fp: 76.0000 - tn: 368.0000 - fn: 70.0000 - accuracy: 0.7949 - precision: 0.7226 - recall: 0.7388 - auc: 0.8174 - val_loss: 0.6689 - val_tp: 53.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 21.0000 - val_accuracy: 0.7821 - val_precision: 0.7465 - val_recall: 0.7162 - val_auc: 0.8777\n",
      "Epoch 47/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6980 - tp: 194.0000 - fp: 80.0000 - tn: 364.0000 - fn: 74.0000 - accuracy: 0.7837 - precision: 0.7080 - recall: 0.7239 - auc: 0.8199 - val_loss: 0.6606 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8779\n",
      "Epoch 48/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6707 - tp: 201.0000 - fp: 79.0000 - tn: 365.0000 - fn: 67.0000 - accuracy: 0.7949 - precision: 0.7179 - recall: 0.7500 - auc: 0.8360 - val_loss: 0.6533 - val_tp: 57.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 17.0000 - val_accuracy: 0.7877 - val_precision: 0.7308 - val_recall: 0.7703 - val_auc: 0.8756\n",
      "Epoch 49/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6848 - tp: 204.0000 - fp: 81.0000 - tn: 363.0000 - fn: 64.0000 - accuracy: 0.7963 - precision: 0.7158 - recall: 0.7612 - auc: 0.8251 - val_loss: 0.6488 - val_tp: 57.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 17.0000 - val_accuracy: 0.7989 - val_precision: 0.7500 - val_recall: 0.7703 - val_auc: 0.8790\n",
      "Epoch 50/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6801 - tp: 195.0000 - fp: 76.0000 - tn: 368.0000 - fn: 73.0000 - accuracy: 0.7907 - precision: 0.7196 - recall: 0.7276 - auc: 0.8252 - val_loss: 0.6484 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8777\n",
      "Epoch 51/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.6797 - tp: 211.0000 - fp: 86.0000 - tn: 358.0000 - fn: 57.0000 - accuracy: 0.7992 - precision: 0.7104 - recall: 0.7873 - auc: 0.8219 - val_loss: 0.6395 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8775\n",
      "Epoch 52/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6577 - tp: 201.0000 - fp: 78.0000 - tn: 366.0000 - fn: 67.0000 - accuracy: 0.7963 - precision: 0.7204 - recall: 0.7500 - auc: 0.8320 - val_loss: 0.6356 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8766\n",
      "Epoch 53/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6461 - tp: 202.0000 - fp: 70.0000 - tn: 374.0000 - fn: 66.0000 - accuracy: 0.8090 - precision: 0.7426 - recall: 0.7537 - auc: 0.8432 - val_loss: 0.6356 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8736\n",
      "Epoch 54/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6604 - tp: 201.0000 - fp: 90.0000 - tn: 354.0000 - fn: 67.0000 - accuracy: 0.7795 - precision: 0.6907 - recall: 0.7500 - auc: 0.8283 - val_loss: 0.6278 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8797\n",
      "Epoch 55/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6453 - tp: 200.0000 - fp: 74.0000 - tn: 370.0000 - fn: 68.0000 - accuracy: 0.8006 - precision: 0.7299 - recall: 0.7463 - auc: 0.8394 - val_loss: 0.6274 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8792\n",
      "Epoch 56/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6586 - tp: 187.0000 - fp: 70.0000 - tn: 374.0000 - fn: 81.0000 - accuracy: 0.7879 - precision: 0.7276 - recall: 0.6978 - auc: 0.8175 - val_loss: 0.6254 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8794\n",
      "Epoch 57/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6974 - tp: 105.0000 - fp: 164.0000 - tn: 280.0000 - fn: 163.0000 - accuracy: 0.5407 - precision: 0.3903 - recall: 0.3918 - auc: 0.5064 - val_loss: 0.7116 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 157/400\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6999 - tp: 64.0000 - fp: 104.0000 - tn: 340.0000 - fn: 204.0000 - accuracy: 0.5674 - precision: 0.3810 - recall: 0.2388 - auc: 0.4697 - val_loss: 0.7118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 158/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6985 - tp: 50.0000 - fp: 98.0000 - tn: 346.0000 - fn: 218.0000 - accuracy: 0.5562 - precision: 0.3378 - recall: 0.1866 - auc: 0.4773 - val_loss: 0.7114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 159/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6982 - tp: 53.0000 - fp: 122.0000 - tn: 322.0000 - fn: 215.0000 - accuracy: 0.5267 - precision: 0.3029 - recall: 0.1978 - auc: 0.4856 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 160/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6962 - tp: 117.0000 - fp: 175.0000 - tn: 269.0000 - fn: 151.0000 - accuracy: 0.5421 - precision: 0.4007 - recall: 0.4366 - auc: 0.5179 - val_loss: 0.7095 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 161/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.6984 - tp: 124.0000 - fp: 188.0000 - tn: 256.0000 - fn: 144.0000 - accuracy: 0.5337 - precision: 0.3974 - recall: 0.4627 - auc: 0.4875 - val_loss: 0.7096 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 162/400\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.6977 - tp: 135.0000 - fp: 231.0000 - tn: 213.0000 - fn: 133.0000 - accuracy: 0.4888 - precision: 0.3689 - recall: 0.5037 - auc: 0.4943 - val_loss: 0.7093 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 163/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.6955 - tp: 91.0000 - fp: 142.0000 - tn: 302.0000 - fn: 177.0000 - accuracy: 0.5520 - precision: 0.3906 - recall: 0.3396 - auc: 0.5330 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 164/400\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6950 - tp: 100.0000 - fp: 142.0000 - tn: 302.0000 - fn: 168.0000 - accuracy: 0.5646 - precision: 0.4132 - recall: 0.3731 - auc: 0.5363 - val_loss: 0.7096 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 165/400\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6950 - tp: 146.0000 - fp: 200.0000 - tn: 244.0000 - fn: 122.0000 - accuracy: 0.5478 - precision: 0.4220 - recall: 0.5448 - auc: 0.5382 - val_loss: 0.7094 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 166/400\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6972 - tp: 119.0000 - fp: 200.0000 - tn: 244.0000 - fn: 149.0000 - accuracy: 0.5098 - precision: 0.3730 - recall: 0.4440 - auc: 0.5068 - val_loss: 0.7097 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 167/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.6990 - tp: 104.0000 - fp: 186.0000 - tn: 258.0000 - fn: 164.0000 - accuracy: 0.5084 - precision: 0.3586 - recall: 0.3881 - auc: 0.4844 - val_loss: 0.7107 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 168/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 0.6990 - tp: 56.0000 - fp: 113.0000 - tn: 331.0000 - fn: 212.0000 - accuracy: 0.5435 - precision: 0.3314 - recall: 0.2090 - auc: 0.4820 - val_loss: 0.7116 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 169/400\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.6988 - tp: 42.0000 - fp: 85.0000 - tn: 359.0000 - fn: 226.0000 - accuracy: 0.5632 - precision: 0.3307 - recall: 0.1567 - auc: 0.4672 - val_loss: 0.7116 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 170/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6992 - tp: 39.0000 - fp: 99.0000 - tn: 345.0000 - fn: 229.0000 - accuracy: 0.5393 - precision: 0.2826 - recall: 0.1455 - auc: 0.4670 - val_loss: 0.7107 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 171/400\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.6981 - tp: 78.0000 - fp: 137.0000 - tn: 307.0000 - fn: 190.0000 - accuracy: 0.5407 - precision: 0.3628 - recall: 0.2910 - auc: 0.4810 - val_loss: 0.7102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 172/400\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.6969 - tp: 71.0000 - fp: 129.0000 - tn: 315.0000 - fn: 197.0000 - accuracy: 0.5421 - precision: 0.3550 - recall: 0.2649 - auc: 0.4922 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 173/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6976 - tp: 45.0000 - fp: 101.0000 - tn: 343.0000 - fn: 223.0000 - accuracy: 0.5449 - precision: 0.3082 - recall: 0.1679 - auc: 0.4786 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 174/400\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.6962 - tp: 71.0000 - fp: 104.0000 - tn: 340.0000 - fn: 197.0000 - accuracy: 0.5772 - precision: 0.4057 - recall: 0.2649 - auc: 0.5096 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 175/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6969 - tp: 32.0000 - fp: 69.0000 - tn: 375.0000 - fn: 236.0000 - accuracy: 0.5716 - precision: 0.3168 - recall: 0.1194 - auc: 0.5034 - val_loss: 0.7110 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 176/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6975 - tp: 66.0000 - fp: 98.0000 - tn: 346.0000 - fn: 202.0000 - accuracy: 0.5787 - precision: 0.4024 - recall: 0.2463 - auc: 0.4943 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 177/400\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6969 - tp: 79.0000 - fp: 135.0000 - tn: 309.0000 - fn: 189.0000 - accuracy: 0.5449 - precision: 0.3692 - recall: 0.2948 - auc: 0.4985 - val_loss: 0.7098 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 178/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6972 - tp: 75.0000 - fp: 127.0000 - tn: 317.0000 - fn: 193.0000 - accuracy: 0.5506 - precision: 0.3713 - recall: 0.2799 - auc: 0.4866 - val_loss: 0.7107 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 179/400\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6975 - tp: 46.0000 - fp: 71.0000 - tn: 373.0000 - fn: 222.0000 - accuracy: 0.5885 - precision: 0.3932 - recall: 0.1716 - auc: 0.4795 - val_loss: 0.7102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 180/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6969 - tp: 49.0000 - fp: 88.0000 - tn: 356.0000 - fn: 219.0000 - accuracy: 0.5688 - precision: 0.3577 - recall: 0.1828 - auc: 0.4884 - val_loss: 0.7097 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 181/400\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.6970 - tp: 75.0000 - fp: 129.0000 - tn: 315.0000 - fn: 193.0000 - accuracy: 0.5478 - precision: 0.3676 - recall: 0.2799 - auc: 0.4810 - val_loss: 0.7099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 182/400\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6966 - tp: 59.0000 - fp: 100.0000 - tn: 344.0000 - fn: 209.0000 - accuracy: 0.5660 - precision: 0.3711 - recall: 0.2201 - auc: 0.4904 - val_loss: 0.7098 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 183/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6974 - tp: 102.0000 - fp: 192.0000 - tn: 252.0000 - fn: 166.0000 - accuracy: 0.4972 - precision: 0.3469 - recall: 0.3806 - auc: 0.4809 - val_loss: 0.7092 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 184/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6979 - tp: 47.0000 - fp: 104.0000 - tn: 340.0000 - fn: 221.0000 - accuracy: 0.5435 - precision: 0.3113 - recall: 0.1754 - auc: 0.4720 - val_loss: 0.7107 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 185/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6968 - tp: 35.0000 - fp: 64.0000 - tn: 380.0000 - fn: 233.0000 - accuracy: 0.5829 - precision: 0.3535 - recall: 0.1306 - auc: 0.4842 - val_loss: 0.7103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 186/400\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.6959 - tp: 53.0000 - fp: 82.0000 - tn: 362.0000 - fn: 215.0000 - accuracy: 0.5829 - precision: 0.3926 - recall: 0.1978 - auc: 0.5099 - val_loss: 0.7105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 187/400\n",
      "712/712 [==============================] - 0s 175us/sample - loss: 0.6973 - tp: 50.0000 - fp: 89.0000 - tn: 355.0000 - fn: 218.0000 - accuracy: 0.5688 - precision: 0.3597 - recall: 0.1866 - auc: 0.4790 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 188/400\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.6983 - tp: 45.0000 - fp: 103.0000 - tn: 341.0000 - fn: 223.0000 - accuracy: 0.5421 - precision: 0.3041 - recall: 0.1679 - auc: 0.4600 - val_loss: 0.7101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 189/400\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.6971 - tp: 90.0000 - fp: 152.0000 - tn: 292.0000 - fn: 178.0000 - accuracy: 0.5365 - precision: 0.3719 - recall: 0.3358 - auc: 0.4774 - val_loss: 0.7088 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 190/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6967 - tp: 132.0000 - fp: 232.0000 - tn: 212.0000 - fn: 136.0000 - accuracy: 0.4831 - precision: 0.3626 - recall: 0.4925 - auc: 0.4867 - val_loss: 0.7087 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 191/400\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.6966 - tp: 96.0000 - fp: 166.0000 - tn: 278.0000 - fn: 172.0000 - accuracy: 0.5253 - precision: 0.3664 - recall: 0.3582 - auc: 0.4933 - val_loss: 0.7092 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 192/400\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.6978 - tp: 98.0000 - fp: 184.0000 - tn: 260.0000 - fn: 170.0000 - accuracy: 0.5028 - precision: 0.3475 - recall: 0.3657 - auc: 0.4727 - val_loss: 0.7092 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 193/400\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6973 - tp: 119.0000 - fp: 195.0000 - tn: 249.0000 - fn: 149.0000 - accuracy: 0.5169 - precision: 0.3790 - recall: 0.4440 - auc: 0.4838 - val_loss: 0.7088 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 194/400\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.9908 - tp: 170.0000 - fp: 128.0000 - tn: 316.0000 - fn: 98.0000 - accuracy: 0.6826 - precision: 0.5705 - recall: 0.6343 - auc: 0.7351 - val_loss: 0.9574 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8402\n",
      "Epoch 478/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.9853 - tp: 168.0000 - fp: 118.0000 - tn: 326.0000 - fn: 100.0000 - accuracy: 0.6938 - precision: 0.5874 - recall: 0.6269 - auc: 0.7357 - val_loss: 0.9570 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8405\n",
      "Epoch 479/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.9922 - tp: 169.0000 - fp: 124.0000 - tn: 320.0000 - fn: 99.0000 - accuracy: 0.6868 - precision: 0.5768 - recall: 0.6306 - auc: 0.7257 - val_loss: 0.9567 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8403\n",
      "Epoch 480/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.9781 - tp: 165.0000 - fp: 129.0000 - tn: 315.0000 - fn: 103.0000 - accuracy: 0.6742 - precision: 0.5612 - recall: 0.6157 - auc: 0.7445 - val_loss: 0.9564 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8405\n",
      "Epoch 481/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.9791 - tp: 177.0000 - fp: 117.0000 - tn: 327.0000 - fn: 91.0000 - accuracy: 0.7079 - precision: 0.6020 - recall: 0.6604 - auc: 0.7453 - val_loss: 0.9561 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8405\n",
      "Epoch 482/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.9898 - tp: 166.0000 - fp: 125.0000 - tn: 319.0000 - fn: 102.0000 - accuracy: 0.6812 - precision: 0.5704 - recall: 0.6194 - auc: 0.7298 - val_loss: 0.9558 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8401\n",
      "Epoch 483/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.9731 - tp: 177.0000 - fp: 124.0000 - tn: 320.0000 - fn: 91.0000 - accuracy: 0.6980 - precision: 0.5880 - recall: 0.6604 - auc: 0.7633 - val_loss: 0.9555 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8401\n",
      "Epoch 484/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.9789 - tp: 173.0000 - fp: 116.0000 - tn: 328.0000 - fn: 95.0000 - accuracy: 0.7037 - precision: 0.5986 - recall: 0.6455 - auc: 0.7518 - val_loss: 0.9552 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8402\n",
      "Epoch 485/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.9628 - tp: 185.0000 - fp: 110.0000 - tn: 334.0000 - fn: 83.0000 - accuracy: 0.7289 - precision: 0.6271 - recall: 0.6903 - auc: 0.7748 - val_loss: 0.9549 - val_tp: 56.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 18.0000 - val_accuracy: 0.7374 - val_precision: 0.6588 - val_recall: 0.7568 - val_auc: 0.8400\n",
      "Epoch 486/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.9672 - tp: 168.0000 - fp: 115.0000 - tn: 329.0000 - fn: 100.0000 - accuracy: 0.6980 - precision: 0.5936 - recall: 0.6269 - auc: 0.7669 - val_loss: 0.9545 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8402\n",
      "Epoch 487/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.9911 - tp: 172.0000 - fp: 134.0000 - tn: 310.0000 - fn: 96.0000 - accuracy: 0.6770 - precision: 0.5621 - recall: 0.6418 - auc: 0.7216 - val_loss: 0.9542 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8402\n",
      "Epoch 488/500\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 0.9700 - tp: 171.0000 - fp: 113.0000 - tn: 331.0000 - fn: 97.0000 - accuracy: 0.7051 - precision: 0.6021 - recall: 0.6381 - auc: 0.7610 - val_loss: 0.9539 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8398\n",
      "Epoch 489/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.9791 - tp: 164.0000 - fp: 131.0000 - tn: 313.0000 - fn: 104.0000 - accuracy: 0.6699 - precision: 0.5559 - recall: 0.6119 - auc: 0.7385 - val_loss: 0.9536 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8398\n",
      "Epoch 490/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.9777 - tp: 181.0000 - fp: 124.0000 - tn: 320.0000 - fn: 87.0000 - accuracy: 0.7037 - precision: 0.5934 - recall: 0.6754 - auc: 0.7522 - val_loss: 0.9533 - val_tp: 55.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 19.0000 - val_accuracy: 0.7318 - val_precision: 0.6548 - val_recall: 0.7432 - val_auc: 0.8398\n",
      "Epoch 491/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.9852 - tp: 166.0000 - fp: 116.0000 - tn: 328.0000 - fn: 102.0000 - accuracy: 0.6938 - precision: 0.5887 - recall: 0.6194 - auc: 0.7377 - val_loss: 0.9529 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8398\n",
      "Epoch 492/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.9866 - tp: 167.0000 - fp: 116.0000 - tn: 328.0000 - fn: 101.0000 - accuracy: 0.6952 - precision: 0.5901 - recall: 0.6231 - auc: 0.7366 - val_loss: 0.9526 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8396\n",
      "Epoch 493/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.9827 - tp: 167.0000 - fp: 124.0000 - tn: 320.0000 - fn: 101.0000 - accuracy: 0.6840 - precision: 0.5739 - recall: 0.6231 - auc: 0.7368 - val_loss: 0.9522 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8398\n",
      "Epoch 494/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.9912 - tp: 158.0000 - fp: 124.0000 - tn: 320.0000 - fn: 110.0000 - accuracy: 0.6713 - precision: 0.5603 - recall: 0.5896 - auc: 0.7204 - val_loss: 0.9519 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8401\n",
      "Epoch 495/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.9725 - tp: 178.0000 - fp: 110.0000 - tn: 334.0000 - fn: 90.0000 - accuracy: 0.7191 - precision: 0.6181 - recall: 0.6642 - auc: 0.7601 - val_loss: 0.9516 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8402\n",
      "Epoch 496/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.9732 - tp: 171.0000 - fp: 121.0000 - tn: 323.0000 - fn: 97.0000 - accuracy: 0.6938 - precision: 0.5856 - recall: 0.6381 - auc: 0.7507 - val_loss: 0.9513 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8403\n",
      "Epoch 497/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.9880 - tp: 159.0000 - fp: 127.0000 - tn: 317.0000 - fn: 109.0000 - accuracy: 0.6685 - precision: 0.5559 - recall: 0.5933 - auc: 0.7248 - val_loss: 0.9510 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8402\n",
      "Epoch 498/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.9799 - tp: 168.0000 - fp: 122.0000 - tn: 322.0000 - fn: 100.0000 - accuracy: 0.6882 - precision: 0.5793 - recall: 0.6269 - auc: 0.7382 - val_loss: 0.9506 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8402\n",
      "Epoch 499/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.9831 - tp: 174.0000 - fp: 117.0000 - tn: 327.0000 - fn: 94.0000 - accuracy: 0.7037 - precision: 0.5979 - recall: 0.6493 - auc: 0.7374 - val_loss: 0.9503 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8402\n",
      "Epoch 500/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.9758 - tp: 171.0000 - fp: 119.0000 - tn: 325.0000 - fn: 97.0000 - accuracy: 0.6966 - precision: 0.5897 - recall: 0.6381 - auc: 0.7437 - val_loss: 0.9500 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 17.0000 - val_accuracy: 0.7430 - val_precision: 0.6628 - val_recall: 0.7703 - val_auc: 0.8403\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 9634c9442928e34ab7cf39b8aa1bfed1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.74301677942276</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-batch_size: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_0: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_1: sigmoid</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_2: sigmoid</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_3: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_4: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation_5: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_activation_6: sigmoid</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_0: 56</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_1: 40</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_2: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_3: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_4: 24</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_units_5: 48</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_units_6: 48</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_0: 0.30000000000000004</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_1: 0.2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_2: 0.4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_3: 0.35000000000000003</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_4: 0.35000000000000003</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout_5: 0.30000000000000004</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dropout_6: 0.1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-epoch_number: 500</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_0: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_1: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_2: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_3: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_4: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l1_5: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l1_6: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_0: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_1: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_2: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_3: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_4: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-l2_5: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-l2_6: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-learning_rate: 0.0005</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: SGD</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/500\n",
      "712/712 [==============================] - 4s 5ms/sample - loss: 3.7987 - tp: 64.0000 - fp: 95.0000 - tn: 349.0000 - fn: 204.0000 - accuracy: 0.5801 - precision: 0.4025 - recall: 0.2388 - auc: 0.5225 - val_loss: 3.7692 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4920\n",
      "Epoch 2/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 3.7527 - tp: 79.0000 - fp: 135.0000 - tn: 309.0000 - fn: 189.0000 - accuracy: 0.5449 - precision: 0.3692 - recall: 0.2948 - auc: 0.4803 - val_loss: 3.7121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6316\n",
      "Epoch 3/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 3.6923 - tp: 97.0000 - fp: 160.0000 - tn: 284.0000 - fn: 171.0000 - accuracy: 0.5351 - precision: 0.3774 - recall: 0.3619 - auc: 0.5048 - val_loss: 3.6602 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 4/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 3.6608 - tp: 100.0000 - fp: 194.0000 - tn: 250.0000 - fn: 168.0000 - accuracy: 0.4916 - precision: 0.3401 - recall: 0.3731 - auc: 0.4749 - val_loss: 3.6172 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 5/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 3.6035 - tp: 109.0000 - fp: 186.0000 - tn: 258.0000 - fn: 159.0000 - accuracy: 0.5154 - precision: 0.3695 - recall: 0.4067 - auc: 0.5064 - val_loss: 3.5702 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 6/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 3.5603 - tp: 136.0000 - fp: 217.0000 - tn: 227.0000 - fn: 132.0000 - accuracy: 0.5098 - precision: 0.3853 - recall: 0.5075 - auc: 0.5102 - val_loss: 3.5283 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 7/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 3.5181 - tp: 125.0000 - fp: 200.0000 - tn: 244.0000 - fn: 143.0000 - accuracy: 0.5183 - precision: 0.3846 - recall: 0.4664 - auc: 0.5037 - val_loss: 3.4857 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6121\n",
      "Epoch 8/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 3.4806 - tp: 132.0000 - fp: 203.0000 - tn: 241.0000 - fn: 136.0000 - accuracy: 0.5239 - precision: 0.3940 - recall: 0.4925 - auc: 0.5055 - val_loss: 3.4448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6364\n",
      "Epoch 9/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 3.4333 - tp: 137.0000 - fp: 202.0000 - tn: 242.0000 - fn: 131.0000 - accuracy: 0.5323 - precision: 0.4041 - recall: 0.5112 - auc: 0.5183 - val_loss: 3.4032 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 10/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 3.3942 - tp: 123.0000 - fp: 197.0000 - tn: 247.0000 - fn: 145.0000 - accuracy: 0.5197 - precision: 0.3844 - recall: 0.4590 - auc: 0.5030 - val_loss: 3.3625 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6606\n",
      "Epoch 11/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 3.3535 - tp: 119.0000 - fp: 215.0000 - tn: 229.0000 - fn: 149.0000 - accuracy: 0.4888 - precision: 0.3563 - recall: 0.4440 - auc: 0.4957 - val_loss: 3.3213 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 12/500\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 3.3178 - tp: 130.0000 - fp: 216.0000 - tn: 228.0000 - fn: 138.0000 - accuracy: 0.5028 - precision: 0.3757 - recall: 0.4851 - auc: 0.4913 - val_loss: 3.2809 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6654\n",
      "Epoch 13/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 3.2722 - tp: 132.0000 - fp: 193.0000 - tn: 251.0000 - fn: 136.0000 - accuracy: 0.5379 - precision: 0.4062 - recall: 0.4925 - auc: 0.5081 - val_loss: 3.2407 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 14/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 3.2486 - tp: 122.0000 - fp: 235.0000 - tn: 209.0000 - fn: 146.0000 - accuracy: 0.4649 - precision: 0.3417 - recall: 0.4552 - auc: 0.4565 - val_loss: 3.2023 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7301\n",
      "Epoch 15/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 3.1892 - tp: 125.0000 - fp: 205.0000 - tn: 239.0000 - fn: 143.0000 - accuracy: 0.5112 - precision: 0.3788 - recall: 0.4664 - auc: 0.5135 - val_loss: 3.1635 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6606\n",
      "Epoch 16/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 3.1720 - tp: 109.0000 - fp: 211.0000 - tn: 233.0000 - fn: 159.0000 - accuracy: 0.4803 - precision: 0.3406 - recall: 0.4067 - auc: 0.4523 - val_loss: 3.1257 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7539\n",
      "Epoch 17/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 3.1176 - tp: 117.0000 - fp: 206.0000 - tn: 238.0000 - fn: 151.0000 - accuracy: 0.4986 - precision: 0.3622 - recall: 0.4366 - auc: 0.4849 - val_loss: 3.0864 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 18/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6317 - tp: 190.0000 - fp: 99.0000 - tn: 345.0000 - fn: 78.0000 - accuracy: 0.7514 - precision: 0.6574 - recall: 0.7090 - auc: 0.8032 - val_loss: 0.5938 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8732\n",
      "Epoch 122/600\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.6470 - tp: 180.0000 - fp: 89.0000 - tn: 355.0000 - fn: 88.0000 - accuracy: 0.7514 - precision: 0.6691 - recall: 0.6716 - auc: 0.7876 - val_loss: 0.5922 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8732\n",
      "Epoch 123/600\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6299 - tp: 182.0000 - fp: 89.0000 - tn: 355.0000 - fn: 86.0000 - accuracy: 0.7542 - precision: 0.6716 - recall: 0.6791 - auc: 0.8095 - val_loss: 0.5924 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8725\n",
      "Epoch 124/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6336 - tp: 186.0000 - fp: 80.0000 - tn: 364.0000 - fn: 82.0000 - accuracy: 0.7725 - precision: 0.6992 - recall: 0.6940 - auc: 0.8037 - val_loss: 0.5924 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8714\n",
      "Epoch 125/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6437 - tp: 183.0000 - fp: 85.0000 - tn: 359.0000 - fn: 85.0000 - accuracy: 0.7612 - precision: 0.6828 - recall: 0.6828 - auc: 0.7957 - val_loss: 0.5931 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8741\n",
      "Epoch 126/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6343 - tp: 181.0000 - fp: 89.0000 - tn: 355.0000 - fn: 87.0000 - accuracy: 0.7528 - precision: 0.6704 - recall: 0.6754 - auc: 0.7955 - val_loss: 0.5916 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8748\n",
      "Epoch 127/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6412 - tp: 177.0000 - fp: 85.0000 - tn: 359.0000 - fn: 91.0000 - accuracy: 0.7528 - precision: 0.6756 - recall: 0.6604 - auc: 0.7901 - val_loss: 0.5926 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8715\n",
      "Epoch 128/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6304 - tp: 175.0000 - fp: 73.0000 - tn: 371.0000 - fn: 93.0000 - accuracy: 0.7669 - precision: 0.7056 - recall: 0.6530 - auc: 0.8042 - val_loss: 0.5918 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8723\n",
      "Epoch 129/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6329 - tp: 187.0000 - fp: 89.0000 - tn: 355.0000 - fn: 81.0000 - accuracy: 0.7612 - precision: 0.6775 - recall: 0.6978 - auc: 0.8046 - val_loss: 0.5924 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8726\n",
      "Epoch 130/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6491 - tp: 179.0000 - fp: 84.0000 - tn: 360.0000 - fn: 89.0000 - accuracy: 0.7570 - precision: 0.6806 - recall: 0.6679 - auc: 0.7825 - val_loss: 0.5931 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8739\n",
      "Epoch 131/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6496 - tp: 174.0000 - fp: 75.0000 - tn: 369.0000 - fn: 94.0000 - accuracy: 0.7626 - precision: 0.6988 - recall: 0.6493 - auc: 0.7879 - val_loss: 0.5922 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8721\n",
      "Epoch 132/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6280 - tp: 189.0000 - fp: 83.0000 - tn: 361.0000 - fn: 79.0000 - accuracy: 0.7725 - precision: 0.6949 - recall: 0.7052 - auc: 0.8108 - val_loss: 0.5928 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8736\n",
      "Epoch 133/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6378 - tp: 188.0000 - fp: 85.0000 - tn: 359.0000 - fn: 80.0000 - accuracy: 0.7683 - precision: 0.6886 - recall: 0.7015 - auc: 0.7981 - val_loss: 0.5946 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8752\n",
      "Epoch 134/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6321 - tp: 179.0000 - fp: 65.0000 - tn: 379.0000 - fn: 89.0000 - accuracy: 0.7837 - precision: 0.7336 - recall: 0.6679 - auc: 0.8074 - val_loss: 0.5918 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8739\n",
      "Epoch 135/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6292 - tp: 190.0000 - fp: 81.0000 - tn: 363.0000 - fn: 78.0000 - accuracy: 0.7767 - precision: 0.7011 - recall: 0.7090 - auc: 0.8116 - val_loss: 0.5913 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8748\n",
      "Epoch 136/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6254 - tp: 196.0000 - fp: 78.0000 - tn: 366.0000 - fn: 72.0000 - accuracy: 0.7893 - precision: 0.7153 - recall: 0.7313 - auc: 0.8146 - val_loss: 0.5917 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8752\n",
      "Epoch 137/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6546 - tp: 189.0000 - fp: 91.0000 - tn: 353.0000 - fn: 79.0000 - accuracy: 0.7612 - precision: 0.6750 - recall: 0.7052 - auc: 0.7825 - val_loss: 0.5929 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8711\n",
      "Epoch 138/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.6370 - tp: 182.0000 - fp: 79.0000 - tn: 365.0000 - fn: 86.0000 - accuracy: 0.7683 - precision: 0.6973 - recall: 0.6791 - auc: 0.7962 - val_loss: 0.5931 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8716\n",
      "Epoch 139/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6435 - tp: 177.0000 - fp: 82.0000 - tn: 362.0000 - fn: 91.0000 - accuracy: 0.7570 - precision: 0.6834 - recall: 0.6604 - auc: 0.7956 - val_loss: 0.5924 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8763\n",
      "Epoch 140/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6504 - tp: 187.0000 - fp: 79.0000 - tn: 365.0000 - fn: 81.0000 - accuracy: 0.7753 - precision: 0.7030 - recall: 0.6978 - auc: 0.7893 - val_loss: 0.5911 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8728\n",
      "Epoch 141/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6444 - tp: 181.0000 - fp: 81.0000 - tn: 363.0000 - fn: 87.0000 - accuracy: 0.7640 - precision: 0.6908 - recall: 0.6754 - auc: 0.7842 - val_loss: 0.5916 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8754\n",
      "Epoch 142/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6411 - tp: 179.0000 - fp: 75.0000 - tn: 369.0000 - fn: 89.0000 - accuracy: 0.7697 - precision: 0.7047 - recall: 0.6679 - auc: 0.7916 - val_loss: 0.5917 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8739\n",
      "Epoch 143/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6469 - tp: 176.0000 - fp: 82.0000 - tn: 362.0000 - fn: 92.0000 - accuracy: 0.7556 - precision: 0.6822 - recall: 0.6567 - auc: 0.7857 - val_loss: 0.5903 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8732\n",
      "Epoch 144/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6378 - tp: 179.0000 - fp: 68.0000 - tn: 376.0000 - fn: 89.0000 - accuracy: 0.7795 - precision: 0.7247 - recall: 0.6679 - auc: 0.8020 - val_loss: 0.5904 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8720\n",
      "Epoch 145/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6288 - tp: 190.0000 - fp: 96.0000 - tn: 348.0000 - fn: 78.0000 - accuracy: 0.7556 - precision: 0.6643 - recall: 0.7090 - auc: 0.8019 - val_loss: 0.5927 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8716\n",
      "Epoch 146/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6161 - tp: 186.0000 - fp: 72.0000 - tn: 372.0000 - fn: 82.0000 - accuracy: 0.7837 - precision: 0.7209 - recall: 0.6940 - auc: 0.8210 - val_loss: 0.5907 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8744\n",
      "Epoch 147/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6453 - tp: 183.0000 - fp: 70.0000 - tn: 374.0000 - fn: 85.0000 - accuracy: 0.7823 - precision: 0.7233 - recall: 0.6828 - auc: 0.7838 - val_loss: 0.5902 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8714\n",
      "Epoch 148/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6348 - tp: 185.0000 - fp: 69.0000 - tn: 375.0000 - fn: 83.0000 - accuracy: 0.7865 - precision: 0.7283 - recall: 0.6903 - auc: 0.7917 - val_loss: 0.5894 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8738\n",
      "Epoch 149/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6240 - tp: 189.0000 - fp: 65.0000 - tn: 379.0000 - fn: 79.0000 - accuracy: 0.7978 - precision: 0.7441 - recall: 0.7052 - auc: 0.8103 - val_loss: 0.5897 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8739\n",
      "Epoch 150/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.6406 - tp: 181.0000 - fp: 73.0000 - tn: 371.0000 - fn: 87.0000 - accuracy: 0.7753 - precision: 0.7126 - recall: 0.6754 - auc: 0.7861 - val_loss: 0.5912 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8745\n",
      "Epoch 151/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6478 - tp: 176.0000 - fp: 80.0000 - tn: 364.0000 - fn: 92.0000 - accuracy: 0.7584 - precision: 0.6875 - recall: 0.6567 - auc: 0.7822 - val_loss: 0.5902 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8754\n",
      "Epoch 152/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.6353 - tp: 181.0000 - fp: 79.0000 - tn: 365.0000 - fn: 87.0000 - accuracy: 0.7669 - precision: 0.6962 - recall: 0.6754 - auc: 0.7876 - val_loss: 0.5913 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8757\n",
      "Epoch 153/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6330 - tp: 177.0000 - fp: 77.0000 - tn: 367.0000 - fn: 91.0000 - accuracy: 0.7640 - precision: 0.6969 - recall: 0.6604 - auc: 0.8011 - val_loss: 0.5902 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8748\n",
      "Epoch 154/600\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6405 - tp: 186.0000 - fp: 76.0000 - tn: 368.0000 - fn: 82.0000 - accuracy: 0.7781 - precision: 0.7099 - recall: 0.6940 - auc: 0.7885 - val_loss: 0.5897 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8746\n",
      "Epoch 155/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6284 - tp: 185.0000 - fp: 85.0000 - tn: 359.0000 - fn: 83.0000 - accuracy: 0.7640 - precision: 0.6852 - recall: 0.6903 - auc: 0.8118 - val_loss: 0.5915 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8759\n",
      "Epoch 156/600\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6193 - tp: 181.0000 - fp: 61.0000 - tn: 383.0000 - fn: 87.0000 - accuracy: 0.7921 - precision: 0.7479 - recall: 0.6754 - auc: 0.8165 - val_loss: 0.5892 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8743\n",
      "Epoch 157/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6405 - tp: 178.0000 - fp: 78.0000 - tn: 366.0000 - fn: 90.0000 - accuracy: 0.7640 - precision: 0.6953 - recall: 0.6642 - auc: 0.8072 - val_loss: 0.5889 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8748\n",
      "Epoch 158/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6173 - tp: 190.0000 - fp: 85.0000 - tn: 359.0000 - fn: 78.0000 - accuracy: 0.7711 - precision: 0.6909 - recall: 0.7090 - auc: 0.8120 - val_loss: 0.5885 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8729\n",
      "Epoch 159/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1712 - tp: 112.0000 - fp: 163.0000 - tn: 281.0000 - fn: 156.0000 - accuracy: 0.5520 - precision: 0.4073 - recall: 0.4179 - auc: 0.5166 - val_loss: 1.1847 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4369\n",
      "Epoch 166/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.1725 - tp: 94.0000 - fp: 169.0000 - tn: 275.0000 - fn: 174.0000 - accuracy: 0.5183 - precision: 0.3574 - recall: 0.3507 - auc: 0.4903 - val_loss: 1.1843 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4498\n",
      "Epoch 167/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1762 - tp: 102.0000 - fp: 180.0000 - tn: 264.0000 - fn: 166.0000 - accuracy: 0.5140 - precision: 0.3617 - recall: 0.3806 - auc: 0.4576 - val_loss: 1.1841 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5050\n",
      "Epoch 168/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1715 - tp: 94.0000 - fp: 169.0000 - tn: 275.0000 - fn: 174.0000 - accuracy: 0.5183 - precision: 0.3574 - recall: 0.3507 - auc: 0.4995 - val_loss: 1.1837 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5029\n",
      "Epoch 169/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.1679 - tp: 99.0000 - fp: 161.0000 - tn: 283.0000 - fn: 169.0000 - accuracy: 0.5365 - precision: 0.3808 - recall: 0.3694 - auc: 0.5225 - val_loss: 1.1833 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4985\n",
      "Epoch 170/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1728 - tp: 95.0000 - fp: 170.0000 - tn: 274.0000 - fn: 173.0000 - accuracy: 0.5183 - precision: 0.3585 - recall: 0.3545 - auc: 0.4839 - val_loss: 1.1828 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5446\n",
      "Epoch 171/600\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 1.1688 - tp: 106.0000 - fp: 163.0000 - tn: 281.0000 - fn: 162.0000 - accuracy: 0.5435 - precision: 0.3941 - recall: 0.3955 - auc: 0.5063 - val_loss: 1.1825 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5359\n",
      "Epoch 172/600\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 1.1655 - tp: 114.0000 - fp: 166.0000 - tn: 278.0000 - fn: 154.0000 - accuracy: 0.5506 - precision: 0.4071 - recall: 0.4254 - auc: 0.5404 - val_loss: 1.1822 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4963\n",
      "Epoch 173/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.1681 - tp: 110.0000 - fp: 162.0000 - tn: 282.0000 - fn: 158.0000 - accuracy: 0.5506 - precision: 0.4044 - recall: 0.4104 - auc: 0.5068 - val_loss: 1.1819 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4915\n",
      "Epoch 174/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1656 - tp: 108.0000 - fp: 157.0000 - tn: 287.0000 - fn: 160.0000 - accuracy: 0.5548 - precision: 0.4075 - recall: 0.4030 - auc: 0.5401 - val_loss: 1.1816 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4751\n",
      "Epoch 175/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 1.1720 - tp: 90.0000 - fp: 163.0000 - tn: 281.0000 - fn: 178.0000 - accuracy: 0.5211 - precision: 0.3557 - recall: 0.3358 - auc: 0.4661 - val_loss: 1.1810 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5300\n",
      "Epoch 176/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1658 - tp: 108.0000 - fp: 175.0000 - tn: 269.0000 - fn: 160.0000 - accuracy: 0.5295 - precision: 0.3816 - recall: 0.4030 - auc: 0.5158 - val_loss: 1.1805 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5446\n",
      "Epoch 177/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1662 - tp: 100.0000 - fp: 163.0000 - tn: 281.0000 - fn: 168.0000 - accuracy: 0.5351 - precision: 0.3802 - recall: 0.3731 - auc: 0.5187 - val_loss: 1.1802 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5507\n",
      "Epoch 178/600\n",
      "712/712 [==============================] - 0s 117us/sample - loss: 1.1675 - tp: 103.0000 - fp: 163.0000 - tn: 281.0000 - fn: 165.0000 - accuracy: 0.5393 - precision: 0.3872 - recall: 0.3843 - auc: 0.5084 - val_loss: 1.1798 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5592\n",
      "Epoch 179/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1625 - tp: 110.0000 - fp: 150.0000 - tn: 294.0000 - fn: 158.0000 - accuracy: 0.5674 - precision: 0.4231 - recall: 0.4104 - auc: 0.5482 - val_loss: 1.1793 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4414\n",
      "Epoch 180/600\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 1.1619 - tp: 123.0000 - fp: 154.0000 - tn: 290.0000 - fn: 145.0000 - accuracy: 0.5801 - precision: 0.4440 - recall: 0.4590 - auc: 0.5544 - val_loss: 1.1790 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4414\n",
      "Epoch 181/600\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 1.1651 - tp: 107.0000 - fp: 176.0000 - tn: 268.0000 - fn: 161.0000 - accuracy: 0.5267 - precision: 0.3781 - recall: 0.3993 - auc: 0.5119 - val_loss: 1.1786 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5450\n",
      "Epoch 182/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1631 - tp: 104.0000 - fp: 148.0000 - tn: 296.0000 - fn: 164.0000 - accuracy: 0.5618 - precision: 0.4127 - recall: 0.3881 - auc: 0.5277 - val_loss: 1.1781 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4481\n",
      "Epoch 183/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1603 - tp: 114.0000 - fp: 178.0000 - tn: 266.0000 - fn: 154.0000 - accuracy: 0.5337 - precision: 0.3904 - recall: 0.4254 - auc: 0.5477 - val_loss: 1.1778 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5450\n",
      "Epoch 184/600\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 1.1639 - tp: 106.0000 - fp: 181.0000 - tn: 263.0000 - fn: 162.0000 - accuracy: 0.5183 - precision: 0.3693 - recall: 0.3955 - auc: 0.5030 - val_loss: 1.1775 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5530\n",
      "Epoch 185/600\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 1.1647 - tp: 100.0000 - fp: 159.0000 - tn: 285.0000 - fn: 168.0000 - accuracy: 0.5407 - precision: 0.3861 - recall: 0.3731 - auc: 0.5006 - val_loss: 1.1771 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5427\n",
      "Epoch 186/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1663 - tp: 102.0000 - fp: 171.0000 - tn: 273.0000 - fn: 166.0000 - accuracy: 0.5267 - precision: 0.3736 - recall: 0.3806 - auc: 0.4846 - val_loss: 1.1769 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5181\n",
      "Epoch 187/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1651 - tp: 98.0000 - fp: 172.0000 - tn: 272.0000 - fn: 170.0000 - accuracy: 0.5197 - precision: 0.3630 - recall: 0.3657 - auc: 0.4915 - val_loss: 1.1765 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5241\n",
      "Epoch 188/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.1604 - tp: 112.0000 - fp: 171.0000 - tn: 273.0000 - fn: 156.0000 - accuracy: 0.5407 - precision: 0.3958 - recall: 0.4179 - auc: 0.5273 - val_loss: 1.1759 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4369\n",
      "Epoch 189/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.1648 - tp: 108.0000 - fp: 172.0000 - tn: 272.0000 - fn: 160.0000 - accuracy: 0.5337 - precision: 0.3857 - recall: 0.4030 - auc: 0.4946 - val_loss: 1.1755 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4472\n",
      "Epoch 190/600\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 1.1643 - tp: 97.0000 - fp: 196.0000 - tn: 248.0000 - fn: 171.0000 - accuracy: 0.4846 - precision: 0.3311 - recall: 0.3619 - auc: 0.4783 - val_loss: 1.1751 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4501\n",
      "Epoch 191/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1601 - tp: 117.0000 - fp: 170.0000 - tn: 274.0000 - fn: 151.0000 - accuracy: 0.5492 - precision: 0.4077 - recall: 0.4366 - auc: 0.5227 - val_loss: 1.1747 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4548\n",
      "Epoch 192/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1627 - tp: 98.0000 - fp: 171.0000 - tn: 273.0000 - fn: 170.0000 - accuracy: 0.5211 - precision: 0.3643 - recall: 0.3657 - auc: 0.4974 - val_loss: 1.1743 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4522\n",
      "Epoch 193/600\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 1.1616 - tp: 115.0000 - fp: 178.0000 - tn: 266.0000 - fn: 153.0000 - accuracy: 0.5351 - precision: 0.3925 - recall: 0.4291 - auc: 0.5069 - val_loss: 1.1741 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5410\n",
      "Epoch 194/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1607 - tp: 106.0000 - fp: 174.0000 - tn: 270.0000 - fn: 162.0000 - accuracy: 0.5281 - precision: 0.3786 - recall: 0.3955 - auc: 0.5085 - val_loss: 1.1738 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5181\n",
      "Epoch 195/600\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 1.1606 - tp: 97.0000 - fp: 148.0000 - tn: 296.0000 - fn: 171.0000 - accuracy: 0.5520 - precision: 0.3959 - recall: 0.3619 - auc: 0.5084 - val_loss: 1.1735 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4937\n",
      "Epoch 196/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1624 - tp: 95.0000 - fp: 186.0000 - tn: 258.0000 - fn: 173.0000 - accuracy: 0.4958 - precision: 0.3381 - recall: 0.3545 - auc: 0.4834 - val_loss: 1.1733 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4819\n",
      "Epoch 197/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1605 - tp: 80.0000 - fp: 146.0000 - tn: 298.0000 - fn: 188.0000 - accuracy: 0.5309 - precision: 0.3540 - recall: 0.2985 - auc: 0.4939 - val_loss: 1.1728 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4865\n",
      "Epoch 198/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.1614 - tp: 104.0000 - fp: 162.0000 - tn: 282.0000 - fn: 164.0000 - accuracy: 0.5421 - precision: 0.3910 - recall: 0.3881 - auc: 0.4897 - val_loss: 1.1724 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4937\n",
      "Epoch 199/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.1568 - tp: 104.0000 - fp: 158.0000 - tn: 286.0000 - fn: 164.0000 - accuracy: 0.5478 - precision: 0.3969 - recall: 0.3881 - auc: 0.5252 - val_loss: 1.1721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4730\n",
      "Epoch 200/600\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 1.1600 - tp: 108.0000 - fp: 169.0000 - tn: 275.0000 - fn: 160.0000 - accuracy: 0.5379 - precision: 0.3899 - recall: 0.4030 - auc: 0.4937 - val_loss: 1.1718 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4842\n",
      "Epoch 201/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.1583 - tp: 98.0000 - fp: 158.0000 - tn: 286.0000 - fn: 170.0000 - accuracy: 0.5393 - precision: 0.3828 - recall: 0.3657 - auc: 0.5045 - val_loss: 1.1713 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4730\n",
      "Epoch 202/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1605 - tp: 86.0000 - fp: 162.0000 - tn: 282.0000 - fn: 182.0000 - accuracy: 0.5169 - precision: 0.3468 - recall: 0.3209 - auc: 0.4736 - val_loss: 1.1709 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5069\n",
      "Epoch 203/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.1559 - tp: 104.0000 - fp: 155.0000 - tn: 289.0000 - fn: 164.0000 - accuracy: 0.5520 - precision: 0.4015 - recall: 0.3881 - auc: 0.5316 - val_loss: 1.1706 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4865\n",
      "Epoch 204/600\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.1568 - tp: 88.0000 - fp: 147.0000 - tn: 297.0000 - fn: 180.0000 - accuracy: 0.5407 - precision: 0.3745 - recall: 0.3284 - auc: 0.5178 - val_loss: 1.1700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5530\n",
      "Epoch 205/600\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 1.1575 - tp: 101.0000 - fp: 169.0000 - tn: 275.0000 - fn: 167.0000 - accuracy: 0.5281 - precision: 0.3741 - recall: 0.3769 - auc: 0.4951 - val_loss: 1.1696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4433\n",
      "Epoch 206/600\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 1.1525 - tp: 116.0000 - fp: 142.0000 - tn: 302.0000 - fn: 152.0000 - accuracy: 0.5871 - precision: 0.4496 - recall: 0.4328 - auc: 0.5389 - val_loss: 1.1693 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5530\n",
      "Epoch 207/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1563 - tp: 97.0000 - fp: 169.0000 - tn: 275.0000 - fn: 171.0000 - accuracy: 0.5225 - precision: 0.3647 - recall: 0.3619 - auc: 0.4946 - val_loss: 1.1689 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5431\n",
      "Epoch 208/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1580 - tp: 106.0000 - fp: 195.0000 - tn: 249.0000 - fn: 162.0000 - accuracy: 0.4986 - precision: 0.3522 - recall: 0.3955 - auc: 0.4874 - val_loss: 1.1687 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4988\n",
      "Epoch 209/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.1537 - tp: 103.0000 - fp: 163.0000 - tn: 281.0000 - fn: 165.0000 - accuracy: 0.5393 - precision: 0.3872 - recall: 0.3843 - auc: 0.5200 - val_loss: 1.1682 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5514\n",
      "Epoch 210/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.1551 - tp: 94.0000 - fp: 148.0000 - tn: 296.0000 - fn: 174.0000 - accuracy: 0.5478 - precision: 0.3884 - recall: 0.3507 - auc: 0.5072 - val_loss: 1.1678 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5576\n",
      "Epoch 211/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1547 - tp: 108.0000 - fp: 167.0000 - tn: 277.0000 - fn: 160.0000 - accuracy: 0.5407 - precision: 0.3927 - recall: 0.4030 - auc: 0.5069 - val_loss: 1.1675 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5490\n",
      "Epoch 212/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1523 - tp: 108.0000 - fp: 174.0000 - tn: 270.0000 - fn: 160.0000 - accuracy: 0.5309 - precision: 0.3830 - recall: 0.4030 - auc: 0.5177 - val_loss: 1.1671 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5300\n",
      "Epoch 213/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1540 - tp: 103.0000 - fp: 172.0000 - tn: 272.0000 - fn: 165.0000 - accuracy: 0.5267 - precision: 0.3745 - recall: 0.3843 - auc: 0.5047 - val_loss: 1.1666 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4433\n",
      "Epoch 214/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1568 - tp: 95.0000 - fp: 181.0000 - tn: 263.0000 - fn: 173.0000 - accuracy: 0.5028 - precision: 0.3442 - recall: 0.3545 - auc: 0.4740 - val_loss: 1.1663 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5472\n",
      "Epoch 215/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1538 - tp: 98.0000 - fp: 153.0000 - tn: 291.0000 - fn: 170.0000 - accuracy: 0.5463 - precision: 0.3904 - recall: 0.3657 - auc: 0.5026 - val_loss: 1.1659 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5410\n",
      "Epoch 216/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1544 - tp: 100.0000 - fp: 176.0000 - tn: 268.0000 - fn: 168.0000 - accuracy: 0.5169 - precision: 0.3623 - recall: 0.3731 - auc: 0.4908 - val_loss: 1.1657 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5181\n",
      "Epoch 217/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1565 - tp: 94.0000 - fp: 177.0000 - tn: 267.0000 - fn: 174.0000 - accuracy: 0.5070 - precision: 0.3469 - recall: 0.3507 - auc: 0.4688 - val_loss: 1.1652 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5472\n",
      "Epoch 218/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.1550 - tp: 100.0000 - fp: 184.0000 - tn: 260.0000 - fn: 168.0000 - accuracy: 0.5056 - precision: 0.3521 - recall: 0.3731 - auc: 0.4768 - val_loss: 1.1649 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5530\n",
      "Epoch 219/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 1.1597 - tp: 86.0000 - fp: 184.0000 - tn: 260.0000 - fn: 182.0000 - accuracy: 0.4860 - precision: 0.3185 - recall: 0.3209 - auc: 0.4336 - val_loss: 1.1646 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 220/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6947 - tp: 61.0000 - fp: 89.0000 - tn: 355.0000 - fn: 207.0000 - accuracy: 0.5843 - precision: 0.4067 - recall: 0.2276 - auc: 0.4901 - val_loss: 0.7080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 185/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.6935 - tp: 33.0000 - fp: 61.0000 - tn: 383.0000 - fn: 235.0000 - accuracy: 0.5843 - precision: 0.3511 - recall: 0.1231 - auc: 0.4993 - val_loss: 0.7076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 186/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6932 - tp: 41.0000 - fp: 47.0000 - tn: 397.0000 - fn: 227.0000 - accuracy: 0.6152 - precision: 0.4659 - recall: 0.1530 - auc: 0.5180 - val_loss: 0.7081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 187/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6941 - tp: 41.0000 - fp: 61.0000 - tn: 383.0000 - fn: 227.0000 - accuracy: 0.5955 - precision: 0.4020 - recall: 0.1530 - auc: 0.4989 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 188/500\n",
      "712/712 [==============================] - 0s 212us/sample - loss: 0.6943 - tp: 41.0000 - fp: 52.0000 - tn: 392.0000 - fn: 227.0000 - accuracy: 0.6081 - precision: 0.4409 - recall: 0.1530 - auc: 0.4842 - val_loss: 0.7083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 189/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6934 - tp: 42.0000 - fp: 78.0000 - tn: 366.0000 - fn: 226.0000 - accuracy: 0.5730 - precision: 0.3500 - recall: 0.1567 - auc: 0.5036 - val_loss: 0.7073 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 190/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6947 - tp: 89.0000 - fp: 149.0000 - tn: 295.0000 - fn: 179.0000 - accuracy: 0.5393 - precision: 0.3739 - recall: 0.3321 - auc: 0.4879 - val_loss: 0.7066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 191/500\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6941 - tp: 82.0000 - fp: 128.0000 - tn: 316.0000 - fn: 186.0000 - accuracy: 0.5590 - precision: 0.3905 - recall: 0.3060 - auc: 0.4984 - val_loss: 0.7071 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 192/500\n",
      "712/712 [==============================] - 0s 154us/sample - loss: 0.6936 - tp: 95.0000 - fp: 148.0000 - tn: 296.0000 - fn: 173.0000 - accuracy: 0.5492 - precision: 0.3909 - recall: 0.3545 - auc: 0.5091 - val_loss: 0.7070 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 193/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6948 - tp: 97.0000 - fp: 169.0000 - tn: 275.0000 - fn: 171.0000 - accuracy: 0.5225 - precision: 0.3647 - recall: 0.3619 - auc: 0.4783 - val_loss: 0.7067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 194/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6942 - tp: 45.0000 - fp: 77.0000 - tn: 367.0000 - fn: 223.0000 - accuracy: 0.5787 - precision: 0.3689 - recall: 0.1679 - auc: 0.4810 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 195/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6944 - tp: 32.0000 - fp: 43.0000 - tn: 401.0000 - fn: 236.0000 - accuracy: 0.6081 - precision: 0.4267 - recall: 0.1194 - auc: 0.4864 - val_loss: 0.7083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 196/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6938 - tp: 24.0000 - fp: 37.0000 - tn: 407.0000 - fn: 244.0000 - accuracy: 0.6053 - precision: 0.3934 - recall: 0.0896 - auc: 0.4895 - val_loss: 0.7083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 197/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6929 - tp: 11.0000 - fp: 15.0000 - tn: 429.0000 - fn: 257.0000 - accuracy: 0.6180 - precision: 0.4231 - recall: 0.0410 - auc: 0.5279 - val_loss: 0.7091 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 198/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6950 - tp: 16.0000 - fp: 33.0000 - tn: 411.0000 - fn: 252.0000 - accuracy: 0.5997 - precision: 0.3265 - recall: 0.0597 - auc: 0.4691 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 199/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6947 - tp: 42.0000 - fp: 85.0000 - tn: 359.0000 - fn: 226.0000 - accuracy: 0.5632 - precision: 0.3307 - recall: 0.1567 - auc: 0.4810 - val_loss: 0.7073 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 200/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6937 - tp: 57.0000 - fp: 112.0000 - tn: 332.0000 - fn: 211.0000 - accuracy: 0.5463 - precision: 0.3373 - recall: 0.2127 - auc: 0.5034 - val_loss: 0.7070 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 201/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6944 - tp: 34.0000 - fp: 46.0000 - tn: 398.0000 - fn: 234.0000 - accuracy: 0.6067 - precision: 0.4250 - recall: 0.1269 - auc: 0.4801 - val_loss: 0.7082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 202/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6949 - tp: 52.0000 - fp: 103.0000 - tn: 341.0000 - fn: 216.0000 - accuracy: 0.5520 - precision: 0.3355 - recall: 0.1940 - auc: 0.4676 - val_loss: 0.7069 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 203/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6940 - tp: 78.0000 - fp: 141.0000 - tn: 303.0000 - fn: 190.0000 - accuracy: 0.5351 - precision: 0.3562 - recall: 0.2910 - auc: 0.4872 - val_loss: 0.7068 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 204/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.6924 - tp: 45.0000 - fp: 83.0000 - tn: 361.0000 - fn: 223.0000 - accuracy: 0.5702 - precision: 0.3516 - recall: 0.1679 - auc: 0.5197 - val_loss: 0.7077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 205/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.6919 - tp: 76.0000 - fp: 96.0000 - tn: 348.0000 - fn: 192.0000 - accuracy: 0.5955 - precision: 0.4419 - recall: 0.2836 - auc: 0.5445 - val_loss: 0.7070 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 206/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6935 - tp: 63.0000 - fp: 103.0000 - tn: 341.0000 - fn: 205.0000 - accuracy: 0.5674 - precision: 0.3795 - recall: 0.2351 - auc: 0.4966 - val_loss: 0.7072 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 207/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6936 - tp: 53.0000 - fp: 105.0000 - tn: 339.0000 - fn: 215.0000 - accuracy: 0.5506 - precision: 0.3354 - recall: 0.1978 - auc: 0.5049 - val_loss: 0.7073 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 208/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.6939 - tp: 73.0000 - fp: 123.0000 - tn: 321.0000 - fn: 195.0000 - accuracy: 0.5534 - precision: 0.3724 - recall: 0.2724 - auc: 0.4895 - val_loss: 0.7069 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 209/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.6929 - tp: 39.0000 - fp: 54.0000 - tn: 390.0000 - fn: 229.0000 - accuracy: 0.6025 - precision: 0.4194 - recall: 0.1455 - auc: 0.5069 - val_loss: 0.7079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 210/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6930 - tp: 39.0000 - fp: 62.0000 - tn: 382.0000 - fn: 229.0000 - accuracy: 0.5913 - precision: 0.3861 - recall: 0.1455 - auc: 0.5200 - val_loss: 0.7072 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 211/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.6928 - tp: 62.0000 - fp: 78.0000 - tn: 366.0000 - fn: 206.0000 - accuracy: 0.6011 - precision: 0.4429 - recall: 0.2313 - auc: 0.5296 - val_loss: 0.7071 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 212/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6931 - tp: 67.0000 - fp: 93.0000 - tn: 351.0000 - fn: 201.0000 - accuracy: 0.5871 - precision: 0.4187 - recall: 0.2500 - auc: 0.5246 - val_loss: 0.7068 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 213/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.6944 - tp: 86.0000 - fp: 144.0000 - tn: 300.0000 - fn: 182.0000 - accuracy: 0.5421 - precision: 0.3739 - recall: 0.3209 - auc: 0.4902 - val_loss: 0.7069 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 214/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6946 - tp: 80.0000 - fp: 127.0000 - tn: 317.0000 - fn: 188.0000 - accuracy: 0.5576 - precision: 0.3865 - recall: 0.2985 - auc: 0.4787 - val_loss: 0.7063 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 215/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6920 - tp: 103.0000 - fp: 145.0000 - tn: 299.0000 - fn: 165.0000 - accuracy: 0.5646 - precision: 0.4153 - recall: 0.3843 - auc: 0.5365 - val_loss: 0.7069 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 216/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6951 - tp: 71.0000 - fp: 139.0000 - tn: 305.0000 - fn: 197.0000 - accuracy: 0.5281 - precision: 0.3381 - recall: 0.2649 - auc: 0.4616 - val_loss: 0.7072 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 217/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6938 - tp: 56.0000 - fp: 84.0000 - tn: 360.0000 - fn: 212.0000 - accuracy: 0.5843 - precision: 0.4000 - recall: 0.2090 - auc: 0.4933 - val_loss: 0.7074 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 218/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6938 - tp: 84.0000 - fp: 152.0000 - tn: 292.0000 - fn: 184.0000 - accuracy: 0.5281 - precision: 0.3559 - recall: 0.3134 - auc: 0.4880 - val_loss: 0.7066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 219/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6927 - tp: 75.0000 - fp: 110.0000 - tn: 334.0000 - fn: 193.0000 - accuracy: 0.5744 - precision: 0.4054 - recall: 0.2799 - auc: 0.5246 - val_loss: 0.7072 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 220/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6951 - tp: 19.0000 - fp: 37.0000 - tn: 407.0000 - fn: 249.0000 - accuracy: 0.5983 - precision: 0.3393 - recall: 0.0709 - auc: 0.4703 - val_loss: 0.7085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 221/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6933 - tp: 11.0000 - fp: 23.0000 - tn: 421.0000 - fn: 257.0000 - accuracy: 0.6067 - precision: 0.3235 - recall: 0.0410 - auc: 0.5091 - val_loss: 0.7084 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 222/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5327 - tp: 210.0000 - fp: 73.0000 - tn: 371.0000 - fn: 58.0000 - accuracy: 0.8160 - precision: 0.7420 - recall: 0.7836 - auc: 0.8685 - val_loss: 0.5348 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8786\n",
      "Epoch 310/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5341 - tp: 207.0000 - fp: 72.0000 - tn: 372.0000 - fn: 61.0000 - accuracy: 0.8132 - precision: 0.7419 - recall: 0.7724 - auc: 0.8659 - val_loss: 0.5343 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8796\n",
      "Epoch 311/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5333 - tp: 208.0000 - fp: 72.0000 - tn: 372.0000 - fn: 60.0000 - accuracy: 0.8146 - precision: 0.7429 - recall: 0.7761 - auc: 0.8699 - val_loss: 0.5342 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8794\n",
      "Epoch 312/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5304 - tp: 212.0000 - fp: 72.0000 - tn: 372.0000 - fn: 56.0000 - accuracy: 0.8202 - precision: 0.7465 - recall: 0.7910 - auc: 0.8702 - val_loss: 0.5340 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8790\n",
      "Epoch 313/600\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.5359 - tp: 209.0000 - fp: 65.0000 - tn: 379.0000 - fn: 59.0000 - accuracy: 0.8258 - precision: 0.7628 - recall: 0.7799 - auc: 0.8627 - val_loss: 0.5336 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8793\n",
      "Epoch 314/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5369 - tp: 208.0000 - fp: 72.0000 - tn: 372.0000 - fn: 60.0000 - accuracy: 0.8146 - precision: 0.7429 - recall: 0.7761 - auc: 0.8634 - val_loss: 0.5333 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8799\n",
      "Epoch 315/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5421 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8588 - val_loss: 0.5334 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8792\n",
      "Epoch 316/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.5458 - tp: 203.0000 - fp: 73.0000 - tn: 371.0000 - fn: 65.0000 - accuracy: 0.8062 - precision: 0.7355 - recall: 0.7575 - auc: 0.8528 - val_loss: 0.5330 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8795\n",
      "Epoch 317/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.5361 - tp: 205.0000 - fp: 68.0000 - tn: 376.0000 - fn: 63.0000 - accuracy: 0.8160 - precision: 0.7509 - recall: 0.7649 - auc: 0.8613 - val_loss: 0.5328 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8793\n",
      "Epoch 318/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5336 - tp: 206.0000 - fp: 68.0000 - tn: 376.0000 - fn: 62.0000 - accuracy: 0.8174 - precision: 0.7518 - recall: 0.7687 - auc: 0.8662 - val_loss: 0.5325 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8794\n",
      "Epoch 319/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5396 - tp: 207.0000 - fp: 76.0000 - tn: 368.0000 - fn: 61.0000 - accuracy: 0.8076 - precision: 0.7314 - recall: 0.7724 - auc: 0.8636 - val_loss: 0.5322 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8793\n",
      "Epoch 320/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5359 - tp: 208.0000 - fp: 67.0000 - tn: 377.0000 - fn: 60.0000 - accuracy: 0.8216 - precision: 0.7564 - recall: 0.7761 - auc: 0.8626 - val_loss: 0.5316 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8795\n",
      "Epoch 321/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5337 - tp: 208.0000 - fp: 71.0000 - tn: 373.0000 - fn: 60.0000 - accuracy: 0.8160 - precision: 0.7455 - recall: 0.7761 - auc: 0.8658 - val_loss: 0.5317 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8800\n",
      "Epoch 322/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5384 - tp: 205.0000 - fp: 71.0000 - tn: 373.0000 - fn: 63.0000 - accuracy: 0.8118 - precision: 0.7428 - recall: 0.7649 - auc: 0.8630 - val_loss: 0.5314 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8797\n",
      "Epoch 323/600\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5342 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8667 - val_loss: 0.5313 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8799\n",
      "Epoch 324/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5376 - tp: 211.0000 - fp: 73.0000 - tn: 371.0000 - fn: 57.0000 - accuracy: 0.8174 - precision: 0.7430 - recall: 0.7873 - auc: 0.8566 - val_loss: 0.5311 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8798\n",
      "Epoch 325/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5406 - tp: 206.0000 - fp: 69.0000 - tn: 375.0000 - fn: 62.0000 - accuracy: 0.8160 - precision: 0.7491 - recall: 0.7687 - auc: 0.8593 - val_loss: 0.5309 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8797\n",
      "Epoch 326/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5401 - tp: 208.0000 - fp: 74.0000 - tn: 370.0000 - fn: 60.0000 - accuracy: 0.8118 - precision: 0.7376 - recall: 0.7761 - auc: 0.8580 - val_loss: 0.5305 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8797\n",
      "Epoch 327/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.5362 - tp: 207.0000 - fp: 68.0000 - tn: 376.0000 - fn: 61.0000 - accuracy: 0.8188 - precision: 0.7527 - recall: 0.7724 - auc: 0.8614 - val_loss: 0.5302 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8795\n",
      "Epoch 328/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5424 - tp: 207.0000 - fp: 73.0000 - tn: 371.0000 - fn: 61.0000 - accuracy: 0.8118 - precision: 0.7393 - recall: 0.7724 - auc: 0.8560 - val_loss: 0.5300 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8799\n",
      "Epoch 329/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5360 - tp: 207.0000 - fp: 71.0000 - tn: 373.0000 - fn: 61.0000 - accuracy: 0.8146 - precision: 0.7446 - recall: 0.7724 - auc: 0.8612 - val_loss: 0.5299 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8793\n",
      "Epoch 330/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5323 - tp: 211.0000 - fp: 72.0000 - tn: 372.0000 - fn: 57.0000 - accuracy: 0.8188 - precision: 0.7456 - recall: 0.7873 - auc: 0.8622 - val_loss: 0.5297 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8795\n",
      "Epoch 331/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5350 - tp: 208.0000 - fp: 70.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.8174 - precision: 0.7482 - recall: 0.7761 - auc: 0.8637 - val_loss: 0.5297 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8799\n",
      "Epoch 332/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5364 - tp: 212.0000 - fp: 74.0000 - tn: 370.0000 - fn: 56.0000 - accuracy: 0.8174 - precision: 0.7413 - recall: 0.7910 - auc: 0.8588 - val_loss: 0.5296 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8795\n",
      "Epoch 333/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5431 - tp: 206.0000 - fp: 74.0000 - tn: 370.0000 - fn: 62.0000 - accuracy: 0.8090 - precision: 0.7357 - recall: 0.7687 - auc: 0.8536 - val_loss: 0.5292 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8795\n",
      "Epoch 334/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5331 - tp: 206.0000 - fp: 71.0000 - tn: 373.0000 - fn: 62.0000 - accuracy: 0.8132 - precision: 0.7437 - recall: 0.7687 - auc: 0.8633 - val_loss: 0.5291 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8796\n",
      "Epoch 335/600\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.5406 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8584 - val_loss: 0.5289 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8794\n",
      "Epoch 336/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5347 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8660 - val_loss: 0.5290 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8794\n",
      "Epoch 337/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5289 - tp: 206.0000 - fp: 69.0000 - tn: 375.0000 - fn: 62.0000 - accuracy: 0.8160 - precision: 0.7491 - recall: 0.7687 - auc: 0.8676 - val_loss: 0.5285 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8793\n",
      "Epoch 338/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.5306 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8659 - val_loss: 0.5285 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8796\n",
      "Epoch 339/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5309 - tp: 208.0000 - fp: 65.0000 - tn: 379.0000 - fn: 60.0000 - accuracy: 0.8244 - precision: 0.7619 - recall: 0.7761 - auc: 0.8696 - val_loss: 0.5282 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8799\n",
      "Epoch 340/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5361 - tp: 206.0000 - fp: 71.0000 - tn: 373.0000 - fn: 62.0000 - accuracy: 0.8132 - precision: 0.7437 - recall: 0.7687 - auc: 0.8623 - val_loss: 0.5279 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8795\n",
      "Epoch 341/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.5343 - tp: 207.0000 - fp: 68.0000 - tn: 376.0000 - fn: 61.0000 - accuracy: 0.8188 - precision: 0.7527 - recall: 0.7724 - auc: 0.8598 - val_loss: 0.5278 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8799\n",
      "Epoch 342/600\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.5324 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8628 - val_loss: 0.5275 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8803\n",
      "Epoch 343/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5332 - tp: 209.0000 - fp: 73.0000 - tn: 371.0000 - fn: 59.0000 - accuracy: 0.8146 - precision: 0.7411 - recall: 0.7799 - auc: 0.8640 - val_loss: 0.5274 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8795\n",
      "Epoch 344/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5319 - tp: 208.0000 - fp: 73.0000 - tn: 371.0000 - fn: 60.0000 - accuracy: 0.8132 - precision: 0.7402 - recall: 0.7761 - auc: 0.8663 - val_loss: 0.5273 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8799\n",
      "Epoch 345/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.5325 - tp: 209.0000 - fp: 73.0000 - tn: 371.0000 - fn: 59.0000 - accuracy: 0.8146 - precision: 0.7411 - recall: 0.7799 - auc: 0.8597 - val_loss: 0.5271 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8797\n",
      "Epoch 346/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.5276 - tp: 210.0000 - fp: 71.0000 - tn: 373.0000 - fn: 58.0000 - accuracy: 0.8188 - precision: 0.7473 - recall: 0.7836 - auc: 0.8679 - val_loss: 0.5268 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8799\n",
      "Epoch 347/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.5342 - tp: 209.0000 - fp: 76.0000 - tn: 368.0000 - fn: 59.0000 - accuracy: 0.8104 - precision: 0.7333 - recall: 0.7799 - auc: 0.8599 - val_loss: 0.5268 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8797\n",
      "Epoch 348/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5332 - tp: 207.0000 - fp: 73.0000 - tn: 371.0000 - fn: 61.0000 - accuracy: 0.8118 - precision: 0.7393 - recall: 0.7724 - auc: 0.8630 - val_loss: 0.5266 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8794\n",
      "Epoch 349/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5293 - tp: 210.0000 - fp: 70.0000 - tn: 374.0000 - fn: 58.0000 - accuracy: 0.8202 - precision: 0.7500 - recall: 0.7836 - auc: 0.8644 - val_loss: 0.5261 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8800\n",
      "Epoch 350/600\n",
      "704/712 [============================>.] - ETA: 0s - loss: 0.5331 - tp: 207.0000 - fp: 71.0000 - tn: 367.0000 - fn: 59.0000 - accuracy: 0.8153 - precision: 0.7446 - recall: 0.7782 - auc: 0.8611\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4973 - tp: 203.0000 - fp: 79.0000 - tn: 365.0000 - fn: 65.0000 - accuracy: 0.7978 - precision: 0.7199 - recall: 0.7575 - auc: 0.8619 - val_loss: 0.4864 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8782\n",
      "Epoch 408/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4983 - tp: 202.0000 - fp: 80.0000 - tn: 364.0000 - fn: 66.0000 - accuracy: 0.7949 - precision: 0.7163 - recall: 0.7537 - auc: 0.8573 - val_loss: 0.4862 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8790\n",
      "Epoch 409/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4986 - tp: 201.0000 - fp: 73.0000 - tn: 371.0000 - fn: 67.0000 - accuracy: 0.8034 - precision: 0.7336 - recall: 0.7500 - auc: 0.8565 - val_loss: 0.4861 - val_tp: 55.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 19.0000 - val_accuracy: 0.7765 - val_precision: 0.7237 - val_recall: 0.7432 - val_auc: 0.8788\n",
      "Epoch 410/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5012 - tp: 198.0000 - fp: 82.0000 - tn: 362.0000 - fn: 70.0000 - accuracy: 0.7865 - precision: 0.7071 - recall: 0.7388 - auc: 0.8549 - val_loss: 0.4860 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8786\n",
      "Epoch 411/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.5044 - tp: 200.0000 - fp: 80.0000 - tn: 364.0000 - fn: 68.0000 - accuracy: 0.7921 - precision: 0.7143 - recall: 0.7463 - auc: 0.8509 - val_loss: 0.4860 - val_tp: 56.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 18.0000 - val_accuracy: 0.7765 - val_precision: 0.7179 - val_recall: 0.7568 - val_auc: 0.8780\n",
      "Epoch 412/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5003 - tp: 201.0000 - fp: 82.0000 - tn: 362.0000 - fn: 67.0000 - accuracy: 0.7907 - precision: 0.7102 - recall: 0.7500 - auc: 0.8586 - val_loss: 0.4860 - val_tp: 56.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 18.0000 - val_accuracy: 0.7765 - val_precision: 0.7179 - val_recall: 0.7568 - val_auc: 0.8789\n",
      "Epoch 413/500\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4998 - tp: 203.0000 - fp: 79.0000 - tn: 365.0000 - fn: 65.0000 - accuracy: 0.7978 - precision: 0.7199 - recall: 0.7575 - auc: 0.8568 - val_loss: 0.4858 - val_tp: 56.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 18.0000 - val_accuracy: 0.7765 - val_precision: 0.7179 - val_recall: 0.7568 - val_auc: 0.8794\n",
      "Epoch 414/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5038 - tp: 201.0000 - fp: 76.0000 - tn: 368.0000 - fn: 67.0000 - accuracy: 0.7992 - precision: 0.7256 - recall: 0.7500 - auc: 0.8525 - val_loss: 0.4856 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8781\n",
      "Epoch 415/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5023 - tp: 199.0000 - fp: 76.0000 - tn: 368.0000 - fn: 69.0000 - accuracy: 0.7963 - precision: 0.7236 - recall: 0.7425 - auc: 0.8496 - val_loss: 0.4855 - val_tp: 56.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 18.0000 - val_accuracy: 0.7765 - val_precision: 0.7179 - val_recall: 0.7568 - val_auc: 0.8789\n",
      "Epoch 416/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4995 - tp: 203.0000 - fp: 75.0000 - tn: 369.0000 - fn: 65.0000 - accuracy: 0.8034 - precision: 0.7302 - recall: 0.7575 - auc: 0.8552 - val_loss: 0.4854 - val_tp: 56.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 18.0000 - val_accuracy: 0.7765 - val_precision: 0.7179 - val_recall: 0.7568 - val_auc: 0.8785\n",
      "Epoch 417/500\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 0.4974 - tp: 203.0000 - fp: 78.0000 - tn: 366.0000 - fn: 65.0000 - accuracy: 0.7992 - precision: 0.7224 - recall: 0.7575 - auc: 0.8611 - val_loss: 0.4852 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8797\n",
      "Epoch 418/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4973 - tp: 197.0000 - fp: 82.0000 - tn: 362.0000 - fn: 71.0000 - accuracy: 0.7851 - precision: 0.7061 - recall: 0.7351 - auc: 0.8617 - val_loss: 0.4849 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8796\n",
      "Epoch 419/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5003 - tp: 203.0000 - fp: 75.0000 - tn: 369.0000 - fn: 65.0000 - accuracy: 0.8034 - precision: 0.7302 - recall: 0.7575 - auc: 0.8555 - val_loss: 0.4848 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8797\n",
      "Epoch 420/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4927 - tp: 201.0000 - fp: 75.0000 - tn: 369.0000 - fn: 67.0000 - accuracy: 0.8006 - precision: 0.7283 - recall: 0.7500 - auc: 0.8625 - val_loss: 0.4849 - val_tp: 56.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 18.0000 - val_accuracy: 0.7765 - val_precision: 0.7179 - val_recall: 0.7568 - val_auc: 0.8793\n",
      "Epoch 421/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4937 - tp: 200.0000 - fp: 83.0000 - tn: 361.0000 - fn: 68.0000 - accuracy: 0.7879 - precision: 0.7067 - recall: 0.7463 - auc: 0.8629 - val_loss: 0.4847 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8786\n",
      "Epoch 422/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4999 - tp: 201.0000 - fp: 82.0000 - tn: 362.0000 - fn: 67.0000 - accuracy: 0.7907 - precision: 0.7102 - recall: 0.7500 - auc: 0.8581 - val_loss: 0.4846 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8786\n",
      "Epoch 423/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.4978 - tp: 196.0000 - fp: 82.0000 - tn: 362.0000 - fn: 72.0000 - accuracy: 0.7837 - precision: 0.7050 - recall: 0.7313 - auc: 0.8628 - val_loss: 0.4845 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8789\n",
      "Epoch 424/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4878 - tp: 202.0000 - fp: 79.0000 - tn: 365.0000 - fn: 66.0000 - accuracy: 0.7963 - precision: 0.7189 - recall: 0.7537 - auc: 0.8683 - val_loss: 0.4843 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8782\n",
      "Epoch 425/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.5003 - tp: 201.0000 - fp: 77.0000 - tn: 367.0000 - fn: 67.0000 - accuracy: 0.7978 - precision: 0.7230 - recall: 0.7500 - auc: 0.8549 - val_loss: 0.4842 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8781\n",
      "Epoch 426/500\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.5038 - tp: 203.0000 - fp: 78.0000 - tn: 366.0000 - fn: 65.0000 - accuracy: 0.7992 - precision: 0.7224 - recall: 0.7575 - auc: 0.8499 - val_loss: 0.4841 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8788\n",
      "Epoch 427/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.5023 - tp: 205.0000 - fp: 80.0000 - tn: 364.0000 - fn: 63.0000 - accuracy: 0.7992 - precision: 0.7193 - recall: 0.7649 - auc: 0.8520 - val_loss: 0.4843 - val_tp: 56.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 18.0000 - val_accuracy: 0.7765 - val_precision: 0.7179 - val_recall: 0.7568 - val_auc: 0.8793\n",
      "Epoch 428/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4951 - tp: 205.0000 - fp: 79.0000 - tn: 365.0000 - fn: 63.0000 - accuracy: 0.8006 - precision: 0.7218 - recall: 0.7649 - auc: 0.8585 - val_loss: 0.4839 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8797\n",
      "Epoch 429/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4996 - tp: 201.0000 - fp: 80.0000 - tn: 364.0000 - fn: 67.0000 - accuracy: 0.7935 - precision: 0.7153 - recall: 0.7500 - auc: 0.8554 - val_loss: 0.4838 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8789\n",
      "Epoch 430/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.4977 - tp: 198.0000 - fp: 74.0000 - tn: 370.0000 - fn: 70.0000 - accuracy: 0.7978 - precision: 0.7279 - recall: 0.7388 - auc: 0.8594 - val_loss: 0.4836 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8799\n",
      "Epoch 431/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.4995 - tp: 201.0000 - fp: 83.0000 - tn: 361.0000 - fn: 67.0000 - accuracy: 0.7893 - precision: 0.7077 - recall: 0.7500 - auc: 0.8571 - val_loss: 0.4836 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8797\n",
      "Epoch 432/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4956 - tp: 200.0000 - fp: 80.0000 - tn: 364.0000 - fn: 68.0000 - accuracy: 0.7921 - precision: 0.7143 - recall: 0.7463 - auc: 0.8596 - val_loss: 0.4833 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8793\n",
      "Epoch 433/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.4930 - tp: 204.0000 - fp: 83.0000 - tn: 361.0000 - fn: 64.0000 - accuracy: 0.7935 - precision: 0.7108 - recall: 0.7612 - auc: 0.8636 - val_loss: 0.4833 - val_tp: 56.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 18.0000 - val_accuracy: 0.7765 - val_precision: 0.7179 - val_recall: 0.7568 - val_auc: 0.8799\n",
      "Epoch 434/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.5004 - tp: 198.0000 - fp: 74.0000 - tn: 370.0000 - fn: 70.0000 - accuracy: 0.7978 - precision: 0.7279 - recall: 0.7388 - auc: 0.8597 - val_loss: 0.4832 - val_tp: 56.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 18.0000 - val_accuracy: 0.7765 - val_precision: 0.7179 - val_recall: 0.7568 - val_auc: 0.8795\n",
      "Epoch 435/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4988 - tp: 204.0000 - fp: 78.0000 - tn: 366.0000 - fn: 64.0000 - accuracy: 0.8006 - precision: 0.7234 - recall: 0.7612 - auc: 0.8559 - val_loss: 0.4830 - val_tp: 56.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 18.0000 - val_accuracy: 0.7765 - val_precision: 0.7179 - val_recall: 0.7568 - val_auc: 0.8798\n",
      "Epoch 436/500\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4969 - tp: 202.0000 - fp: 84.0000 - tn: 360.0000 - fn: 66.0000 - accuracy: 0.7893 - precision: 0.7063 - recall: 0.7537 - auc: 0.8584 - val_loss: 0.4828 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8793\n",
      "Epoch 437/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.4974 - tp: 202.0000 - fp: 73.0000 - tn: 371.0000 - fn: 66.0000 - accuracy: 0.8048 - precision: 0.7345 - recall: 0.7537 - auc: 0.8606 - val_loss: 0.4827 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8803\n",
      "Epoch 438/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.4926 - tp: 201.0000 - fp: 73.0000 - tn: 371.0000 - fn: 67.0000 - accuracy: 0.8034 - precision: 0.7336 - recall: 0.7500 - auc: 0.8599 - val_loss: 0.4825 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8794\n",
      "Epoch 439/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 0.4923 - tp: 204.0000 - fp: 72.0000 - tn: 372.0000 - fn: 64.0000 - accuracy: 0.8090 - precision: 0.7391 - recall: 0.7612 - auc: 0.8620 - val_loss: 0.4823 - val_tp: 56.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 18.0000 - val_accuracy: 0.7877 - val_precision: 0.7368 - val_recall: 0.7568 - val_auc: 0.8800\n",
      "Epoch 440/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.4994 - tp: 203.0000 - fp: 74.0000 - tn: 370.0000 - fn: 65.0000 - accuracy: 0.8048 - precision: 0.7329 - recall: 0.7575 - auc: 0.8545 - val_loss: 0.4824 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8799\n",
      "Epoch 441/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.4904 - tp: 201.0000 - fp: 80.0000 - tn: 364.0000 - fn: 67.0000 - accuracy: 0.7935 - precision: 0.7153 - recall: 0.7500 - auc: 0.8676 - val_loss: 0.4822 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8806\n",
      "Epoch 442/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4925 - tp: 204.0000 - fp: 74.0000 - tn: 370.0000 - fn: 64.0000 - accuracy: 0.8062 - precision: 0.7338 - recall: 0.7612 - auc: 0.8604 - val_loss: 0.4821 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8801\n",
      "Epoch 443/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.4916 - tp: 203.0000 - fp: 72.0000 - tn: 372.0000 - fn: 65.0000 - accuracy: 0.8076 - precision: 0.7382 - recall: 0.7575 - auc: 0.8602 - val_loss: 0.4820 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8802\n",
      "Epoch 444/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.4972 - tp: 203.0000 - fp: 74.0000 - tn: 370.0000 - fn: 65.0000 - accuracy: 0.8048 - precision: 0.7329 - recall: 0.7575 - auc: 0.8592 - val_loss: 0.4819 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8784\n",
      "Epoch 445/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4883 - tp: 203.0000 - fp: 75.0000 - tn: 369.0000 - fn: 65.0000 - accuracy: 0.8034 - precision: 0.7302 - recall: 0.7575 - auc: 0.8662 - val_loss: 0.4817 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8809\n",
      "Epoch 446/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.4959 - tp: 201.0000 - fp: 76.0000 - tn: 368.0000 - fn: 67.0000 - accuracy: 0.7992 - precision: 0.7256 - recall: 0.7500 - auc: 0.8580 - val_loss: 0.4816 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8796\n",
      "Epoch 447/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4884 - tp: 203.0000 - fp: 74.0000 - tn: 370.0000 - fn: 65.0000 - accuracy: 0.8048 - precision: 0.7329 - recall: 0.7575 - auc: 0.8669 - val_loss: 0.4815 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8792\n",
      "Epoch 448/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.4917 - tp: 203.0000 - fp: 74.0000 - tn: 370.0000 - fn: 65.0000 - accuracy: 0.8048 - precision: 0.7329 - recall: 0.7575 - auc: 0.8595 - val_loss: 0.4814 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8806\n",
      "Epoch 449/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 0.4951 - tp: 202.0000 - fp: 81.0000 - tn: 363.0000 - fn: 66.0000 - accuracy: 0.7935 - precision: 0.7138 - recall: 0.7537 - auc: 0.8603 - val_loss: 0.4812 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8806\n",
      "Epoch 450/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.4915 - tp: 205.0000 - fp: 74.0000 - tn: 370.0000 - fn: 63.0000 - accuracy: 0.8076 - precision: 0.7348 - recall: 0.7649 - auc: 0.8613 - val_loss: 0.4813 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8802\n",
      "Epoch 451/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4915 - tp: 209.0000 - fp: 80.0000 - tn: 364.0000 - fn: 59.0000 - accuracy: 0.8048 - precision: 0.7232 - recall: 0.7799 - auc: 0.8635 - val_loss: 0.4811 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8802\n",
      "Epoch 452/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.4907 - tp: 200.0000 - fp: 69.0000 - tn: 375.0000 - fn: 68.0000 - accuracy: 0.8076 - precision: 0.7435 - recall: 0.7463 - auc: 0.8657 - val_loss: 0.4809 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8792\n",
      "Epoch 453/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 0.4908 - tp: 204.0000 - fp: 72.0000 - tn: 372.0000 - fn: 64.0000 - accuracy: 0.8090 - precision: 0.7391 - recall: 0.7612 - auc: 0.8608 - val_loss: 0.4808 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8798\n",
      "Epoch 454/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4988 - tp: 203.0000 - fp: 73.0000 - tn: 371.0000 - fn: 65.0000 - accuracy: 0.8062 - precision: 0.7355 - recall: 0.7575 - auc: 0.8528 - val_loss: 0.4806 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8806\n",
      "Epoch 455/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.4913 - tp: 202.0000 - fp: 72.0000 - tn: 372.0000 - fn: 66.0000 - accuracy: 0.8062 - precision: 0.7372 - recall: 0.7537 - auc: 0.8637 - val_loss: 0.4806 - val_tp: 56.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 18.0000 - val_accuracy: 0.7877 - val_precision: 0.7368 - val_recall: 0.7568 - val_auc: 0.8815\n",
      "Epoch 456/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.4941 - tp: 205.0000 - fp: 74.0000 - tn: 370.0000 - fn: 63.0000 - accuracy: 0.8076 - precision: 0.7348 - recall: 0.7649 - auc: 0.8589 - val_loss: 0.4805 - val_tp: 56.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 18.0000 - val_accuracy: 0.7821 - val_precision: 0.7273 - val_recall: 0.7568 - val_auc: 0.8804\n",
      "Epoch 457/500\n",
      "712/712 [==============================] - 0s 187us/sample - loss: 1.2743 - tp: 126.0000 - fp: 181.0000 - tn: 263.0000 - fn: 142.0000 - accuracy: 0.5463 - precision: 0.4104 - recall: 0.4701 - auc: 0.5202 - val_loss: 1.2736 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 90/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 1.2494 - tp: 102.0000 - fp: 181.0000 - tn: 263.0000 - fn: 166.0000 - accuracy: 0.5126 - precision: 0.3604 - recall: 0.3806 - auc: 0.4842 - val_loss: 1.2471 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 91/500\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 1.2202 - tp: 113.0000 - fp: 178.0000 - tn: 266.0000 - fn: 155.0000 - accuracy: 0.5323 - precision: 0.3883 - recall: 0.4216 - auc: 0.5347 - val_loss: 1.2214 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 92/500\n",
      "712/712 [==============================] - 0s 190us/sample - loss: 1.1961 - tp: 118.0000 - fp: 181.0000 - tn: 263.0000 - fn: 150.0000 - accuracy: 0.5351 - precision: 0.3946 - recall: 0.4403 - auc: 0.5150 - val_loss: 1.1965 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 93/500\n",
      "712/712 [==============================] - 0s 189us/sample - loss: 1.1717 - tp: 114.0000 - fp: 178.0000 - tn: 266.0000 - fn: 154.0000 - accuracy: 0.5337 - precision: 0.3904 - recall: 0.4254 - auc: 0.5145 - val_loss: 1.1726 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 94/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 1.1493 - tp: 99.0000 - fp: 165.0000 - tn: 279.0000 - fn: 169.0000 - accuracy: 0.5309 - precision: 0.3750 - recall: 0.3694 - auc: 0.4912 - val_loss: 1.1493 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 95/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 1.1249 - tp: 103.0000 - fp: 162.0000 - tn: 282.0000 - fn: 165.0000 - accuracy: 0.5407 - precision: 0.3887 - recall: 0.3843 - auc: 0.5203 - val_loss: 1.1267 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 96/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 1.1040 - tp: 103.0000 - fp: 189.0000 - tn: 255.0000 - fn: 165.0000 - accuracy: 0.5028 - precision: 0.3527 - recall: 0.3843 - auc: 0.4856 - val_loss: 1.1050 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 97/500\n",
      "712/712 [==============================] - 0s 181us/sample - loss: 1.0838 - tp: 109.0000 - fp: 187.0000 - tn: 257.0000 - fn: 159.0000 - accuracy: 0.5140 - precision: 0.3682 - recall: 0.4067 - auc: 0.4688 - val_loss: 1.0838 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 98/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 1.0636 - tp: 99.0000 - fp: 196.0000 - tn: 248.0000 - fn: 169.0000 - accuracy: 0.4874 - precision: 0.3356 - recall: 0.3694 - auc: 0.4563 - val_loss: 1.0634 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 99/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 1.0425 - tp: 91.0000 - fp: 168.0000 - tn: 276.0000 - fn: 177.0000 - accuracy: 0.5154 - precision: 0.3514 - recall: 0.3396 - auc: 0.4768 - val_loss: 1.0438 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 100/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 1.0227 - tp: 87.0000 - fp: 144.0000 - tn: 300.0000 - fn: 181.0000 - accuracy: 0.5435 - precision: 0.3766 - recall: 0.3246 - auc: 0.4982 - val_loss: 1.0249 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 101/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 1.0023 - tp: 90.0000 - fp: 167.0000 - tn: 277.0000 - fn: 178.0000 - accuracy: 0.5154 - precision: 0.3502 - recall: 0.3358 - auc: 0.5031 - val_loss: 1.0068 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 102/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.9851 - tp: 85.0000 - fp: 162.0000 - tn: 282.0000 - fn: 183.0000 - accuracy: 0.5154 - precision: 0.3441 - recall: 0.3172 - auc: 0.5076 - val_loss: 0.9894 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 103/500\n",
      "712/712 [==============================] - 0s 171us/sample - loss: 0.9678 - tp: 88.0000 - fp: 141.0000 - tn: 303.0000 - fn: 180.0000 - accuracy: 0.5492 - precision: 0.3843 - recall: 0.3284 - auc: 0.5143 - val_loss: 0.9725 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 104/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.9524 - tp: 89.0000 - fp: 155.0000 - tn: 289.0000 - fn: 179.0000 - accuracy: 0.5309 - precision: 0.3648 - recall: 0.3321 - auc: 0.4833 - val_loss: 0.9564 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 105/500\n",
      "712/712 [==============================] - 0s 176us/sample - loss: 0.9380 - tp: 89.0000 - fp: 140.0000 - tn: 304.0000 - fn: 179.0000 - accuracy: 0.5520 - precision: 0.3886 - recall: 0.3321 - auc: 0.4796 - val_loss: 0.9410 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 106/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.9210 - tp: 82.0000 - fp: 133.0000 - tn: 311.0000 - fn: 186.0000 - accuracy: 0.5520 - precision: 0.3814 - recall: 0.3060 - auc: 0.5076 - val_loss: 0.9264 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 107/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.9064 - tp: 92.0000 - fp: 140.0000 - tn: 304.0000 - fn: 176.0000 - accuracy: 0.5562 - precision: 0.3966 - recall: 0.3433 - auc: 0.5102 - val_loss: 0.9126 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 108/500\n",
      "712/712 [==============================] - 0s 159us/sample - loss: 0.8941 - tp: 67.0000 - fp: 145.0000 - tn: 299.0000 - fn: 201.0000 - accuracy: 0.5140 - precision: 0.3160 - recall: 0.2500 - auc: 0.4880 - val_loss: 0.8998 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 109/500\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.8802 - tp: 87.0000 - fp: 131.0000 - tn: 313.0000 - fn: 181.0000 - accuracy: 0.5618 - precision: 0.3991 - recall: 0.3246 - auc: 0.5077 - val_loss: 0.8876 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 110/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.8704 - tp: 77.0000 - fp: 134.0000 - tn: 310.0000 - fn: 191.0000 - accuracy: 0.5435 - precision: 0.3649 - recall: 0.2873 - auc: 0.4844 - val_loss: 0.8761 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 111/500\n",
      "712/712 [==============================] - 0s 178us/sample - loss: 0.8553 - tp: 86.0000 - fp: 120.0000 - tn: 324.0000 - fn: 182.0000 - accuracy: 0.5758 - precision: 0.4175 - recall: 0.3209 - auc: 0.5548 - val_loss: 0.8653 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 112/500\n",
      "712/712 [==============================] - 0s 172us/sample - loss: 0.8467 - tp: 79.0000 - fp: 114.0000 - tn: 330.0000 - fn: 189.0000 - accuracy: 0.5744 - precision: 0.4093 - recall: 0.2948 - auc: 0.5186 - val_loss: 0.8553 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 113/500\n",
      "712/712 [==============================] - 0s 160us/sample - loss: 0.8366 - tp: 79.0000 - fp: 100.0000 - tn: 344.0000 - fn: 189.0000 - accuracy: 0.5941 - precision: 0.4413 - recall: 0.2948 - auc: 0.5298 - val_loss: 0.8460 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 114/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.8288 - tp: 65.0000 - fp: 112.0000 - tn: 332.0000 - fn: 203.0000 - accuracy: 0.5576 - precision: 0.3672 - recall: 0.2425 - auc: 0.4851 - val_loss: 0.8375 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 115/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.8204 - tp: 79.0000 - fp: 114.0000 - tn: 330.0000 - fn: 189.0000 - accuracy: 0.5744 - precision: 0.4093 - recall: 0.2948 - auc: 0.5213 - val_loss: 0.8297 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 116/500\n",
      "712/712 [==============================] - 0s 165us/sample - loss: 0.8119 - tp: 75.0000 - fp: 99.0000 - tn: 345.0000 - fn: 193.0000 - accuracy: 0.5899 - precision: 0.4310 - recall: 0.2799 - auc: 0.5289 - val_loss: 0.8227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 117/500\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 0.8069 - tp: 53.0000 - fp: 99.0000 - tn: 345.0000 - fn: 215.0000 - accuracy: 0.5590 - precision: 0.3487 - recall: 0.1978 - auc: 0.4788 - val_loss: 0.8162 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 118/500\n",
      "712/712 [==============================] - 0s 167us/sample - loss: 0.7990 - tp: 62.0000 - fp: 91.0000 - tn: 353.0000 - fn: 206.0000 - accuracy: 0.5829 - precision: 0.4052 - recall: 0.2313 - auc: 0.5235 - val_loss: 0.8104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 119/500\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.7945 - tp: 60.0000 - fp: 104.0000 - tn: 340.0000 - fn: 208.0000 - accuracy: 0.5618 - precision: 0.3659 - recall: 0.2239 - auc: 0.4971 - val_loss: 0.8051 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 120/500\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 0.7914 - tp: 50.0000 - fp: 97.0000 - tn: 347.0000 - fn: 218.0000 - accuracy: 0.5576 - precision: 0.3401 - recall: 0.1866 - auc: 0.4558 - val_loss: 0.8006 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 121/500\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 0.7828 - tp: 66.0000 - fp: 82.0000 - tn: 362.0000 - fn: 202.0000 - accuracy: 0.6011 - precision: 0.4459 - recall: 0.2463 - auc: 0.5585 - val_loss: 0.7965 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 122/500\n",
      "712/712 [==============================] - 0s 164us/sample - loss: 0.7809 - tp: 60.0000 - fp: 83.0000 - tn: 361.0000 - fn: 208.0000 - accuracy: 0.5913 - precision: 0.4196 - recall: 0.2239 - auc: 0.5135 - val_loss: 0.7929 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 123/500\n",
      "712/712 [==============================] - 0s 180us/sample - loss: 0.7784 - tp: 41.0000 - fp: 79.0000 - tn: 365.0000 - fn: 227.0000 - accuracy: 0.5702 - precision: 0.3417 - recall: 0.1530 - auc: 0.4952 - val_loss: 0.7898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 124/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.7737 - tp: 52.0000 - fp: 71.0000 - tn: 373.0000 - fn: 216.0000 - accuracy: 0.5969 - precision: 0.4228 - recall: 0.1940 - auc: 0.5343 - val_loss: 0.7870 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 125/500\n",
      "712/712 [==============================] - 0s 168us/sample - loss: 0.7729 - tp: 39.0000 - fp: 76.0000 - tn: 368.0000 - fn: 229.0000 - accuracy: 0.5716 - precision: 0.3391 - recall: 0.1455 - auc: 0.4876 - val_loss: 0.7846 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 126/500\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 0.7693 - tp: 32.0000 - fp: 52.0000 - tn: 392.0000 - fn: 236.0000 - accuracy: 0.5955 - precision: 0.3810 - recall: 0.1194 - auc: 0.5180 - val_loss: 0.7823 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 127/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 3.7866 - tp: 238.0000 - fp: 382.0000 - tn: 62.0000 - fn: 30.0000 - accuracy: 0.4213 - precision: 0.3839 - recall: 0.8881 - auc: 0.5678 - val_loss: 3.7556 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7441\n",
      "Epoch 589/700\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 3.7781 - tp: 249.0000 - fp: 383.0000 - tn: 61.0000 - fn: 19.0000 - accuracy: 0.4354 - precision: 0.3940 - recall: 0.9291 - auc: 0.5985 - val_loss: 3.7555 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7452\n",
      "Epoch 590/700\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 3.7894 - tp: 237.0000 - fp: 383.0000 - tn: 61.0000 - fn: 31.0000 - accuracy: 0.4185 - precision: 0.3823 - recall: 0.8843 - auc: 0.5705 - val_loss: 3.7554 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7457\n",
      "Epoch 591/700\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 3.7861 - tp: 241.0000 - fp: 395.0000 - tn: 49.0000 - fn: 27.0000 - accuracy: 0.4073 - precision: 0.3789 - recall: 0.8993 - auc: 0.5790 - val_loss: 3.7554 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7459\n",
      "Epoch 592/700\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 3.7812 - tp: 240.0000 - fp: 383.0000 - tn: 61.0000 - fn: 28.0000 - accuracy: 0.4228 - precision: 0.3852 - recall: 0.8955 - auc: 0.5937 - val_loss: 3.7553 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7459\n",
      "Epoch 593/700\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 3.7863 - tp: 249.0000 - fp: 386.0000 - tn: 58.0000 - fn: 19.0000 - accuracy: 0.4312 - precision: 0.3921 - recall: 0.9291 - auc: 0.5856 - val_loss: 3.7552 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7490\n",
      "Epoch 594/700\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 3.7777 - tp: 235.0000 - fp: 385.0000 - tn: 59.0000 - fn: 33.0000 - accuracy: 0.4129 - precision: 0.3790 - recall: 0.8769 - auc: 0.6030 - val_loss: 3.7551 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7486\n",
      "Epoch 595/700\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 3.7837 - tp: 238.0000 - fp: 389.0000 - tn: 55.0000 - fn: 30.0000 - accuracy: 0.4115 - precision: 0.3796 - recall: 0.8881 - auc: 0.5879 - val_loss: 3.7550 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7503\n",
      "Epoch 596/700\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 3.7804 - tp: 245.0000 - fp: 381.0000 - tn: 63.0000 - fn: 23.0000 - accuracy: 0.4326 - precision: 0.3914 - recall: 0.9142 - auc: 0.6029 - val_loss: 3.7549 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7503\n",
      "Epoch 597/700\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 3.7936 - tp: 236.0000 - fp: 390.0000 - tn: 54.0000 - fn: 32.0000 - accuracy: 0.4073 - precision: 0.3770 - recall: 0.8806 - auc: 0.5697 - val_loss: 3.7548 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7505\n",
      "Epoch 598/700\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 3.7768 - tp: 249.0000 - fp: 392.0000 - tn: 52.0000 - fn: 19.0000 - accuracy: 0.4228 - precision: 0.3885 - recall: 0.9291 - auc: 0.6177 - val_loss: 3.7548 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7505\n",
      "Epoch 599/700\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 3.7821 - tp: 240.0000 - fp: 392.0000 - tn: 52.0000 - fn: 28.0000 - accuracy: 0.4101 - precision: 0.3797 - recall: 0.8955 - auc: 0.5965 - val_loss: 3.7547 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7505\n",
      "Epoch 600/700\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 3.7762 - tp: 237.0000 - fp: 379.0000 - tn: 65.0000 - fn: 31.0000 - accuracy: 0.4242 - precision: 0.3847 - recall: 0.8843 - auc: 0.6011 - val_loss: 3.7546 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7505\n",
      "Epoch 601/700\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 3.7768 - tp: 247.0000 - fp: 379.0000 - tn: 65.0000 - fn: 21.0000 - accuracy: 0.4382 - precision: 0.3946 - recall: 0.9216 - auc: 0.6044 - val_loss: 3.7545 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7510\n",
      "Epoch 602/700\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 3.7777 - tp: 240.0000 - fp: 388.0000 - tn: 56.0000 - fn: 28.0000 - accuracy: 0.4157 - precision: 0.3822 - recall: 0.8955 - auc: 0.6195 - val_loss: 3.7544 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7514\n",
      "Epoch 603/700\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 3.7919 - tp: 240.0000 - fp: 394.0000 - tn: 50.0000 - fn: 28.0000 - accuracy: 0.4073 - precision: 0.3785 - recall: 0.8955 - auc: 0.5571 - val_loss: 3.7543 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7507\n",
      "Epoch 604/700\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 3.7886 - tp: 244.0000 - fp: 395.0000 - tn: 49.0000 - fn: 24.0000 - accuracy: 0.4115 - precision: 0.3818 - recall: 0.9104 - auc: 0.5763 - val_loss: 3.7543 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7507\n",
      "Epoch 605/700\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 3.7804 - tp: 241.0000 - fp: 396.0000 - tn: 48.0000 - fn: 27.0000 - accuracy: 0.4059 - precision: 0.3783 - recall: 0.8993 - auc: 0.6093 - val_loss: 3.7542 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7504\n",
      "Epoch 606/700\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 3.7937 - tp: 230.0000 - fp: 385.0000 - tn: 59.0000 - fn: 38.0000 - accuracy: 0.4059 - precision: 0.3740 - recall: 0.8582 - auc: 0.5591 - val_loss: 3.7541 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7504\n",
      "Epoch 607/700\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 3.7699 - tp: 245.0000 - fp: 387.0000 - tn: 57.0000 - fn: 23.0000 - accuracy: 0.4242 - precision: 0.3877 - recall: 0.9142 - auc: 0.6145 - val_loss: 3.7540 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7508\n",
      "Epoch 608/700\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 3.7786 - tp: 240.0000 - fp: 383.0000 - tn: 61.0000 - fn: 28.0000 - accuracy: 0.4228 - precision: 0.3852 - recall: 0.8955 - auc: 0.6121 - val_loss: 3.7539 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7519\n",
      "Epoch 609/700\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 3.7801 - tp: 239.0000 - fp: 389.0000 - tn: 55.0000 - fn: 29.0000 - accuracy: 0.4129 - precision: 0.3806 - recall: 0.8918 - auc: 0.6043 - val_loss: 3.7539 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7524\n",
      "Epoch 610/700\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 3.7758 - tp: 248.0000 - fp: 392.0000 - tn: 52.0000 - fn: 20.0000 - accuracy: 0.4213 - precision: 0.3875 - recall: 0.9254 - auc: 0.6183 - val_loss: 3.7538 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7524\n",
      "Epoch 611/700\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 3.7922 - tp: 238.0000 - fp: 384.0000 - tn: 60.0000 - fn: 30.0000 - accuracy: 0.4185 - precision: 0.3826 - recall: 0.8881 - auc: 0.5567 - val_loss: 3.7537 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7528\n",
      "Epoch 612/700\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 3.7943 - tp: 225.0000 - fp: 396.0000 - tn: 48.0000 - fn: 43.0000 - accuracy: 0.3834 - precision: 0.3623 - recall: 0.8396 - auc: 0.5683 - val_loss: 3.7536 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7531\n",
      "Epoch 613/700\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 3.7789 - tp: 246.0000 - fp: 387.0000 - tn: 57.0000 - fn: 22.0000 - accuracy: 0.4256 - precision: 0.3886 - recall: 0.9179 - auc: 0.5839 - val_loss: 3.7535 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7545\n",
      "Epoch 614/700\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 3.7774 - tp: 235.0000 - fp: 387.0000 - tn: 57.0000 - fn: 33.0000 - accuracy: 0.4101 - precision: 0.3778 - recall: 0.8769 - auc: 0.6115 - val_loss: 3.7534 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7554\n",
      "Epoch 615/700\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 3.7758 - tp: 243.0000 - fp: 372.0000 - tn: 72.0000 - fn: 25.0000 - accuracy: 0.4424 - precision: 0.3951 - recall: 0.9067 - auc: 0.6016 - val_loss: 3.7534 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7554\n",
      "Epoch 616/700\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 3.7685 - tp: 244.0000 - fp: 368.0000 - tn: 76.0000 - fn: 24.0000 - accuracy: 0.4494 - precision: 0.3987 - recall: 0.9104 - auc: 0.6256 - val_loss: 3.7533 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7551\n",
      "Epoch 617/700\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 3.7758 - tp: 237.0000 - fp: 391.0000 - tn: 53.0000 - fn: 31.0000 - accuracy: 0.4073 - precision: 0.3774 - recall: 0.8843 - auc: 0.6116 - val_loss: 3.7532 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7555\n",
      "Epoch 618/700\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 3.7822 - tp: 241.0000 - fp: 386.0000 - tn: 58.0000 - fn: 27.0000 - accuracy: 0.4199 - precision: 0.3844 - recall: 0.8993 - auc: 0.5900 - val_loss: 3.7531 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7560\n",
      "Epoch 619/700\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 3.7910 - tp: 235.0000 - fp: 396.0000 - tn: 48.0000 - fn: 33.0000 - accuracy: 0.3975 - precision: 0.3724 - recall: 0.8769 - auc: 0.5614 - val_loss: 3.7530 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7560\n",
      "Epoch 620/700\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 3.7869 - tp: 233.0000 - fp: 388.0000 - tn: 56.0000 - fn: 35.0000 - accuracy: 0.4059 - precision: 0.3752 - recall: 0.8694 - auc: 0.5754 - val_loss: 3.7530 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7550\n",
      "Epoch 621/700\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 3.7711 - tp: 237.0000 - fp: 384.0000 - tn: 60.0000 - fn: 31.0000 - accuracy: 0.4171 - precision: 0.3816 - recall: 0.8843 - auc: 0.6238 - val_loss: 3.7529 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7550\n",
      "Epoch 622/700\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 3.7845 - tp: 235.0000 - fp: 382.0000 - tn: 62.0000 - fn: 33.0000 - accuracy: 0.4171 - precision: 0.3809 - recall: 0.8769 - auc: 0.5795 - val_loss: 3.7528 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7537\n",
      "Epoch 623/700\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 3.7855 - tp: 236.0000 - fp: 376.0000 - tn: 68.0000 - fn: 32.0000 - accuracy: 0.4270 - precision: 0.3856 - recall: 0.8806 - auc: 0.5773 - val_loss: 3.7527 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7536\n",
      "Epoch 624/700\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 3.7819 - tp: 237.0000 - fp: 394.0000 - tn: 50.0000 - fn: 31.0000 - accuracy: 0.4031 - precision: 0.3756 - recall: 0.8843 - auc: 0.5838 - val_loss: 3.7526 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7536\n",
      "Epoch 625/700\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 3.7789 - tp: 240.0000 - fp: 382.0000 - tn: 62.0000 - fn: 28.0000 - accuracy: 0.4242 - precision: 0.3859 - recall: 0.8955 - auc: 0.6075 - val_loss: 3.7525 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7536\n",
      "Epoch 626/700\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 3.7709 - tp: 245.0000 - fp: 394.0000 - tn: 50.0000 - fn: 23.0000 - accuracy: 0.4143 - precision: 0.3834 - recall: 0.9142 - auc: 0.6076 - val_loss: 3.7525 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7536\n",
      "Epoch 627/700\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 3.7871 - tp: 233.0000 - fp: 399.0000 - tn: 45.0000 - fn: 35.0000 - accuracy: 0.3904 - precision: 0.3687 - recall: 0.8694 - auc: 0.5615 - val_loss: 3.7524 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7539\n",
      "Epoch 628/700\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 3.7825 - tp: 240.0000 - fp: 384.0000 - tn: 60.0000 - fn: 28.0000 - accuracy: 0.4213 - precision: 0.3846 - recall: 0.8955 - auc: 0.5823 - val_loss: 3.7523 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7540\n",
      "Epoch 629/700\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 3.7819 - tp: 240.0000 - fp: 380.0000 - tn: 64.0000 - fn: 28.0000 - accuracy: 0.4270 - precision: 0.3871 - recall: 0.8955 - auc: 0.5864 - val_loss: 3.7522 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7546\n",
      "Epoch 630/700\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 3.7802 - tp: 241.0000 - fp: 383.0000 - tn: 61.0000 - fn: 27.0000 - accuracy: 0.4242 - precision: 0.3862 - recall: 0.8993 - auc: 0.5797 - val_loss: 3.7521 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7551\n",
      "Epoch 631/700\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 3.7854 - tp: 239.0000 - fp: 375.0000 - tn: 69.0000 - fn: 29.0000 - accuracy: 0.4326 - precision: 0.3893 - recall: 0.8918 - auc: 0.5676 - val_loss: 3.7521 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7551\n",
      "Epoch 632/700\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 3.7908 - tp: 235.0000 - fp: 394.0000 - tn: 50.0000 - fn: 33.0000 - accuracy: 0.4003 - precision: 0.3736 - recall: 0.8769 - auc: 0.5550 - val_loss: 3.7520 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7551\n",
      "Epoch 633/700\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 3.7854 - tp: 240.0000 - fp: 388.0000 - tn: 56.0000 - fn: 28.0000 - accuracy: 0.4157 - precision: 0.3822 - recall: 0.8955 - auc: 0.5766 - val_loss: 3.7519 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7541\n",
      "Epoch 634/700\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 3.7775 - tp: 235.0000 - fp: 383.0000 - tn: 61.0000 - fn: 33.0000 - accuracy: 0.4157 - precision: 0.3803 - recall: 0.8769 - auc: 0.5967 - val_loss: 3.7518 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7542\n",
      "Epoch 635/700\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 3.7721 - tp: 248.0000 - fp: 386.0000 - tn: 58.0000 - fn: 20.0000 - accuracy: 0.4298 - precision: 0.3912 - recall: 0.9254 - auc: 0.6218 - val_loss: 3.7517 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7534\n",
      "Epoch 636/700\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 3.7778 - tp: 234.0000 - fp: 370.0000 - tn: 74.0000 - fn: 34.0000 - accuracy: 0.4326 - precision: 0.3874 - recall: 0.8731 - auc: 0.5873 - val_loss: 3.7516 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7536\n",
      "Epoch 637/700\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 3.7772 - tp: 246.0000 - fp: 374.0000 - tn: 70.0000 - fn: 22.0000 - accuracy: 0.4438 - precision: 0.3968 - recall: 0.9179 - auc: 0.5984 - val_loss: 3.7516 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7527\n",
      "Epoch 638/700\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 3.7750 - tp: 247.0000 - fp: 386.0000 - tn: 58.0000 - fn: 21.0000 - accuracy: 0.4284 - precision: 0.3902 - recall: 0.9216 - auc: 0.6001 - val_loss: 3.7515 - val_tp: 74.0000 - val_fp: 105.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4134 - val_precision: 0.4134 - val_recall: 1.0000 - val_auc: 0.7531\n",
      "Epoch 639/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5310 - tp: 199.0000 - fp: 63.0000 - tn: 381.0000 - fn: 69.0000 - accuracy: 0.8146 - precision: 0.7595 - recall: 0.7425 - auc: 0.8401 - val_loss: 0.5076 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8856\n",
      "Epoch 234/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5119 - tp: 204.0000 - fp: 67.0000 - tn: 377.0000 - fn: 64.0000 - accuracy: 0.8160 - precision: 0.7528 - recall: 0.7612 - auc: 0.8526 - val_loss: 0.5088 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8862\n",
      "Epoch 235/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5213 - tp: 198.0000 - fp: 60.0000 - tn: 384.0000 - fn: 70.0000 - accuracy: 0.8174 - precision: 0.7674 - recall: 0.7388 - auc: 0.8482 - val_loss: 0.5075 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8850\n",
      "Epoch 236/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5289 - tp: 204.0000 - fp: 73.0000 - tn: 371.0000 - fn: 64.0000 - accuracy: 0.8076 - precision: 0.7365 - recall: 0.7612 - auc: 0.8435 - val_loss: 0.5116 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8838\n",
      "Epoch 237/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5116 - tp: 201.0000 - fp: 62.0000 - tn: 382.0000 - fn: 67.0000 - accuracy: 0.8188 - precision: 0.7643 - recall: 0.7500 - auc: 0.8575 - val_loss: 0.5101 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8835\n",
      "Epoch 238/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5078 - tp: 197.0000 - fp: 59.0000 - tn: 385.0000 - fn: 71.0000 - accuracy: 0.8174 - precision: 0.7695 - recall: 0.7351 - auc: 0.8619 - val_loss: 0.5084 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 239/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5284 - tp: 205.0000 - fp: 69.0000 - tn: 375.0000 - fn: 63.0000 - accuracy: 0.8146 - precision: 0.7482 - recall: 0.7649 - auc: 0.8379 - val_loss: 0.5062 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8847\n",
      "Epoch 240/500\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5191 - tp: 196.0000 - fp: 61.0000 - tn: 383.0000 - fn: 72.0000 - accuracy: 0.8132 - precision: 0.7626 - recall: 0.7313 - auc: 0.8488 - val_loss: 0.5053 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8840\n",
      "Epoch 241/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5148 - tp: 203.0000 - fp: 59.0000 - tn: 385.0000 - fn: 65.0000 - accuracy: 0.8258 - precision: 0.7748 - recall: 0.7575 - auc: 0.8482 - val_loss: 0.5058 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8847\n",
      "Epoch 242/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5129 - tp: 206.0000 - fp: 70.0000 - tn: 374.0000 - fn: 62.0000 - accuracy: 0.8146 - precision: 0.7464 - recall: 0.7687 - auc: 0.8563 - val_loss: 0.5050 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8858\n",
      "Epoch 243/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5185 - tp: 206.0000 - fp: 73.0000 - tn: 371.0000 - fn: 62.0000 - accuracy: 0.8104 - precision: 0.7384 - recall: 0.7687 - auc: 0.8522 - val_loss: 0.5061 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8849\n",
      "Epoch 244/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5320 - tp: 201.0000 - fp: 64.0000 - tn: 380.0000 - fn: 67.0000 - accuracy: 0.8160 - precision: 0.7585 - recall: 0.7500 - auc: 0.8385 - val_loss: 0.5074 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8848\n",
      "Epoch 245/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5180 - tp: 210.0000 - fp: 75.0000 - tn: 369.0000 - fn: 58.0000 - accuracy: 0.8132 - precision: 0.7368 - recall: 0.7836 - auc: 0.8519 - val_loss: 0.5076 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8848\n",
      "Epoch 246/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5193 - tp: 195.0000 - fp: 59.0000 - tn: 385.0000 - fn: 73.0000 - accuracy: 0.8146 - precision: 0.7677 - recall: 0.7276 - auc: 0.8516 - val_loss: 0.5065 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8847\n",
      "Epoch 247/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5250 - tp: 199.0000 - fp: 58.0000 - tn: 386.0000 - fn: 69.0000 - accuracy: 0.8216 - precision: 0.7743 - recall: 0.7425 - auc: 0.8421 - val_loss: 0.5054 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8848\n",
      "Epoch 248/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5113 - tp: 206.0000 - fp: 67.0000 - tn: 377.0000 - fn: 62.0000 - accuracy: 0.8188 - precision: 0.7546 - recall: 0.7687 - auc: 0.8531 - val_loss: 0.5053 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8848\n",
      "Epoch 249/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5116 - tp: 203.0000 - fp: 61.0000 - tn: 383.0000 - fn: 65.0000 - accuracy: 0.8230 - precision: 0.7689 - recall: 0.7575 - auc: 0.8508 - val_loss: 0.5063 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8838\n",
      "Epoch 250/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5214 - tp: 201.0000 - fp: 72.0000 - tn: 372.0000 - fn: 67.0000 - accuracy: 0.8048 - precision: 0.7363 - recall: 0.7500 - auc: 0.8507 - val_loss: 0.5050 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8846\n",
      "Epoch 251/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5204 - tp: 204.0000 - fp: 66.0000 - tn: 378.0000 - fn: 64.0000 - accuracy: 0.8174 - precision: 0.7556 - recall: 0.7612 - auc: 0.8447 - val_loss: 0.5055 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8837\n",
      "Epoch 252/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5110 - tp: 205.0000 - fp: 60.0000 - tn: 384.0000 - fn: 63.0000 - accuracy: 0.8272 - precision: 0.7736 - recall: 0.7649 - auc: 0.8586 - val_loss: 0.5042 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8847\n",
      "Epoch 253/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5240 - tp: 208.0000 - fp: 71.0000 - tn: 373.0000 - fn: 60.0000 - accuracy: 0.8160 - precision: 0.7455 - recall: 0.7761 - auc: 0.8428 - val_loss: 0.5056 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8856\n",
      "Epoch 254/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5165 - tp: 203.0000 - fp: 62.0000 - tn: 382.0000 - fn: 65.0000 - accuracy: 0.8216 - precision: 0.7660 - recall: 0.7575 - auc: 0.8471 - val_loss: 0.5045 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8856\n",
      "Epoch 255/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5209 - tp: 199.0000 - fp: 70.0000 - tn: 374.0000 - fn: 69.0000 - accuracy: 0.8048 - precision: 0.7398 - recall: 0.7425 - auc: 0.8505 - val_loss: 0.5043 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8851\n",
      "Epoch 256/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5121 - tp: 203.0000 - fp: 65.0000 - tn: 379.0000 - fn: 65.0000 - accuracy: 0.8174 - precision: 0.7575 - recall: 0.7575 - auc: 0.8575 - val_loss: 0.5040 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8839\n",
      "Epoch 257/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5028 - tp: 204.0000 - fp: 61.0000 - tn: 383.0000 - fn: 64.0000 - accuracy: 0.8244 - precision: 0.7698 - recall: 0.7612 - auc: 0.8684 - val_loss: 0.5035 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8852\n",
      "Epoch 258/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5331 - tp: 201.0000 - fp: 74.0000 - tn: 370.0000 - fn: 67.0000 - accuracy: 0.8020 - precision: 0.7309 - recall: 0.7500 - auc: 0.8356 - val_loss: 0.5042 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8845\n",
      "Epoch 259/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5197 - tp: 200.0000 - fp: 68.0000 - tn: 376.0000 - fn: 68.0000 - accuracy: 0.8090 - precision: 0.7463 - recall: 0.7463 - auc: 0.8519 - val_loss: 0.5040 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8847\n",
      "Epoch 260/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5211 - tp: 202.0000 - fp: 66.0000 - tn: 378.0000 - fn: 66.0000 - accuracy: 0.8146 - precision: 0.7537 - recall: 0.7537 - auc: 0.8457 - val_loss: 0.5032 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8847\n",
      "Epoch 261/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5208 - tp: 204.0000 - fp: 63.0000 - tn: 381.0000 - fn: 64.0000 - accuracy: 0.8216 - precision: 0.7640 - recall: 0.7612 - auc: 0.8483 - val_loss: 0.5029 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8849\n",
      "Epoch 262/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5200 - tp: 202.0000 - fp: 72.0000 - tn: 372.0000 - fn: 66.0000 - accuracy: 0.8062 - precision: 0.7372 - recall: 0.7537 - auc: 0.8512 - val_loss: 0.5024 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8858\n",
      "Epoch 263/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5098 - tp: 203.0000 - fp: 66.0000 - tn: 378.0000 - fn: 65.0000 - accuracy: 0.8160 - precision: 0.7546 - recall: 0.7575 - auc: 0.8555 - val_loss: 0.5034 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8854\n",
      "Epoch 264/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5247 - tp: 204.0000 - fp: 72.0000 - tn: 372.0000 - fn: 64.0000 - accuracy: 0.8090 - precision: 0.7391 - recall: 0.7612 - auc: 0.8437 - val_loss: 0.5040 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8858\n",
      "Epoch 265/500\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5290 - tp: 200.0000 - fp: 62.0000 - tn: 382.0000 - fn: 68.0000 - accuracy: 0.8174 - precision: 0.7634 - recall: 0.7463 - auc: 0.8402 - val_loss: 0.5050 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8846\n",
      "Epoch 266/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5134 - tp: 200.0000 - fp: 55.0000 - tn: 389.0000 - fn: 68.0000 - accuracy: 0.8272 - precision: 0.7843 - recall: 0.7463 - auc: 0.8501 - val_loss: 0.5034 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8851\n",
      "Epoch 267/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5203 - tp: 202.0000 - fp: 67.0000 - tn: 377.0000 - fn: 66.0000 - accuracy: 0.8132 - precision: 0.7509 - recall: 0.7537 - auc: 0.8465 - val_loss: 0.5029 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8848\n",
      "Epoch 268/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5048 - tp: 205.0000 - fp: 64.0000 - tn: 380.0000 - fn: 63.0000 - accuracy: 0.8216 - precision: 0.7621 - recall: 0.7649 - auc: 0.8570 - val_loss: 0.5035 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8862\n",
      "Epoch 269/500\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5171 - tp: 200.0000 - fp: 64.0000 - tn: 380.0000 - fn: 68.0000 - accuracy: 0.8146 - precision: 0.7576 - recall: 0.7463 - auc: 0.8501 - val_loss: 0.5066 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8858\n",
      "Epoch 270/500\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5145 - tp: 202.0000 - fp: 54.0000 - tn: 390.0000 - fn: 66.0000 - accuracy: 0.8315 - precision: 0.7891 - recall: 0.7537 - auc: 0.8544 - val_loss: 0.5036 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8858\n",
      "Epoch 271/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5162 - tp: 207.0000 - fp: 72.0000 - tn: 372.0000 - fn: 61.0000 - accuracy: 0.8132 - precision: 0.7419 - recall: 0.7724 - auc: 0.8506 - val_loss: 0.5036 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8856\n",
      "Epoch 272/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.4654 - tp: 185.0000 - fp: 132.0000 - tn: 312.0000 - fn: 83.0000 - accuracy: 0.6980 - precision: 0.5836 - recall: 0.6903 - auc: 0.7327 - val_loss: 1.4550 - val_tp: 55.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 19.0000 - val_accuracy: 0.7039 - val_precision: 0.6180 - val_recall: 0.7432 - val_auc: 0.8308\n",
      "Epoch 331/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.4723 - tp: 171.0000 - fp: 146.0000 - tn: 298.0000 - fn: 97.0000 - accuracy: 0.6587 - precision: 0.5394 - recall: 0.6381 - auc: 0.7099 - val_loss: 1.4538 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8316\n",
      "Epoch 332/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.4832 - tp: 166.0000 - fp: 151.0000 - tn: 293.0000 - fn: 102.0000 - accuracy: 0.6447 - precision: 0.5237 - recall: 0.6194 - auc: 0.6780 - val_loss: 1.4525 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8317\n",
      "Epoch 333/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.4656 - tp: 163.0000 - fp: 131.0000 - tn: 313.0000 - fn: 105.0000 - accuracy: 0.6685 - precision: 0.5544 - recall: 0.6082 - auc: 0.7195 - val_loss: 1.4512 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8313\n",
      "Epoch 334/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.4601 - tp: 174.0000 - fp: 144.0000 - tn: 300.0000 - fn: 94.0000 - accuracy: 0.6657 - precision: 0.5472 - recall: 0.6493 - auc: 0.7286 - val_loss: 1.4500 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8313\n",
      "Epoch 335/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 1.4761 - tp: 170.0000 - fp: 159.0000 - tn: 285.0000 - fn: 98.0000 - accuracy: 0.6390 - precision: 0.5167 - recall: 0.6343 - auc: 0.6831 - val_loss: 1.4488 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8313\n",
      "Epoch 336/400\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.4645 - tp: 170.0000 - fp: 135.0000 - tn: 309.0000 - fn: 98.0000 - accuracy: 0.6728 - precision: 0.5574 - recall: 0.6343 - auc: 0.7176 - val_loss: 1.4476 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8313\n",
      "Epoch 337/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.4710 - tp: 167.0000 - fp: 147.0000 - tn: 297.0000 - fn: 101.0000 - accuracy: 0.6517 - precision: 0.5318 - recall: 0.6231 - auc: 0.7071 - val_loss: 1.4464 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8320\n",
      "Epoch 338/400\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.4618 - tp: 163.0000 - fp: 131.0000 - tn: 313.0000 - fn: 105.0000 - accuracy: 0.6685 - precision: 0.5544 - recall: 0.6082 - auc: 0.7158 - val_loss: 1.4452 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8322\n",
      "Epoch 339/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.4697 - tp: 169.0000 - fp: 161.0000 - tn: 283.0000 - fn: 99.0000 - accuracy: 0.6348 - precision: 0.5121 - recall: 0.6306 - auc: 0.6980 - val_loss: 1.4440 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8317\n",
      "Epoch 340/400\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.4594 - tp: 165.0000 - fp: 134.0000 - tn: 310.0000 - fn: 103.0000 - accuracy: 0.6671 - precision: 0.5518 - recall: 0.6157 - auc: 0.7158 - val_loss: 1.4429 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8322\n",
      "Epoch 341/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.4637 - tp: 162.0000 - fp: 134.0000 - tn: 310.0000 - fn: 106.0000 - accuracy: 0.6629 - precision: 0.5473 - recall: 0.6045 - auc: 0.7026 - val_loss: 1.4418 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8316\n",
      "Epoch 342/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.4712 - tp: 159.0000 - fp: 149.0000 - tn: 295.0000 - fn: 109.0000 - accuracy: 0.6376 - precision: 0.5162 - recall: 0.5933 - auc: 0.6811 - val_loss: 1.4405 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8322\n",
      "Epoch 343/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.4587 - tp: 161.0000 - fp: 139.0000 - tn: 305.0000 - fn: 107.0000 - accuracy: 0.6545 - precision: 0.5367 - recall: 0.6007 - auc: 0.7107 - val_loss: 1.4393 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8322\n",
      "Epoch 344/400\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.4619 - tp: 175.0000 - fp: 156.0000 - tn: 288.0000 - fn: 93.0000 - accuracy: 0.6503 - precision: 0.5287 - recall: 0.6530 - auc: 0.6982 - val_loss: 1.4382 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8319\n",
      "Epoch 345/400\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.4552 - tp: 177.0000 - fp: 137.0000 - tn: 307.0000 - fn: 91.0000 - accuracy: 0.6798 - precision: 0.5637 - recall: 0.6604 - auc: 0.7173 - val_loss: 1.4369 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8317\n",
      "Epoch 346/400\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.4593 - tp: 170.0000 - fp: 138.0000 - tn: 306.0000 - fn: 98.0000 - accuracy: 0.6685 - precision: 0.5519 - recall: 0.6343 - auc: 0.7049 - val_loss: 1.4357 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8322\n",
      "Epoch 347/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.4558 - tp: 176.0000 - fp: 149.0000 - tn: 295.0000 - fn: 92.0000 - accuracy: 0.6615 - precision: 0.5415 - recall: 0.6567 - auc: 0.7135 - val_loss: 1.4344 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8329\n",
      "Epoch 348/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.4511 - tp: 173.0000 - fp: 139.0000 - tn: 305.0000 - fn: 95.0000 - accuracy: 0.6713 - precision: 0.5545 - recall: 0.6455 - auc: 0.7194 - val_loss: 1.4332 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8324\n",
      "Epoch 349/400\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 1.4642 - tp: 167.0000 - fp: 143.0000 - tn: 301.0000 - fn: 101.0000 - accuracy: 0.6573 - precision: 0.5387 - recall: 0.6231 - auc: 0.6883 - val_loss: 1.4321 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8328\n",
      "Epoch 350/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 1.4482 - tp: 165.0000 - fp: 130.0000 - tn: 314.0000 - fn: 103.0000 - accuracy: 0.6728 - precision: 0.5593 - recall: 0.6157 - auc: 0.7143 - val_loss: 1.4309 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8331\n",
      "Epoch 351/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 1.4600 - tp: 164.0000 - fp: 154.0000 - tn: 290.0000 - fn: 104.0000 - accuracy: 0.6376 - precision: 0.5157 - recall: 0.6119 - auc: 0.6888 - val_loss: 1.4298 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8339\n",
      "Epoch 352/400\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.4413 - tp: 179.0000 - fp: 136.0000 - tn: 308.0000 - fn: 89.0000 - accuracy: 0.6840 - precision: 0.5683 - recall: 0.6679 - auc: 0.7354 - val_loss: 1.4285 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8326\n",
      "Epoch 353/400\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.4445 - tp: 170.0000 - fp: 130.0000 - tn: 314.0000 - fn: 98.0000 - accuracy: 0.6798 - precision: 0.5667 - recall: 0.6343 - auc: 0.7250 - val_loss: 1.4273 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8327\n",
      "Epoch 354/400\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.4408 - tp: 181.0000 - fp: 138.0000 - tn: 306.0000 - fn: 87.0000 - accuracy: 0.6840 - precision: 0.5674 - recall: 0.6754 - auc: 0.7252 - val_loss: 1.4261 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8326\n",
      "Epoch 355/400\n",
      "712/712 [==============================] - 0s 161us/sample - loss: 1.4589 - tp: 170.0000 - fp: 137.0000 - tn: 307.0000 - fn: 98.0000 - accuracy: 0.6699 - precision: 0.5537 - recall: 0.6343 - auc: 0.6940 - val_loss: 1.4250 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8326\n",
      "Epoch 356/400\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 1.4564 - tp: 159.0000 - fp: 149.0000 - tn: 295.0000 - fn: 109.0000 - accuracy: 0.6376 - precision: 0.5162 - recall: 0.5933 - auc: 0.6866 - val_loss: 1.4238 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8324\n",
      "Epoch 357/400\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.4445 - tp: 163.0000 - fp: 145.0000 - tn: 299.0000 - fn: 105.0000 - accuracy: 0.6489 - precision: 0.5292 - recall: 0.6082 - auc: 0.7126 - val_loss: 1.4225 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8321\n",
      "Epoch 358/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.4526 - tp: 156.0000 - fp: 135.0000 - tn: 309.0000 - fn: 112.0000 - accuracy: 0.6531 - precision: 0.5361 - recall: 0.5821 - auc: 0.6851 - val_loss: 1.4215 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8333\n",
      "Epoch 359/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.4345 - tp: 177.0000 - fp: 137.0000 - tn: 307.0000 - fn: 91.0000 - accuracy: 0.6798 - precision: 0.5637 - recall: 0.6604 - auc: 0.7358 - val_loss: 1.4203 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8325\n",
      "Epoch 360/400\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 1.4426 - tp: 168.0000 - fp: 129.0000 - tn: 315.0000 - fn: 100.0000 - accuracy: 0.6784 - precision: 0.5657 - recall: 0.6269 - auc: 0.7138 - val_loss: 1.4190 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8328\n",
      "Epoch 361/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.4373 - tp: 170.0000 - fp: 137.0000 - tn: 307.0000 - fn: 98.0000 - accuracy: 0.6699 - precision: 0.5537 - recall: 0.6343 - auc: 0.7150 - val_loss: 1.4179 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8327\n",
      "Epoch 362/400\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.4351 - tp: 165.0000 - fp: 124.0000 - tn: 320.0000 - fn: 103.0000 - accuracy: 0.6812 - precision: 0.5709 - recall: 0.6157 - auc: 0.7256 - val_loss: 1.4167 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8333\n",
      "Epoch 363/400\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.4334 - tp: 173.0000 - fp: 137.0000 - tn: 307.0000 - fn: 95.0000 - accuracy: 0.6742 - precision: 0.5581 - recall: 0.6455 - auc: 0.7247 - val_loss: 1.4155 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8327\n",
      "Epoch 364/400\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.4408 - tp: 171.0000 - fp: 156.0000 - tn: 288.0000 - fn: 97.0000 - accuracy: 0.6447 - precision: 0.5229 - recall: 0.6381 - auc: 0.7035 - val_loss: 1.4143 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8335\n",
      "Epoch 365/400\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.4344 - tp: 170.0000 - fp: 132.0000 - tn: 312.0000 - fn: 98.0000 - accuracy: 0.6770 - precision: 0.5629 - recall: 0.6343 - auc: 0.7181 - val_loss: 1.4131 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8344\n",
      "Epoch 366/400\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 1.4254 - tp: 170.0000 - fp: 122.0000 - tn: 322.0000 - fn: 98.0000 - accuracy: 0.6910 - precision: 0.5822 - recall: 0.6343 - auc: 0.7462 - val_loss: 1.4118 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8346\n",
      "Epoch 367/400\n",
      "712/712 [==============================] - 0s 157us/sample - loss: 1.4276 - tp: 168.0000 - fp: 137.0000 - tn: 307.0000 - fn: 100.0000 - accuracy: 0.6671 - precision: 0.5508 - recall: 0.6269 - auc: 0.7303 - val_loss: 1.4105 - val_tp: 56.0000 - val_fp: 34.0000 - val_tn: 71.0000 - val_fn: 18.0000 - val_accuracy: 0.7095 - val_precision: 0.6222 - val_recall: 0.7568 - val_auc: 0.8328\n",
      "Epoch 368/400\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2502 - tp: 143.0000 - fp: 185.0000 - tn: 259.0000 - fn: 125.0000 - accuracy: 0.5646 - precision: 0.4360 - recall: 0.5336 - auc: 0.5955 - val_loss: 1.2158 - val_tp: 50.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 24.0000 - val_accuracy: 0.7598 - val_precision: 0.7246 - val_recall: 0.6757 - val_auc: 0.8412\n",
      "Epoch 240/700\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.2586 - tp: 153.0000 - fp: 188.0000 - tn: 256.0000 - fn: 115.0000 - accuracy: 0.5744 - precision: 0.4487 - recall: 0.5709 - auc: 0.5895 - val_loss: 1.2150 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8420\n",
      "Epoch 241/700\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.2494 - tp: 145.0000 - fp: 173.0000 - tn: 271.0000 - fn: 123.0000 - accuracy: 0.5843 - precision: 0.4560 - recall: 0.5410 - auc: 0.5959 - val_loss: 1.2139 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8432\n",
      "Epoch 242/700\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.2470 - tp: 143.0000 - fp: 161.0000 - tn: 283.0000 - fn: 125.0000 - accuracy: 0.5983 - precision: 0.4704 - recall: 0.5336 - auc: 0.6066 - val_loss: 1.2128 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8421\n",
      "Epoch 243/700\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2662 - tp: 143.0000 - fp: 197.0000 - tn: 247.0000 - fn: 125.0000 - accuracy: 0.5478 - precision: 0.4206 - recall: 0.5336 - auc: 0.5688 - val_loss: 1.2116 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8423\n",
      "Epoch 244/700\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.2507 - tp: 142.0000 - fp: 177.0000 - tn: 267.0000 - fn: 126.0000 - accuracy: 0.5744 - precision: 0.4451 - recall: 0.5299 - auc: 0.5872 - val_loss: 1.2105 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8420\n",
      "Epoch 245/700\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.2302 - tp: 155.0000 - fp: 178.0000 - tn: 266.0000 - fn: 113.0000 - accuracy: 0.5913 - precision: 0.4655 - recall: 0.5784 - auc: 0.6281 - val_loss: 1.2094 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8422\n",
      "Epoch 246/700\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.2381 - tp: 150.0000 - fp: 172.0000 - tn: 272.0000 - fn: 118.0000 - accuracy: 0.5927 - precision: 0.4658 - recall: 0.5597 - auc: 0.6134 - val_loss: 1.2085 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8423\n",
      "Epoch 247/700\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.2463 - tp: 144.0000 - fp: 190.0000 - tn: 254.0000 - fn: 124.0000 - accuracy: 0.5590 - precision: 0.4311 - recall: 0.5373 - auc: 0.5845 - val_loss: 1.2074 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8418\n",
      "Epoch 248/700\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.2493 - tp: 140.0000 - fp: 184.0000 - tn: 260.0000 - fn: 128.0000 - accuracy: 0.5618 - precision: 0.4321 - recall: 0.5224 - auc: 0.5867 - val_loss: 1.2063 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8420\n",
      "Epoch 249/700\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.2448 - tp: 146.0000 - fp: 181.0000 - tn: 263.0000 - fn: 122.0000 - accuracy: 0.5744 - precision: 0.4465 - recall: 0.5448 - auc: 0.6007 - val_loss: 1.2052 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8425\n",
      "Epoch 250/700\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.2345 - tp: 148.0000 - fp: 181.0000 - tn: 263.0000 - fn: 120.0000 - accuracy: 0.5772 - precision: 0.4498 - recall: 0.5522 - auc: 0.6072 - val_loss: 1.2041 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8426\n",
      "Epoch 251/700\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2472 - tp: 148.0000 - fp: 174.0000 - tn: 270.0000 - fn: 120.0000 - accuracy: 0.5871 - precision: 0.4596 - recall: 0.5522 - auc: 0.5871 - val_loss: 1.2030 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8418\n",
      "Epoch 252/700\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.2302 - tp: 149.0000 - fp: 168.0000 - tn: 276.0000 - fn: 119.0000 - accuracy: 0.5969 - precision: 0.4700 - recall: 0.5560 - auc: 0.6195 - val_loss: 1.2019 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8426\n",
      "Epoch 253/700\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.2300 - tp: 148.0000 - fp: 162.0000 - tn: 282.0000 - fn: 120.0000 - accuracy: 0.6039 - precision: 0.4774 - recall: 0.5522 - auc: 0.6249 - val_loss: 1.2009 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8430\n",
      "Epoch 254/700\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.2570 - tp: 132.0000 - fp: 184.0000 - tn: 260.0000 - fn: 136.0000 - accuracy: 0.5506 - precision: 0.4177 - recall: 0.4925 - auc: 0.5660 - val_loss: 1.1999 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8427\n",
      "Epoch 255/700\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.2416 - tp: 142.0000 - fp: 170.0000 - tn: 274.0000 - fn: 126.0000 - accuracy: 0.5843 - precision: 0.4551 - recall: 0.5299 - auc: 0.5902 - val_loss: 1.1989 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8426\n",
      "Epoch 256/700\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.2430 - tp: 150.0000 - fp: 191.0000 - tn: 253.0000 - fn: 118.0000 - accuracy: 0.5660 - precision: 0.4399 - recall: 0.5597 - auc: 0.5849 - val_loss: 1.1979 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8432\n",
      "Epoch 257/700\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.2253 - tp: 141.0000 - fp: 167.0000 - tn: 277.0000 - fn: 127.0000 - accuracy: 0.5871 - precision: 0.4578 - recall: 0.5261 - auc: 0.6152 - val_loss: 1.1969 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8423\n",
      "Epoch 258/700\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.2304 - tp: 150.0000 - fp: 176.0000 - tn: 268.0000 - fn: 118.0000 - accuracy: 0.5871 - precision: 0.4601 - recall: 0.5597 - auc: 0.6159 - val_loss: 1.1956 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8439\n",
      "Epoch 259/700\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.2244 - tp: 154.0000 - fp: 177.0000 - tn: 267.0000 - fn: 114.0000 - accuracy: 0.5913 - precision: 0.4653 - recall: 0.5746 - auc: 0.6167 - val_loss: 1.1944 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8443\n",
      "Epoch 260/700\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.2362 - tp: 144.0000 - fp: 159.0000 - tn: 285.0000 - fn: 124.0000 - accuracy: 0.6025 - precision: 0.4752 - recall: 0.5373 - auc: 0.5985 - val_loss: 1.1934 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8439\n",
      "Epoch 261/700\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.2329 - tp: 135.0000 - fp: 168.0000 - tn: 276.0000 - fn: 133.0000 - accuracy: 0.5772 - precision: 0.4455 - recall: 0.5037 - auc: 0.6015 - val_loss: 1.1924 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 25.0000 - val_accuracy: 0.7542 - val_precision: 0.7206 - val_recall: 0.6622 - val_auc: 0.8447\n",
      "Epoch 262/700\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.2355 - tp: 141.0000 - fp: 177.0000 - tn: 267.0000 - fn: 127.0000 - accuracy: 0.5730 - precision: 0.4434 - recall: 0.5261 - auc: 0.5901 - val_loss: 1.1911 - val_tp: 50.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 24.0000 - val_accuracy: 0.7542 - val_precision: 0.7143 - val_recall: 0.6757 - val_auc: 0.8432\n",
      "Epoch 263/700\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.2324 - tp: 140.0000 - fp: 200.0000 - tn: 244.0000 - fn: 128.0000 - accuracy: 0.5393 - precision: 0.4118 - recall: 0.5224 - auc: 0.5897 - val_loss: 1.1900 - val_tp: 50.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 24.0000 - val_accuracy: 0.7542 - val_precision: 0.7143 - val_recall: 0.6757 - val_auc: 0.8422\n",
      "Epoch 264/700\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2304 - tp: 156.0000 - fp: 181.0000 - tn: 263.0000 - fn: 112.0000 - accuracy: 0.5885 - precision: 0.4629 - recall: 0.5821 - auc: 0.6063 - val_loss: 1.1888 - val_tp: 50.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 24.0000 - val_accuracy: 0.7542 - val_precision: 0.7143 - val_recall: 0.6757 - val_auc: 0.8434\n",
      "Epoch 265/700\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.2124 - tp: 157.0000 - fp: 164.0000 - tn: 280.0000 - fn: 111.0000 - accuracy: 0.6138 - precision: 0.4891 - recall: 0.5858 - auc: 0.6347 - val_loss: 1.1877 - val_tp: 50.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 24.0000 - val_accuracy: 0.7486 - val_precision: 0.7042 - val_recall: 0.6757 - val_auc: 0.8432\n",
      "Epoch 266/700\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.2236 - tp: 137.0000 - fp: 164.0000 - tn: 280.0000 - fn: 131.0000 - accuracy: 0.5857 - precision: 0.4551 - recall: 0.5112 - auc: 0.6094 - val_loss: 1.1867 - val_tp: 50.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 24.0000 - val_accuracy: 0.7486 - val_precision: 0.7042 - val_recall: 0.6757 - val_auc: 0.8426\n",
      "Epoch 267/700\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.2157 - tp: 160.0000 - fp: 170.0000 - tn: 274.0000 - fn: 108.0000 - accuracy: 0.6096 - precision: 0.4848 - recall: 0.5970 - auc: 0.6306 - val_loss: 1.1857 - val_tp: 50.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 24.0000 - val_accuracy: 0.7486 - val_precision: 0.7042 - val_recall: 0.6757 - val_auc: 0.8426\n",
      "Epoch 268/700\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.2141 - tp: 147.0000 - fp: 156.0000 - tn: 288.0000 - fn: 121.0000 - accuracy: 0.6110 - precision: 0.4851 - recall: 0.5485 - auc: 0.6250 - val_loss: 1.1845 - val_tp: 50.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 24.0000 - val_accuracy: 0.7486 - val_precision: 0.7042 - val_recall: 0.6757 - val_auc: 0.8424\n",
      "Epoch 269/700\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.2151 - tp: 156.0000 - fp: 163.0000 - tn: 281.0000 - fn: 112.0000 - accuracy: 0.6138 - precision: 0.4890 - recall: 0.5821 - auc: 0.6281 - val_loss: 1.1834 - val_tp: 50.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 24.0000 - val_accuracy: 0.7486 - val_precision: 0.7042 - val_recall: 0.6757 - val_auc: 0.8427\n",
      "Epoch 270/700\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.2237 - tp: 137.0000 - fp: 174.0000 - tn: 270.0000 - fn: 131.0000 - accuracy: 0.5716 - precision: 0.4405 - recall: 0.5112 - auc: 0.6041 - val_loss: 1.1824 - val_tp: 50.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 24.0000 - val_accuracy: 0.7486 - val_precision: 0.7042 - val_recall: 0.6757 - val_auc: 0.8423\n",
      "Epoch 271/700\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.2136 - tp: 148.0000 - fp: 170.0000 - tn: 274.0000 - fn: 120.0000 - accuracy: 0.5927 - precision: 0.4654 - recall: 0.5522 - auc: 0.6282 - val_loss: 1.1814 - val_tp: 50.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 24.0000 - val_accuracy: 0.7486 - val_precision: 0.7042 - val_recall: 0.6757 - val_auc: 0.8429\n",
      "Epoch 272/700\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2126 - tp: 149.0000 - fp: 166.0000 - tn: 278.0000 - fn: 119.0000 - accuracy: 0.5997 - precision: 0.4730 - recall: 0.5560 - auc: 0.6277 - val_loss: 1.1802 - val_tp: 50.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 24.0000 - val_accuracy: 0.7430 - val_precision: 0.6944 - val_recall: 0.6757 - val_auc: 0.8441\n",
      "Epoch 273/700\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.2346 - tp: 146.0000 - fp: 188.0000 - tn: 256.0000 - fn: 122.0000 - accuracy: 0.5646 - precision: 0.4371 - recall: 0.5448 - auc: 0.5810 - val_loss: 1.1791 - val_tp: 50.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 24.0000 - val_accuracy: 0.7430 - val_precision: 0.6944 - val_recall: 0.6757 - val_auc: 0.8445\n",
      "Epoch 274/700\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.2185 - tp: 153.0000 - fp: 175.0000 - tn: 269.0000 - fn: 115.0000 - accuracy: 0.5927 - precision: 0.4665 - recall: 0.5709 - auc: 0.6044 - val_loss: 1.1781 - val_tp: 50.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 24.0000 - val_accuracy: 0.7430 - val_precision: 0.6944 - val_recall: 0.6757 - val_auc: 0.8445\n",
      "Epoch 275/700\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.2126 - tp: 159.0000 - fp: 192.0000 - tn: 252.0000 - fn: 109.0000 - accuracy: 0.5772 - precision: 0.4530 - recall: 0.5933 - auc: 0.6198 - val_loss: 1.1771 - val_tp: 50.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 24.0000 - val_accuracy: 0.7430 - val_precision: 0.6944 - val_recall: 0.6757 - val_auc: 0.8460\n",
      "Epoch 276/700\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.2114 - tp: 146.0000 - fp: 166.0000 - tn: 278.0000 - fn: 122.0000 - accuracy: 0.5955 - precision: 0.4679 - recall: 0.5448 - auc: 0.6213 - val_loss: 1.1760 - val_tp: 50.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 24.0000 - val_accuracy: 0.7430 - val_precision: 0.6944 - val_recall: 0.6757 - val_auc: 0.8443\n",
      "Epoch 277/700\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2102 - tp: 150.0000 - fp: 172.0000 - tn: 272.0000 - fn: 118.0000 - accuracy: 0.5927 - precision: 0.4658 - recall: 0.5597 - auc: 0.6235 - val_loss: 1.1750 - val_tp: 50.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 24.0000 - val_accuracy: 0.7430 - val_precision: 0.6944 - val_recall: 0.6757 - val_auc: 0.8442\n",
      "712/712 [==============================] - 3s 4ms/sample - loss: 0.7998 - tp: 78.0000 - fp: 121.0000 - tn: 323.0000 - fn: 190.0000 - accuracy: 0.5632 - precision: 0.3920 - recall: 0.2910 - auc: 0.5357 - val_loss: 0.8103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6910\n",
      "Epoch 2/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.8190 - tp: 88.0000 - fp: 139.0000 - tn: 305.0000 - fn: 180.0000 - accuracy: 0.5520 - precision: 0.3877 - recall: 0.3284 - auc: 0.4956 - val_loss: 0.8057 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7125\n",
      "Epoch 3/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.8091 - tp: 86.0000 - fp: 143.0000 - tn: 301.0000 - fn: 182.0000 - accuracy: 0.5435 - precision: 0.3755 - recall: 0.3209 - auc: 0.5051 - val_loss: 0.8013 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7409\n",
      "Epoch 4/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7976 - tp: 100.0000 - fp: 146.0000 - tn: 298.0000 - fn: 168.0000 - accuracy: 0.5590 - precision: 0.4065 - recall: 0.3731 - auc: 0.5297 - val_loss: 0.7987 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7826\n",
      "Epoch 5/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.8111 - tp: 81.0000 - fp: 165.0000 - tn: 279.0000 - fn: 187.0000 - accuracy: 0.5056 - precision: 0.3293 - recall: 0.3022 - auc: 0.4814 - val_loss: 0.7953 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7305\n",
      "Epoch 6/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.8061 - tp: 109.0000 - fp: 173.0000 - tn: 271.0000 - fn: 159.0000 - accuracy: 0.5337 - precision: 0.3865 - recall: 0.4067 - auc: 0.4970 - val_loss: 0.7934 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7911\n",
      "Epoch 7/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.8030 - tp: 104.0000 - fp: 180.0000 - tn: 264.0000 - fn: 164.0000 - accuracy: 0.5169 - precision: 0.3662 - recall: 0.3881 - auc: 0.4967 - val_loss: 0.7907 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7819\n",
      "Epoch 8/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.8009 - tp: 119.0000 - fp: 191.0000 - tn: 253.0000 - fn: 149.0000 - accuracy: 0.5225 - precision: 0.3839 - recall: 0.4440 - auc: 0.5134 - val_loss: 0.7892 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7558\n",
      "Epoch 9/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7971 - tp: 111.0000 - fp: 175.0000 - tn: 269.0000 - fn: 157.0000 - accuracy: 0.5337 - precision: 0.3881 - recall: 0.4142 - auc: 0.5103 - val_loss: 0.7870 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7860\n",
      "Epoch 10/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.7920 - tp: 123.0000 - fp: 197.0000 - tn: 247.0000 - fn: 145.0000 - accuracy: 0.5197 - precision: 0.3844 - recall: 0.4590 - auc: 0.5138 - val_loss: 0.7856 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7921\n",
      "Epoch 11/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.7807 - tp: 117.0000 - fp: 181.0000 - tn: 263.0000 - fn: 151.0000 - accuracy: 0.5337 - precision: 0.3926 - recall: 0.4366 - auc: 0.5481 - val_loss: 0.7837 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8256\n",
      "Epoch 12/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 0.7992 - tp: 116.0000 - fp: 197.0000 - tn: 247.0000 - fn: 152.0000 - accuracy: 0.5098 - precision: 0.3706 - recall: 0.4328 - auc: 0.5010 - val_loss: 0.7816 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8167\n",
      "Epoch 13/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7932 - tp: 125.0000 - fp: 208.0000 - tn: 236.0000 - fn: 143.0000 - accuracy: 0.5070 - precision: 0.3754 - recall: 0.4664 - auc: 0.5129 - val_loss: 0.7801 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8340\n",
      "Epoch 14/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7993 - tp: 119.0000 - fp: 184.0000 - tn: 260.0000 - fn: 149.0000 - accuracy: 0.5323 - precision: 0.3927 - recall: 0.4440 - auc: 0.4963 - val_loss: 0.7787 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8284\n",
      "Epoch 15/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7997 - tp: 122.0000 - fp: 216.0000 - tn: 228.0000 - fn: 146.0000 - accuracy: 0.4916 - precision: 0.3609 - recall: 0.4552 - auc: 0.4855 - val_loss: 0.7773 - val_tp: 4.0000 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 70.0000 - val_accuracy: 0.6089 - val_precision: 1.0000 - val_recall: 0.0541 - val_auc: 0.8384\n",
      "Epoch 16/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7912 - tp: 124.0000 - fp: 211.0000 - tn: 233.0000 - fn: 144.0000 - accuracy: 0.5014 - precision: 0.3701 - recall: 0.4627 - auc: 0.5029 - val_loss: 0.7764 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8396\n",
      "Epoch 17/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.7996 - tp: 112.0000 - fp: 209.0000 - tn: 235.0000 - fn: 156.0000 - accuracy: 0.4874 - precision: 0.3489 - recall: 0.4179 - auc: 0.4748 - val_loss: 0.7750 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 73.0000 - val_accuracy: 0.5922 - val_precision: 1.0000 - val_recall: 0.0135 - val_auc: 0.8383\n",
      "Epoch 18/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7867 - tp: 125.0000 - fp: 191.0000 - tn: 253.0000 - fn: 143.0000 - accuracy: 0.5309 - precision: 0.3956 - recall: 0.4664 - auc: 0.5220 - val_loss: 0.7736 - val_tp: 8.0000 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 66.0000 - val_accuracy: 0.6313 - val_precision: 1.0000 - val_recall: 0.1081 - val_auc: 0.8464\n",
      "Epoch 19/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.7903 - tp: 124.0000 - fp: 192.0000 - tn: 252.0000 - fn: 144.0000 - accuracy: 0.5281 - precision: 0.3924 - recall: 0.4627 - auc: 0.5079 - val_loss: 0.7719 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 102.0000 - val_fn: 54.0000 - val_accuracy: 0.6816 - val_precision: 0.8696 - val_recall: 0.2703 - val_auc: 0.8364\n",
      "Epoch 20/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7763 - tp: 141.0000 - fp: 186.0000 - tn: 258.0000 - fn: 127.0000 - accuracy: 0.5604 - precision: 0.4312 - recall: 0.5261 - auc: 0.5508 - val_loss: 0.7711 - val_tp: 10.0000 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 64.0000 - val_accuracy: 0.6425 - val_precision: 1.0000 - val_recall: 0.1351 - val_auc: 0.8519\n",
      "Epoch 21/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7807 - tp: 121.0000 - fp: 180.0000 - tn: 264.0000 - fn: 147.0000 - accuracy: 0.5407 - precision: 0.4020 - recall: 0.4515 - auc: 0.5292 - val_loss: 0.7695 - val_tp: 26.0000 - val_fp: 3.0000 - val_tn: 102.0000 - val_fn: 48.0000 - val_accuracy: 0.7151 - val_precision: 0.8966 - val_recall: 0.3514 - val_auc: 0.8385\n",
      "Epoch 22/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.7803 - tp: 123.0000 - fp: 198.0000 - tn: 246.0000 - fn: 145.0000 - accuracy: 0.5183 - precision: 0.3832 - recall: 0.4590 - auc: 0.5179 - val_loss: 0.7678 - val_tp: 35.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 39.0000 - val_accuracy: 0.7318 - val_precision: 0.7955 - val_recall: 0.4730 - val_auc: 0.8484\n",
      "Epoch 23/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.7825 - tp: 127.0000 - fp: 191.0000 - tn: 253.0000 - fn: 141.0000 - accuracy: 0.5337 - precision: 0.3994 - recall: 0.4739 - auc: 0.5207 - val_loss: 0.7664 - val_tp: 36.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 38.0000 - val_accuracy: 0.7318 - val_precision: 0.7826 - val_recall: 0.4865 - val_auc: 0.8533\n",
      "Epoch 24/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7855 - tp: 128.0000 - fp: 196.0000 - tn: 248.0000 - fn: 140.0000 - accuracy: 0.5281 - precision: 0.3951 - recall: 0.4776 - auc: 0.5163 - val_loss: 0.7651 - val_tp: 35.0000 - val_fp: 9.0000 - val_tn: 96.0000 - val_fn: 39.0000 - val_accuracy: 0.7318 - val_precision: 0.7955 - val_recall: 0.4730 - val_auc: 0.8499\n",
      "Epoch 25/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7856 - tp: 128.0000 - fp: 206.0000 - tn: 238.0000 - fn: 140.0000 - accuracy: 0.5140 - precision: 0.3832 - recall: 0.4776 - auc: 0.5071 - val_loss: 0.7636 - val_tp: 36.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 38.0000 - val_accuracy: 0.7318 - val_precision: 0.7826 - val_recall: 0.4865 - val_auc: 0.8599\n",
      "Epoch 26/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7828 - tp: 124.0000 - fp: 192.0000 - tn: 252.0000 - fn: 144.0000 - accuracy: 0.5281 - precision: 0.3924 - recall: 0.4627 - auc: 0.5158 - val_loss: 0.7621 - val_tp: 39.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 35.0000 - val_accuracy: 0.7486 - val_precision: 0.7959 - val_recall: 0.5270 - val_auc: 0.8584\n",
      "Epoch 27/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.7839 - tp: 128.0000 - fp: 202.0000 - tn: 242.0000 - fn: 140.0000 - accuracy: 0.5197 - precision: 0.3879 - recall: 0.4776 - auc: 0.5119 - val_loss: 0.7606 - val_tp: 44.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 30.0000 - val_accuracy: 0.7709 - val_precision: 0.8000 - val_recall: 0.5946 - val_auc: 0.8596\n",
      "Epoch 28/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7707 - tp: 138.0000 - fp: 212.0000 - tn: 232.0000 - fn: 130.0000 - accuracy: 0.5197 - precision: 0.3943 - recall: 0.5149 - auc: 0.5320 - val_loss: 0.7591 - val_tp: 45.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 29.0000 - val_accuracy: 0.7709 - val_precision: 0.7895 - val_recall: 0.6081 - val_auc: 0.8575\n",
      "Epoch 29/600\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 0.7580 - tp: 151.0000 - fp: 186.0000 - tn: 258.0000 - fn: 117.0000 - accuracy: 0.5744 - precision: 0.4481 - recall: 0.5634 - auc: 0.5796 - val_loss: 0.7583 - val_tp: 34.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 40.0000 - val_accuracy: 0.7430 - val_precision: 0.8500 - val_recall: 0.4595 - val_auc: 0.8559\n",
      "Epoch 30/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7637 - tp: 134.0000 - fp: 194.0000 - tn: 250.0000 - fn: 134.0000 - accuracy: 0.5393 - precision: 0.4085 - recall: 0.5000 - auc: 0.5546 - val_loss: 0.7570 - val_tp: 34.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 40.0000 - val_accuracy: 0.7430 - val_precision: 0.8500 - val_recall: 0.4595 - val_auc: 0.8528\n",
      "Epoch 31/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.7663 - tp: 128.0000 - fp: 188.0000 - tn: 256.0000 - fn: 140.0000 - accuracy: 0.5393 - precision: 0.4051 - recall: 0.4776 - auc: 0.5434 - val_loss: 0.7550 - val_tp: 43.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 31.0000 - val_accuracy: 0.7654 - val_precision: 0.7963 - val_recall: 0.5811 - val_auc: 0.8546\n",
      "Epoch 32/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7591 - tp: 139.0000 - fp: 189.0000 - tn: 255.0000 - fn: 129.0000 - accuracy: 0.5534 - precision: 0.4238 - recall: 0.5187 - auc: 0.5620 - val_loss: 0.7536 - val_tp: 41.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 33.0000 - val_accuracy: 0.7542 - val_precision: 0.7885 - val_recall: 0.5541 - val_auc: 0.8564\n",
      "Epoch 33/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 0.7701 - tp: 135.0000 - fp: 194.0000 - tn: 250.0000 - fn: 133.0000 - accuracy: 0.5407 - precision: 0.4103 - recall: 0.5037 - auc: 0.5406 - val_loss: 0.7523 - val_tp: 39.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 35.0000 - val_accuracy: 0.7486 - val_precision: 0.7959 - val_recall: 0.5270 - val_auc: 0.8505\n",
      "Epoch 34/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 0.7637 - tp: 131.0000 - fp: 184.0000 - tn: 260.0000 - fn: 137.0000 - accuracy: 0.5492 - precision: 0.4159 - recall: 0.4888 - auc: 0.5570 - val_loss: 0.7507 - val_tp: 39.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 35.0000 - val_accuracy: 0.7430 - val_precision: 0.7800 - val_recall: 0.5270 - val_auc: 0.8523\n",
      "Epoch 35/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 0.7616 - tp: 130.0000 - fp: 194.0000 - tn: 250.0000 - fn: 138.0000 - accuracy: 0.5337 - precision: 0.4012 - recall: 0.4851 - auc: 0.5439 - val_loss: 0.7488 - val_tp: 45.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 29.0000 - val_accuracy: 0.7654 - val_precision: 0.7759 - val_recall: 0.6081 - val_auc: 0.8535\n",
      "Epoch 36/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 0.7562 - tp: 137.0000 - fp: 203.0000 - tn: 241.0000 - fn: 131.0000 - accuracy: 0.5309 - precision: 0.4029 - recall: 0.5112 - auc: 0.5564 - val_loss: 0.7477 - val_tp: 39.0000 - val_fp: 10.0000 - val_tn: 95.0000 - val_fn: 35.0000 - val_accuracy: 0.7486 - val_precision: 0.7959 - val_recall: 0.5270 - val_auc: 0.8532\n",
      "Epoch 37/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.7576 - tp: 130.0000 - fp: 164.0000 - tn: 280.0000 - fn: 138.0000 - accuracy: 0.5758 - precision: 0.4422 - recall: 0.4851 - auc: 0.5576 - val_loss: 0.7461 - val_tp: 41.0000 - val_fp: 11.0000 - val_tn: 94.0000 - val_fn: 33.0000 - val_accuracy: 0.7542 - val_precision: 0.7885 - val_recall: 0.5541 - val_auc: 0.8574\n",
      "Epoch 38/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7538 - tp: 136.0000 - fp: 195.0000 - tn: 249.0000 - fn: 132.0000 - accuracy: 0.5407 - precision: 0.4109 - recall: 0.5075 - auc: 0.5671 - val_loss: 0.7444 - val_tp: 41.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 33.0000 - val_accuracy: 0.7486 - val_precision: 0.7736 - val_recall: 0.5541 - val_auc: 0.8589\n",
      "Epoch 39/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7658 - tp: 133.0000 - fp: 200.0000 - tn: 244.0000 - fn: 135.0000 - accuracy: 0.5295 - precision: 0.3994 - recall: 0.4963 - auc: 0.5327 - val_loss: 0.7428 - val_tp: 41.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 33.0000 - val_accuracy: 0.7486 - val_precision: 0.7736 - val_recall: 0.5541 - val_auc: 0.8618\n",
      "Epoch 40/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.7639 - tp: 128.0000 - fp: 180.0000 - tn: 264.0000 - fn: 140.0000 - accuracy: 0.5506 - precision: 0.4156 - recall: 0.4776 - auc: 0.5479 - val_loss: 0.7408 - val_tp: 50.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 24.0000 - val_accuracy: 0.7877 - val_precision: 0.7812 - val_recall: 0.6757 - val_auc: 0.8544\n",
      "Epoch 41/600\n",
      "712/712 [==============================] - 0s 163us/sample - loss: 1.3060 - tp: 146.0000 - fp: 147.0000 - tn: 297.0000 - fn: 122.0000 - accuracy: 0.6222 - precision: 0.4983 - recall: 0.5448 - auc: 0.6624 - val_loss: 1.2463 - val_tp: 58.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 16.0000 - val_accuracy: 0.7486 - val_precision: 0.6667 - val_recall: 0.7838 - val_auc: 0.8193\n",
      "Epoch 514/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.2958 - tp: 153.0000 - fp: 141.0000 - tn: 303.0000 - fn: 115.0000 - accuracy: 0.6404 - precision: 0.5204 - recall: 0.5709 - auc: 0.6775 - val_loss: 1.2453 - val_tp: 58.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 16.0000 - val_accuracy: 0.7486 - val_precision: 0.6667 - val_recall: 0.7838 - val_auc: 0.8194\n",
      "Epoch 515/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.2765 - tp: 167.0000 - fp: 137.0000 - tn: 307.0000 - fn: 101.0000 - accuracy: 0.6657 - precision: 0.5493 - recall: 0.6231 - auc: 0.7032 - val_loss: 1.2443 - val_tp: 58.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 16.0000 - val_accuracy: 0.7486 - val_precision: 0.6667 - val_recall: 0.7838 - val_auc: 0.8192\n",
      "Epoch 516/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.2811 - tp: 167.0000 - fp: 140.0000 - tn: 304.0000 - fn: 101.0000 - accuracy: 0.6615 - precision: 0.5440 - recall: 0.6231 - auc: 0.7015 - val_loss: 1.2433 - val_tp: 58.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 16.0000 - val_accuracy: 0.7486 - val_precision: 0.6667 - val_recall: 0.7838 - val_auc: 0.8193\n",
      "Epoch 517/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.2998 - tp: 159.0000 - fp: 141.0000 - tn: 303.0000 - fn: 109.0000 - accuracy: 0.6489 - precision: 0.5300 - recall: 0.5933 - auc: 0.6707 - val_loss: 1.2424 - val_tp: 58.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 16.0000 - val_accuracy: 0.7486 - val_precision: 0.6667 - val_recall: 0.7838 - val_auc: 0.8189\n",
      "Epoch 518/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.3013 - tp: 156.0000 - fp: 152.0000 - tn: 292.0000 - fn: 112.0000 - accuracy: 0.6292 - precision: 0.5065 - recall: 0.5821 - auc: 0.6701 - val_loss: 1.2414 - val_tp: 58.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 16.0000 - val_accuracy: 0.7486 - val_precision: 0.6667 - val_recall: 0.7838 - val_auc: 0.8181\n",
      "Epoch 519/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.2771 - tp: 170.0000 - fp: 136.0000 - tn: 308.0000 - fn: 98.0000 - accuracy: 0.6713 - precision: 0.5556 - recall: 0.6343 - auc: 0.7122 - val_loss: 1.2404 - val_tp: 58.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 16.0000 - val_accuracy: 0.7486 - val_precision: 0.6667 - val_recall: 0.7838 - val_auc: 0.8181\n",
      "Epoch 520/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.2658 - tp: 172.0000 - fp: 135.0000 - tn: 309.0000 - fn: 96.0000 - accuracy: 0.6756 - precision: 0.5603 - recall: 0.6418 - auc: 0.7261 - val_loss: 1.2393 - val_tp: 58.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 16.0000 - val_accuracy: 0.7486 - val_precision: 0.6667 - val_recall: 0.7838 - val_auc: 0.8186\n",
      "Epoch 521/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.2810 - tp: 159.0000 - fp: 145.0000 - tn: 299.0000 - fn: 109.0000 - accuracy: 0.6433 - precision: 0.5230 - recall: 0.5933 - auc: 0.6921 - val_loss: 1.2384 - val_tp: 58.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 16.0000 - val_accuracy: 0.7486 - val_precision: 0.6667 - val_recall: 0.7838 - val_auc: 0.8188\n",
      "Epoch 522/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.2942 - tp: 159.0000 - fp: 165.0000 - tn: 279.0000 - fn: 109.0000 - accuracy: 0.6152 - precision: 0.4907 - recall: 0.5933 - auc: 0.6644 - val_loss: 1.2373 - val_tp: 59.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 15.0000 - val_accuracy: 0.7542 - val_precision: 0.6705 - val_recall: 0.7973 - val_auc: 0.8194\n",
      "Epoch 523/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.2857 - tp: 156.0000 - fp: 152.0000 - tn: 292.0000 - fn: 112.0000 - accuracy: 0.6292 - precision: 0.5065 - recall: 0.5821 - auc: 0.6775 - val_loss: 1.2364 - val_tp: 59.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 15.0000 - val_accuracy: 0.7542 - val_precision: 0.6705 - val_recall: 0.7973 - val_auc: 0.8208\n",
      "Epoch 524/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.2803 - tp: 172.0000 - fp: 160.0000 - tn: 284.0000 - fn: 96.0000 - accuracy: 0.6404 - precision: 0.5181 - recall: 0.6418 - auc: 0.6888 - val_loss: 1.2354 - val_tp: 59.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 15.0000 - val_accuracy: 0.7542 - val_precision: 0.6705 - val_recall: 0.7973 - val_auc: 0.8210\n",
      "Epoch 525/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.2821 - tp: 172.0000 - fp: 146.0000 - tn: 298.0000 - fn: 96.0000 - accuracy: 0.6601 - precision: 0.5409 - recall: 0.6418 - auc: 0.6958 - val_loss: 1.2345 - val_tp: 58.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 16.0000 - val_accuracy: 0.7486 - val_precision: 0.6667 - val_recall: 0.7838 - val_auc: 0.8211\n",
      "Epoch 526/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.2797 - tp: 159.0000 - fp: 151.0000 - tn: 293.0000 - fn: 109.0000 - accuracy: 0.6348 - precision: 0.5129 - recall: 0.5933 - auc: 0.6788 - val_loss: 1.2337 - val_tp: 58.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 16.0000 - val_accuracy: 0.7486 - val_precision: 0.6667 - val_recall: 0.7838 - val_auc: 0.8208\n",
      "Epoch 527/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.2847 - tp: 159.0000 - fp: 140.0000 - tn: 304.0000 - fn: 109.0000 - accuracy: 0.6503 - precision: 0.5318 - recall: 0.5933 - auc: 0.6808 - val_loss: 1.2326 - val_tp: 58.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 16.0000 - val_accuracy: 0.7486 - val_precision: 0.6667 - val_recall: 0.7838 - val_auc: 0.8209\n",
      "Epoch 528/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.2882 - tp: 162.0000 - fp: 140.0000 - tn: 304.0000 - fn: 106.0000 - accuracy: 0.6545 - precision: 0.5364 - recall: 0.6045 - auc: 0.6749 - val_loss: 1.2317 - val_tp: 59.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 15.0000 - val_accuracy: 0.7542 - val_precision: 0.6705 - val_recall: 0.7973 - val_auc: 0.8210\n",
      "Epoch 529/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.2816 - tp: 161.0000 - fp: 139.0000 - tn: 305.0000 - fn: 107.0000 - accuracy: 0.6545 - precision: 0.5367 - recall: 0.6007 - auc: 0.6864 - val_loss: 1.2307 - val_tp: 59.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 15.0000 - val_accuracy: 0.7542 - val_precision: 0.6705 - val_recall: 0.7973 - val_auc: 0.8221\n",
      "Epoch 530/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.2860 - tp: 172.0000 - fp: 163.0000 - tn: 281.0000 - fn: 96.0000 - accuracy: 0.6362 - precision: 0.5134 - recall: 0.6418 - auc: 0.6808 - val_loss: 1.2297 - val_tp: 59.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 15.0000 - val_accuracy: 0.7542 - val_precision: 0.6705 - val_recall: 0.7973 - val_auc: 0.8219\n",
      "Epoch 531/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.2879 - tp: 152.0000 - fp: 151.0000 - tn: 293.0000 - fn: 116.0000 - accuracy: 0.6250 - precision: 0.5017 - recall: 0.5672 - auc: 0.6658 - val_loss: 1.2287 - val_tp: 59.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 15.0000 - val_accuracy: 0.7542 - val_precision: 0.6705 - val_recall: 0.7973 - val_auc: 0.8215\n",
      "Epoch 532/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.2824 - tp: 163.0000 - fp: 153.0000 - tn: 291.0000 - fn: 105.0000 - accuracy: 0.6376 - precision: 0.5158 - recall: 0.6082 - auc: 0.6788 - val_loss: 1.2278 - val_tp: 59.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 15.0000 - val_accuracy: 0.7542 - val_precision: 0.6705 - val_recall: 0.7973 - val_auc: 0.8201\n",
      "Epoch 533/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2747 - tp: 158.0000 - fp: 145.0000 - tn: 299.0000 - fn: 110.0000 - accuracy: 0.6419 - precision: 0.5215 - recall: 0.5896 - auc: 0.6813 - val_loss: 1.2268 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8207\n",
      "Epoch 534/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.2810 - tp: 169.0000 - fp: 148.0000 - tn: 296.0000 - fn: 99.0000 - accuracy: 0.6531 - precision: 0.5331 - recall: 0.6306 - auc: 0.6785 - val_loss: 1.2258 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8212\n",
      "Epoch 535/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.2782 - tp: 154.0000 - fp: 145.0000 - tn: 299.0000 - fn: 114.0000 - accuracy: 0.6362 - precision: 0.5151 - recall: 0.5746 - auc: 0.6741 - val_loss: 1.2249 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8216\n",
      "Epoch 536/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.2920 - tp: 158.0000 - fp: 165.0000 - tn: 279.0000 - fn: 110.0000 - accuracy: 0.6138 - precision: 0.4892 - recall: 0.5896 - auc: 0.6520 - val_loss: 1.2240 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8207\n",
      "Epoch 537/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.2683 - tp: 167.0000 - fp: 142.0000 - tn: 302.0000 - fn: 101.0000 - accuracy: 0.6587 - precision: 0.5405 - recall: 0.6231 - auc: 0.6995 - val_loss: 1.2230 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8208\n",
      "Epoch 538/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.2737 - tp: 162.0000 - fp: 147.0000 - tn: 297.0000 - fn: 106.0000 - accuracy: 0.6447 - precision: 0.5243 - recall: 0.6045 - auc: 0.6879 - val_loss: 1.2221 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8202\n",
      "Epoch 539/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.2569 - tp: 159.0000 - fp: 129.0000 - tn: 315.0000 - fn: 109.0000 - accuracy: 0.6657 - precision: 0.5521 - recall: 0.5933 - auc: 0.7131 - val_loss: 1.2211 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8210\n",
      "Epoch 540/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.2525 - tp: 163.0000 - fp: 142.0000 - tn: 302.0000 - fn: 105.0000 - accuracy: 0.6531 - precision: 0.5344 - recall: 0.6082 - auc: 0.7183 - val_loss: 1.2201 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8206\n",
      "Epoch 541/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.2509 - tp: 163.0000 - fp: 140.0000 - tn: 304.0000 - fn: 105.0000 - accuracy: 0.6559 - precision: 0.5380 - recall: 0.6082 - auc: 0.7156 - val_loss: 1.2192 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8205\n",
      "Epoch 542/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.2559 - tp: 175.0000 - fp: 148.0000 - tn: 296.0000 - fn: 93.0000 - accuracy: 0.6615 - precision: 0.5418 - recall: 0.6530 - auc: 0.7090 - val_loss: 1.2182 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8198\n",
      "Epoch 543/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.2725 - tp: 167.0000 - fp: 141.0000 - tn: 303.0000 - fn: 101.0000 - accuracy: 0.6601 - precision: 0.5422 - recall: 0.6231 - auc: 0.6804 - val_loss: 1.2172 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8200\n",
      "Epoch 544/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.2677 - tp: 166.0000 - fp: 159.0000 - tn: 285.0000 - fn: 102.0000 - accuracy: 0.6334 - precision: 0.5108 - recall: 0.6194 - auc: 0.6849 - val_loss: 1.2163 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8211\n",
      "Epoch 545/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2717 - tp: 161.0000 - fp: 155.0000 - tn: 289.0000 - fn: 107.0000 - accuracy: 0.6320 - precision: 0.5095 - recall: 0.6007 - auc: 0.6835 - val_loss: 1.2153 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8212\n",
      "Epoch 546/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.2578 - tp: 176.0000 - fp: 145.0000 - tn: 299.0000 - fn: 92.0000 - accuracy: 0.6671 - precision: 0.5483 - recall: 0.6567 - auc: 0.7067 - val_loss: 1.2144 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8210\n",
      "Epoch 547/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.2347 - tp: 179.0000 - fp: 129.0000 - tn: 315.0000 - fn: 89.0000 - accuracy: 0.6938 - precision: 0.5812 - recall: 0.6679 - auc: 0.7507 - val_loss: 1.2135 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8211\n",
      "Epoch 548/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.2542 - tp: 156.0000 - fp: 137.0000 - tn: 307.0000 - fn: 112.0000 - accuracy: 0.6503 - precision: 0.5324 - recall: 0.5821 - auc: 0.6984 - val_loss: 1.2126 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8212\n",
      "Epoch 549/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2421 - tp: 176.0000 - fp: 150.0000 - tn: 294.0000 - fn: 92.0000 - accuracy: 0.6601 - precision: 0.5399 - recall: 0.6567 - auc: 0.7243 - val_loss: 1.2116 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8211\n",
      "Epoch 550/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.2759 - tp: 148.0000 - fp: 145.0000 - tn: 299.0000 - fn: 120.0000 - accuracy: 0.6278 - precision: 0.5051 - recall: 0.5522 - auc: 0.6682 - val_loss: 1.2107 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8228\n",
      "Epoch 551/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.2478 - tp: 164.0000 - fp: 132.0000 - tn: 312.0000 - fn: 104.0000 - accuracy: 0.6685 - precision: 0.5541 - recall: 0.6119 - auc: 0.7212 - val_loss: 1.2098 - val_tp: 60.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 14.0000 - val_accuracy: 0.7598 - val_precision: 0.6742 - val_recall: 0.8108 - val_auc: 0.8225\n",
      "Epoch 552/600\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.6051 - tp: 193.0000 - fp: 53.0000 - tn: 391.0000 - fn: 75.0000 - accuracy: 0.8202 - precision: 0.7846 - recall: 0.7201 - auc: 0.8341 - val_loss: 0.5876 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8826\n",
      "Epoch 398/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5872 - tp: 191.0000 - fp: 51.0000 - tn: 393.0000 - fn: 77.0000 - accuracy: 0.8202 - precision: 0.7893 - recall: 0.7127 - auc: 0.8443 - val_loss: 0.5816 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8833\n",
      "Epoch 399/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5984 - tp: 191.0000 - fp: 64.0000 - tn: 380.0000 - fn: 77.0000 - accuracy: 0.8020 - precision: 0.7490 - recall: 0.7127 - auc: 0.8427 - val_loss: 0.5813 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8835\n",
      "Epoch 400/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6102 - tp: 189.0000 - fp: 73.0000 - tn: 371.0000 - fn: 79.0000 - accuracy: 0.7865 - precision: 0.7214 - recall: 0.7052 - auc: 0.8216 - val_loss: 0.5834 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8833\n",
      "Epoch 401/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6106 - tp: 187.0000 - fp: 63.0000 - tn: 381.0000 - fn: 81.0000 - accuracy: 0.7978 - precision: 0.7480 - recall: 0.6978 - auc: 0.8342 - val_loss: 0.5807 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8838\n",
      "Epoch 402/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5962 - tp: 191.0000 - fp: 62.0000 - tn: 382.0000 - fn: 77.0000 - accuracy: 0.8048 - precision: 0.7549 - recall: 0.7127 - auc: 0.8422 - val_loss: 0.5795 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8834\n",
      "Epoch 403/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6190 - tp: 191.0000 - fp: 65.0000 - tn: 379.0000 - fn: 77.0000 - accuracy: 0.8006 - precision: 0.7461 - recall: 0.7127 - auc: 0.8194 - val_loss: 0.5844 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8842\n",
      "Epoch 404/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5899 - tp: 190.0000 - fp: 51.0000 - tn: 393.0000 - fn: 78.0000 - accuracy: 0.8188 - precision: 0.7884 - recall: 0.7090 - auc: 0.8425 - val_loss: 0.5802 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8837\n",
      "Epoch 405/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5959 - tp: 191.0000 - fp: 59.0000 - tn: 385.0000 - fn: 77.0000 - accuracy: 0.8090 - precision: 0.7640 - recall: 0.7127 - auc: 0.8332 - val_loss: 0.5823 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8832\n",
      "Epoch 406/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5982 - tp: 197.0000 - fp: 65.0000 - tn: 379.0000 - fn: 71.0000 - accuracy: 0.8090 - precision: 0.7519 - recall: 0.7351 - auc: 0.8323 - val_loss: 0.5879 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8829\n",
      "Epoch 407/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6127 - tp: 187.0000 - fp: 54.0000 - tn: 390.0000 - fn: 81.0000 - accuracy: 0.8104 - precision: 0.7759 - recall: 0.6978 - auc: 0.8293 - val_loss: 0.5816 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8840\n",
      "Epoch 408/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6164 - tp: 193.0000 - fp: 61.0000 - tn: 383.0000 - fn: 75.0000 - accuracy: 0.8090 - precision: 0.7598 - recall: 0.7201 - auc: 0.8271 - val_loss: 0.5815 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8828\n",
      "Epoch 409/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5954 - tp: 191.0000 - fp: 60.0000 - tn: 384.0000 - fn: 77.0000 - accuracy: 0.8076 - precision: 0.7610 - recall: 0.7127 - auc: 0.8389 - val_loss: 0.5787 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8845\n",
      "Epoch 410/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6033 - tp: 192.0000 - fp: 61.0000 - tn: 383.0000 - fn: 76.0000 - accuracy: 0.8076 - precision: 0.7589 - recall: 0.7164 - auc: 0.8317 - val_loss: 0.5795 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8835\n",
      "Epoch 411/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6118 - tp: 189.0000 - fp: 68.0000 - tn: 376.0000 - fn: 79.0000 - accuracy: 0.7935 - precision: 0.7354 - recall: 0.7052 - auc: 0.8268 - val_loss: 0.5799 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8822\n",
      "Epoch 412/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6028 - tp: 196.0000 - fp: 63.0000 - tn: 381.0000 - fn: 72.0000 - accuracy: 0.8104 - precision: 0.7568 - recall: 0.7313 - auc: 0.8366 - val_loss: 0.5772 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8861\n",
      "Epoch 413/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5959 - tp: 196.0000 - fp: 69.0000 - tn: 375.0000 - fn: 72.0000 - accuracy: 0.8020 - precision: 0.7396 - recall: 0.7313 - auc: 0.8382 - val_loss: 0.5760 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8845\n",
      "Epoch 414/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6162 - tp: 191.0000 - fp: 70.0000 - tn: 374.0000 - fn: 77.0000 - accuracy: 0.7935 - precision: 0.7318 - recall: 0.7127 - auc: 0.8200 - val_loss: 0.5764 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8828\n",
      "Epoch 415/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6048 - tp: 192.0000 - fp: 61.0000 - tn: 383.0000 - fn: 76.0000 - accuracy: 0.8076 - precision: 0.7589 - recall: 0.7164 - auc: 0.8350 - val_loss: 0.5753 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 416/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6042 - tp: 193.0000 - fp: 61.0000 - tn: 383.0000 - fn: 75.0000 - accuracy: 0.8090 - precision: 0.7598 - recall: 0.7201 - auc: 0.8287 - val_loss: 0.5791 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 417/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.6115 - tp: 185.0000 - fp: 59.0000 - tn: 385.0000 - fn: 83.0000 - accuracy: 0.8006 - precision: 0.7582 - recall: 0.6903 - auc: 0.8236 - val_loss: 0.5791 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8843\n",
      "Epoch 418/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6127 - tp: 189.0000 - fp: 59.0000 - tn: 385.0000 - fn: 79.0000 - accuracy: 0.8062 - precision: 0.7621 - recall: 0.7052 - auc: 0.8175 - val_loss: 0.5794 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 419/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5987 - tp: 194.0000 - fp: 63.0000 - tn: 381.0000 - fn: 74.0000 - accuracy: 0.8076 - precision: 0.7549 - recall: 0.7239 - auc: 0.8393 - val_loss: 0.5769 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8843\n",
      "Epoch 420/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6148 - tp: 193.0000 - fp: 70.0000 - tn: 374.0000 - fn: 75.0000 - accuracy: 0.7963 - precision: 0.7338 - recall: 0.7201 - auc: 0.8269 - val_loss: 0.5779 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8837\n",
      "Epoch 421/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6030 - tp: 191.0000 - fp: 65.0000 - tn: 379.0000 - fn: 77.0000 - accuracy: 0.8006 - precision: 0.7461 - recall: 0.7127 - auc: 0.8332 - val_loss: 0.5790 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8823\n",
      "Epoch 422/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5876 - tp: 195.0000 - fp: 59.0000 - tn: 385.0000 - fn: 73.0000 - accuracy: 0.8146 - precision: 0.7677 - recall: 0.7276 - auc: 0.8444 - val_loss: 0.5805 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8823\n",
      "Epoch 423/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5994 - tp: 188.0000 - fp: 61.0000 - tn: 383.0000 - fn: 80.0000 - accuracy: 0.8020 - precision: 0.7550 - recall: 0.7015 - auc: 0.8425 - val_loss: 0.5797 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8831\n",
      "Epoch 424/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6108 - tp: 188.0000 - fp: 57.0000 - tn: 387.0000 - fn: 80.0000 - accuracy: 0.8076 - precision: 0.7673 - recall: 0.7015 - auc: 0.8212 - val_loss: 0.5801 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8820\n",
      "Epoch 425/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6041 - tp: 191.0000 - fp: 56.0000 - tn: 388.0000 - fn: 77.0000 - accuracy: 0.8132 - precision: 0.7733 - recall: 0.7127 - auc: 0.8287 - val_loss: 0.5778 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8822\n",
      "Epoch 426/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6045 - tp: 194.0000 - fp: 70.0000 - tn: 374.0000 - fn: 74.0000 - accuracy: 0.7978 - precision: 0.7348 - recall: 0.7239 - auc: 0.8363 - val_loss: 0.5763 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8835\n",
      "Epoch 427/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5906 - tp: 196.0000 - fp: 67.0000 - tn: 377.0000 - fn: 72.0000 - accuracy: 0.8048 - precision: 0.7452 - recall: 0.7313 - auc: 0.8416 - val_loss: 0.5782 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8853\n",
      "Epoch 428/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6053 - tp: 184.0000 - fp: 68.0000 - tn: 376.0000 - fn: 84.0000 - accuracy: 0.7865 - precision: 0.7302 - recall: 0.6866 - auc: 0.8337 - val_loss: 0.5756 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8842\n",
      "Epoch 429/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5801 - tp: 190.0000 - fp: 54.0000 - tn: 390.0000 - fn: 78.0000 - accuracy: 0.8146 - precision: 0.7787 - recall: 0.7090 - auc: 0.8457 - val_loss: 0.5756 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8855\n",
      "Epoch 430/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6011 - tp: 194.0000 - fp: 68.0000 - tn: 376.0000 - fn: 74.0000 - accuracy: 0.8006 - precision: 0.7405 - recall: 0.7239 - auc: 0.8418 - val_loss: 0.5763 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8847\n",
      "Epoch 431/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6226 - tp: 190.0000 - fp: 69.0000 - tn: 375.0000 - fn: 78.0000 - accuracy: 0.7935 - precision: 0.7336 - recall: 0.7090 - auc: 0.8116 - val_loss: 0.5771 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8839\n",
      "Epoch 432/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6130 - tp: 191.0000 - fp: 63.0000 - tn: 381.0000 - fn: 77.0000 - accuracy: 0.8034 - precision: 0.7520 - recall: 0.7127 - auc: 0.8295 - val_loss: 0.5770 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8826\n",
      "Epoch 433/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5972 - tp: 198.0000 - fp: 70.0000 - tn: 374.0000 - fn: 70.0000 - accuracy: 0.8034 - precision: 0.7388 - recall: 0.7388 - auc: 0.8352 - val_loss: 0.5775 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8849\n",
      "Epoch 434/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6011 - tp: 189.0000 - fp: 58.0000 - tn: 386.0000 - fn: 79.0000 - accuracy: 0.8076 - precision: 0.7652 - recall: 0.7052 - auc: 0.8321 - val_loss: 0.5769 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8849\n",
      "Epoch 435/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5868 - tp: 200.0000 - fp: 64.0000 - tn: 380.0000 - fn: 68.0000 - accuracy: 0.8146 - precision: 0.7576 - recall: 0.7463 - auc: 0.8357 - val_loss: 0.5787 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 436/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6045 - tp: 187.0000 - fp: 65.0000 - tn: 379.0000 - fn: 81.0000 - accuracy: 0.7949 - precision: 0.7421 - recall: 0.6978 - auc: 0.8351 - val_loss: 0.5813 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 437/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6092 - tp: 186.0000 - fp: 67.0000 - tn: 377.0000 - fn: 82.0000 - accuracy: 0.7907 - precision: 0.7352 - recall: 0.6940 - auc: 0.8267 - val_loss: 0.5828 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8824\n",
      "Epoch 438/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6079 - tp: 189.0000 - fp: 55.0000 - tn: 389.0000 - fn: 79.0000 - accuracy: 0.8118 - precision: 0.7746 - recall: 0.7052 - auc: 0.8292 - val_loss: 0.5798 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8811\n",
      "Epoch 439/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6141 - tp: 195.0000 - fp: 62.0000 - tn: 382.0000 - fn: 73.0000 - accuracy: 0.8104 - precision: 0.7588 - recall: 0.7276 - auc: 0.8276 - val_loss: 0.5765 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8842\n",
      "Epoch 440/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5956 - tp: 199.0000 - fp: 67.0000 - tn: 377.0000 - fn: 69.0000 - accuracy: 0.8090 - precision: 0.7481 - recall: 0.7425 - auc: 0.8468 - val_loss: 0.5805 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8847\n",
      "Epoch 441/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6024 - tp: 193.0000 - fp: 58.0000 - tn: 386.0000 - fn: 75.0000 - accuracy: 0.8132 - precision: 0.7689 - recall: 0.7201 - auc: 0.8373 - val_loss: 0.5810 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8827\n",
      "Epoch 442/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5924 - tp: 191.0000 - fp: 59.0000 - tn: 385.0000 - fn: 77.0000 - accuracy: 0.8090 - precision: 0.7640 - recall: 0.7127 - auc: 0.8379 - val_loss: 0.5773 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8840\n",
      "Epoch 443/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6112 - tp: 187.0000 - fp: 57.0000 - tn: 387.0000 - fn: 81.0000 - accuracy: 0.8062 - precision: 0.7664 - recall: 0.6978 - auc: 0.8245 - val_loss: 0.5789 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8850\n",
      "Epoch 444/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5987 - tp: 194.0000 - fp: 66.0000 - tn: 378.0000 - fn: 74.0000 - accuracy: 0.8034 - precision: 0.7462 - recall: 0.7239 - auc: 0.8347 - val_loss: 0.5784 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8842\n",
      "Epoch 445/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5759 - tp: 199.0000 - fp: 51.0000 - tn: 393.0000 - fn: 69.0000 - accuracy: 0.8315 - precision: 0.7960 - recall: 0.7425 - auc: 0.8496 - val_loss: 0.5802 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8832\n",
      "Epoch 446/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6132 - tp: 190.0000 - fp: 69.0000 - tn: 375.0000 - fn: 78.0000 - accuracy: 0.7935 - precision: 0.7336 - recall: 0.7090 - auc: 0.8294 - val_loss: 0.5798 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8840\n",
      "Epoch 447/700\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 0.5968 - tp: 191.0000 - fp: 54.0000 - tn: 390.0000 - fn: 77.0000 - accuracy: 0.8160 - precision: 0.7796 - recall: 0.7127 - auc: 0.8351 - val_loss: 0.5761 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8848\n",
      "Epoch 448/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6048 - tp: 192.0000 - fp: 65.0000 - tn: 379.0000 - fn: 76.0000 - accuracy: 0.8020 - precision: 0.7471 - recall: 0.7164 - auc: 0.8272 - val_loss: 0.5770 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8853\n",
      "Epoch 449/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5943 - tp: 192.0000 - fp: 60.0000 - tn: 384.0000 - fn: 76.0000 - accuracy: 0.8090 - precision: 0.7619 - recall: 0.7164 - auc: 0.8388 - val_loss: 0.5773 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8837\n",
      "Epoch 450/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6002 - tp: 194.0000 - fp: 61.0000 - tn: 383.0000 - fn: 74.0000 - accuracy: 0.8104 - precision: 0.7608 - recall: 0.7239 - auc: 0.8372 - val_loss: 0.5806 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8842\n",
      "Epoch 451/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5808 - tp: 190.0000 - fp: 61.0000 - tn: 383.0000 - fn: 78.0000 - accuracy: 0.8048 - precision: 0.7570 - recall: 0.7090 - auc: 0.8565 - val_loss: 0.5756 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8847\n",
      "Epoch 452/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6173 - tp: 196.0000 - fp: 66.0000 - tn: 378.0000 - fn: 72.0000 - accuracy: 0.8062 - precision: 0.7481 - recall: 0.7313 - auc: 0.8176 - val_loss: 0.5769 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8843\n",
      "Epoch 453/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5989 - tp: 190.0000 - fp: 53.0000 - tn: 391.0000 - fn: 78.0000 - accuracy: 0.8160 - precision: 0.7819 - recall: 0.7090 - auc: 0.8293 - val_loss: 0.5786 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8849\n",
      "Epoch 454/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5979 - tp: 197.0000 - fp: 54.0000 - tn: 390.0000 - fn: 71.0000 - accuracy: 0.8244 - precision: 0.7849 - recall: 0.7351 - auc: 0.8437 - val_loss: 0.5785 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8846\n",
      "Epoch 455/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6068 - tp: 200.0000 - fp: 67.0000 - tn: 377.0000 - fn: 68.0000 - accuracy: 0.8104 - precision: 0.7491 - recall: 0.7463 - auc: 0.8267 - val_loss: 0.5806 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8856\n",
      "Epoch 456/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5943 - tp: 192.0000 - fp: 58.0000 - tn: 386.0000 - fn: 76.0000 - accuracy: 0.8118 - precision: 0.7680 - recall: 0.7164 - auc: 0.8421 - val_loss: 0.5801 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8853\n",
      "Epoch 457/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5953 - tp: 194.0000 - fp: 57.0000 - tn: 387.0000 - fn: 74.0000 - accuracy: 0.8160 - precision: 0.7729 - recall: 0.7239 - auc: 0.8379 - val_loss: 0.5786 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8834\n",
      "Epoch 458/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6034 - tp: 190.0000 - fp: 70.0000 - tn: 374.0000 - fn: 78.0000 - accuracy: 0.7921 - precision: 0.7308 - recall: 0.7090 - auc: 0.8286 - val_loss: 0.5817 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 459/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6153 - tp: 181.0000 - fp: 59.0000 - tn: 385.0000 - fn: 87.0000 - accuracy: 0.7949 - precision: 0.7542 - recall: 0.6754 - auc: 0.8214 - val_loss: 0.5836 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8852\n",
      "Epoch 460/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5980 - tp: 189.0000 - fp: 59.0000 - tn: 385.0000 - fn: 79.0000 - accuracy: 0.8062 - precision: 0.7621 - recall: 0.7052 - auc: 0.8287 - val_loss: 0.5798 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8849\n",
      "Epoch 461/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6025 - tp: 190.0000 - fp: 63.0000 - tn: 381.0000 - fn: 78.0000 - accuracy: 0.8020 - precision: 0.7510 - recall: 0.7090 - auc: 0.8346 - val_loss: 0.5805 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8846\n",
      "Epoch 462/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6241 - tp: 192.0000 - fp: 70.0000 - tn: 374.0000 - fn: 76.0000 - accuracy: 0.7949 - precision: 0.7328 - recall: 0.7164 - auc: 0.8141 - val_loss: 0.5820 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8839\n",
      "Epoch 463/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6120 - tp: 187.0000 - fp: 57.0000 - tn: 387.0000 - fn: 81.0000 - accuracy: 0.8062 - precision: 0.7664 - recall: 0.6978 - auc: 0.8279 - val_loss: 0.5798 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8812\n",
      "Epoch 464/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.6061 - tp: 194.0000 - fp: 61.0000 - tn: 383.0000 - fn: 74.0000 - accuracy: 0.8104 - precision: 0.7608 - recall: 0.7239 - auc: 0.8183 - val_loss: 0.5793 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8819\n",
      "Epoch 465/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6024 - tp: 193.0000 - fp: 62.0000 - tn: 382.0000 - fn: 75.0000 - accuracy: 0.8076 - precision: 0.7569 - recall: 0.7201 - auc: 0.8249 - val_loss: 0.5806 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8828\n",
      "Epoch 466/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5907 - tp: 193.0000 - fp: 54.0000 - tn: 390.0000 - fn: 75.0000 - accuracy: 0.8188 - precision: 0.7814 - recall: 0.7201 - auc: 0.8387 - val_loss: 0.5813 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8848\n",
      "Epoch 467/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6035 - tp: 189.0000 - fp: 63.0000 - tn: 381.0000 - fn: 79.0000 - accuracy: 0.8006 - precision: 0.7500 - recall: 0.7052 - auc: 0.8374 - val_loss: 0.5791 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8831\n",
      "Epoch 468/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6000 - tp: 189.0000 - fp: 58.0000 - tn: 386.0000 - fn: 79.0000 - accuracy: 0.8076 - precision: 0.7652 - recall: 0.7052 - auc: 0.8353 - val_loss: 0.5794 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8831\n",
      "Epoch 469/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5912 - tp: 197.0000 - fp: 63.0000 - tn: 381.0000 - fn: 71.0000 - accuracy: 0.8118 - precision: 0.7577 - recall: 0.7351 - auc: 0.8496 - val_loss: 0.5794 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8841\n",
      "Epoch 470/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5738 - tp: 199.0000 - fp: 61.0000 - tn: 383.0000 - fn: 69.0000 - accuracy: 0.8174 - precision: 0.7654 - recall: 0.7425 - auc: 0.8589 - val_loss: 0.5738 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8842\n",
      "Epoch 471/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6086 - tp: 192.0000 - fp: 68.0000 - tn: 376.0000 - fn: 76.0000 - accuracy: 0.7978 - precision: 0.7385 - recall: 0.7164 - auc: 0.8271 - val_loss: 0.5779 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8853\n",
      "Epoch 472/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6021 - tp: 190.0000 - fp: 64.0000 - tn: 380.0000 - fn: 78.0000 - accuracy: 0.8006 - precision: 0.7480 - recall: 0.7090 - auc: 0.8298 - val_loss: 0.5762 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8851\n",
      "Epoch 473/700\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.6000 - tp: 195.0000 - fp: 58.0000 - tn: 386.0000 - fn: 73.0000 - accuracy: 0.8160 - precision: 0.7708 - recall: 0.7276 - auc: 0.8424 - val_loss: 0.5728 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8838\n",
      "Epoch 474/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5924 - tp: 200.0000 - fp: 64.0000 - tn: 380.0000 - fn: 68.0000 - accuracy: 0.8146 - precision: 0.7576 - recall: 0.7463 - auc: 0.8323 - val_loss: 0.5755 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8817\n",
      "Epoch 475/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.5968 - tp: 194.0000 - fp: 66.0000 - tn: 378.0000 - fn: 74.0000 - accuracy: 0.8034 - precision: 0.7462 - recall: 0.7239 - auc: 0.8371 - val_loss: 0.5770 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8842\n",
      "Epoch 476/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5970 - tp: 192.0000 - fp: 62.0000 - tn: 382.0000 - fn: 76.0000 - accuracy: 0.8062 - precision: 0.7559 - recall: 0.7164 - auc: 0.8335 - val_loss: 0.5757 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 477/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5969 - tp: 198.0000 - fp: 75.0000 - tn: 369.0000 - fn: 70.0000 - accuracy: 0.7963 - precision: 0.7253 - recall: 0.7388 - auc: 0.8361 - val_loss: 0.5793 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8822\n",
      "Epoch 478/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5867 - tp: 187.0000 - fp: 60.0000 - tn: 384.0000 - fn: 81.0000 - accuracy: 0.8020 - precision: 0.7571 - recall: 0.6978 - auc: 0.8430 - val_loss: 0.5776 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8850\n",
      "Epoch 479/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5916 - tp: 190.0000 - fp: 64.0000 - tn: 380.0000 - fn: 78.0000 - accuracy: 0.8006 - precision: 0.7480 - recall: 0.7090 - auc: 0.8424 - val_loss: 0.5756 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8819\n",
      "Epoch 480/700\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.6094 - tp: 190.0000 - fp: 69.0000 - tn: 375.0000 - fn: 78.0000 - accuracy: 0.7935 - precision: 0.7336 - recall: 0.7090 - auc: 0.8228 - val_loss: 0.5782 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8850\n",
      "Epoch 481/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5954 - tp: 188.0000 - fp: 63.0000 - tn: 381.0000 - fn: 80.0000 - accuracy: 0.7992 - precision: 0.7490 - recall: 0.7015 - auc: 0.8356 - val_loss: 0.5780 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8845\n",
      "Epoch 482/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.6033 - tp: 192.0000 - fp: 57.0000 - tn: 387.0000 - fn: 76.0000 - accuracy: 0.8132 - precision: 0.7711 - recall: 0.7164 - auc: 0.8340 - val_loss: 0.5782 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 483/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5975 - tp: 194.0000 - fp: 65.0000 - tn: 379.0000 - fn: 74.0000 - accuracy: 0.8048 - precision: 0.7490 - recall: 0.7239 - auc: 0.8320 - val_loss: 0.5785 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8849\n",
      "Epoch 484/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6036 - tp: 193.0000 - fp: 61.0000 - tn: 383.0000 - fn: 75.0000 - accuracy: 0.8090 - precision: 0.7598 - recall: 0.7201 - auc: 0.8321 - val_loss: 0.5791 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8856\n",
      "Epoch 485/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6036 - tp: 191.0000 - fp: 61.0000 - tn: 383.0000 - fn: 77.0000 - accuracy: 0.8062 - precision: 0.7579 - recall: 0.7127 - auc: 0.8301 - val_loss: 0.5761 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8826\n",
      "Epoch 486/700\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5938 - tp: 191.0000 - fp: 59.0000 - tn: 385.0000 - fn: 77.0000 - accuracy: 0.8090 - precision: 0.7640 - recall: 0.7127 - auc: 0.8327 - val_loss: 0.5770 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8850\n",
      "Epoch 487/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5976 - tp: 197.0000 - fp: 61.0000 - tn: 383.0000 - fn: 71.0000 - accuracy: 0.8146 - precision: 0.7636 - recall: 0.7351 - auc: 0.8311 - val_loss: 0.5769 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8851\n",
      "Epoch 488/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5880 - tp: 196.0000 - fp: 59.0000 - tn: 385.0000 - fn: 72.0000 - accuracy: 0.8160 - precision: 0.7686 - recall: 0.7313 - auc: 0.8421 - val_loss: 0.5751 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8860\n",
      "Epoch 489/700\n",
      "712/712 [==============================] - 0s 188us/sample - loss: 0.5890 - tp: 194.0000 - fp: 68.0000 - tn: 376.0000 - fn: 74.0000 - accuracy: 0.8006 - precision: 0.7405 - recall: 0.7239 - auc: 0.8442 - val_loss: 0.5764 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8859\n",
      "Epoch 490/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6061 - tp: 186.0000 - fp: 60.0000 - tn: 384.0000 - fn: 82.0000 - accuracy: 0.8006 - precision: 0.7561 - recall: 0.6940 - auc: 0.8252 - val_loss: 0.5745 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 491/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.6072 - tp: 192.0000 - fp: 64.0000 - tn: 380.0000 - fn: 76.0000 - accuracy: 0.8034 - precision: 0.7500 - recall: 0.7164 - auc: 0.8344 - val_loss: 0.5745 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8858\n",
      "Epoch 492/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5960 - tp: 193.0000 - fp: 68.0000 - tn: 376.0000 - fn: 75.0000 - accuracy: 0.7992 - precision: 0.7395 - recall: 0.7201 - auc: 0.8349 - val_loss: 0.5731 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8840\n",
      "Epoch 493/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6029 - tp: 191.0000 - fp: 64.0000 - tn: 380.0000 - fn: 77.0000 - accuracy: 0.8020 - precision: 0.7490 - recall: 0.7127 - auc: 0.8316 - val_loss: 0.5779 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8831\n",
      "Epoch 494/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6003 - tp: 192.0000 - fp: 64.0000 - tn: 380.0000 - fn: 76.0000 - accuracy: 0.8034 - precision: 0.7500 - recall: 0.7164 - auc: 0.8307 - val_loss: 0.5752 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8848\n",
      "Epoch 495/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6028 - tp: 193.0000 - fp: 66.0000 - tn: 378.0000 - fn: 75.0000 - accuracy: 0.8020 - precision: 0.7452 - recall: 0.7201 - auc: 0.8254 - val_loss: 0.5740 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8846\n",
      "Epoch 496/700\n",
      "712/712 [==============================] - 0s 173us/sample - loss: 0.6056 - tp: 187.0000 - fp: 68.0000 - tn: 376.0000 - fn: 81.0000 - accuracy: 0.7907 - precision: 0.7333 - recall: 0.6978 - auc: 0.8243 - val_loss: 0.5758 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8845\n",
      "Epoch 497/700\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 0.5900 - tp: 192.0000 - fp: 59.0000 - tn: 385.0000 - fn: 76.0000 - accuracy: 0.8104 - precision: 0.7649 - recall: 0.7164 - auc: 0.8447 - val_loss: 0.5748 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8858\n",
      "Epoch 498/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5936 - tp: 190.0000 - fp: 64.0000 - tn: 380.0000 - fn: 78.0000 - accuracy: 0.8006 - precision: 0.7480 - recall: 0.7090 - auc: 0.8426 - val_loss: 0.5791 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8853\n",
      "Epoch 499/700\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 0.5739 - tp: 196.0000 - fp: 58.0000 - tn: 386.0000 - fn: 72.0000 - accuracy: 0.8174 - precision: 0.7717 - recall: 0.7313 - auc: 0.8492 - val_loss: 0.5723 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8855\n",
      "Epoch 500/700\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 0.6013 - tp: 195.0000 - fp: 78.0000 - tn: 366.0000 - fn: 73.0000 - accuracy: 0.7879 - precision: 0.7143 - recall: 0.7276 - auc: 0.8279 - val_loss: 0.5796 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8865\n",
      "Epoch 501/700\n",
      "712/712 [==============================] - 0s 162us/sample - loss: 0.6074 - tp: 181.0000 - fp: 60.0000 - tn: 384.0000 - fn: 87.0000 - accuracy: 0.7935 - precision: 0.7510 - recall: 0.6754 - auc: 0.8279 - val_loss: 0.5748 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8820\n",
      "Epoch 502/700\n",
      "712/712 [==============================] - 0s 183us/sample - loss: 0.5944 - tp: 193.0000 - fp: 61.0000 - tn: 383.0000 - fn: 75.0000 - accuracy: 0.8090 - precision: 0.7598 - recall: 0.7201 - auc: 0.8329 - val_loss: 0.5766 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8832\n",
      "Epoch 503/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5965 - tp: 191.0000 - fp: 67.0000 - tn: 377.0000 - fn: 77.0000 - accuracy: 0.7978 - precision: 0.7403 - recall: 0.7127 - auc: 0.8408 - val_loss: 0.5784 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8835\n",
      "Epoch 504/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5992 - tp: 192.0000 - fp: 60.0000 - tn: 384.0000 - fn: 76.0000 - accuracy: 0.8090 - precision: 0.7619 - recall: 0.7164 - auc: 0.8351 - val_loss: 0.5745 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8824\n",
      "Epoch 505/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5970 - tp: 192.0000 - fp: 68.0000 - tn: 376.0000 - fn: 76.0000 - accuracy: 0.7978 - precision: 0.7385 - recall: 0.7164 - auc: 0.8345 - val_loss: 0.5745 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8836\n",
      "Epoch 506/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5929 - tp: 191.0000 - fp: 59.0000 - tn: 385.0000 - fn: 77.0000 - accuracy: 0.8090 - precision: 0.7640 - recall: 0.7127 - auc: 0.8460 - val_loss: 0.5774 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8831\n",
      "Epoch 507/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5974 - tp: 186.0000 - fp: 63.0000 - tn: 381.0000 - fn: 82.0000 - accuracy: 0.7963 - precision: 0.7470 - recall: 0.6940 - auc: 0.8294 - val_loss: 0.5725 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8830\n",
      "Epoch 508/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5810 - tp: 197.0000 - fp: 54.0000 - tn: 390.0000 - fn: 71.0000 - accuracy: 0.8244 - precision: 0.7849 - recall: 0.7351 - auc: 0.8437 - val_loss: 0.5736 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8835\n",
      "Epoch 509/700\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5967 - tp: 196.0000 - fp: 72.0000 - tn: 372.0000 - fn: 72.0000 - accuracy: 0.7978 - precision: 0.7313 - recall: 0.7313 - auc: 0.8350 - val_loss: 0.5718 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8866\n",
      "Epoch 510/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6176 - tp: 190.0000 - fp: 60.0000 - tn: 384.0000 - fn: 78.0000 - accuracy: 0.8062 - precision: 0.7600 - recall: 0.7090 - auc: 0.8228 - val_loss: 0.5724 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8840\n",
      "Epoch 511/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5832 - tp: 195.0000 - fp: 70.0000 - tn: 374.0000 - fn: 73.0000 - accuracy: 0.7992 - precision: 0.7358 - recall: 0.7276 - auc: 0.8458 - val_loss: 0.5721 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8834\n",
      "Epoch 512/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5926 - tp: 188.0000 - fp: 70.0000 - tn: 374.0000 - fn: 80.0000 - accuracy: 0.7893 - precision: 0.7287 - recall: 0.7015 - auc: 0.8419 - val_loss: 0.5712 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8869\n",
      "Epoch 513/700\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6086 - tp: 187.0000 - fp: 60.0000 - tn: 384.0000 - fn: 81.0000 - accuracy: 0.8020 - precision: 0.7571 - recall: 0.6978 - auc: 0.8252 - val_loss: 0.5708 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8849\n",
      "Epoch 514/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5808 - tp: 190.0000 - fp: 62.0000 - tn: 382.0000 - fn: 78.0000 - accuracy: 0.8034 - precision: 0.7540 - recall: 0.7090 - auc: 0.8492 - val_loss: 0.5690 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8855\n",
      "Epoch 515/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5945 - tp: 190.0000 - fp: 71.0000 - tn: 373.0000 - fn: 78.0000 - accuracy: 0.7907 - precision: 0.7280 - recall: 0.7090 - auc: 0.8335 - val_loss: 0.5750 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8843\n",
      "Epoch 516/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5911 - tp: 187.0000 - fp: 65.0000 - tn: 379.0000 - fn: 81.0000 - accuracy: 0.7949 - precision: 0.7421 - recall: 0.6978 - auc: 0.8459 - val_loss: 0.5729 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8849\n",
      "Epoch 517/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5968 - tp: 195.0000 - fp: 63.0000 - tn: 381.0000 - fn: 73.0000 - accuracy: 0.8090 - precision: 0.7558 - recall: 0.7276 - auc: 0.8365 - val_loss: 0.5720 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8858\n",
      "Epoch 518/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.6026 - tp: 191.0000 - fp: 63.0000 - tn: 381.0000 - fn: 77.0000 - accuracy: 0.8034 - precision: 0.7520 - recall: 0.7127 - auc: 0.8301 - val_loss: 0.5727 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8860\n",
      "Epoch 519/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5874 - tp: 195.0000 - fp: 62.0000 - tn: 382.0000 - fn: 73.0000 - accuracy: 0.8104 - precision: 0.7588 - recall: 0.7276 - auc: 0.8398 - val_loss: 0.5721 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8862\n",
      "Epoch 520/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6005 - tp: 197.0000 - fp: 65.0000 - tn: 379.0000 - fn: 71.0000 - accuracy: 0.8090 - precision: 0.7519 - recall: 0.7351 - auc: 0.8333 - val_loss: 0.5717 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8846\n",
      "Epoch 521/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6136 - tp: 189.0000 - fp: 67.0000 - tn: 377.0000 - fn: 79.0000 - accuracy: 0.7949 - precision: 0.7383 - recall: 0.7052 - auc: 0.8261 - val_loss: 0.5715 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8836\n",
      "Epoch 522/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6100 - tp: 185.0000 - fp: 67.0000 - tn: 377.0000 - fn: 83.0000 - accuracy: 0.7893 - precision: 0.7341 - recall: 0.6903 - auc: 0.8165 - val_loss: 0.5711 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8820\n",
      "Epoch 523/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6002 - tp: 196.0000 - fp: 68.0000 - tn: 376.0000 - fn: 72.0000 - accuracy: 0.8034 - precision: 0.7424 - recall: 0.7313 - auc: 0.8354 - val_loss: 0.5767 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8867\n",
      "Epoch 524/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5993 - tp: 195.0000 - fp: 58.0000 - tn: 386.0000 - fn: 73.0000 - accuracy: 0.8160 - precision: 0.7708 - recall: 0.7276 - auc: 0.8317 - val_loss: 0.5752 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8851\n",
      "Epoch 525/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.6084 - tp: 195.0000 - fp: 64.0000 - tn: 380.0000 - fn: 73.0000 - accuracy: 0.8076 - precision: 0.7529 - recall: 0.7276 - auc: 0.8347 - val_loss: 0.5723 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8843\n",
      "Epoch 526/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5891 - tp: 195.0000 - fp: 67.0000 - tn: 377.0000 - fn: 73.0000 - accuracy: 0.8034 - precision: 0.7443 - recall: 0.7276 - auc: 0.8468 - val_loss: 0.5784 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8858\n",
      "Epoch 527/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6002 - tp: 189.0000 - fp: 58.0000 - tn: 386.0000 - fn: 79.0000 - accuracy: 0.8076 - precision: 0.7652 - recall: 0.7052 - auc: 0.8385 - val_loss: 0.5732 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8839\n",
      "Epoch 528/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5807 - tp: 198.0000 - fp: 64.0000 - tn: 380.0000 - fn: 70.0000 - accuracy: 0.8118 - precision: 0.7557 - recall: 0.7388 - auc: 0.8386 - val_loss: 0.5780 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8827\n",
      "Epoch 529/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5953 - tp: 197.0000 - fp: 71.0000 - tn: 373.0000 - fn: 71.0000 - accuracy: 0.8006 - precision: 0.7351 - recall: 0.7351 - auc: 0.8383 - val_loss: 0.5730 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8837\n",
      "Epoch 530/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6002 - tp: 186.0000 - fp: 67.0000 - tn: 377.0000 - fn: 82.0000 - accuracy: 0.7907 - precision: 0.7352 - recall: 0.6940 - auc: 0.8311 - val_loss: 0.5735 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8860\n",
      "Epoch 531/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5792 - tp: 197.0000 - fp: 60.0000 - tn: 384.0000 - fn: 71.0000 - accuracy: 0.8160 - precision: 0.7665 - recall: 0.7351 - auc: 0.8454 - val_loss: 0.5731 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8841\n",
      "Epoch 532/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6094 - tp: 198.0000 - fp: 68.0000 - tn: 376.0000 - fn: 70.0000 - accuracy: 0.8062 - precision: 0.7444 - recall: 0.7388 - auc: 0.8356 - val_loss: 0.5727 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8838\n",
      "Epoch 533/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5822 - tp: 190.0000 - fp: 53.0000 - tn: 391.0000 - fn: 78.0000 - accuracy: 0.8160 - precision: 0.7819 - recall: 0.7090 - auc: 0.8413 - val_loss: 0.5725 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8844\n",
      "Epoch 534/700\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.6023 - tp: 196.0000 - fp: 63.0000 - tn: 381.0000 - fn: 72.0000 - accuracy: 0.8104 - precision: 0.7568 - recall: 0.7313 - auc: 0.8210 - val_loss: 0.5750 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8808\n",
      "Epoch 535/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5799 - tp: 192.0000 - fp: 62.0000 - tn: 382.0000 - fn: 76.0000 - accuracy: 0.8062 - precision: 0.7559 - recall: 0.7164 - auc: 0.8343 - val_loss: 0.5767 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8857\n",
      "Epoch 536/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6128 - tp: 189.0000 - fp: 62.0000 - tn: 382.0000 - fn: 79.0000 - accuracy: 0.8020 - precision: 0.7530 - recall: 0.7052 - auc: 0.8195 - val_loss: 0.5759 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8824\n",
      "Epoch 537/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5979 - tp: 188.0000 - fp: 60.0000 - tn: 384.0000 - fn: 80.0000 - accuracy: 0.8034 - precision: 0.7581 - recall: 0.7015 - auc: 0.8345 - val_loss: 0.5743 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8852\n",
      "Epoch 538/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5805 - tp: 196.0000 - fp: 56.0000 - tn: 388.0000 - fn: 72.0000 - accuracy: 0.8202 - precision: 0.7778 - recall: 0.7313 - auc: 0.8425 - val_loss: 0.5775 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8828\n",
      "Epoch 539/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6036 - tp: 190.0000 - fp: 61.0000 - tn: 383.0000 - fn: 78.0000 - accuracy: 0.8048 - precision: 0.7570 - recall: 0.7090 - auc: 0.8286 - val_loss: 0.5756 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8805\n",
      "Epoch 540/700\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.5942 - tp: 192.0000 - fp: 58.0000 - tn: 386.0000 - fn: 76.0000 - accuracy: 0.8118 - precision: 0.7680 - recall: 0.7164 - auc: 0.8322 - val_loss: 0.5752 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8860\n",
      "Epoch 541/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6042 - tp: 185.0000 - fp: 59.0000 - tn: 385.0000 - fn: 83.0000 - accuracy: 0.8006 - precision: 0.7582 - recall: 0.6903 - auc: 0.8290 - val_loss: 0.5734 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8834\n",
      "Epoch 542/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5919 - tp: 194.0000 - fp: 64.0000 - tn: 380.0000 - fn: 74.0000 - accuracy: 0.8062 - precision: 0.7519 - recall: 0.7239 - auc: 0.8318 - val_loss: 0.5744 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8814\n",
      "Epoch 543/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5904 - tp: 187.0000 - fp: 63.0000 - tn: 381.0000 - fn: 81.0000 - accuracy: 0.7978 - precision: 0.7480 - recall: 0.6978 - auc: 0.8385 - val_loss: 0.5741 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8813\n",
      "Epoch 544/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5967 - tp: 186.0000 - fp: 59.0000 - tn: 385.0000 - fn: 82.0000 - accuracy: 0.8020 - precision: 0.7592 - recall: 0.6940 - auc: 0.8336 - val_loss: 0.5750 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8808\n",
      "Epoch 545/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5992 - tp: 196.0000 - fp: 62.0000 - tn: 382.0000 - fn: 72.0000 - accuracy: 0.8118 - precision: 0.7597 - recall: 0.7313 - auc: 0.8338 - val_loss: 0.5749 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8830\n",
      "Epoch 546/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5918 - tp: 200.0000 - fp: 56.0000 - tn: 388.0000 - fn: 68.0000 - accuracy: 0.8258 - precision: 0.7812 - recall: 0.7463 - auc: 0.8314 - val_loss: 0.5777 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8802\n",
      "Epoch 547/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5866 - tp: 197.0000 - fp: 63.0000 - tn: 381.0000 - fn: 71.0000 - accuracy: 0.8118 - precision: 0.7577 - recall: 0.7351 - auc: 0.8365 - val_loss: 0.5751 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8845\n",
      "Epoch 548/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.5781 - tp: 190.0000 - fp: 57.0000 - tn: 387.0000 - fn: 78.0000 - accuracy: 0.8104 - precision: 0.7692 - recall: 0.7090 - auc: 0.8549 - val_loss: 0.5748 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8859\n",
      "Epoch 549/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5878 - tp: 191.0000 - fp: 56.0000 - tn: 388.0000 - fn: 77.0000 - accuracy: 0.8132 - precision: 0.7733 - recall: 0.7127 - auc: 0.8383 - val_loss: 0.5739 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8848\n",
      "Epoch 550/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5914 - tp: 190.0000 - fp: 64.0000 - tn: 380.0000 - fn: 78.0000 - accuracy: 0.8006 - precision: 0.7480 - recall: 0.7090 - auc: 0.8375 - val_loss: 0.5764 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8862\n",
      "Epoch 551/700\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5964 - tp: 195.0000 - fp: 63.0000 - tn: 381.0000 - fn: 73.0000 - accuracy: 0.8090 - precision: 0.7558 - recall: 0.7276 - auc: 0.8406 - val_loss: 0.5718 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8853\n",
      "Epoch 552/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5943 - tp: 188.0000 - fp: 64.0000 - tn: 380.0000 - fn: 80.0000 - accuracy: 0.7978 - precision: 0.7460 - recall: 0.7015 - auc: 0.8421 - val_loss: 0.5761 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8860\n",
      "Epoch 553/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5928 - tp: 188.0000 - fp: 62.0000 - tn: 382.0000 - fn: 80.0000 - accuracy: 0.8006 - precision: 0.7520 - recall: 0.7015 - auc: 0.8279 - val_loss: 0.5730 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8843\n",
      "Epoch 554/700\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5767 - tp: 198.0000 - fp: 62.0000 - tn: 382.0000 - fn: 70.0000 - accuracy: 0.8146 - precision: 0.7615 - recall: 0.7388 - auc: 0.8496 - val_loss: 0.5722 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8862\n",
      "Epoch 555/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5959 - tp: 197.0000 - fp: 64.0000 - tn: 380.0000 - fn: 71.0000 - accuracy: 0.8104 - precision: 0.7548 - recall: 0.7351 - auc: 0.8367 - val_loss: 0.5731 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8819\n",
      "Epoch 556/700\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5864 - tp: 197.0000 - fp: 54.0000 - tn: 390.0000 - fn: 71.0000 - accuracy: 0.8244 - precision: 0.7849 - recall: 0.7351 - auc: 0.8442 - val_loss: 0.5744 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8823\n",
      "Epoch 557/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6212 - tp: 189.0000 - fp: 59.0000 - tn: 385.0000 - fn: 79.0000 - accuracy: 0.8062 - precision: 0.7621 - recall: 0.7052 - auc: 0.8222 - val_loss: 0.5736 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8851\n",
      "Epoch 558/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6008 - tp: 192.0000 - fp: 62.0000 - tn: 382.0000 - fn: 76.0000 - accuracy: 0.8062 - precision: 0.7559 - recall: 0.7164 - auc: 0.8311 - val_loss: 0.5745 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8867\n",
      "Epoch 559/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5852 - tp: 194.0000 - fp: 61.0000 - tn: 383.0000 - fn: 74.0000 - accuracy: 0.8104 - precision: 0.7608 - recall: 0.7239 - auc: 0.8402 - val_loss: 0.5732 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8829\n",
      "Epoch 560/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5898 - tp: 191.0000 - fp: 58.0000 - tn: 386.0000 - fn: 77.0000 - accuracy: 0.8104 - precision: 0.7671 - recall: 0.7127 - auc: 0.8326 - val_loss: 0.5722 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8848\n",
      "Epoch 561/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5950 - tp: 190.0000 - fp: 62.0000 - tn: 382.0000 - fn: 78.0000 - accuracy: 0.8034 - precision: 0.7540 - recall: 0.7090 - auc: 0.8333 - val_loss: 0.5741 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8833\n",
      "Epoch 562/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5984 - tp: 190.0000 - fp: 61.0000 - tn: 383.0000 - fn: 78.0000 - accuracy: 0.8048 - precision: 0.7570 - recall: 0.7090 - auc: 0.8318 - val_loss: 0.5741 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8851\n",
      "Epoch 563/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5961 - tp: 188.0000 - fp: 60.0000 - tn: 384.0000 - fn: 80.0000 - accuracy: 0.8034 - precision: 0.7581 - recall: 0.7015 - auc: 0.8299 - val_loss: 0.5778 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8855\n",
      "Epoch 564/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6032 - tp: 188.0000 - fp: 58.0000 - tn: 386.0000 - fn: 80.0000 - accuracy: 0.8062 - precision: 0.7642 - recall: 0.7015 - auc: 0.8167 - val_loss: 0.5734 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8860\n",
      "Epoch 565/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6140 - tp: 189.0000 - fp: 60.0000 - tn: 384.0000 - fn: 79.0000 - accuracy: 0.8048 - precision: 0.7590 - recall: 0.7052 - auc: 0.8202 - val_loss: 0.5725 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8817\n",
      "Epoch 566/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5989 - tp: 192.0000 - fp: 60.0000 - tn: 384.0000 - fn: 76.0000 - accuracy: 0.8090 - precision: 0.7619 - recall: 0.7164 - auc: 0.8313 - val_loss: 0.5735 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8810\n",
      "Epoch 567/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5823 - tp: 193.0000 - fp: 56.0000 - tn: 388.0000 - fn: 75.0000 - accuracy: 0.8160 - precision: 0.7751 - recall: 0.7201 - auc: 0.8420 - val_loss: 0.5713 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8845\n",
      "Epoch 568/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.5935 - tp: 197.0000 - fp: 67.0000 - tn: 377.0000 - fn: 71.0000 - accuracy: 0.8062 - precision: 0.7462 - recall: 0.7351 - auc: 0.8306 - val_loss: 0.5802 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8840\n",
      "Epoch 569/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6023 - tp: 181.0000 - fp: 61.0000 - tn: 383.0000 - fn: 87.0000 - accuracy: 0.7921 - precision: 0.7479 - recall: 0.6754 - auc: 0.8217 - val_loss: 0.5794 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8821\n",
      "Epoch 570/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5883 - tp: 188.0000 - fp: 57.0000 - tn: 387.0000 - fn: 80.0000 - accuracy: 0.8076 - precision: 0.7673 - recall: 0.7015 - auc: 0.8315 - val_loss: 0.5717 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8811\n",
      "Epoch 571/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6086 - tp: 193.0000 - fp: 68.0000 - tn: 376.0000 - fn: 75.0000 - accuracy: 0.7992 - precision: 0.7395 - recall: 0.7201 - auc: 0.8299 - val_loss: 0.5707 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8855\n",
      "Epoch 572/700\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5932 - tp: 194.0000 - fp: 60.0000 - tn: 384.0000 - fn: 74.0000 - accuracy: 0.8118 - precision: 0.7638 - recall: 0.7239 - auc: 0.8334 - val_loss: 0.5759 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8808\n",
      "Epoch 573/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.5988 - tp: 192.0000 - fp: 68.0000 - tn: 376.0000 - fn: 76.0000 - accuracy: 0.7978 - precision: 0.7385 - recall: 0.7164 - auc: 0.8419 - val_loss: 0.5782 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8850\n",
      "Epoch 574/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5914 - tp: 193.0000 - fp: 64.0000 - tn: 380.0000 - fn: 75.0000 - accuracy: 0.8048 - precision: 0.7510 - recall: 0.7201 - auc: 0.8375 - val_loss: 0.5695 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8861\n",
      "Epoch 575/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6041 - tp: 191.0000 - fp: 64.0000 - tn: 380.0000 - fn: 77.0000 - accuracy: 0.8020 - precision: 0.7490 - recall: 0.7127 - auc: 0.8262 - val_loss: 0.5719 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8810\n",
      "Epoch 576/700\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5884 - tp: 201.0000 - fp: 63.0000 - tn: 381.0000 - fn: 67.0000 - accuracy: 0.8174 - precision: 0.7614 - recall: 0.7500 - auc: 0.8381 - val_loss: 0.5726 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8835\n",
      "Epoch 577/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.6055 - tp: 187.0000 - fp: 60.0000 - tn: 384.0000 - fn: 81.0000 - accuracy: 0.8020 - precision: 0.7571 - recall: 0.6978 - auc: 0.8290 - val_loss: 0.5716 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8824\n",
      "Epoch 578/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 0.6019 - tp: 187.0000 - fp: 60.0000 - tn: 384.0000 - fn: 81.0000 - accuracy: 0.8020 - precision: 0.7571 - recall: 0.6978 - auc: 0.8204 - val_loss: 0.5705 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8818\n",
      "Epoch 579/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5976 - tp: 200.0000 - fp: 66.0000 - tn: 378.0000 - fn: 68.0000 - accuracy: 0.8118 - precision: 0.7519 - recall: 0.7463 - auc: 0.8353 - val_loss: 0.5717 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8839\n",
      "Epoch 580/700\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 0.6005 - tp: 193.0000 - fp: 70.0000 - tn: 374.0000 - fn: 75.0000 - accuracy: 0.7963 - precision: 0.7338 - recall: 0.7201 - auc: 0.8287 - val_loss: 0.5732 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8817\n",
      "Epoch 581/700\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 0.6035 - tp: 181.0000 - fp: 72.0000 - tn: 372.0000 - fn: 87.0000 - accuracy: 0.7767 - precision: 0.7154 - recall: 0.6754 - auc: 0.8366 - val_loss: 0.5732 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8812\n",
      "Epoch 582/700\n",
      "712/712 [==============================] - 0s 155us/sample - loss: 0.5946 - tp: 193.0000 - fp: 75.0000 - tn: 369.0000 - fn: 75.0000 - accuracy: 0.7893 - precision: 0.7201 - recall: 0.7201 - auc: 0.8239 - val_loss: 0.5865 - val_tp: 53.0000 - val_fp: 12.0000 - val_tn: 93.0000 - val_fn: 21.0000 - val_accuracy: 0.8156 - val_precision: 0.8154 - val_recall: 0.7162 - val_auc: 0.8829\n",
      "Epoch 583/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6090 - tp: 185.0000 - fp: 57.0000 - tn: 387.0000 - fn: 83.0000 - accuracy: 0.8034 - precision: 0.7645 - recall: 0.6903 - auc: 0.8278 - val_loss: 0.5770 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8833\n",
      "Epoch 584/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.5973 - tp: 192.0000 - fp: 64.0000 - tn: 380.0000 - fn: 76.0000 - accuracy: 0.8034 - precision: 0.7500 - recall: 0.7164 - auc: 0.8224 - val_loss: 0.5750 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8864\n",
      "Epoch 585/700\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.5777 - tp: 190.0000 - fp: 66.0000 - tn: 378.0000 - fn: 78.0000 - accuracy: 0.7978 - precision: 0.7422 - recall: 0.7090 - auc: 0.8504 - val_loss: 0.5736 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8848\n",
      "Epoch 586/700\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 0.6018 - tp: 192.0000 - fp: 60.0000 - tn: 384.0000 - fn: 76.0000 - accuracy: 0.8090 - precision: 0.7619 - recall: 0.7164 - auc: 0.8225 - val_loss: 0.5762 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8827\n",
      "Epoch 587/700\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5987 - tp: 194.0000 - fp: 64.0000 - tn: 380.0000 - fn: 74.0000 - accuracy: 0.8062 - precision: 0.7519 - recall: 0.7239 - auc: 0.8334 - val_loss: 0.5758 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8820\n",
      "Epoch 588/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.6008 - tp: 186.0000 - fp: 63.0000 - tn: 381.0000 - fn: 82.0000 - accuracy: 0.7963 - precision: 0.7470 - recall: 0.6940 - auc: 0.8251 - val_loss: 0.5848 - val_tp: 53.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 21.0000 - val_accuracy: 0.8101 - val_precision: 0.8030 - val_recall: 0.7162 - val_auc: 0.8833\n",
      "Epoch 589/700\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.2167 - tp: 131.0000 - fp: 84.0000 - tn: 360.0000 - fn: 137.0000 - accuracy: 0.6896 - precision: 0.6093 - recall: 0.4888 - auc: 0.7301 - val_loss: 1.2039 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8216\n",
      "Epoch 523/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 1.2155 - tp: 126.0000 - fp: 83.0000 - tn: 361.0000 - fn: 142.0000 - accuracy: 0.6840 - precision: 0.6029 - recall: 0.4701 - auc: 0.7273 - val_loss: 1.2032 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8210\n",
      "Epoch 524/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.2068 - tp: 142.0000 - fp: 68.0000 - tn: 376.0000 - fn: 126.0000 - accuracy: 0.7275 - precision: 0.6762 - recall: 0.5299 - auc: 0.7522 - val_loss: 1.2023 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8212\n",
      "Epoch 525/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.2064 - tp: 140.0000 - fp: 77.0000 - tn: 367.0000 - fn: 128.0000 - accuracy: 0.7121 - precision: 0.6452 - recall: 0.5224 - auc: 0.7528 - val_loss: 1.2014 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8210\n",
      "Epoch 526/600\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 1.2113 - tp: 139.0000 - fp: 76.0000 - tn: 368.0000 - fn: 129.0000 - accuracy: 0.7121 - precision: 0.6465 - recall: 0.5187 - auc: 0.7311 - val_loss: 1.2006 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8210\n",
      "Epoch 527/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.2084 - tp: 138.0000 - fp: 87.0000 - tn: 357.0000 - fn: 130.0000 - accuracy: 0.6952 - precision: 0.6133 - recall: 0.5149 - auc: 0.7382 - val_loss: 1.1997 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8219\n",
      "Epoch 528/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.2015 - tp: 142.0000 - fp: 74.0000 - tn: 370.0000 - fn: 126.0000 - accuracy: 0.7191 - precision: 0.6574 - recall: 0.5299 - auc: 0.7571 - val_loss: 1.1989 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8230\n",
      "Epoch 529/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.2043 - tp: 143.0000 - fp: 80.0000 - tn: 364.0000 - fn: 125.0000 - accuracy: 0.7121 - precision: 0.6413 - recall: 0.5336 - auc: 0.7532 - val_loss: 1.1980 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8225\n",
      "Epoch 530/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.2006 - tp: 143.0000 - fp: 74.0000 - tn: 370.0000 - fn: 125.0000 - accuracy: 0.7205 - precision: 0.6590 - recall: 0.5336 - auc: 0.7708 - val_loss: 1.1972 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8227\n",
      "Epoch 531/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.2085 - tp: 137.0000 - fp: 77.0000 - tn: 367.0000 - fn: 131.0000 - accuracy: 0.7079 - precision: 0.6402 - recall: 0.5112 - auc: 0.7359 - val_loss: 1.1963 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8217\n",
      "Epoch 532/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.2118 - tp: 130.0000 - fp: 85.0000 - tn: 359.0000 - fn: 138.0000 - accuracy: 0.6868 - precision: 0.6047 - recall: 0.4851 - auc: 0.7211 - val_loss: 1.1955 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8219\n",
      "Epoch 533/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.2076 - tp: 148.0000 - fp: 80.0000 - tn: 364.0000 - fn: 120.0000 - accuracy: 0.7191 - precision: 0.6491 - recall: 0.5522 - auc: 0.7349 - val_loss: 1.1947 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8222\n",
      "Epoch 534/600\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 1.2041 - tp: 143.0000 - fp: 79.0000 - tn: 365.0000 - fn: 125.0000 - accuracy: 0.7135 - precision: 0.6441 - recall: 0.5336 - auc: 0.7392 - val_loss: 1.1939 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8223\n",
      "Epoch 535/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.2002 - tp: 139.0000 - fp: 77.0000 - tn: 367.0000 - fn: 129.0000 - accuracy: 0.7107 - precision: 0.6435 - recall: 0.5187 - auc: 0.7527 - val_loss: 1.1930 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8232\n",
      "Epoch 536/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1988 - tp: 145.0000 - fp: 79.0000 - tn: 365.0000 - fn: 123.0000 - accuracy: 0.7163 - precision: 0.6473 - recall: 0.5410 - auc: 0.7586 - val_loss: 1.1921 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8239\n",
      "Epoch 537/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1949 - tp: 145.0000 - fp: 74.0000 - tn: 370.0000 - fn: 123.0000 - accuracy: 0.7233 - precision: 0.6621 - recall: 0.5410 - auc: 0.7669 - val_loss: 1.1913 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8246\n",
      "Epoch 538/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1987 - tp: 143.0000 - fp: 79.0000 - tn: 365.0000 - fn: 125.0000 - accuracy: 0.7135 - precision: 0.6441 - recall: 0.5336 - auc: 0.7546 - val_loss: 1.1904 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8250\n",
      "Epoch 539/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1949 - tp: 144.0000 - fp: 85.0000 - tn: 359.0000 - fn: 124.0000 - accuracy: 0.7065 - precision: 0.6288 - recall: 0.5373 - auc: 0.7573 - val_loss: 1.1895 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8247\n",
      "Epoch 540/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1961 - tp: 150.0000 - fp: 87.0000 - tn: 357.0000 - fn: 118.0000 - accuracy: 0.7121 - precision: 0.6329 - recall: 0.5597 - auc: 0.7492 - val_loss: 1.1886 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8240\n",
      "Epoch 541/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1957 - tp: 145.0000 - fp: 87.0000 - tn: 357.0000 - fn: 123.0000 - accuracy: 0.7051 - precision: 0.6250 - recall: 0.5410 - auc: 0.7447 - val_loss: 1.1878 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8234\n",
      "Epoch 542/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.2035 - tp: 141.0000 - fp: 77.0000 - tn: 367.0000 - fn: 127.0000 - accuracy: 0.7135 - precision: 0.6468 - recall: 0.5261 - auc: 0.7354 - val_loss: 1.1869 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8231\n",
      "Epoch 543/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1937 - tp: 138.0000 - fp: 77.0000 - tn: 367.0000 - fn: 130.0000 - accuracy: 0.7093 - precision: 0.6419 - recall: 0.5149 - auc: 0.7496 - val_loss: 1.1860 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8237\n",
      "Epoch 544/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1950 - tp: 152.0000 - fp: 91.0000 - tn: 353.0000 - fn: 116.0000 - accuracy: 0.7093 - precision: 0.6255 - recall: 0.5672 - auc: 0.7456 - val_loss: 1.1851 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8237\n",
      "Epoch 545/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1932 - tp: 145.0000 - fp: 81.0000 - tn: 363.0000 - fn: 123.0000 - accuracy: 0.7135 - precision: 0.6416 - recall: 0.5410 - auc: 0.7557 - val_loss: 1.1843 - val_tp: 41.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 33.0000 - val_accuracy: 0.6983 - val_precision: 0.6613 - val_recall: 0.5541 - val_auc: 0.8239\n",
      "Epoch 546/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1912 - tp: 133.0000 - fp: 74.0000 - tn: 370.0000 - fn: 135.0000 - accuracy: 0.7065 - precision: 0.6425 - recall: 0.4963 - auc: 0.7603 - val_loss: 1.1834 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8250\n",
      "Epoch 547/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1940 - tp: 147.0000 - fp: 87.0000 - tn: 357.0000 - fn: 121.0000 - accuracy: 0.7079 - precision: 0.6282 - recall: 0.5485 - auc: 0.7435 - val_loss: 1.1826 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8259\n",
      "Epoch 548/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1863 - tp: 154.0000 - fp: 77.0000 - tn: 367.0000 - fn: 114.0000 - accuracy: 0.7317 - precision: 0.6667 - recall: 0.5746 - auc: 0.7607 - val_loss: 1.1818 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8251\n",
      "Epoch 549/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1899 - tp: 146.0000 - fp: 77.0000 - tn: 367.0000 - fn: 122.0000 - accuracy: 0.7205 - precision: 0.6547 - recall: 0.5448 - auc: 0.7474 - val_loss: 1.1809 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8254\n",
      "Epoch 550/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1909 - tp: 147.0000 - fp: 78.0000 - tn: 366.0000 - fn: 121.0000 - accuracy: 0.7205 - precision: 0.6533 - recall: 0.5485 - auc: 0.7549 - val_loss: 1.1801 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8256\n",
      "Epoch 551/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.1911 - tp: 139.0000 - fp: 74.0000 - tn: 370.0000 - fn: 129.0000 - accuracy: 0.7149 - precision: 0.6526 - recall: 0.5187 - auc: 0.7513 - val_loss: 1.1792 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8253\n",
      "Epoch 552/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 1.1977 - tp: 139.0000 - fp: 75.0000 - tn: 369.0000 - fn: 129.0000 - accuracy: 0.7135 - precision: 0.6495 - recall: 0.5187 - auc: 0.7346 - val_loss: 1.1784 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8263\n",
      "Epoch 553/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1893 - tp: 148.0000 - fp: 78.0000 - tn: 366.0000 - fn: 120.0000 - accuracy: 0.7219 - precision: 0.6549 - recall: 0.5522 - auc: 0.7394 - val_loss: 1.1776 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8264\n",
      "Epoch 554/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1860 - tp: 146.0000 - fp: 73.0000 - tn: 371.0000 - fn: 122.0000 - accuracy: 0.7261 - precision: 0.6667 - recall: 0.5448 - auc: 0.7598 - val_loss: 1.1766 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8264\n",
      "Epoch 555/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1831 - tp: 143.0000 - fp: 76.0000 - tn: 368.0000 - fn: 125.0000 - accuracy: 0.7177 - precision: 0.6530 - recall: 0.5336 - auc: 0.7613 - val_loss: 1.1758 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8269\n",
      "Epoch 556/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1884 - tp: 136.0000 - fp: 86.0000 - tn: 358.0000 - fn: 132.0000 - accuracy: 0.6938 - precision: 0.6126 - recall: 0.5075 - auc: 0.7415 - val_loss: 1.1749 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8269\n",
      "Epoch 557/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 1.1838 - tp: 142.0000 - fp: 81.0000 - tn: 363.0000 - fn: 126.0000 - accuracy: 0.7093 - precision: 0.6368 - recall: 0.5299 - auc: 0.7528 - val_loss: 1.1741 - val_tp: 41.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 33.0000 - val_accuracy: 0.6927 - val_precision: 0.6508 - val_recall: 0.5541 - val_auc: 0.8270\n",
      "Epoch 558/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1876 - tp: 148.0000 - fp: 82.0000 - tn: 362.0000 - fn: 120.0000 - accuracy: 0.7163 - precision: 0.6435 - recall: 0.5522 - auc: 0.7420 - val_loss: 1.1732 - val_tp: 43.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 31.0000 - val_accuracy: 0.7039 - val_precision: 0.6615 - val_recall: 0.5811 - val_auc: 0.8265\n",
      "Epoch 559/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.1818 - tp: 150.0000 - fp: 79.0000 - tn: 365.0000 - fn: 118.0000 - accuracy: 0.7233 - precision: 0.6550 - recall: 0.5597 - auc: 0.7559 - val_loss: 1.1723 - val_tp: 43.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 31.0000 - val_accuracy: 0.7039 - val_precision: 0.6615 - val_recall: 0.5811 - val_auc: 0.8266\n",
      "Epoch 560/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1880 - tp: 141.0000 - fp: 89.0000 - tn: 355.0000 - fn: 127.0000 - accuracy: 0.6966 - precision: 0.6130 - recall: 0.5261 - auc: 0.7349 - val_loss: 1.1715 - val_tp: 44.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 30.0000 - val_accuracy: 0.7095 - val_precision: 0.6667 - val_recall: 0.5946 - val_auc: 0.8266\n",
      "Epoch 561/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1828 - tp: 142.0000 - fp: 79.0000 - tn: 365.0000 - fn: 126.0000 - accuracy: 0.7121 - precision: 0.6425 - recall: 0.5299 - auc: 0.7551 - val_loss: 1.1707 - val_tp: 44.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 30.0000 - val_accuracy: 0.7095 - val_precision: 0.6667 - val_recall: 0.5946 - val_auc: 0.8263\n",
      "Epoch 562/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1784 - tp: 143.0000 - fp: 85.0000 - tn: 359.0000 - fn: 125.0000 - accuracy: 0.7051 - precision: 0.6272 - recall: 0.5336 - auc: 0.7597 - val_loss: 1.1698 - val_tp: 44.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 30.0000 - val_accuracy: 0.7095 - val_precision: 0.6667 - val_recall: 0.5946 - val_auc: 0.8263\n",
      "Epoch 563/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1847 - tp: 132.0000 - fp: 81.0000 - tn: 363.0000 - fn: 136.0000 - accuracy: 0.6952 - precision: 0.6197 - recall: 0.4925 - auc: 0.7509 - val_loss: 1.1689 - val_tp: 44.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 30.0000 - val_accuracy: 0.7095 - val_precision: 0.6667 - val_recall: 0.5946 - val_auc: 0.8264\n",
      "Epoch 564/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1745 - tp: 150.0000 - fp: 79.0000 - tn: 365.0000 - fn: 118.0000 - accuracy: 0.7233 - precision: 0.6550 - recall: 0.5597 - auc: 0.7680 - val_loss: 1.1680 - val_tp: 44.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 30.0000 - val_accuracy: 0.7095 - val_precision: 0.6667 - val_recall: 0.5946 - val_auc: 0.8270\n",
      "Epoch 565/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4519 - tp: 200.0000 - fp: 57.0000 - tn: 387.0000 - fn: 68.0000 - accuracy: 0.8244 - precision: 0.7782 - recall: 0.7463 - auc: 0.8722 - val_loss: 0.4314 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8992\n",
      "Epoch 87/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4681 - tp: 206.0000 - fp: 64.0000 - tn: 380.0000 - fn: 62.0000 - accuracy: 0.8230 - precision: 0.7630 - recall: 0.7687 - auc: 0.8607 - val_loss: 0.4220 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.8268 - val_precision: 0.8028 - val_recall: 0.7703 - val_auc: 0.9008\n",
      "Epoch 88/600\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 0.4339 - tp: 203.0000 - fp: 55.0000 - tn: 389.0000 - fn: 65.0000 - accuracy: 0.8315 - precision: 0.7868 - recall: 0.7575 - auc: 0.8849 - val_loss: 0.4285 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8993\n",
      "Epoch 89/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.4532 - tp: 202.0000 - fp: 60.0000 - tn: 384.0000 - fn: 66.0000 - accuracy: 0.8230 - precision: 0.7710 - recall: 0.7537 - auc: 0.8700 - val_loss: 0.4227 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 17.0000 - val_accuracy: 0.8101 - val_precision: 0.7703 - val_recall: 0.7703 - val_auc: 0.8995\n",
      "Epoch 90/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 0.4486 - tp: 204.0000 - fp: 57.0000 - tn: 387.0000 - fn: 64.0000 - accuracy: 0.8301 - precision: 0.7816 - recall: 0.7612 - auc: 0.8721 - val_loss: 0.4282 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8986\n",
      "Epoch 91/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4483 - tp: 202.0000 - fp: 59.0000 - tn: 385.0000 - fn: 66.0000 - accuracy: 0.8244 - precision: 0.7739 - recall: 0.7537 - auc: 0.8729 - val_loss: 0.4267 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8982\n",
      "Epoch 92/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.4335 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8790 - val_loss: 0.4295 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8992\n",
      "Epoch 93/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4295 - tp: 204.0000 - fp: 58.0000 - tn: 386.0000 - fn: 64.0000 - accuracy: 0.8287 - precision: 0.7786 - recall: 0.7612 - auc: 0.8835 - val_loss: 0.4315 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8979\n",
      "Epoch 94/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4454 - tp: 207.0000 - fp: 58.0000 - tn: 386.0000 - fn: 61.0000 - accuracy: 0.8329 - precision: 0.7811 - recall: 0.7724 - auc: 0.8746 - val_loss: 0.4270 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.9001\n",
      "Epoch 95/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.4414 - tp: 204.0000 - fp: 55.0000 - tn: 389.0000 - fn: 64.0000 - accuracy: 0.8329 - precision: 0.7876 - recall: 0.7612 - auc: 0.8757 - val_loss: 0.4297 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.8982\n",
      "Epoch 96/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 0.4413 - tp: 204.0000 - fp: 53.0000 - tn: 391.0000 - fn: 64.0000 - accuracy: 0.8357 - precision: 0.7938 - recall: 0.7612 - auc: 0.8756 - val_loss: 0.4317 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8990\n",
      "Epoch 97/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4431 - tp: 200.0000 - fp: 53.0000 - tn: 391.0000 - fn: 68.0000 - accuracy: 0.8301 - precision: 0.7905 - recall: 0.7463 - auc: 0.8776 - val_loss: 0.4298 - val_tp: 60.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 14.0000 - val_accuracy: 0.7877 - val_precision: 0.7143 - val_recall: 0.8108 - val_auc: 0.9000\n",
      "Epoch 98/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4391 - tp: 208.0000 - fp: 67.0000 - tn: 377.0000 - fn: 60.0000 - accuracy: 0.8216 - precision: 0.7564 - recall: 0.7761 - auc: 0.8759 - val_loss: 0.4249 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.9012\n",
      "Epoch 99/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.4319 - tp: 201.0000 - fp: 49.0000 - tn: 395.0000 - fn: 67.0000 - accuracy: 0.8371 - precision: 0.8040 - recall: 0.7500 - auc: 0.8842 - val_loss: 0.4296 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 15.0000 - val_accuracy: 0.8101 - val_precision: 0.7564 - val_recall: 0.7973 - val_auc: 0.8995\n",
      "Epoch 100/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.4567 - tp: 206.0000 - fp: 54.0000 - tn: 390.0000 - fn: 62.0000 - accuracy: 0.8371 - precision: 0.7923 - recall: 0.7687 - auc: 0.8721 - val_loss: 0.4276 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.9007\n",
      "Epoch 101/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4428 - tp: 202.0000 - fp: 55.0000 - tn: 389.0000 - fn: 66.0000 - accuracy: 0.8301 - precision: 0.7860 - recall: 0.7537 - auc: 0.8759 - val_loss: 0.4276 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8997\n",
      "Epoch 102/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4374 - tp: 201.0000 - fp: 61.0000 - tn: 383.0000 - fn: 67.0000 - accuracy: 0.8202 - precision: 0.7672 - recall: 0.7500 - auc: 0.8838 - val_loss: 0.4276 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.9003\n",
      "Epoch 103/600\n",
      "712/712 [==============================] - 0s 169us/sample - loss: 0.4367 - tp: 206.0000 - fp: 57.0000 - tn: 387.0000 - fn: 62.0000 - accuracy: 0.8329 - precision: 0.7833 - recall: 0.7687 - auc: 0.8802 - val_loss: 0.4298 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 14.0000 - val_accuracy: 0.8045 - val_precision: 0.7407 - val_recall: 0.8108 - val_auc: 0.8999\n",
      "Epoch 104/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4332 - tp: 212.0000 - fp: 59.0000 - tn: 385.0000 - fn: 56.0000 - accuracy: 0.8385 - precision: 0.7823 - recall: 0.7910 - auc: 0.8795 - val_loss: 0.4344 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.9001\n",
      "Epoch 105/600\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 0.4431 - tp: 203.0000 - fp: 60.0000 - tn: 384.0000 - fn: 65.0000 - accuracy: 0.8244 - precision: 0.7719 - recall: 0.7575 - auc: 0.8750 - val_loss: 0.4316 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8991\n",
      "Epoch 106/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4360 - tp: 199.0000 - fp: 62.0000 - tn: 382.0000 - fn: 69.0000 - accuracy: 0.8160 - precision: 0.7625 - recall: 0.7425 - auc: 0.8825 - val_loss: 0.4256 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.9006\n",
      "Epoch 107/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4144 - tp: 206.0000 - fp: 47.0000 - tn: 397.0000 - fn: 62.0000 - accuracy: 0.8469 - precision: 0.8142 - recall: 0.7687 - auc: 0.8902 - val_loss: 0.4257 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.9012\n",
      "Epoch 108/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4431 - tp: 203.0000 - fp: 54.0000 - tn: 390.0000 - fn: 65.0000 - accuracy: 0.8329 - precision: 0.7899 - recall: 0.7575 - auc: 0.8759 - val_loss: 0.4363 - val_tp: 60.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 14.0000 - val_accuracy: 0.7933 - val_precision: 0.7229 - val_recall: 0.8108 - val_auc: 0.8980\n",
      "Epoch 109/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4328 - tp: 213.0000 - fp: 71.0000 - tn: 373.0000 - fn: 55.0000 - accuracy: 0.8230 - precision: 0.7500 - recall: 0.7948 - auc: 0.8822 - val_loss: 0.4309 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8988\n",
      "Epoch 110/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.4335 - tp: 203.0000 - fp: 53.0000 - tn: 391.0000 - fn: 65.0000 - accuracy: 0.8343 - precision: 0.7930 - recall: 0.7575 - auc: 0.8810 - val_loss: 0.4278 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 16.0000 - val_accuracy: 0.8156 - val_precision: 0.7733 - val_recall: 0.7838 - val_auc: 0.8990\n",
      "Epoch 111/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.4410 - tp: 203.0000 - fp: 58.0000 - tn: 386.0000 - fn: 65.0000 - accuracy: 0.8272 - precision: 0.7778 - recall: 0.7575 - auc: 0.8722 - val_loss: 0.4272 - val_tp: 57.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 17.0000 - val_accuracy: 0.8156 - val_precision: 0.7808 - val_recall: 0.7703 - val_auc: 0.9006\n",
      "Epoch 112/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4421 - tp: 205.0000 - fp: 55.0000 - tn: 389.0000 - fn: 63.0000 - accuracy: 0.8343 - precision: 0.7885 - recall: 0.7649 - auc: 0.8733 - val_loss: 0.4250 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.9021\n",
      "Epoch 113/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.4482 - tp: 204.0000 - fp: 52.0000 - tn: 392.0000 - fn: 64.0000 - accuracy: 0.8371 - precision: 0.7969 - recall: 0.7612 - auc: 0.8708 - val_loss: 0.4292 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8992\n",
      "Epoch 114/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 0.4651 - tp: 202.0000 - fp: 59.0000 - tn: 385.0000 - fn: 66.0000 - accuracy: 0.8244 - precision: 0.7739 - recall: 0.7537 - auc: 0.8617 - val_loss: 0.4284 - val_tp: 59.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 15.0000 - val_accuracy: 0.8156 - val_precision: 0.7662 - val_recall: 0.7973 - val_auc: 0.9004\n",
      "Epoch 115/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4316 - tp: 207.0000 - fp: 58.0000 - tn: 386.0000 - fn: 61.0000 - accuracy: 0.8329 - precision: 0.7811 - recall: 0.7724 - auc: 0.8823 - val_loss: 0.4313 - val_tp: 56.0000 - val_fp: 13.0000 - val_tn: 92.0000 - val_fn: 18.0000 - val_accuracy: 0.8268 - val_precision: 0.8116 - val_recall: 0.7568 - val_auc: 0.8992\n",
      "Epoch 116/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.4401 - tp: 200.0000 - fp: 50.0000 - tn: 394.0000 - fn: 68.0000 - accuracy: 0.8343 - precision: 0.8000 - recall: 0.7463 - auc: 0.8745 - val_loss: 0.4283 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8988\n",
      "Epoch 117/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4275 - tp: 205.0000 - fp: 50.0000 - tn: 394.0000 - fn: 63.0000 - accuracy: 0.8413 - precision: 0.8039 - recall: 0.7649 - auc: 0.8818 - val_loss: 0.4294 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.9015\n",
      "Epoch 118/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4427 - tp: 200.0000 - fp: 47.0000 - tn: 397.0000 - fn: 68.0000 - accuracy: 0.8385 - precision: 0.8097 - recall: 0.7463 - auc: 0.8735 - val_loss: 0.4391 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 14.0000 - val_accuracy: 0.7989 - val_precision: 0.7317 - val_recall: 0.8108 - val_auc: 0.8986\n",
      "Epoch 119/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 0.4313 - tp: 207.0000 - fp: 63.0000 - tn: 381.0000 - fn: 61.0000 - accuracy: 0.8258 - precision: 0.7667 - recall: 0.7724 - auc: 0.8812 - val_loss: 0.4293 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8992\n",
      "Epoch 120/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4455 - tp: 201.0000 - fp: 58.0000 - tn: 386.0000 - fn: 67.0000 - accuracy: 0.8244 - precision: 0.7761 - recall: 0.7500 - auc: 0.8694 - val_loss: 0.4309 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 17.0000 - val_accuracy: 0.8212 - val_precision: 0.7917 - val_recall: 0.7703 - val_auc: 0.8984\n",
      "Epoch 121/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4338 - tp: 207.0000 - fp: 53.0000 - tn: 391.0000 - fn: 61.0000 - accuracy: 0.8399 - precision: 0.7962 - recall: 0.7724 - auc: 0.8832 - val_loss: 0.4297 - val_tp: 56.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 18.0000 - val_accuracy: 0.8101 - val_precision: 0.7778 - val_recall: 0.7568 - val_auc: 0.8995\n",
      "Epoch 122/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.4324 - tp: 201.0000 - fp: 51.0000 - tn: 393.0000 - fn: 67.0000 - accuracy: 0.8343 - precision: 0.7976 - recall: 0.7500 - auc: 0.8830 - val_loss: 0.4365 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 13.0000 - val_accuracy: 0.8045 - val_precision: 0.7349 - val_recall: 0.8243 - val_auc: 0.8992\n",
      "Epoch 123/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.4317 - tp: 210.0000 - fp: 64.0000 - tn: 380.0000 - fn: 58.0000 - accuracy: 0.8287 - precision: 0.7664 - recall: 0.7836 - auc: 0.8809 - val_loss: 0.4250 - val_tp: 56.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 18.0000 - val_accuracy: 0.8156 - val_precision: 0.7887 - val_recall: 0.7568 - val_auc: 0.8980\n",
      "Epoch 124/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.4310 - tp: 200.0000 - fp: 59.0000 - tn: 385.0000 - fn: 68.0000 - accuracy: 0.8216 - precision: 0.7722 - recall: 0.7463 - auc: 0.8833 - val_loss: 0.4235 - val_tp: 56.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 18.0000 - val_accuracy: 0.8212 - val_precision: 0.8000 - val_recall: 0.7568 - val_auc: 0.8986\n",
      "Epoch 125/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.0826 - tp: 138.0000 - fp: 190.0000 - tn: 254.0000 - fn: 130.0000 - accuracy: 0.5506 - precision: 0.4207 - recall: 0.5149 - auc: 0.5311 - val_loss: 1.0863 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5215\n",
      "Epoch 228/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.0799 - tp: 132.0000 - fp: 212.0000 - tn: 232.0000 - fn: 136.0000 - accuracy: 0.5112 - precision: 0.3837 - recall: 0.4925 - auc: 0.5226 - val_loss: 1.0855 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6228\n",
      "Epoch 229/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.0801 - tp: 135.0000 - fp: 198.0000 - tn: 246.0000 - fn: 133.0000 - accuracy: 0.5351 - precision: 0.4054 - recall: 0.5037 - auc: 0.5249 - val_loss: 1.0849 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5243\n",
      "Epoch 230/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 1.0762 - tp: 133.0000 - fp: 190.0000 - tn: 254.0000 - fn: 135.0000 - accuracy: 0.5435 - precision: 0.4118 - recall: 0.4963 - auc: 0.5300 - val_loss: 1.0841 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5215\n",
      "Epoch 231/600\n",
      "712/712 [==============================] - 0s 151us/sample - loss: 1.0690 - tp: 139.0000 - fp: 197.0000 - tn: 247.0000 - fn: 129.0000 - accuracy: 0.5421 - precision: 0.4137 - recall: 0.5187 - auc: 0.5613 - val_loss: 1.0834 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5243\n",
      "Epoch 232/600\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 1.0810 - tp: 131.0000 - fp: 212.0000 - tn: 232.0000 - fn: 137.0000 - accuracy: 0.5098 - precision: 0.3819 - recall: 0.4888 - auc: 0.5019 - val_loss: 1.0827 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5891\n",
      "Epoch 233/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.0934 - tp: 119.0000 - fp: 209.0000 - tn: 235.0000 - fn: 149.0000 - accuracy: 0.4972 - precision: 0.3628 - recall: 0.4440 - auc: 0.4825 - val_loss: 1.0820 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5263\n",
      "Epoch 234/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.0796 - tp: 121.0000 - fp: 201.0000 - tn: 243.0000 - fn: 147.0000 - accuracy: 0.5112 - precision: 0.3758 - recall: 0.4515 - auc: 0.5089 - val_loss: 1.0813 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5310\n",
      "Epoch 235/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.0738 - tp: 130.0000 - fp: 195.0000 - tn: 249.0000 - fn: 138.0000 - accuracy: 0.5323 - precision: 0.4000 - recall: 0.4851 - auc: 0.5295 - val_loss: 1.0806 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5243\n",
      "Epoch 236/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.0777 - tp: 127.0000 - fp: 201.0000 - tn: 243.0000 - fn: 141.0000 - accuracy: 0.5197 - precision: 0.3872 - recall: 0.4739 - auc: 0.5184 - val_loss: 1.0798 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5823\n",
      "Epoch 237/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.0936 - tp: 112.0000 - fp: 205.0000 - tn: 239.0000 - fn: 156.0000 - accuracy: 0.4930 - precision: 0.3533 - recall: 0.4179 - auc: 0.4681 - val_loss: 1.0791 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6228\n",
      "Epoch 238/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.0699 - tp: 123.0000 - fp: 188.0000 - tn: 256.0000 - fn: 145.0000 - accuracy: 0.5323 - precision: 0.3955 - recall: 0.4590 - auc: 0.5366 - val_loss: 1.0785 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5243\n",
      "Epoch 239/600\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 1.0734 - tp: 136.0000 - fp: 195.0000 - tn: 249.0000 - fn: 132.0000 - accuracy: 0.5407 - precision: 0.4109 - recall: 0.5075 - auc: 0.5253 - val_loss: 1.0777 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6228\n",
      "Epoch 240/600\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 1.0799 - tp: 131.0000 - fp: 215.0000 - tn: 229.0000 - fn: 137.0000 - accuracy: 0.5056 - precision: 0.3786 - recall: 0.4888 - auc: 0.5117 - val_loss: 1.0770 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5290\n",
      "Epoch 241/600\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 1.0826 - tp: 123.0000 - fp: 209.0000 - tn: 235.0000 - fn: 145.0000 - accuracy: 0.5028 - precision: 0.3705 - recall: 0.4590 - auc: 0.4933 - val_loss: 1.0763 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5290\n",
      "Epoch 242/600\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 1.0676 - tp: 135.0000 - fp: 204.0000 - tn: 240.0000 - fn: 133.0000 - accuracy: 0.5267 - precision: 0.3982 - recall: 0.5037 - auc: 0.5302 - val_loss: 1.0757 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 243/600\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 1.0776 - tp: 127.0000 - fp: 206.0000 - tn: 238.0000 - fn: 141.0000 - accuracy: 0.5126 - precision: 0.3814 - recall: 0.4739 - auc: 0.4981 - val_loss: 1.0749 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 244/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.0705 - tp: 133.0000 - fp: 208.0000 - tn: 236.0000 - fn: 135.0000 - accuracy: 0.5183 - precision: 0.3900 - recall: 0.4963 - auc: 0.5187 - val_loss: 1.0742 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 245/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.0596 - tp: 137.0000 - fp: 189.0000 - tn: 255.0000 - fn: 131.0000 - accuracy: 0.5506 - precision: 0.4202 - recall: 0.5112 - auc: 0.5484 - val_loss: 1.0735 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 246/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.0879 - tp: 109.0000 - fp: 184.0000 - tn: 260.0000 - fn: 159.0000 - accuracy: 0.5183 - precision: 0.3720 - recall: 0.4067 - auc: 0.4728 - val_loss: 1.0728 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5338\n",
      "Epoch 247/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.0751 - tp: 130.0000 - fp: 223.0000 - tn: 221.0000 - fn: 138.0000 - accuracy: 0.4930 - precision: 0.3683 - recall: 0.4851 - auc: 0.4966 - val_loss: 1.0721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 248/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.0803 - tp: 102.0000 - fp: 190.0000 - tn: 254.0000 - fn: 166.0000 - accuracy: 0.5000 - precision: 0.3493 - recall: 0.3806 - auc: 0.4799 - val_loss: 1.0714 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 249/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.0895 - tp: 116.0000 - fp: 208.0000 - tn: 236.0000 - fn: 152.0000 - accuracy: 0.4944 - precision: 0.3580 - recall: 0.4328 - auc: 0.4546 - val_loss: 1.0708 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5135\n",
      "Epoch 250/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.0691 - tp: 123.0000 - fp: 211.0000 - tn: 233.0000 - fn: 145.0000 - accuracy: 0.5000 - precision: 0.3683 - recall: 0.4590 - auc: 0.5096 - val_loss: 1.0700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5290\n",
      "Epoch 251/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.0716 - tp: 125.0000 - fp: 201.0000 - tn: 243.0000 - fn: 143.0000 - accuracy: 0.5169 - precision: 0.3834 - recall: 0.4664 - auc: 0.4967 - val_loss: 1.0693 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 252/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.0740 - tp: 128.0000 - fp: 217.0000 - tn: 227.0000 - fn: 140.0000 - accuracy: 0.4986 - precision: 0.3710 - recall: 0.4776 - auc: 0.4936 - val_loss: 1.0686 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5270\n",
      "Epoch 253/600\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 1.0607 - tp: 127.0000 - fp: 190.0000 - tn: 254.0000 - fn: 141.0000 - accuracy: 0.5351 - precision: 0.4006 - recall: 0.4739 - auc: 0.5320 - val_loss: 1.0680 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 254/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 1.0728 - tp: 112.0000 - fp: 196.0000 - tn: 248.0000 - fn: 156.0000 - accuracy: 0.5056 - precision: 0.3636 - recall: 0.4179 - auc: 0.4969 - val_loss: 1.0673 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 255/600\n",
      "712/712 [==============================] - 0s 152us/sample - loss: 1.0749 - tp: 119.0000 - fp: 203.0000 - tn: 241.0000 - fn: 149.0000 - accuracy: 0.5056 - precision: 0.3696 - recall: 0.4440 - auc: 0.4869 - val_loss: 1.0666 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 256/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.0689 - tp: 112.0000 - fp: 202.0000 - tn: 242.0000 - fn: 156.0000 - accuracy: 0.4972 - precision: 0.3567 - recall: 0.4179 - auc: 0.4883 - val_loss: 1.0659 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5068\n",
      "Epoch 257/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.0658 - tp: 119.0000 - fp: 207.0000 - tn: 237.0000 - fn: 149.0000 - accuracy: 0.5000 - precision: 0.3650 - recall: 0.4440 - auc: 0.5002 - val_loss: 1.0652 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 258/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.0582 - tp: 128.0000 - fp: 194.0000 - tn: 250.0000 - fn: 140.0000 - accuracy: 0.5309 - precision: 0.3975 - recall: 0.4776 - auc: 0.5299 - val_loss: 1.0645 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5338\n",
      "Epoch 259/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.0682 - tp: 123.0000 - fp: 213.0000 - tn: 231.0000 - fn: 145.0000 - accuracy: 0.4972 - precision: 0.3661 - recall: 0.4590 - auc: 0.4974 - val_loss: 1.0638 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5338\n",
      "Epoch 260/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.0607 - tp: 132.0000 - fp: 199.0000 - tn: 245.0000 - fn: 136.0000 - accuracy: 0.5295 - precision: 0.3988 - recall: 0.4925 - auc: 0.5203 - val_loss: 1.0631 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5068\n",
      "Epoch 261/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.0645 - tp: 121.0000 - fp: 192.0000 - tn: 252.0000 - fn: 147.0000 - accuracy: 0.5239 - precision: 0.3866 - recall: 0.4515 - auc: 0.5006 - val_loss: 1.0625 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5068\n",
      "Epoch 262/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.0711 - tp: 121.0000 - fp: 203.0000 - tn: 241.0000 - fn: 147.0000 - accuracy: 0.5084 - precision: 0.3735 - recall: 0.4515 - auc: 0.4836 - val_loss: 1.0617 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203\n",
      "Epoch 263/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.0704 - tp: 118.0000 - fp: 180.0000 - tn: 264.0000 - fn: 150.0000 - accuracy: 0.5365 - precision: 0.3960 - recall: 0.4403 - auc: 0.4934 - val_loss: 1.0610 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5378\n",
      "Epoch 264/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.0603 - tp: 124.0000 - fp: 183.0000 - tn: 261.0000 - fn: 144.0000 - accuracy: 0.5407 - precision: 0.4039 - recall: 0.4627 - auc: 0.5083 - val_loss: 1.0602 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6181\n",
      "Epoch 265/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5735 - tp: 199.0000 - fp: 70.0000 - tn: 374.0000 - fn: 69.0000 - accuracy: 0.8048 - precision: 0.7398 - recall: 0.7425 - auc: 0.8412 - val_loss: 0.5372 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8874\n",
      "Epoch 381/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5669 - tp: 194.0000 - fp: 71.0000 - tn: 373.0000 - fn: 74.0000 - accuracy: 0.7963 - precision: 0.7321 - recall: 0.7239 - auc: 0.8432 - val_loss: 0.5361 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8884\n",
      "Epoch 382/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.5781 - tp: 199.0000 - fp: 81.0000 - tn: 363.0000 - fn: 69.0000 - accuracy: 0.7893 - precision: 0.7107 - recall: 0.7425 - auc: 0.8343 - val_loss: 0.5371 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8889\n",
      "Epoch 383/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5735 - tp: 196.0000 - fp: 85.0000 - tn: 359.0000 - fn: 72.0000 - accuracy: 0.7795 - precision: 0.6975 - recall: 0.7313 - auc: 0.8426 - val_loss: 0.5348 - val_tp: 58.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 16.0000 - val_accuracy: 0.7877 - val_precision: 0.7250 - val_recall: 0.7838 - val_auc: 0.8889\n",
      "Epoch 384/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5809 - tp: 198.0000 - fp: 76.0000 - tn: 368.0000 - fn: 70.0000 - accuracy: 0.7949 - precision: 0.7226 - recall: 0.7388 - auc: 0.8276 - val_loss: 0.5350 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8889\n",
      "Epoch 385/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5731 - tp: 198.0000 - fp: 77.0000 - tn: 367.0000 - fn: 70.0000 - accuracy: 0.7935 - precision: 0.7200 - recall: 0.7388 - auc: 0.8341 - val_loss: 0.5345 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8887\n",
      "Epoch 386/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.5739 - tp: 192.0000 - fp: 65.0000 - tn: 379.0000 - fn: 76.0000 - accuracy: 0.8020 - precision: 0.7471 - recall: 0.7164 - auc: 0.8319 - val_loss: 0.5354 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8885\n",
      "Epoch 387/500\n",
      "712/712 [==============================] - 0s 205us/sample - loss: 0.5626 - tp: 197.0000 - fp: 81.0000 - tn: 363.0000 - fn: 71.0000 - accuracy: 0.7865 - precision: 0.7086 - recall: 0.7351 - auc: 0.8453 - val_loss: 0.5330 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8888\n",
      "Epoch 388/500\n",
      "712/712 [==============================] - 0s 148us/sample - loss: 0.5699 - tp: 195.0000 - fp: 81.0000 - tn: 363.0000 - fn: 73.0000 - accuracy: 0.7837 - precision: 0.7065 - recall: 0.7276 - auc: 0.8316 - val_loss: 0.5334 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8884\n",
      "Epoch 389/500\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 0.5840 - tp: 187.0000 - fp: 70.0000 - tn: 374.0000 - fn: 81.0000 - accuracy: 0.7879 - precision: 0.7276 - recall: 0.6978 - auc: 0.8194 - val_loss: 0.5357 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8882\n",
      "Epoch 390/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 0.5605 - tp: 196.0000 - fp: 69.0000 - tn: 375.0000 - fn: 72.0000 - accuracy: 0.8020 - precision: 0.7396 - recall: 0.7313 - auc: 0.8436 - val_loss: 0.5344 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8880\n",
      "Epoch 391/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5468 - tp: 206.0000 - fp: 80.0000 - tn: 364.0000 - fn: 62.0000 - accuracy: 0.8006 - precision: 0.7203 - recall: 0.7687 - auc: 0.8563 - val_loss: 0.5315 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 16.0000 - val_accuracy: 0.7933 - val_precision: 0.7342 - val_recall: 0.7838 - val_auc: 0.8883\n",
      "Epoch 392/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5650 - tp: 191.0000 - fp: 71.0000 - tn: 373.0000 - fn: 77.0000 - accuracy: 0.7921 - precision: 0.7290 - recall: 0.7127 - auc: 0.8415 - val_loss: 0.5331 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8885\n",
      "Epoch 393/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5636 - tp: 198.0000 - fp: 71.0000 - tn: 373.0000 - fn: 70.0000 - accuracy: 0.8020 - precision: 0.7361 - recall: 0.7388 - auc: 0.8482 - val_loss: 0.5327 - val_tp: 57.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 17.0000 - val_accuracy: 0.8045 - val_precision: 0.7600 - val_recall: 0.7703 - val_auc: 0.8891\n",
      "Epoch 394/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5813 - tp: 200.0000 - fp: 80.0000 - tn: 364.0000 - fn: 68.0000 - accuracy: 0.7921 - precision: 0.7143 - recall: 0.7463 - auc: 0.8273 - val_loss: 0.5345 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8881\n",
      "Epoch 395/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5642 - tp: 201.0000 - fp: 70.0000 - tn: 374.0000 - fn: 67.0000 - accuracy: 0.8076 - precision: 0.7417 - recall: 0.7500 - auc: 0.8426 - val_loss: 0.5379 - val_tp: 55.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 19.0000 - val_accuracy: 0.7989 - val_precision: 0.7639 - val_recall: 0.7432 - val_auc: 0.8889\n",
      "Epoch 396/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5752 - tp: 198.0000 - fp: 68.0000 - tn: 376.0000 - fn: 70.0000 - accuracy: 0.8062 - precision: 0.7444 - recall: 0.7388 - auc: 0.8291 - val_loss: 0.5362 - val_tp: 55.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 19.0000 - val_accuracy: 0.7933 - val_precision: 0.7534 - val_recall: 0.7432 - val_auc: 0.8901\n",
      "Epoch 397/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5659 - tp: 196.0000 - fp: 85.0000 - tn: 359.0000 - fn: 72.0000 - accuracy: 0.7795 - precision: 0.6975 - recall: 0.7313 - auc: 0.8399 - val_loss: 0.5336 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8891\n",
      "Epoch 398/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5641 - tp: 195.0000 - fp: 62.0000 - tn: 382.0000 - fn: 73.0000 - accuracy: 0.8104 - precision: 0.7588 - recall: 0.7276 - auc: 0.8414 - val_loss: 0.5328 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8892\n",
      "Epoch 399/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.5780 - tp: 193.0000 - fp: 72.0000 - tn: 372.0000 - fn: 75.0000 - accuracy: 0.7935 - precision: 0.7283 - recall: 0.7201 - auc: 0.8251 - val_loss: 0.5353 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8891\n",
      "Epoch 400/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5608 - tp: 198.0000 - fp: 73.0000 - tn: 371.0000 - fn: 70.0000 - accuracy: 0.7992 - precision: 0.7306 - recall: 0.7388 - auc: 0.8442 - val_loss: 0.5348 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8876\n",
      "Epoch 401/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.5667 - tp: 199.0000 - fp: 75.0000 - tn: 369.0000 - fn: 69.0000 - accuracy: 0.7978 - precision: 0.7263 - recall: 0.7425 - auc: 0.8412 - val_loss: 0.5333 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8883\n",
      "Epoch 402/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5543 - tp: 196.0000 - fp: 66.0000 - tn: 378.0000 - fn: 72.0000 - accuracy: 0.8062 - precision: 0.7481 - recall: 0.7313 - auc: 0.8490 - val_loss: 0.5328 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 16.0000 - val_accuracy: 0.8101 - val_precision: 0.7632 - val_recall: 0.7838 - val_auc: 0.8886\n",
      "Epoch 403/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5796 - tp: 184.0000 - fp: 69.0000 - tn: 375.0000 - fn: 84.0000 - accuracy: 0.7851 - precision: 0.7273 - recall: 0.6866 - auc: 0.8288 - val_loss: 0.5348 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8883\n",
      "Epoch 404/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5522 - tp: 199.0000 - fp: 68.0000 - tn: 376.0000 - fn: 69.0000 - accuracy: 0.8076 - precision: 0.7453 - recall: 0.7425 - auc: 0.8600 - val_loss: 0.5330 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8879\n",
      "Epoch 405/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5772 - tp: 195.0000 - fp: 72.0000 - tn: 372.0000 - fn: 73.0000 - accuracy: 0.7963 - precision: 0.7303 - recall: 0.7276 - auc: 0.8315 - val_loss: 0.5313 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8886\n",
      "Epoch 406/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5766 - tp: 196.0000 - fp: 71.0000 - tn: 373.0000 - fn: 72.0000 - accuracy: 0.7992 - precision: 0.7341 - recall: 0.7313 - auc: 0.8252 - val_loss: 0.5333 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8878\n",
      "Epoch 407/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5767 - tp: 188.0000 - fp: 62.0000 - tn: 382.0000 - fn: 80.0000 - accuracy: 0.8006 - precision: 0.7520 - recall: 0.7015 - auc: 0.8225 - val_loss: 0.5381 - val_tp: 55.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 19.0000 - val_accuracy: 0.7989 - val_precision: 0.7639 - val_recall: 0.7432 - val_auc: 0.8880\n",
      "Epoch 408/500\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5578 - tp: 202.0000 - fp: 75.0000 - tn: 369.0000 - fn: 66.0000 - accuracy: 0.8020 - precision: 0.7292 - recall: 0.7537 - auc: 0.8485 - val_loss: 0.5357 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8890\n",
      "Epoch 409/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5614 - tp: 193.0000 - fp: 63.0000 - tn: 381.0000 - fn: 75.0000 - accuracy: 0.8062 - precision: 0.7539 - recall: 0.7201 - auc: 0.8441 - val_loss: 0.5337 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8880\n",
      "Epoch 410/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5684 - tp: 205.0000 - fp: 79.0000 - tn: 365.0000 - fn: 63.0000 - accuracy: 0.8006 - precision: 0.7218 - recall: 0.7649 - auc: 0.8358 - val_loss: 0.5337 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8884\n",
      "Epoch 411/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.5801 - tp: 199.0000 - fp: 79.0000 - tn: 365.0000 - fn: 69.0000 - accuracy: 0.7921 - precision: 0.7158 - recall: 0.7425 - auc: 0.8247 - val_loss: 0.5349 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8883\n",
      "Epoch 412/500\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5810 - tp: 201.0000 - fp: 78.0000 - tn: 366.0000 - fn: 67.0000 - accuracy: 0.7963 - precision: 0.7204 - recall: 0.7500 - auc: 0.8286 - val_loss: 0.5353 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8882\n",
      "Epoch 413/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5763 - tp: 200.0000 - fp: 79.0000 - tn: 365.0000 - fn: 68.0000 - accuracy: 0.7935 - precision: 0.7168 - recall: 0.7463 - auc: 0.8298 - val_loss: 0.5345 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8874\n",
      "Epoch 414/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5632 - tp: 192.0000 - fp: 68.0000 - tn: 376.0000 - fn: 76.0000 - accuracy: 0.7978 - precision: 0.7385 - recall: 0.7164 - auc: 0.8434 - val_loss: 0.5354 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8882\n",
      "Epoch 415/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 0.5668 - tp: 196.0000 - fp: 75.0000 - tn: 369.0000 - fn: 72.0000 - accuracy: 0.7935 - precision: 0.7232 - recall: 0.7313 - auc: 0.8348 - val_loss: 0.5350 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8888\n",
      "Epoch 416/500\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 0.5749 - tp: 195.0000 - fp: 69.0000 - tn: 375.0000 - fn: 73.0000 - accuracy: 0.8006 - precision: 0.7386 - recall: 0.7276 - auc: 0.8293 - val_loss: 0.5343 - val_tp: 56.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 18.0000 - val_accuracy: 0.7989 - val_precision: 0.7568 - val_recall: 0.7568 - val_auc: 0.8884\n",
      "Epoch 417/500\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 0.5708 - tp: 195.0000 - fp: 74.0000 - tn: 370.0000 - fn: 73.0000 - accuracy: 0.7935 - precision: 0.7249 - recall: 0.7276 - auc: 0.8368 - val_loss: 0.5335 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8882\n",
      "Epoch 418/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5194 - tp: 209.0000 - fp: 76.0000 - tn: 368.0000 - fn: 59.0000 - accuracy: 0.8104 - precision: 0.7333 - recall: 0.7799 - auc: 0.8496 - val_loss: 0.5025 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8790\n",
      "Epoch 188/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5287 - tp: 204.0000 - fp: 68.0000 - tn: 376.0000 - fn: 64.0000 - accuracy: 0.8146 - precision: 0.7500 - recall: 0.7612 - auc: 0.8403 - val_loss: 0.5025 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8806\n",
      "Epoch 189/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5081 - tp: 205.0000 - fp: 69.0000 - tn: 375.0000 - fn: 63.0000 - accuracy: 0.8146 - precision: 0.7482 - recall: 0.7649 - auc: 0.8587 - val_loss: 0.5020 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8799\n",
      "Epoch 190/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5057 - tp: 207.0000 - fp: 70.0000 - tn: 374.0000 - fn: 61.0000 - accuracy: 0.8160 - precision: 0.7473 - recall: 0.7724 - auc: 0.8625 - val_loss: 0.5017 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8797\n",
      "Epoch 191/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5117 - tp: 207.0000 - fp: 72.0000 - tn: 372.0000 - fn: 61.0000 - accuracy: 0.8132 - precision: 0.7419 - recall: 0.7724 - auc: 0.8509 - val_loss: 0.5013 - val_tp: 59.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 15.0000 - val_accuracy: 0.7989 - val_precision: 0.7375 - val_recall: 0.7973 - val_auc: 0.8797\n",
      "Epoch 192/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5178 - tp: 206.0000 - fp: 75.0000 - tn: 369.0000 - fn: 62.0000 - accuracy: 0.8076 - precision: 0.7331 - recall: 0.7687 - auc: 0.8491 - val_loss: 0.5010 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8792\n",
      "Epoch 193/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5109 - tp: 209.0000 - fp: 72.0000 - tn: 372.0000 - fn: 59.0000 - accuracy: 0.8160 - precision: 0.7438 - recall: 0.7799 - auc: 0.8568 - val_loss: 0.5011 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8805\n",
      "Epoch 194/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5155 - tp: 207.0000 - fp: 61.0000 - tn: 383.0000 - fn: 61.0000 - accuracy: 0.8287 - precision: 0.7724 - recall: 0.7724 - auc: 0.8455 - val_loss: 0.5009 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8802\n",
      "Epoch 195/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 0.5214 - tp: 205.0000 - fp: 74.0000 - tn: 370.0000 - fn: 63.0000 - accuracy: 0.8076 - precision: 0.7348 - recall: 0.7649 - auc: 0.8463 - val_loss: 0.5008 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8806\n",
      "Epoch 196/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5043 - tp: 209.0000 - fp: 70.0000 - tn: 374.0000 - fn: 59.0000 - accuracy: 0.8188 - precision: 0.7491 - recall: 0.7799 - auc: 0.8577 - val_loss: 0.5004 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8797\n",
      "Epoch 197/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5206 - tp: 205.0000 - fp: 73.0000 - tn: 371.0000 - fn: 63.0000 - accuracy: 0.8090 - precision: 0.7374 - recall: 0.7649 - auc: 0.8488 - val_loss: 0.5004 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8802\n",
      "Epoch 198/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5161 - tp: 206.0000 - fp: 75.0000 - tn: 369.0000 - fn: 62.0000 - accuracy: 0.8076 - precision: 0.7331 - recall: 0.7687 - auc: 0.8520 - val_loss: 0.5002 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8801\n",
      "Epoch 199/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5251 - tp: 205.0000 - fp: 71.0000 - tn: 373.0000 - fn: 63.0000 - accuracy: 0.8118 - precision: 0.7428 - recall: 0.7649 - auc: 0.8434 - val_loss: 0.4998 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8813\n",
      "Epoch 200/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5175 - tp: 207.0000 - fp: 70.0000 - tn: 374.0000 - fn: 61.0000 - accuracy: 0.8160 - precision: 0.7473 - recall: 0.7724 - auc: 0.8456 - val_loss: 0.4995 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8806\n",
      "Epoch 201/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5153 - tp: 205.0000 - fp: 76.0000 - tn: 368.0000 - fn: 63.0000 - accuracy: 0.8048 - precision: 0.7295 - recall: 0.7649 - auc: 0.8487 - val_loss: 0.4995 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8815\n",
      "Epoch 202/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5183 - tp: 201.0000 - fp: 70.0000 - tn: 374.0000 - fn: 67.0000 - accuracy: 0.8076 - precision: 0.7417 - recall: 0.7500 - auc: 0.8487 - val_loss: 0.4989 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8804\n",
      "Epoch 203/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5054 - tp: 205.0000 - fp: 70.0000 - tn: 374.0000 - fn: 63.0000 - accuracy: 0.8132 - precision: 0.7455 - recall: 0.7649 - auc: 0.8579 - val_loss: 0.4988 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8808\n",
      "Epoch 204/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5058 - tp: 207.0000 - fp: 63.0000 - tn: 381.0000 - fn: 61.0000 - accuracy: 0.8258 - precision: 0.7667 - recall: 0.7724 - auc: 0.8568 - val_loss: 0.4984 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8813\n",
      "Epoch 205/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5054 - tp: 206.0000 - fp: 72.0000 - tn: 372.0000 - fn: 62.0000 - accuracy: 0.8118 - precision: 0.7410 - recall: 0.7687 - auc: 0.8590 - val_loss: 0.4981 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8813\n",
      "Epoch 206/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5051 - tp: 210.0000 - fp: 69.0000 - tn: 375.0000 - fn: 58.0000 - accuracy: 0.8216 - precision: 0.7527 - recall: 0.7836 - auc: 0.8569 - val_loss: 0.4979 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8817\n",
      "Epoch 207/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5194 - tp: 209.0000 - fp: 74.0000 - tn: 370.0000 - fn: 59.0000 - accuracy: 0.8132 - precision: 0.7385 - recall: 0.7799 - auc: 0.8440 - val_loss: 0.4978 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8818\n",
      "Epoch 208/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5024 - tp: 205.0000 - fp: 72.0000 - tn: 372.0000 - fn: 63.0000 - accuracy: 0.8104 - precision: 0.7401 - recall: 0.7649 - auc: 0.8607 - val_loss: 0.4975 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8819\n",
      "Epoch 209/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.4987 - tp: 208.0000 - fp: 70.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.8174 - precision: 0.7482 - recall: 0.7761 - auc: 0.8630 - val_loss: 0.4975 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8817\n",
      "Epoch 210/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5134 - tp: 207.0000 - fp: 66.0000 - tn: 378.0000 - fn: 61.0000 - accuracy: 0.8216 - precision: 0.7582 - recall: 0.7724 - auc: 0.8488 - val_loss: 0.4972 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8820\n",
      "Epoch 211/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.5062 - tp: 203.0000 - fp: 71.0000 - tn: 373.0000 - fn: 65.0000 - accuracy: 0.8090 - precision: 0.7409 - recall: 0.7575 - auc: 0.8552 - val_loss: 0.4967 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8819\n",
      "Epoch 212/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5085 - tp: 208.0000 - fp: 65.0000 - tn: 379.0000 - fn: 60.0000 - accuracy: 0.8244 - precision: 0.7619 - recall: 0.7761 - auc: 0.8534 - val_loss: 0.4964 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8817\n",
      "Epoch 213/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 0.5106 - tp: 202.0000 - fp: 73.0000 - tn: 371.0000 - fn: 66.0000 - accuracy: 0.8048 - precision: 0.7345 - recall: 0.7537 - auc: 0.8555 - val_loss: 0.4962 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8819\n",
      "Epoch 214/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.5037 - tp: 208.0000 - fp: 75.0000 - tn: 369.0000 - fn: 60.0000 - accuracy: 0.8104 - precision: 0.7350 - recall: 0.7761 - auc: 0.8587 - val_loss: 0.4956 - val_tp: 59.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 15.0000 - val_accuracy: 0.8045 - val_precision: 0.7468 - val_recall: 0.7973 - val_auc: 0.8817\n",
      "Epoch 215/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.4995 - tp: 206.0000 - fp: 71.0000 - tn: 373.0000 - fn: 62.0000 - accuracy: 0.8132 - precision: 0.7437 - recall: 0.7687 - auc: 0.8617 - val_loss: 0.4953 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8819\n",
      "Epoch 216/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.5086 - tp: 208.0000 - fp: 71.0000 - tn: 373.0000 - fn: 60.0000 - accuracy: 0.8160 - precision: 0.7455 - recall: 0.7761 - auc: 0.8556 - val_loss: 0.4953 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8817\n",
      "Epoch 217/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5095 - tp: 207.0000 - fp: 74.0000 - tn: 370.0000 - fn: 61.0000 - accuracy: 0.8104 - precision: 0.7367 - recall: 0.7724 - auc: 0.8538 - val_loss: 0.4952 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8816\n",
      "Epoch 218/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 0.5131 - tp: 208.0000 - fp: 80.0000 - tn: 364.0000 - fn: 60.0000 - accuracy: 0.8034 - precision: 0.7222 - recall: 0.7761 - auc: 0.8497 - val_loss: 0.4950 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8812\n",
      "Epoch 219/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5040 - tp: 206.0000 - fp: 75.0000 - tn: 369.0000 - fn: 62.0000 - accuracy: 0.8076 - precision: 0.7331 - recall: 0.7687 - auc: 0.8577 - val_loss: 0.4949 - val_tp: 58.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 16.0000 - val_accuracy: 0.7989 - val_precision: 0.7436 - val_recall: 0.7838 - val_auc: 0.8823\n",
      "Epoch 220/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.5000 - tp: 203.0000 - fp: 73.0000 - tn: 371.0000 - fn: 65.0000 - accuracy: 0.8062 - precision: 0.7355 - recall: 0.7575 - auc: 0.8643 - val_loss: 0.4950 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8821\n",
      "Epoch 221/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.5120 - tp: 204.0000 - fp: 71.0000 - tn: 373.0000 - fn: 64.0000 - accuracy: 0.8104 - precision: 0.7418 - recall: 0.7612 - auc: 0.8491 - val_loss: 0.4950 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8831\n",
      "Epoch 222/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.5093 - tp: 204.0000 - fp: 67.0000 - tn: 377.0000 - fn: 64.0000 - accuracy: 0.8160 - precision: 0.7528 - recall: 0.7612 - auc: 0.8528 - val_loss: 0.4947 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8818\n",
      "Epoch 223/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.5027 - tp: 211.0000 - fp: 68.0000 - tn: 376.0000 - fn: 57.0000 - accuracy: 0.8244 - precision: 0.7563 - recall: 0.7873 - auc: 0.8535 - val_loss: 0.4947 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8824\n",
      "Epoch 224/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.4995 - tp: 205.0000 - fp: 78.0000 - tn: 366.0000 - fn: 63.0000 - accuracy: 0.8020 - precision: 0.7244 - recall: 0.7649 - auc: 0.8632 - val_loss: 0.4947 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 16.0000 - val_accuracy: 0.8045 - val_precision: 0.7532 - val_recall: 0.7838 - val_auc: 0.8824\n",
      "Epoch 225/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1631 - tp: 128.0000 - fp: 215.0000 - tn: 229.0000 - fn: 140.0000 - accuracy: 0.5014 - precision: 0.3732 - recall: 0.4776 - auc: 0.5136 - val_loss: 1.1610 - val_tp: 42.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 32.0000 - val_accuracy: 0.6760 - val_precision: 0.6176 - val_recall: 0.5676 - val_auc: 0.6961\n",
      "Epoch 292/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1638 - tp: 133.0000 - fp: 202.0000 - tn: 242.0000 - fn: 135.0000 - accuracy: 0.5267 - precision: 0.3970 - recall: 0.4963 - auc: 0.5230 - val_loss: 1.1609 - val_tp: 42.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 32.0000 - val_accuracy: 0.6760 - val_precision: 0.6176 - val_recall: 0.5676 - val_auc: 0.6936\n",
      "Epoch 293/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1668 - tp: 119.0000 - fp: 212.0000 - tn: 232.0000 - fn: 149.0000 - accuracy: 0.4930 - precision: 0.3595 - recall: 0.4440 - auc: 0.5025 - val_loss: 1.1608 - val_tp: 42.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 32.0000 - val_accuracy: 0.6760 - val_precision: 0.6176 - val_recall: 0.5676 - val_auc: 0.6936\n",
      "Epoch 294/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1572 - tp: 136.0000 - fp: 200.0000 - tn: 244.0000 - fn: 132.0000 - accuracy: 0.5337 - precision: 0.4048 - recall: 0.5075 - auc: 0.5356 - val_loss: 1.1606 - val_tp: 42.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 32.0000 - val_accuracy: 0.6760 - val_precision: 0.6176 - val_recall: 0.5676 - val_auc: 0.6942\n",
      "Epoch 295/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1638 - tp: 132.0000 - fp: 195.0000 - tn: 249.0000 - fn: 136.0000 - accuracy: 0.5351 - precision: 0.4037 - recall: 0.4925 - auc: 0.5155 - val_loss: 1.1605 - val_tp: 42.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 32.0000 - val_accuracy: 0.6760 - val_precision: 0.6176 - val_recall: 0.5676 - val_auc: 0.6910\n",
      "Epoch 296/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1667 - tp: 130.0000 - fp: 200.0000 - tn: 244.0000 - fn: 138.0000 - accuracy: 0.5253 - precision: 0.3939 - recall: 0.4851 - auc: 0.5089 - val_loss: 1.1604 - val_tp: 42.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 32.0000 - val_accuracy: 0.6760 - val_precision: 0.6176 - val_recall: 0.5676 - val_auc: 0.6931\n",
      "Epoch 297/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.1675 - tp: 114.0000 - fp: 200.0000 - tn: 244.0000 - fn: 154.0000 - accuracy: 0.5028 - precision: 0.3631 - recall: 0.4254 - auc: 0.4851 - val_loss: 1.1602 - val_tp: 42.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 32.0000 - val_accuracy: 0.6760 - val_precision: 0.6176 - val_recall: 0.5676 - val_auc: 0.6891\n",
      "Epoch 298/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1633 - tp: 135.0000 - fp: 214.0000 - tn: 230.0000 - fn: 133.0000 - accuracy: 0.5126 - precision: 0.3868 - recall: 0.5037 - auc: 0.5028 - val_loss: 1.1601 - val_tp: 42.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 32.0000 - val_accuracy: 0.6760 - val_precision: 0.6176 - val_recall: 0.5676 - val_auc: 0.6942\n",
      "Epoch 299/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1582 - tp: 124.0000 - fp: 190.0000 - tn: 254.0000 - fn: 144.0000 - accuracy: 0.5309 - precision: 0.3949 - recall: 0.4627 - auc: 0.5223 - val_loss: 1.1599 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.6979\n",
      "Epoch 300/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.1562 - tp: 129.0000 - fp: 191.0000 - tn: 253.0000 - fn: 139.0000 - accuracy: 0.5365 - precision: 0.4031 - recall: 0.4813 - auc: 0.5359 - val_loss: 1.1598 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7040\n",
      "Epoch 301/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.1672 - tp: 131.0000 - fp: 227.0000 - tn: 217.0000 - fn: 137.0000 - accuracy: 0.4888 - precision: 0.3659 - recall: 0.4888 - auc: 0.4829 - val_loss: 1.1596 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7077\n",
      "Epoch 302/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1489 - tp: 137.0000 - fp: 184.0000 - tn: 260.0000 - fn: 131.0000 - accuracy: 0.5576 - precision: 0.4268 - recall: 0.5112 - auc: 0.5606 - val_loss: 1.1595 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7003\n",
      "Epoch 303/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1611 - tp: 123.0000 - fp: 204.0000 - tn: 240.0000 - fn: 145.0000 - accuracy: 0.5098 - precision: 0.3761 - recall: 0.4590 - auc: 0.5130 - val_loss: 1.1593 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7083\n",
      "Epoch 304/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1639 - tp: 118.0000 - fp: 205.0000 - tn: 239.0000 - fn: 150.0000 - accuracy: 0.5014 - precision: 0.3653 - recall: 0.4403 - auc: 0.4947 - val_loss: 1.1592 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7091\n",
      "Epoch 305/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1613 - tp: 131.0000 - fp: 202.0000 - tn: 242.0000 - fn: 137.0000 - accuracy: 0.5239 - precision: 0.3934 - recall: 0.4888 - auc: 0.5057 - val_loss: 1.1591 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7077\n",
      "Epoch 306/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1692 - tp: 127.0000 - fp: 212.0000 - tn: 232.0000 - fn: 141.0000 - accuracy: 0.5042 - precision: 0.3746 - recall: 0.4739 - auc: 0.4873 - val_loss: 1.1589 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7077\n",
      "Epoch 307/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1534 - tp: 143.0000 - fp: 181.0000 - tn: 263.0000 - fn: 125.0000 - accuracy: 0.5702 - precision: 0.4414 - recall: 0.5336 - auc: 0.5514 - val_loss: 1.1588 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7086\n",
      "Epoch 308/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1661 - tp: 132.0000 - fp: 212.0000 - tn: 232.0000 - fn: 136.0000 - accuracy: 0.5112 - precision: 0.3837 - recall: 0.4925 - auc: 0.4917 - val_loss: 1.1586 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7086\n",
      "Epoch 309/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1541 - tp: 133.0000 - fp: 197.0000 - tn: 247.0000 - fn: 135.0000 - accuracy: 0.5337 - precision: 0.4030 - recall: 0.4963 - auc: 0.5328 - val_loss: 1.1585 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7081\n",
      "Epoch 310/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.1588 - tp: 126.0000 - fp: 212.0000 - tn: 232.0000 - fn: 142.0000 - accuracy: 0.5028 - precision: 0.3728 - recall: 0.4701 - auc: 0.5100 - val_loss: 1.1583 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7078\n",
      "Epoch 311/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.1608 - tp: 126.0000 - fp: 207.0000 - tn: 237.0000 - fn: 142.0000 - accuracy: 0.5098 - precision: 0.3784 - recall: 0.4701 - auc: 0.5041 - val_loss: 1.1582 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7086\n",
      "Epoch 312/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.1585 - tp: 134.0000 - fp: 207.0000 - tn: 237.0000 - fn: 134.0000 - accuracy: 0.5211 - precision: 0.3930 - recall: 0.5000 - auc: 0.5091 - val_loss: 1.1580 - val_tp: 43.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 31.0000 - val_accuracy: 0.6760 - val_precision: 0.6143 - val_recall: 0.5811 - val_auc: 0.7078\n",
      "Epoch 313/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 1.1582 - tp: 136.0000 - fp: 207.0000 - tn: 237.0000 - fn: 132.0000 - accuracy: 0.5239 - precision: 0.3965 - recall: 0.5075 - auc: 0.5147 - val_loss: 1.1579 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7081\n",
      "Epoch 314/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1656 - tp: 121.0000 - fp: 214.0000 - tn: 230.0000 - fn: 147.0000 - accuracy: 0.4930 - precision: 0.3612 - recall: 0.4515 - auc: 0.4791 - val_loss: 1.1578 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7081\n",
      "Epoch 315/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 1.1601 - tp: 131.0000 - fp: 191.0000 - tn: 253.0000 - fn: 137.0000 - accuracy: 0.5393 - precision: 0.4068 - recall: 0.4888 - auc: 0.5268 - val_loss: 1.1577 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7044\n",
      "Epoch 316/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1582 - tp: 128.0000 - fp: 205.0000 - tn: 239.0000 - fn: 140.0000 - accuracy: 0.5154 - precision: 0.3844 - recall: 0.4776 - auc: 0.5173 - val_loss: 1.1576 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7039\n",
      "Epoch 317/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1631 - tp: 111.0000 - fp: 207.0000 - tn: 237.0000 - fn: 157.0000 - accuracy: 0.4888 - precision: 0.3491 - recall: 0.4142 - auc: 0.4953 - val_loss: 1.1574 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7051\n",
      "Epoch 318/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1633 - tp: 129.0000 - fp: 199.0000 - tn: 245.0000 - fn: 139.0000 - accuracy: 0.5253 - precision: 0.3933 - recall: 0.4813 - auc: 0.4984 - val_loss: 1.1573 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7042\n",
      "Epoch 319/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 1.1534 - tp: 130.0000 - fp: 209.0000 - tn: 235.0000 - fn: 138.0000 - accuracy: 0.5126 - precision: 0.3835 - recall: 0.4851 - auc: 0.5268 - val_loss: 1.1572 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7044\n",
      "Epoch 320/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1558 - tp: 132.0000 - fp: 214.0000 - tn: 230.0000 - fn: 136.0000 - accuracy: 0.5084 - precision: 0.3815 - recall: 0.4925 - auc: 0.5241 - val_loss: 1.1570 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7051\n",
      "Epoch 321/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.1618 - tp: 133.0000 - fp: 208.0000 - tn: 236.0000 - fn: 135.0000 - accuracy: 0.5183 - precision: 0.3900 - recall: 0.4963 - auc: 0.4958 - val_loss: 1.1569 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7074\n",
      "Epoch 322/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1614 - tp: 120.0000 - fp: 215.0000 - tn: 229.0000 - fn: 148.0000 - accuracy: 0.4902 - precision: 0.3582 - recall: 0.4478 - auc: 0.5001 - val_loss: 1.1568 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7074\n",
      "Epoch 323/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.1592 - tp: 132.0000 - fp: 213.0000 - tn: 231.0000 - fn: 136.0000 - accuracy: 0.5098 - precision: 0.3826 - recall: 0.4925 - auc: 0.5168 - val_loss: 1.1566 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7074\n",
      "Epoch 324/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1516 - tp: 135.0000 - fp: 193.0000 - tn: 251.0000 - fn: 133.0000 - accuracy: 0.5421 - precision: 0.4116 - recall: 0.5037 - auc: 0.5449 - val_loss: 1.1565 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7069\n",
      "Epoch 325/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1576 - tp: 136.0000 - fp: 211.0000 - tn: 233.0000 - fn: 132.0000 - accuracy: 0.5183 - precision: 0.3919 - recall: 0.5075 - auc: 0.5042 - val_loss: 1.1564 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.6990\n",
      "Epoch 326/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1508 - tp: 129.0000 - fp: 188.0000 - tn: 256.0000 - fn: 139.0000 - accuracy: 0.5407 - precision: 0.4069 - recall: 0.4813 - auc: 0.5360 - val_loss: 1.1563 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.6964\n",
      "Epoch 327/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1554 - tp: 128.0000 - fp: 201.0000 - tn: 243.0000 - fn: 140.0000 - accuracy: 0.5211 - precision: 0.3891 - recall: 0.4776 - auc: 0.5204 - val_loss: 1.1561 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.6990\n",
      "Epoch 328/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1575 - tp: 132.0000 - fp: 210.0000 - tn: 234.0000 - fn: 136.0000 - accuracy: 0.5140 - precision: 0.3860 - recall: 0.4925 - auc: 0.5130 - val_loss: 1.1559 - val_tp: 42.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 32.0000 - val_accuracy: 0.6704 - val_precision: 0.6087 - val_recall: 0.5676 - val_auc: 0.7079\n",
      "Epoch 329/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.1691 - tp: 96.0000 - fp: 195.0000 - tn: 249.0000 - fn: 172.0000 - accuracy: 0.4846 - precision: 0.3299 - recall: 0.3582 - auc: 0.4648 - val_loss: 1.1558 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7149\n",
      "Epoch 330/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1526 - tp: 125.0000 - fp: 193.0000 - tn: 251.0000 - fn: 143.0000 - accuracy: 0.5281 - precision: 0.3931 - recall: 0.4664 - auc: 0.5384 - val_loss: 1.1557 - val_tp: 43.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 31.0000 - val_accuracy: 0.6760 - val_precision: 0.6143 - val_recall: 0.5811 - val_auc: 0.7079\n",
      "Epoch 331/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1448 - tp: 146.0000 - fp: 178.0000 - tn: 266.0000 - fn: 122.0000 - accuracy: 0.5787 - precision: 0.4506 - recall: 0.5448 - auc: 0.5806 - val_loss: 1.1555 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7122\n",
      "Epoch 332/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.1576 - tp: 131.0000 - fp: 205.0000 - tn: 239.0000 - fn: 137.0000 - accuracy: 0.5197 - precision: 0.3899 - recall: 0.4888 - auc: 0.5176 - val_loss: 1.1553 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7122\n",
      "Epoch 333/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.1567 - tp: 130.0000 - fp: 212.0000 - tn: 232.0000 - fn: 138.0000 - accuracy: 0.5084 - precision: 0.3801 - recall: 0.4851 - auc: 0.5104 - val_loss: 1.1552 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7271\n",
      "Epoch 334/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.1557 - tp: 129.0000 - fp: 201.0000 - tn: 243.0000 - fn: 139.0000 - accuracy: 0.5225 - precision: 0.3909 - recall: 0.4813 - auc: 0.5136 - val_loss: 1.1550 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7282\n",
      "Epoch 335/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1512 - tp: 143.0000 - fp: 200.0000 - tn: 244.0000 - fn: 125.0000 - accuracy: 0.5435 - precision: 0.4169 - recall: 0.5336 - auc: 0.5368 - val_loss: 1.1549 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7274\n",
      "Epoch 336/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.1628 - tp: 133.0000 - fp: 214.0000 - tn: 230.0000 - fn: 135.0000 - accuracy: 0.5098 - precision: 0.3833 - recall: 0.4963 - auc: 0.4898 - val_loss: 1.1548 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7268\n",
      "Epoch 337/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.1533 - tp: 133.0000 - fp: 204.0000 - tn: 240.0000 - fn: 135.0000 - accuracy: 0.5239 - precision: 0.3947 - recall: 0.4963 - auc: 0.5355 - val_loss: 1.1546 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7268\n",
      "Epoch 338/600\n",
      "712/712 [==============================] - 0s 153us/sample - loss: 1.1464 - tp: 132.0000 - fp: 205.0000 - tn: 239.0000 - fn: 136.0000 - accuracy: 0.5211 - precision: 0.3917 - recall: 0.4925 - auc: 0.5448 - val_loss: 1.1544 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7294\n",
      "Epoch 339/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1583 - tp: 125.0000 - fp: 204.0000 - tn: 240.0000 - fn: 143.0000 - accuracy: 0.5126 - precision: 0.3799 - recall: 0.4664 - auc: 0.4994 - val_loss: 1.1543 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7312\n",
      "Epoch 340/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1530 - tp: 122.0000 - fp: 195.0000 - tn: 249.0000 - fn: 146.0000 - accuracy: 0.5211 - precision: 0.3849 - recall: 0.4552 - auc: 0.5196 - val_loss: 1.1542 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7308\n",
      "Epoch 341/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.1588 - tp: 131.0000 - fp: 218.0000 - tn: 226.0000 - fn: 137.0000 - accuracy: 0.5014 - precision: 0.3754 - recall: 0.4888 - auc: 0.4913 - val_loss: 1.1541 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7312\n",
      "Epoch 342/600\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 1.1534 - tp: 125.0000 - fp: 211.0000 - tn: 233.0000 - fn: 143.0000 - accuracy: 0.5028 - precision: 0.3720 - recall: 0.4664 - auc: 0.5141 - val_loss: 1.1540 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7308\n",
      "Epoch 343/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.1423 - tp: 141.0000 - fp: 196.0000 - tn: 248.0000 - fn: 127.0000 - accuracy: 0.5463 - precision: 0.4184 - recall: 0.5261 - auc: 0.5712 - val_loss: 1.1538 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7308\n",
      "Epoch 344/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1562 - tp: 131.0000 - fp: 220.0000 - tn: 224.0000 - fn: 137.0000 - accuracy: 0.4986 - precision: 0.3732 - recall: 0.4888 - auc: 0.5040 - val_loss: 1.1537 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7312\n",
      "Epoch 345/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1672 - tp: 114.0000 - fp: 215.0000 - tn: 229.0000 - fn: 154.0000 - accuracy: 0.4817 - precision: 0.3465 - recall: 0.4254 - auc: 0.4582 - val_loss: 1.1536 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7308\n",
      "Epoch 346/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1565 - tp: 131.0000 - fp: 205.0000 - tn: 239.0000 - fn: 137.0000 - accuracy: 0.5197 - precision: 0.3899 - recall: 0.4888 - auc: 0.5152 - val_loss: 1.1534 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7308\n",
      "Epoch 347/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1535 - tp: 144.0000 - fp: 222.0000 - tn: 222.0000 - fn: 124.0000 - accuracy: 0.5140 - precision: 0.3934 - recall: 0.5373 - auc: 0.5231 - val_loss: 1.1533 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7308\n",
      "Epoch 348/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1599 - tp: 113.0000 - fp: 214.0000 - tn: 230.0000 - fn: 155.0000 - accuracy: 0.4817 - precision: 0.3456 - recall: 0.4216 - auc: 0.4746 - val_loss: 1.1532 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7281\n",
      "Epoch 349/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1623 - tp: 124.0000 - fp: 214.0000 - tn: 230.0000 - fn: 144.0000 - accuracy: 0.4972 - precision: 0.3669 - recall: 0.4627 - auc: 0.4813 - val_loss: 1.1531 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7149\n",
      "Epoch 350/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 1.1578 - tp: 121.0000 - fp: 200.0000 - tn: 244.0000 - fn: 147.0000 - accuracy: 0.5126 - precision: 0.3769 - recall: 0.4515 - auc: 0.5005 - val_loss: 1.1529 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7122\n",
      "Epoch 351/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1554 - tp: 129.0000 - fp: 211.0000 - tn: 233.0000 - fn: 139.0000 - accuracy: 0.5084 - precision: 0.3794 - recall: 0.4813 - auc: 0.5123 - val_loss: 1.1528 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7154\n",
      "Epoch 352/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.1507 - tp: 138.0000 - fp: 199.0000 - tn: 245.0000 - fn: 130.0000 - accuracy: 0.5379 - precision: 0.4095 - recall: 0.5149 - auc: 0.5271 - val_loss: 1.1526 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7154\n",
      "Epoch 353/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1499 - tp: 128.0000 - fp: 207.0000 - tn: 237.0000 - fn: 140.0000 - accuracy: 0.5126 - precision: 0.3821 - recall: 0.4776 - auc: 0.5290 - val_loss: 1.1525 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7154\n",
      "Epoch 354/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.1523 - tp: 129.0000 - fp: 198.0000 - tn: 246.0000 - fn: 139.0000 - accuracy: 0.5267 - precision: 0.3945 - recall: 0.4813 - auc: 0.5194 - val_loss: 1.1523 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7281\n",
      "Epoch 355/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 1.1525 - tp: 120.0000 - fp: 207.0000 - tn: 237.0000 - fn: 148.0000 - accuracy: 0.5014 - precision: 0.3670 - recall: 0.4478 - auc: 0.5030 - val_loss: 1.1521 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7305\n",
      "Epoch 356/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1618 - tp: 120.0000 - fp: 204.0000 - tn: 240.0000 - fn: 148.0000 - accuracy: 0.5056 - precision: 0.3704 - recall: 0.4478 - auc: 0.4869 - val_loss: 1.1520 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7317\n",
      "Epoch 357/600\n",
      "712/712 [==============================] - 0s 116us/sample - loss: 1.1553 - tp: 127.0000 - fp: 195.0000 - tn: 249.0000 - fn: 141.0000 - accuracy: 0.5281 - precision: 0.3944 - recall: 0.4739 - auc: 0.5081 - val_loss: 1.1519 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7310\n",
      "Epoch 358/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 1.1486 - tp: 131.0000 - fp: 189.0000 - tn: 255.0000 - fn: 137.0000 - accuracy: 0.5421 - precision: 0.4094 - recall: 0.4888 - auc: 0.5360 - val_loss: 1.1517 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7337\n",
      "Epoch 359/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1495 - tp: 130.0000 - fp: 197.0000 - tn: 247.0000 - fn: 138.0000 - accuracy: 0.5295 - precision: 0.3976 - recall: 0.4851 - auc: 0.5336 - val_loss: 1.1515 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7329\n",
      "Epoch 360/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1537 - tp: 134.0000 - fp: 226.0000 - tn: 218.0000 - fn: 134.0000 - accuracy: 0.4944 - precision: 0.3722 - recall: 0.5000 - auc: 0.5181 - val_loss: 1.1515 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7141\n",
      "Epoch 361/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1489 - tp: 128.0000 - fp: 182.0000 - tn: 262.0000 - fn: 140.0000 - accuracy: 0.5478 - precision: 0.4129 - recall: 0.4776 - auc: 0.5297 - val_loss: 1.1513 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7141\n",
      "Epoch 362/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1537 - tp: 135.0000 - fp: 187.0000 - tn: 257.0000 - fn: 133.0000 - accuracy: 0.5506 - precision: 0.4193 - recall: 0.5037 - auc: 0.5214 - val_loss: 1.1511 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7178\n",
      "Epoch 363/600\n",
      "712/712 [==============================] - 0s 150us/sample - loss: 1.1557 - tp: 125.0000 - fp: 202.0000 - tn: 242.0000 - fn: 143.0000 - accuracy: 0.5154 - precision: 0.3823 - recall: 0.4664 - auc: 0.5072 - val_loss: 1.1510 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7106\n",
      "Epoch 364/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1577 - tp: 128.0000 - fp: 223.0000 - tn: 221.0000 - fn: 140.0000 - accuracy: 0.4902 - precision: 0.3647 - recall: 0.4776 - auc: 0.4833 - val_loss: 1.1509 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7178\n",
      "Epoch 365/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1450 - tp: 143.0000 - fp: 203.0000 - tn: 241.0000 - fn: 125.0000 - accuracy: 0.5393 - precision: 0.4133 - recall: 0.5336 - auc: 0.5496 - val_loss: 1.1507 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7178\n",
      "Epoch 366/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1502 - tp: 130.0000 - fp: 217.0000 - tn: 227.0000 - fn: 138.0000 - accuracy: 0.5014 - precision: 0.3746 - recall: 0.4851 - auc: 0.5190 - val_loss: 1.1506 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7178\n",
      "Epoch 367/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1483 - tp: 134.0000 - fp: 197.0000 - tn: 247.0000 - fn: 134.0000 - accuracy: 0.5351 - precision: 0.4048 - recall: 0.5000 - auc: 0.5358 - val_loss: 1.1505 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7129\n",
      "Epoch 368/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1509 - tp: 128.0000 - fp: 211.0000 - tn: 233.0000 - fn: 140.0000 - accuracy: 0.5070 - precision: 0.3776 - recall: 0.4776 - auc: 0.5123 - val_loss: 1.1504 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7112\n",
      "Epoch 369/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1529 - tp: 123.0000 - fp: 190.0000 - tn: 254.0000 - fn: 145.0000 - accuracy: 0.5295 - precision: 0.3930 - recall: 0.4590 - auc: 0.5036 - val_loss: 1.1502 - val_tp: 43.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 31.0000 - val_accuracy: 0.6704 - val_precision: 0.6056 - val_recall: 0.5811 - val_auc: 0.7178\n",
      "Epoch 370/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1532 - tp: 127.0000 - fp: 205.0000 - tn: 239.0000 - fn: 141.0000 - accuracy: 0.5140 - precision: 0.3825 - recall: 0.4739 - auc: 0.5063 - val_loss: 1.1500 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7309\n",
      "Epoch 371/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1575 - tp: 128.0000 - fp: 215.0000 - tn: 229.0000 - fn: 140.0000 - accuracy: 0.5014 - precision: 0.3732 - recall: 0.4776 - auc: 0.5000 - val_loss: 1.1499 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7309\n",
      "Epoch 372/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1508 - tp: 130.0000 - fp: 213.0000 - tn: 231.0000 - fn: 138.0000 - accuracy: 0.5070 - precision: 0.3790 - recall: 0.4851 - auc: 0.5103 - val_loss: 1.1497 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7309\n",
      "Epoch 373/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1450 - tp: 141.0000 - fp: 211.0000 - tn: 233.0000 - fn: 127.0000 - accuracy: 0.5253 - precision: 0.4006 - recall: 0.5261 - auc: 0.5380 - val_loss: 1.1496 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7309\n",
      "Epoch 374/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1578 - tp: 127.0000 - fp: 213.0000 - tn: 231.0000 - fn: 141.0000 - accuracy: 0.5028 - precision: 0.3735 - recall: 0.4739 - auc: 0.4834 - val_loss: 1.1494 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7286\n",
      "Epoch 375/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1557 - tp: 126.0000 - fp: 220.0000 - tn: 224.0000 - fn: 142.0000 - accuracy: 0.4916 - precision: 0.3642 - recall: 0.4701 - auc: 0.4868 - val_loss: 1.1492 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7324\n",
      "Epoch 376/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1484 - tp: 129.0000 - fp: 192.0000 - tn: 252.0000 - fn: 139.0000 - accuracy: 0.5351 - precision: 0.4019 - recall: 0.4813 - auc: 0.5306 - val_loss: 1.1491 - val_tp: 43.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 31.0000 - val_accuracy: 0.6592 - val_precision: 0.5890 - val_recall: 0.5811 - val_auc: 0.7324\n",
      "Epoch 377/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1477 - tp: 122.0000 - fp: 182.0000 - tn: 262.0000 - fn: 146.0000 - accuracy: 0.5393 - precision: 0.4013 - recall: 0.4552 - auc: 0.5264 - val_loss: 1.1489 - val_tp: 43.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 31.0000 - val_accuracy: 0.6592 - val_precision: 0.5890 - val_recall: 0.5811 - val_auc: 0.7312\n",
      "Epoch 378/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1461 - tp: 141.0000 - fp: 217.0000 - tn: 227.0000 - fn: 127.0000 - accuracy: 0.5169 - precision: 0.3939 - recall: 0.5261 - auc: 0.5292 - val_loss: 1.1488 - val_tp: 43.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 31.0000 - val_accuracy: 0.6592 - val_precision: 0.5890 - val_recall: 0.5811 - val_auc: 0.7312\n",
      "Epoch 379/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1552 - tp: 134.0000 - fp: 210.0000 - tn: 234.0000 - fn: 134.0000 - accuracy: 0.5169 - precision: 0.3895 - recall: 0.5000 - auc: 0.4962 - val_loss: 1.1487 - val_tp: 43.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 31.0000 - val_accuracy: 0.6592 - val_precision: 0.5890 - val_recall: 0.5811 - val_auc: 0.7324\n",
      "Epoch 380/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.1431 - tp: 132.0000 - fp: 194.0000 - tn: 250.0000 - fn: 136.0000 - accuracy: 0.5365 - precision: 0.4049 - recall: 0.4925 - auc: 0.5397 - val_loss: 1.1485 - val_tp: 43.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 31.0000 - val_accuracy: 0.6592 - val_precision: 0.5890 - val_recall: 0.5811 - val_auc: 0.7312\n",
      "Epoch 381/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1491 - tp: 133.0000 - fp: 200.0000 - tn: 244.0000 - fn: 135.0000 - accuracy: 0.5295 - precision: 0.3994 - recall: 0.4963 - auc: 0.5235 - val_loss: 1.1484 - val_tp: 43.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 31.0000 - val_accuracy: 0.6592 - val_precision: 0.5890 - val_recall: 0.5811 - val_auc: 0.7312\n",
      "Epoch 382/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1547 - tp: 134.0000 - fp: 221.0000 - tn: 223.0000 - fn: 134.0000 - accuracy: 0.5014 - precision: 0.3775 - recall: 0.5000 - auc: 0.4945 - val_loss: 1.1483 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7324\n",
      "Epoch 383/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1482 - tp: 132.0000 - fp: 201.0000 - tn: 243.0000 - fn: 136.0000 - accuracy: 0.5267 - precision: 0.3964 - recall: 0.4925 - auc: 0.5232 - val_loss: 1.1482 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7324\n",
      "Epoch 384/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1572 - tp: 121.0000 - fp: 225.0000 - tn: 219.0000 - fn: 147.0000 - accuracy: 0.4775 - precision: 0.3497 - recall: 0.4515 - auc: 0.4747 - val_loss: 1.1481 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7324\n",
      "Epoch 385/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1476 - tp: 132.0000 - fp: 208.0000 - tn: 236.0000 - fn: 136.0000 - accuracy: 0.5169 - precision: 0.3882 - recall: 0.4925 - auc: 0.5140 - val_loss: 1.1479 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7324\n",
      "Epoch 386/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.1536 - tp: 120.0000 - fp: 220.0000 - tn: 224.0000 - fn: 148.0000 - accuracy: 0.4831 - precision: 0.3529 - recall: 0.4478 - auc: 0.4902 - val_loss: 1.1478 - val_tp: 43.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 31.0000 - val_accuracy: 0.6592 - val_precision: 0.5890 - val_recall: 0.5811 - val_auc: 0.7312\n",
      "Epoch 387/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1524 - tp: 126.0000 - fp: 208.0000 - tn: 236.0000 - fn: 142.0000 - accuracy: 0.5084 - precision: 0.3772 - recall: 0.4701 - auc: 0.5027 - val_loss: 1.1476 - val_tp: 43.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 31.0000 - val_accuracy: 0.6592 - val_precision: 0.5890 - val_recall: 0.5811 - val_auc: 0.7296\n",
      "Epoch 388/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.1530 - tp: 126.0000 - fp: 232.0000 - tn: 212.0000 - fn: 142.0000 - accuracy: 0.4747 - precision: 0.3520 - recall: 0.4701 - auc: 0.4875 - val_loss: 1.1475 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7338\n",
      "Epoch 389/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1479 - tp: 125.0000 - fp: 206.0000 - tn: 238.0000 - fn: 143.0000 - accuracy: 0.5098 - precision: 0.3776 - recall: 0.4664 - auc: 0.5151 - val_loss: 1.1474 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7324\n",
      "Epoch 390/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1471 - tp: 126.0000 - fp: 207.0000 - tn: 237.0000 - fn: 142.0000 - accuracy: 0.5098 - precision: 0.3784 - recall: 0.4701 - auc: 0.5183 - val_loss: 1.1473 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7338\n",
      "Epoch 391/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1455 - tp: 136.0000 - fp: 203.0000 - tn: 241.0000 - fn: 132.0000 - accuracy: 0.5295 - precision: 0.4012 - recall: 0.5075 - auc: 0.5325 - val_loss: 1.1471 - val_tp: 43.0000 - val_fp: 29.0000 - val_tn: 76.0000 - val_fn: 31.0000 - val_accuracy: 0.6648 - val_precision: 0.5972 - val_recall: 0.5811 - val_auc: 0.7338\n",
      "Epoch 392/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1446 - tp: 141.0000 - fp: 216.0000 - tn: 228.0000 - fn: 127.0000 - accuracy: 0.5183 - precision: 0.3950 - recall: 0.5261 - auc: 0.5296 - val_loss: 1.1469 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7323\n",
      "Epoch 393/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1498 - tp: 126.0000 - fp: 196.0000 - tn: 248.0000 - fn: 142.0000 - accuracy: 0.5253 - precision: 0.3913 - recall: 0.4701 - auc: 0.5142 - val_loss: 1.1468 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7317\n",
      "Epoch 394/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1552 - tp: 115.0000 - fp: 211.0000 - tn: 233.0000 - fn: 153.0000 - accuracy: 0.4888 - precision: 0.3528 - recall: 0.4291 - auc: 0.4772 - val_loss: 1.1466 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7310\n",
      "Epoch 395/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1464 - tp: 140.0000 - fp: 201.0000 - tn: 243.0000 - fn: 128.0000 - accuracy: 0.5379 - precision: 0.4106 - recall: 0.5224 - auc: 0.5206 - val_loss: 1.1465 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7310\n",
      "Epoch 396/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1380 - tp: 141.0000 - fp: 191.0000 - tn: 253.0000 - fn: 127.0000 - accuracy: 0.5534 - precision: 0.4247 - recall: 0.5261 - auc: 0.5685 - val_loss: 1.1464 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7310\n",
      "Epoch 397/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.1456 - tp: 139.0000 - fp: 218.0000 - tn: 226.0000 - fn: 129.0000 - accuracy: 0.5126 - precision: 0.3894 - recall: 0.5187 - auc: 0.5155 - val_loss: 1.1462 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7303\n",
      "Epoch 398/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1531 - tp: 132.0000 - fp: 215.0000 - tn: 229.0000 - fn: 136.0000 - accuracy: 0.5070 - precision: 0.3804 - recall: 0.4925 - auc: 0.4953 - val_loss: 1.1461 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7329\n",
      "Epoch 399/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1489 - tp: 118.0000 - fp: 195.0000 - tn: 249.0000 - fn: 150.0000 - accuracy: 0.5154 - precision: 0.3770 - recall: 0.4403 - auc: 0.5139 - val_loss: 1.1459 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7306\n",
      "Epoch 400/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1442 - tp: 136.0000 - fp: 213.0000 - tn: 231.0000 - fn: 132.0000 - accuracy: 0.5154 - precision: 0.3897 - recall: 0.5075 - auc: 0.5279 - val_loss: 1.1458 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7306\n",
      "Epoch 401/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1567 - tp: 126.0000 - fp: 227.0000 - tn: 217.0000 - fn: 142.0000 - accuracy: 0.4817 - precision: 0.3569 - recall: 0.4701 - auc: 0.4804 - val_loss: 1.1456 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7297\n",
      "Epoch 402/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1504 - tp: 124.0000 - fp: 211.0000 - tn: 233.0000 - fn: 144.0000 - accuracy: 0.5014 - precision: 0.3701 - recall: 0.4627 - auc: 0.4985 - val_loss: 1.1455 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7334\n",
      "Epoch 403/600\n",
      "712/712 [==============================] - 0s 118us/sample - loss: 1.1477 - tp: 134.0000 - fp: 211.0000 - tn: 233.0000 - fn: 134.0000 - accuracy: 0.5154 - precision: 0.3884 - recall: 0.5000 - auc: 0.5159 - val_loss: 1.1454 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7306\n",
      "Epoch 404/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.1438 - tp: 134.0000 - fp: 192.0000 - tn: 252.0000 - fn: 134.0000 - accuracy: 0.5421 - precision: 0.4110 - recall: 0.5000 - auc: 0.5395 - val_loss: 1.1453 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7297\n",
      "Epoch 405/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1400 - tp: 143.0000 - fp: 193.0000 - tn: 251.0000 - fn: 125.0000 - accuracy: 0.5534 - precision: 0.4256 - recall: 0.5336 - auc: 0.5440 - val_loss: 1.1451 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7336\n",
      "Epoch 406/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1473 - tp: 127.0000 - fp: 206.0000 - tn: 238.0000 - fn: 141.0000 - accuracy: 0.5126 - precision: 0.3814 - recall: 0.4739 - auc: 0.5089 - val_loss: 1.1450 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7306\n",
      "Epoch 407/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1519 - tp: 134.0000 - fp: 230.0000 - tn: 214.0000 - fn: 134.0000 - accuracy: 0.4888 - precision: 0.3681 - recall: 0.5000 - auc: 0.4934 - val_loss: 1.1449 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7344\n",
      "Epoch 408/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 1.1458 - tp: 130.0000 - fp: 208.0000 - tn: 236.0000 - fn: 138.0000 - accuracy: 0.5140 - precision: 0.3846 - recall: 0.4851 - auc: 0.5076 - val_loss: 1.1447 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7344\n",
      "Epoch 409/600\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 1.1533 - tp: 120.0000 - fp: 204.0000 - tn: 240.0000 - fn: 148.0000 - accuracy: 0.5056 - precision: 0.3704 - recall: 0.4478 - auc: 0.4862 - val_loss: 1.1446 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7328\n",
      "Epoch 410/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1424 - tp: 123.0000 - fp: 222.0000 - tn: 222.0000 - fn: 145.0000 - accuracy: 0.4846 - precision: 0.3565 - recall: 0.4590 - auc: 0.5197 - val_loss: 1.1445 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7328\n",
      "Epoch 411/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1457 - tp: 121.0000 - fp: 207.0000 - tn: 237.0000 - fn: 147.0000 - accuracy: 0.5028 - precision: 0.3689 - recall: 0.4515 - auc: 0.5088 - val_loss: 1.1444 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7334\n",
      "Epoch 412/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.1538 - tp: 123.0000 - fp: 235.0000 - tn: 209.0000 - fn: 145.0000 - accuracy: 0.4663 - precision: 0.3436 - recall: 0.4590 - auc: 0.4714 - val_loss: 1.1442 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7310\n",
      "Epoch 413/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1480 - tp: 133.0000 - fp: 221.0000 - tn: 223.0000 - fn: 135.0000 - accuracy: 0.5000 - precision: 0.3757 - recall: 0.4963 - auc: 0.4921 - val_loss: 1.1440 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7311\n",
      "Epoch 414/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1514 - tp: 127.0000 - fp: 223.0000 - tn: 221.0000 - fn: 141.0000 - accuracy: 0.4888 - precision: 0.3629 - recall: 0.4739 - auc: 0.4774 - val_loss: 1.1440 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7334\n",
      "Epoch 415/600\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 1.1400 - tp: 129.0000 - fp: 192.0000 - tn: 252.0000 - fn: 139.0000 - accuracy: 0.5351 - precision: 0.4019 - recall: 0.4813 - auc: 0.5335 - val_loss: 1.1438 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7314\n",
      "Epoch 416/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1460 - tp: 130.0000 - fp: 208.0000 - tn: 236.0000 - fn: 138.0000 - accuracy: 0.5140 - precision: 0.3846 - recall: 0.4851 - auc: 0.5209 - val_loss: 1.1437 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7311\n",
      "Epoch 417/600\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 1.1391 - tp: 147.0000 - fp: 211.0000 - tn: 233.0000 - fn: 121.0000 - accuracy: 0.5337 - precision: 0.4106 - recall: 0.5485 - auc: 0.5458 - val_loss: 1.1435 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7305\n",
      "Epoch 418/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.1463 - tp: 133.0000 - fp: 222.0000 - tn: 222.0000 - fn: 135.0000 - accuracy: 0.4986 - precision: 0.3746 - recall: 0.4963 - auc: 0.5056 - val_loss: 1.1434 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7344\n",
      "Epoch 419/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1454 - tp: 130.0000 - fp: 212.0000 - tn: 232.0000 - fn: 138.0000 - accuracy: 0.5084 - precision: 0.3801 - recall: 0.4851 - auc: 0.5132 - val_loss: 1.1433 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7305\n",
      "Epoch 420/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1472 - tp: 132.0000 - fp: 205.0000 - tn: 239.0000 - fn: 136.0000 - accuracy: 0.5211 - precision: 0.3917 - recall: 0.4925 - auc: 0.5056 - val_loss: 1.1432 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7336\n",
      "Epoch 421/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 1.1466 - tp: 133.0000 - fp: 216.0000 - tn: 228.0000 - fn: 135.0000 - accuracy: 0.5070 - precision: 0.3811 - recall: 0.4963 - auc: 0.5011 - val_loss: 1.1430 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7371\n",
      "Epoch 422/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1434 - tp: 139.0000 - fp: 195.0000 - tn: 249.0000 - fn: 129.0000 - accuracy: 0.5449 - precision: 0.4162 - recall: 0.5187 - auc: 0.5271 - val_loss: 1.1429 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7336\n",
      "Epoch 423/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1407 - tp: 139.0000 - fp: 212.0000 - tn: 232.0000 - fn: 129.0000 - accuracy: 0.5211 - precision: 0.3960 - recall: 0.5187 - auc: 0.5249 - val_loss: 1.1427 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7356\n",
      "Epoch 424/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.1411 - tp: 136.0000 - fp: 211.0000 - tn: 233.0000 - fn: 132.0000 - accuracy: 0.5183 - precision: 0.3919 - recall: 0.5075 - auc: 0.5252 - val_loss: 1.1426 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7344\n",
      "Epoch 425/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1404 - tp: 136.0000 - fp: 213.0000 - tn: 231.0000 - fn: 132.0000 - accuracy: 0.5154 - precision: 0.3897 - recall: 0.5075 - auc: 0.5279 - val_loss: 1.1424 - val_tp: 44.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 30.0000 - val_accuracy: 0.6536 - val_precision: 0.5789 - val_recall: 0.5946 - val_auc: 0.7328\n",
      "Epoch 426/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1400 - tp: 139.0000 - fp: 209.0000 - tn: 235.0000 - fn: 129.0000 - accuracy: 0.5253 - precision: 0.3994 - recall: 0.5187 - auc: 0.5386 - val_loss: 1.1423 - val_tp: 44.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 30.0000 - val_accuracy: 0.6536 - val_precision: 0.5789 - val_recall: 0.5946 - val_auc: 0.7328\n",
      "Epoch 427/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1394 - tp: 136.0000 - fp: 203.0000 - tn: 241.0000 - fn: 132.0000 - accuracy: 0.5295 - precision: 0.4012 - recall: 0.5075 - auc: 0.5264 - val_loss: 1.1422 - val_tp: 44.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 30.0000 - val_accuracy: 0.6536 - val_precision: 0.5789 - val_recall: 0.5946 - val_auc: 0.7318\n",
      "Epoch 428/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1497 - tp: 125.0000 - fp: 202.0000 - tn: 242.0000 - fn: 143.0000 - accuracy: 0.5154 - precision: 0.3823 - recall: 0.4664 - auc: 0.4971 - val_loss: 1.1421 - val_tp: 44.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 30.0000 - val_accuracy: 0.6536 - val_precision: 0.5789 - val_recall: 0.5946 - val_auc: 0.7328\n",
      "Epoch 429/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1325 - tp: 135.0000 - fp: 197.0000 - tn: 247.0000 - fn: 133.0000 - accuracy: 0.5365 - precision: 0.4066 - recall: 0.5037 - auc: 0.5638 - val_loss: 1.1419 - val_tp: 44.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 30.0000 - val_accuracy: 0.6536 - val_precision: 0.5789 - val_recall: 0.5946 - val_auc: 0.7325\n",
      "Epoch 430/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1348 - tp: 138.0000 - fp: 191.0000 - tn: 253.0000 - fn: 130.0000 - accuracy: 0.5492 - precision: 0.4195 - recall: 0.5149 - auc: 0.5653 - val_loss: 1.1418 - val_tp: 44.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 30.0000 - val_accuracy: 0.6536 - val_precision: 0.5789 - val_recall: 0.5946 - val_auc: 0.7387\n",
      "Epoch 431/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1458 - tp: 136.0000 - fp: 223.0000 - tn: 221.0000 - fn: 132.0000 - accuracy: 0.5014 - precision: 0.3788 - recall: 0.5075 - auc: 0.5011 - val_loss: 1.1416 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7374\n",
      "Epoch 432/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1402 - tp: 134.0000 - fp: 200.0000 - tn: 244.0000 - fn: 134.0000 - accuracy: 0.5309 - precision: 0.4012 - recall: 0.5000 - auc: 0.5191 - val_loss: 1.1415 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7400\n",
      "Epoch 433/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1350 - tp: 143.0000 - fp: 216.0000 - tn: 228.0000 - fn: 125.0000 - accuracy: 0.5211 - precision: 0.3983 - recall: 0.5336 - auc: 0.5415 - val_loss: 1.1413 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7420\n",
      "Epoch 434/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1377 - tp: 145.0000 - fp: 208.0000 - tn: 236.0000 - fn: 123.0000 - accuracy: 0.5351 - precision: 0.4108 - recall: 0.5410 - auc: 0.5456 - val_loss: 1.1411 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7420\n",
      "Epoch 435/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1396 - tp: 133.0000 - fp: 203.0000 - tn: 241.0000 - fn: 135.0000 - accuracy: 0.5253 - precision: 0.3958 - recall: 0.4963 - auc: 0.5274 - val_loss: 1.1409 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7405\n",
      "Epoch 436/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1437 - tp: 124.0000 - fp: 203.0000 - tn: 241.0000 - fn: 144.0000 - accuracy: 0.5126 - precision: 0.3792 - recall: 0.4627 - auc: 0.5116 - val_loss: 1.1408 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7420\n",
      "Epoch 437/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 1.1402 - tp: 121.0000 - fp: 204.0000 - tn: 240.0000 - fn: 147.0000 - accuracy: 0.5070 - precision: 0.3723 - recall: 0.4515 - auc: 0.5200 - val_loss: 1.1407 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7439\n",
      "Epoch 438/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1339 - tp: 148.0000 - fp: 207.0000 - tn: 237.0000 - fn: 120.0000 - accuracy: 0.5407 - precision: 0.4169 - recall: 0.5522 - auc: 0.5552 - val_loss: 1.1405 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7402\n",
      "Epoch 439/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.1453 - tp: 129.0000 - fp: 203.0000 - tn: 241.0000 - fn: 139.0000 - accuracy: 0.5197 - precision: 0.3886 - recall: 0.4813 - auc: 0.5033 - val_loss: 1.1404 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7402\n",
      "Epoch 440/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1377 - tp: 134.0000 - fp: 223.0000 - tn: 221.0000 - fn: 134.0000 - accuracy: 0.4986 - precision: 0.3754 - recall: 0.5000 - auc: 0.5302 - val_loss: 1.1403 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7402\n",
      "Epoch 441/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 1.1401 - tp: 151.0000 - fp: 213.0000 - tn: 231.0000 - fn: 117.0000 - accuracy: 0.5365 - precision: 0.4148 - recall: 0.5634 - auc: 0.5344 - val_loss: 1.1402 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7402\n",
      "Epoch 442/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1446 - tp: 145.0000 - fp: 225.0000 - tn: 219.0000 - fn: 123.0000 - accuracy: 0.5112 - precision: 0.3919 - recall: 0.5410 - auc: 0.5150 - val_loss: 1.1400 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7402\n",
      "Epoch 443/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1415 - tp: 128.0000 - fp: 203.0000 - tn: 241.0000 - fn: 140.0000 - accuracy: 0.5183 - precision: 0.3867 - recall: 0.4776 - auc: 0.5158 - val_loss: 1.1399 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7420\n",
      "Epoch 444/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1378 - tp: 142.0000 - fp: 204.0000 - tn: 240.0000 - fn: 126.0000 - accuracy: 0.5365 - precision: 0.4104 - recall: 0.5299 - auc: 0.5295 - val_loss: 1.1398 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7400\n",
      "Epoch 445/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.1295 - tp: 151.0000 - fp: 204.0000 - tn: 240.0000 - fn: 117.0000 - accuracy: 0.5492 - precision: 0.4254 - recall: 0.5634 - auc: 0.5669 - val_loss: 1.1397 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7400\n",
      "Epoch 446/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1417 - tp: 143.0000 - fp: 216.0000 - tn: 228.0000 - fn: 125.0000 - accuracy: 0.5211 - precision: 0.3983 - recall: 0.5336 - auc: 0.5219 - val_loss: 1.1396 - val_tp: 44.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 30.0000 - val_accuracy: 0.6536 - val_precision: 0.5789 - val_recall: 0.5946 - val_auc: 0.7390\n",
      "Epoch 447/600\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 1.1399 - tp: 127.0000 - fp: 209.0000 - tn: 235.0000 - fn: 141.0000 - accuracy: 0.5084 - precision: 0.3780 - recall: 0.4739 - auc: 0.5093 - val_loss: 1.1395 - val_tp: 45.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 29.0000 - val_accuracy: 0.6592 - val_precision: 0.5844 - val_recall: 0.6081 - val_auc: 0.7390\n",
      "Epoch 448/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1383 - tp: 123.0000 - fp: 201.0000 - tn: 243.0000 - fn: 145.0000 - accuracy: 0.5140 - precision: 0.3796 - recall: 0.4590 - auc: 0.5104 - val_loss: 1.1393 - val_tp: 44.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 30.0000 - val_accuracy: 0.6536 - val_precision: 0.5789 - val_recall: 0.5946 - val_auc: 0.7390\n",
      "Epoch 449/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1360 - tp: 132.0000 - fp: 208.0000 - tn: 236.0000 - fn: 136.0000 - accuracy: 0.5169 - precision: 0.3882 - recall: 0.4925 - auc: 0.5322 - val_loss: 1.1392 - val_tp: 44.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 30.0000 - val_accuracy: 0.6536 - val_precision: 0.5789 - val_recall: 0.5946 - val_auc: 0.7395\n",
      "Epoch 450/600\n",
      "712/712 [==============================] - 0s 115us/sample - loss: 1.1388 - tp: 129.0000 - fp: 194.0000 - tn: 250.0000 - fn: 139.0000 - accuracy: 0.5323 - precision: 0.3994 - recall: 0.4813 - auc: 0.5223 - val_loss: 1.1391 - val_tp: 44.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 30.0000 - val_accuracy: 0.6536 - val_precision: 0.5789 - val_recall: 0.5946 - val_auc: 0.7360\n",
      "Epoch 451/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1466 - tp: 126.0000 - fp: 198.0000 - tn: 246.0000 - fn: 142.0000 - accuracy: 0.5225 - precision: 0.3889 - recall: 0.4701 - auc: 0.4987 - val_loss: 1.1390 - val_tp: 44.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 30.0000 - val_accuracy: 0.6536 - val_precision: 0.5789 - val_recall: 0.5946 - val_auc: 0.7360\n",
      "Epoch 452/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1376 - tp: 129.0000 - fp: 208.0000 - tn: 236.0000 - fn: 139.0000 - accuracy: 0.5126 - precision: 0.3828 - recall: 0.4813 - auc: 0.5252 - val_loss: 1.1388 - val_tp: 44.0000 - val_fp: 32.0000 - val_tn: 73.0000 - val_fn: 30.0000 - val_accuracy: 0.6536 - val_precision: 0.5789 - val_recall: 0.5946 - val_auc: 0.7385\n",
      "Epoch 453/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 1.1326 - tp: 136.0000 - fp: 199.0000 - tn: 245.0000 - fn: 132.0000 - accuracy: 0.5351 - precision: 0.4060 - recall: 0.5075 - auc: 0.5473 - val_loss: 1.1387 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7369\n",
      "Epoch 454/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1467 - tp: 121.0000 - fp: 194.0000 - tn: 250.0000 - fn: 147.0000 - accuracy: 0.5211 - precision: 0.3841 - recall: 0.4515 - auc: 0.4901 - val_loss: 1.1386 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7404\n",
      "Epoch 455/600\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 1.1309 - tp: 151.0000 - fp: 198.0000 - tn: 246.0000 - fn: 117.0000 - accuracy: 0.5576 - precision: 0.4327 - recall: 0.5634 - auc: 0.5573 - val_loss: 1.1385 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7377\n",
      "Epoch 456/600\n",
      "712/712 [==============================] - 0s 146us/sample - loss: 1.1410 - tp: 132.0000 - fp: 210.0000 - tn: 234.0000 - fn: 136.0000 - accuracy: 0.5140 - precision: 0.3860 - recall: 0.4925 - auc: 0.5120 - val_loss: 1.1384 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7412\n",
      "Epoch 457/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1433 - tp: 134.0000 - fp: 201.0000 - tn: 243.0000 - fn: 134.0000 - accuracy: 0.5295 - precision: 0.4000 - recall: 0.5000 - auc: 0.5127 - val_loss: 1.1383 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7396\n",
      "Epoch 458/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 1.1417 - tp: 133.0000 - fp: 225.0000 - tn: 219.0000 - fn: 135.0000 - accuracy: 0.4944 - precision: 0.3715 - recall: 0.4963 - auc: 0.5087 - val_loss: 1.1382 - val_tp: 44.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 30.0000 - val_accuracy: 0.6648 - val_precision: 0.5946 - val_recall: 0.5946 - val_auc: 0.7349\n",
      "Epoch 459/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.1370 - tp: 131.0000 - fp: 201.0000 - tn: 243.0000 - fn: 137.0000 - accuracy: 0.5253 - precision: 0.3946 - recall: 0.4888 - auc: 0.5194 - val_loss: 1.1381 - val_tp: 44.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 30.0000 - val_accuracy: 0.6648 - val_precision: 0.5946 - val_recall: 0.5946 - val_auc: 0.7326\n",
      "Epoch 460/600\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 1.1322 - tp: 144.0000 - fp: 187.0000 - tn: 257.0000 - fn: 124.0000 - accuracy: 0.5632 - precision: 0.4350 - recall: 0.5373 - auc: 0.5544 - val_loss: 1.1379 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7357\n",
      "Epoch 461/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1339 - tp: 129.0000 - fp: 210.0000 - tn: 234.0000 - fn: 139.0000 - accuracy: 0.5098 - precision: 0.3805 - recall: 0.4813 - auc: 0.5294 - val_loss: 1.1378 - val_tp: 44.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 30.0000 - val_accuracy: 0.6648 - val_precision: 0.5946 - val_recall: 0.5946 - val_auc: 0.7310\n",
      "Epoch 462/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1372 - tp: 138.0000 - fp: 222.0000 - tn: 222.0000 - fn: 130.0000 - accuracy: 0.5056 - precision: 0.3833 - recall: 0.5149 - auc: 0.5198 - val_loss: 1.1376 - val_tp: 44.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 30.0000 - val_accuracy: 0.6648 - val_precision: 0.5946 - val_recall: 0.5946 - val_auc: 0.7349\n",
      "Epoch 463/600\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 1.1391 - tp: 126.0000 - fp: 210.0000 - tn: 234.0000 - fn: 142.0000 - accuracy: 0.5056 - precision: 0.3750 - recall: 0.4701 - auc: 0.5145 - val_loss: 1.1375 - val_tp: 44.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 30.0000 - val_accuracy: 0.6648 - val_precision: 0.5946 - val_recall: 0.5946 - val_auc: 0.7366\n",
      "Epoch 464/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1443 - tp: 118.0000 - fp: 220.0000 - tn: 224.0000 - fn: 150.0000 - accuracy: 0.4803 - precision: 0.3491 - recall: 0.4403 - auc: 0.4786 - val_loss: 1.1374 - val_tp: 44.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 30.0000 - val_accuracy: 0.6648 - val_precision: 0.5946 - val_recall: 0.5946 - val_auc: 0.7366\n",
      "Epoch 465/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 1.1363 - tp: 128.0000 - fp: 192.0000 - tn: 252.0000 - fn: 140.0000 - accuracy: 0.5337 - precision: 0.4000 - recall: 0.4776 - auc: 0.5259 - val_loss: 1.1373 - val_tp: 44.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 30.0000 - val_accuracy: 0.6648 - val_precision: 0.5946 - val_recall: 0.5946 - val_auc: 0.7360\n",
      "Epoch 466/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1510 - tp: 108.0000 - fp: 201.0000 - tn: 243.0000 - fn: 160.0000 - accuracy: 0.4930 - precision: 0.3495 - recall: 0.4030 - auc: 0.4615 - val_loss: 1.1372 - val_tp: 44.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 30.0000 - val_accuracy: 0.6648 - val_precision: 0.5946 - val_recall: 0.5946 - val_auc: 0.7382\n",
      "Epoch 467/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1314 - tp: 124.0000 - fp: 188.0000 - tn: 256.0000 - fn: 144.0000 - accuracy: 0.5337 - precision: 0.3974 - recall: 0.4627 - auc: 0.5374 - val_loss: 1.1371 - val_tp: 44.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 30.0000 - val_accuracy: 0.6648 - val_precision: 0.5946 - val_recall: 0.5946 - val_auc: 0.7382\n",
      "Epoch 468/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 1.1401 - tp: 139.0000 - fp: 222.0000 - tn: 222.0000 - fn: 129.0000 - accuracy: 0.5070 - precision: 0.3850 - recall: 0.5187 - auc: 0.5129 - val_loss: 1.1369 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7394\n",
      "Epoch 469/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 1.1336 - tp: 127.0000 - fp: 193.0000 - tn: 251.0000 - fn: 141.0000 - accuracy: 0.5309 - precision: 0.3969 - recall: 0.4739 - auc: 0.5319 - val_loss: 1.1368 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7389\n",
      "Epoch 470/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.1296 - tp: 151.0000 - fp: 201.0000 - tn: 243.0000 - fn: 117.0000 - accuracy: 0.5534 - precision: 0.4290 - recall: 0.5634 - auc: 0.5536 - val_loss: 1.1367 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7394\n",
      "Epoch 471/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1369 - tp: 127.0000 - fp: 203.0000 - tn: 241.0000 - fn: 141.0000 - accuracy: 0.5169 - precision: 0.3848 - recall: 0.4739 - auc: 0.5149 - val_loss: 1.1365 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7394\n",
      "Epoch 472/600\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 1.1423 - tp: 120.0000 - fp: 205.0000 - tn: 239.0000 - fn: 148.0000 - accuracy: 0.5042 - precision: 0.3692 - recall: 0.4478 - auc: 0.4914 - val_loss: 1.1364 - val_tp: 44.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 30.0000 - val_accuracy: 0.6648 - val_precision: 0.5946 - val_recall: 0.5946 - val_auc: 0.7376\n",
      "Epoch 473/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1345 - tp: 125.0000 - fp: 191.0000 - tn: 253.0000 - fn: 143.0000 - accuracy: 0.5309 - precision: 0.3956 - recall: 0.4664 - auc: 0.5333 - val_loss: 1.1363 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7394\n",
      "Epoch 474/600\n",
      "712/712 [==============================] - 0s 120us/sample - loss: 1.1347 - tp: 126.0000 - fp: 187.0000 - tn: 257.0000 - fn: 142.0000 - accuracy: 0.5379 - precision: 0.4026 - recall: 0.4701 - auc: 0.5302 - val_loss: 1.1361 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7401\n",
      "Epoch 475/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1357 - tp: 119.0000 - fp: 211.0000 - tn: 233.0000 - fn: 149.0000 - accuracy: 0.4944 - precision: 0.3606 - recall: 0.4440 - auc: 0.5119 - val_loss: 1.1360 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7389\n",
      "Epoch 476/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1335 - tp: 121.0000 - fp: 210.0000 - tn: 234.0000 - fn: 147.0000 - accuracy: 0.4986 - precision: 0.3656 - recall: 0.4515 - auc: 0.5112 - val_loss: 1.1359 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7382\n",
      "Epoch 477/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1371 - tp: 131.0000 - fp: 215.0000 - tn: 229.0000 - fn: 137.0000 - accuracy: 0.5056 - precision: 0.3786 - recall: 0.4888 - auc: 0.5121 - val_loss: 1.1357 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7381\n",
      "Epoch 478/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1352 - tp: 119.0000 - fp: 204.0000 - tn: 240.0000 - fn: 149.0000 - accuracy: 0.5042 - precision: 0.3684 - recall: 0.4440 - auc: 0.5112 - val_loss: 1.1355 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7414\n",
      "Epoch 479/600\n",
      "712/712 [==============================] - 0s 121us/sample - loss: 1.1295 - tp: 140.0000 - fp: 210.0000 - tn: 234.0000 - fn: 128.0000 - accuracy: 0.5253 - precision: 0.4000 - recall: 0.5224 - auc: 0.5559 - val_loss: 1.1354 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7394\n",
      "Epoch 480/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1372 - tp: 134.0000 - fp: 204.0000 - tn: 240.0000 - fn: 134.0000 - accuracy: 0.5253 - precision: 0.3964 - recall: 0.5000 - auc: 0.5209 - val_loss: 1.1353 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7431\n",
      "Epoch 481/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1330 - tp: 135.0000 - fp: 203.0000 - tn: 241.0000 - fn: 133.0000 - accuracy: 0.5281 - precision: 0.3994 - recall: 0.5037 - auc: 0.5207 - val_loss: 1.1352 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7431\n",
      "Epoch 482/600\n",
      "712/712 [==============================] - 0s 122us/sample - loss: 1.1371 - tp: 134.0000 - fp: 212.0000 - tn: 232.0000 - fn: 134.0000 - accuracy: 0.5140 - precision: 0.3873 - recall: 0.5000 - auc: 0.5017 - val_loss: 1.1351 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7404\n",
      "Epoch 483/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1320 - tp: 130.0000 - fp: 194.0000 - tn: 250.0000 - fn: 138.0000 - accuracy: 0.5337 - precision: 0.4012 - recall: 0.4851 - auc: 0.5361 - val_loss: 1.1349 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7404\n",
      "Epoch 484/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1328 - tp: 138.0000 - fp: 201.0000 - tn: 243.0000 - fn: 130.0000 - accuracy: 0.5351 - precision: 0.4071 - recall: 0.5149 - auc: 0.5335 - val_loss: 1.1348 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7391\n",
      "Epoch 485/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1357 - tp: 134.0000 - fp: 208.0000 - tn: 236.0000 - fn: 134.0000 - accuracy: 0.5197 - precision: 0.3918 - recall: 0.5000 - auc: 0.5239 - val_loss: 1.1347 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7389\n",
      "Epoch 486/600\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 1.1351 - tp: 143.0000 - fp: 207.0000 - tn: 237.0000 - fn: 125.0000 - accuracy: 0.5337 - precision: 0.4086 - recall: 0.5336 - auc: 0.5324 - val_loss: 1.1346 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7394\n",
      "Epoch 487/600\n",
      "712/712 [==============================] - 0s 123us/sample - loss: 1.1366 - tp: 129.0000 - fp: 208.0000 - tn: 236.0000 - fn: 139.0000 - accuracy: 0.5126 - precision: 0.3828 - recall: 0.4813 - auc: 0.5167 - val_loss: 1.1345 - val_tp: 44.0000 - val_fp: 31.0000 - val_tn: 74.0000 - val_fn: 30.0000 - val_accuracy: 0.6592 - val_precision: 0.5867 - val_recall: 0.5946 - val_auc: 0.7389\n",
      "Epoch 488/600\n",
      "712/712 [==============================] - 0s 124us/sample - loss: 1.1402 - tp: 121.0000 - fp: 214.0000 - tn: 230.0000 - fn: 147.0000 - accuracy: 0.4930 - precision: 0.3612 - recall: 0.4515 - auc: 0.4957 - val_loss: 1.1344 - val_tp: 44.0000 - val_fp: 30.0000 - val_tn: 75.0000 - val_fn: 30.0000 - val_accuracy: 0.6648 - val_precision: 0.5946 - val_recall: 0.5946 - val_auc: 0.7379\n",
      "Epoch 489/600\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/700\n",
      "712/712 [==============================] - 3s 5ms/sample - loss: 1.5518 - tp: 182.0000 - fp: 277.0000 - tn: 167.0000 - fn: 86.0000 - accuracy: 0.4902 - precision: 0.3965 - recall: 0.6791 - auc: 0.5158 - val_loss: 1.5495 - val_tp: 72.0000 - val_fp: 104.0000 - val_tn: 1.0000 - val_fn: 2.0000 - val_accuracy: 0.4078 - val_precision: 0.4091 - val_recall: 0.9730 - val_auc: 0.4023\n",
      "Epoch 2/700\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.5598 - tp: 175.0000 - fp: 307.0000 - tn: 137.0000 - fn: 93.0000 - accuracy: 0.4382 - precision: 0.3631 - recall: 0.6530 - auc: 0.4755 - val_loss: 1.5485 - val_tp: 72.0000 - val_fp: 102.0000 - val_tn: 3.0000 - val_fn: 2.0000 - val_accuracy: 0.4190 - val_precision: 0.4138 - val_recall: 0.9730 - val_auc: 0.4028\n",
      "Epoch 3/700\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.5597 - tp: 158.0000 - fp: 282.0000 - tn: 162.0000 - fn: 110.0000 - accuracy: 0.4494 - precision: 0.3591 - recall: 0.5896 - auc: 0.4762 - val_loss: 1.5476 - val_tp: 72.0000 - val_fp: 102.0000 - val_tn: 3.0000 - val_fn: 2.0000 - val_accuracy: 0.4190 - val_precision: 0.4138 - val_recall: 0.9730 - val_auc: 0.3936\n",
      "Epoch 4/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 1.5570 - tp: 175.0000 - fp: 288.0000 - tn: 156.0000 - fn: 93.0000 - accuracy: 0.4649 - precision: 0.3780 - recall: 0.6530 - auc: 0.4819 - val_loss: 1.5467 - val_tp: 72.0000 - val_fp: 102.0000 - val_tn: 3.0000 - val_fn: 2.0000 - val_accuracy: 0.4190 - val_precision: 0.4138 - val_recall: 0.9730 - val_auc: 0.3998\n",
      "Epoch 5/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.5498 - tp: 169.0000 - fp: 287.0000 - tn: 157.0000 - fn: 99.0000 - accuracy: 0.4579 - precision: 0.3706 - recall: 0.6306 - auc: 0.5018 - val_loss: 1.5457 - val_tp: 72.0000 - val_fp: 102.0000 - val_tn: 3.0000 - val_fn: 2.0000 - val_accuracy: 0.4190 - val_precision: 0.4138 - val_recall: 0.9730 - val_auc: 0.4286\n",
      "Epoch 6/700\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.5499 - tp: 170.0000 - fp: 292.0000 - tn: 152.0000 - fn: 98.0000 - accuracy: 0.4522 - precision: 0.3680 - recall: 0.6343 - auc: 0.4965 - val_loss: 1.5447 - val_tp: 72.0000 - val_fp: 102.0000 - val_tn: 3.0000 - val_fn: 2.0000 - val_accuracy: 0.4190 - val_precision: 0.4138 - val_recall: 0.9730 - val_auc: 0.4275\n",
      "Epoch 7/700\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.5374 - tp: 180.0000 - fp: 285.0000 - tn: 159.0000 - fn: 88.0000 - accuracy: 0.4761 - precision: 0.3871 - recall: 0.6716 - auc: 0.5344 - val_loss: 1.5437 - val_tp: 72.0000 - val_fp: 102.0000 - val_tn: 3.0000 - val_fn: 2.0000 - val_accuracy: 0.4190 - val_precision: 0.4138 - val_recall: 0.9730 - val_auc: 0.4270\n",
      "Epoch 8/700\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.5453 - tp: 159.0000 - fp: 272.0000 - tn: 172.0000 - fn: 109.0000 - accuracy: 0.4649 - precision: 0.3689 - recall: 0.5933 - auc: 0.5048 - val_loss: 1.5427 - val_tp: 72.0000 - val_fp: 102.0000 - val_tn: 3.0000 - val_fn: 2.0000 - val_accuracy: 0.4190 - val_precision: 0.4138 - val_recall: 0.9730 - val_auc: 0.4229\n",
      "Epoch 9/700\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.5499 - tp: 156.0000 - fp: 265.0000 - tn: 179.0000 - fn: 112.0000 - accuracy: 0.4705 - precision: 0.3705 - recall: 0.5821 - auc: 0.4825 - val_loss: 1.5416 - val_tp: 71.0000 - val_fp: 100.0000 - val_tn: 5.0000 - val_fn: 3.0000 - val_accuracy: 0.4246 - val_precision: 0.4152 - val_recall: 0.9595 - val_auc: 0.4418\n",
      "Epoch 10/700\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.5454 - tp: 161.0000 - fp: 277.0000 - tn: 167.0000 - fn: 107.0000 - accuracy: 0.4607 - precision: 0.3676 - recall: 0.6007 - auc: 0.4961 - val_loss: 1.5407 - val_tp: 71.0000 - val_fp: 100.0000 - val_tn: 5.0000 - val_fn: 3.0000 - val_accuracy: 0.4246 - val_precision: 0.4152 - val_recall: 0.9595 - val_auc: 0.4421\n",
      "Epoch 11/700\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.5370 - tp: 167.0000 - fp: 269.0000 - tn: 175.0000 - fn: 101.0000 - accuracy: 0.4803 - precision: 0.3830 - recall: 0.6231 - auc: 0.5222 - val_loss: 1.5397 - val_tp: 71.0000 - val_fp: 100.0000 - val_tn: 5.0000 - val_fn: 3.0000 - val_accuracy: 0.4246 - val_precision: 0.4152 - val_recall: 0.9595 - val_auc: 0.4476\n",
      "Epoch 12/700\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.5373 - tp: 171.0000 - fp: 266.0000 - tn: 178.0000 - fn: 97.0000 - accuracy: 0.4902 - precision: 0.3913 - recall: 0.6381 - auc: 0.5210 - val_loss: 1.5387 - val_tp: 71.0000 - val_fp: 100.0000 - val_tn: 5.0000 - val_fn: 3.0000 - val_accuracy: 0.4246 - val_precision: 0.4152 - val_recall: 0.9595 - val_auc: 0.4450\n",
      "Epoch 13/700\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.5489 - tp: 160.0000 - fp: 296.0000 - tn: 148.0000 - fn: 108.0000 - accuracy: 0.4326 - precision: 0.3509 - recall: 0.5970 - auc: 0.4763 - val_loss: 1.5377 - val_tp: 65.0000 - val_fp: 100.0000 - val_tn: 5.0000 - val_fn: 9.0000 - val_accuracy: 0.3911 - val_precision: 0.3939 - val_recall: 0.8784 - val_auc: 0.4512\n",
      "Epoch 14/700\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.5404 - tp: 166.0000 - fp: 280.0000 - tn: 164.0000 - fn: 102.0000 - accuracy: 0.4635 - precision: 0.3722 - recall: 0.6194 - auc: 0.5086 - val_loss: 1.5367 - val_tp: 65.0000 - val_fp: 100.0000 - val_tn: 5.0000 - val_fn: 9.0000 - val_accuracy: 0.3911 - val_precision: 0.3939 - val_recall: 0.8784 - val_auc: 0.4566\n",
      "Epoch 15/700\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.5351 - tp: 166.0000 - fp: 268.0000 - tn: 176.0000 - fn: 102.0000 - accuracy: 0.4803 - precision: 0.3825 - recall: 0.6194 - auc: 0.5081 - val_loss: 1.5357 - val_tp: 64.0000 - val_fp: 100.0000 - val_tn: 5.0000 - val_fn: 10.0000 - val_accuracy: 0.3855 - val_precision: 0.3902 - val_recall: 0.8649 - val_auc: 0.4818\n",
      "Epoch 16/700\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.5421 - tp: 160.0000 - fp: 268.0000 - tn: 176.0000 - fn: 108.0000 - accuracy: 0.4719 - precision: 0.3738 - recall: 0.5970 - auc: 0.4865 - val_loss: 1.5347 - val_tp: 63.0000 - val_fp: 100.0000 - val_tn: 5.0000 - val_fn: 11.0000 - val_accuracy: 0.3799 - val_precision: 0.3865 - val_recall: 0.8514 - val_auc: 0.4795\n",
      "Epoch 17/700\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.5363 - tp: 166.0000 - fp: 274.0000 - tn: 170.0000 - fn: 102.0000 - accuracy: 0.4719 - precision: 0.3773 - recall: 0.6194 - auc: 0.5029 - val_loss: 1.5337 - val_tp: 62.0000 - val_fp: 100.0000 - val_tn: 5.0000 - val_fn: 12.0000 - val_accuracy: 0.3743 - val_precision: 0.3827 - val_recall: 0.8378 - val_auc: 0.4697\n",
      "Epoch 18/700\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 1.5330 - tp: 165.0000 - fp: 262.0000 - tn: 182.0000 - fn: 103.0000 - accuracy: 0.4874 - precision: 0.3864 - recall: 0.6157 - auc: 0.5156 - val_loss: 1.5327 - val_tp: 62.0000 - val_fp: 100.0000 - val_tn: 5.0000 - val_fn: 12.0000 - val_accuracy: 0.3743 - val_precision: 0.3827 - val_recall: 0.8378 - val_auc: 0.4786\n",
      "Epoch 19/700\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.5308 - tp: 165.0000 - fp: 275.0000 - tn: 169.0000 - fn: 103.0000 - accuracy: 0.4691 - precision: 0.3750 - recall: 0.6157 - auc: 0.5098 - val_loss: 1.5317 - val_tp: 62.0000 - val_fp: 100.0000 - val_tn: 5.0000 - val_fn: 12.0000 - val_accuracy: 0.3743 - val_precision: 0.3827 - val_recall: 0.8378 - val_auc: 0.4786\n",
      "Epoch 20/700\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.5426 - tp: 164.0000 - fp: 287.0000 - tn: 157.0000 - fn: 104.0000 - accuracy: 0.4508 - precision: 0.3636 - recall: 0.6119 - auc: 0.4752 - val_loss: 1.5307 - val_tp: 62.0000 - val_fp: 100.0000 - val_tn: 5.0000 - val_fn: 12.0000 - val_accuracy: 0.3743 - val_precision: 0.3827 - val_recall: 0.8378 - val_auc: 0.4847\n",
      "Epoch 21/700\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.5360 - tp: 175.0000 - fp: 273.0000 - tn: 171.0000 - fn: 93.0000 - accuracy: 0.4860 - precision: 0.3906 - recall: 0.6530 - auc: 0.5209 - val_loss: 1.5298 - val_tp: 62.0000 - val_fp: 97.0000 - val_tn: 8.0000 - val_fn: 12.0000 - val_accuracy: 0.3911 - val_precision: 0.3899 - val_recall: 0.8378 - val_auc: 0.4716\n",
      "Epoch 22/700\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.5380 - tp: 169.0000 - fp: 282.0000 - tn: 162.0000 - fn: 99.0000 - accuracy: 0.4649 - precision: 0.3747 - recall: 0.6306 - auc: 0.4919 - val_loss: 1.5288 - val_tp: 62.0000 - val_fp: 97.0000 - val_tn: 8.0000 - val_fn: 12.0000 - val_accuracy: 0.3911 - val_precision: 0.3899 - val_recall: 0.8378 - val_auc: 0.4774\n",
      "Epoch 23/700\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.5351 - tp: 161.0000 - fp: 297.0000 - tn: 147.0000 - fn: 107.0000 - accuracy: 0.4326 - precision: 0.3515 - recall: 0.6007 - auc: 0.4756 - val_loss: 1.5279 - val_tp: 61.0000 - val_fp: 97.0000 - val_tn: 8.0000 - val_fn: 13.0000 - val_accuracy: 0.3855 - val_precision: 0.3861 - val_recall: 0.8243 - val_auc: 0.4763\n",
      "Epoch 24/700\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.5342 - tp: 174.0000 - fp: 281.0000 - tn: 163.0000 - fn: 94.0000 - accuracy: 0.4733 - precision: 0.3824 - recall: 0.6493 - auc: 0.5020 - val_loss: 1.5270 - val_tp: 61.0000 - val_fp: 96.0000 - val_tn: 9.0000 - val_fn: 13.0000 - val_accuracy: 0.3911 - val_precision: 0.3885 - val_recall: 0.8243 - val_auc: 0.5192\n",
      "Epoch 25/700\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.5324 - tp: 160.0000 - fp: 276.0000 - tn: 168.0000 - fn: 108.0000 - accuracy: 0.4607 - precision: 0.3670 - recall: 0.5970 - auc: 0.4789 - val_loss: 1.5260 - val_tp: 60.0000 - val_fp: 96.0000 - val_tn: 9.0000 - val_fn: 14.0000 - val_accuracy: 0.3855 - val_precision: 0.3846 - val_recall: 0.8108 - val_auc: 0.5099\n",
      "Epoch 26/700\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.5335 - tp: 140.0000 - fp: 260.0000 - tn: 184.0000 - fn: 128.0000 - accuracy: 0.4551 - precision: 0.3500 - recall: 0.5224 - auc: 0.4776 - val_loss: 1.5250 - val_tp: 60.0000 - val_fp: 94.0000 - val_tn: 11.0000 - val_fn: 14.0000 - val_accuracy: 0.3966 - val_precision: 0.3896 - val_recall: 0.8108 - val_auc: 0.5101\n",
      "Epoch 27/700\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.5237 - tp: 171.0000 - fp: 287.0000 - tn: 157.0000 - fn: 97.0000 - accuracy: 0.4607 - precision: 0.3734 - recall: 0.6381 - auc: 0.5155 - val_loss: 1.5240 - val_tp: 60.0000 - val_fp: 89.0000 - val_tn: 16.0000 - val_fn: 14.0000 - val_accuracy: 0.4246 - val_precision: 0.4027 - val_recall: 0.8108 - val_auc: 0.5188\n",
      "Epoch 28/700\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.5088 - tp: 173.0000 - fp: 252.0000 - tn: 192.0000 - fn: 95.0000 - accuracy: 0.5126 - precision: 0.4071 - recall: 0.6455 - auc: 0.5553 - val_loss: 1.5231 - val_tp: 55.0000 - val_fp: 89.0000 - val_tn: 16.0000 - val_fn: 19.0000 - val_accuracy: 0.3966 - val_precision: 0.3819 - val_recall: 0.7432 - val_auc: 0.5180\n",
      "Epoch 29/700\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.5252 - tp: 155.0000 - fp: 260.0000 - tn: 184.0000 - fn: 113.0000 - accuracy: 0.4761 - precision: 0.3735 - recall: 0.5784 - auc: 0.5063 - val_loss: 1.5220 - val_tp: 57.0000 - val_fp: 81.0000 - val_tn: 24.0000 - val_fn: 17.0000 - val_accuracy: 0.4525 - val_precision: 0.4130 - val_recall: 0.7703 - val_auc: 0.5231\n",
      "Epoch 30/700\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.5219 - tp: 165.0000 - fp: 275.0000 - tn: 169.0000 - fn: 103.0000 - accuracy: 0.4691 - precision: 0.3750 - recall: 0.6157 - auc: 0.5035 - val_loss: 1.5211 - val_tp: 54.0000 - val_fp: 81.0000 - val_tn: 24.0000 - val_fn: 20.0000 - val_accuracy: 0.4358 - val_precision: 0.4000 - val_recall: 0.7297 - val_auc: 0.5274\n",
      "Epoch 31/700\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.5190 - tp: 174.0000 - fp: 277.0000 - tn: 167.0000 - fn: 94.0000 - accuracy: 0.4789 - precision: 0.3858 - recall: 0.6493 - auc: 0.5195 - val_loss: 1.5202 - val_tp: 53.0000 - val_fp: 80.0000 - val_tn: 25.0000 - val_fn: 21.0000 - val_accuracy: 0.4358 - val_precision: 0.3985 - val_recall: 0.7162 - val_auc: 0.5239\n",
      "Epoch 32/700\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.5227 - tp: 152.0000 - fp: 273.0000 - tn: 171.0000 - fn: 116.0000 - accuracy: 0.4537 - precision: 0.3576 - recall: 0.5672 - auc: 0.4976 - val_loss: 1.5192 - val_tp: 52.0000 - val_fp: 79.0000 - val_tn: 26.0000 - val_fn: 22.0000 - val_accuracy: 0.4358 - val_precision: 0.3969 - val_recall: 0.7027 - val_auc: 0.5287\n",
      "Epoch 33/700\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.5177 - tp: 155.0000 - fp: 260.0000 - tn: 184.0000 - fn: 113.0000 - accuracy: 0.4761 - precision: 0.3735 - recall: 0.5784 - auc: 0.5195 - val_loss: 1.5183 - val_tp: 51.0000 - val_fp: 79.0000 - val_tn: 26.0000 - val_fn: 23.0000 - val_accuracy: 0.4302 - val_precision: 0.3923 - val_recall: 0.6892 - val_auc: 0.5343\n",
      "Epoch 34/700\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.5232 - tp: 156.0000 - fp: 274.0000 - tn: 170.0000 - fn: 112.0000 - accuracy: 0.4579 - precision: 0.3628 - recall: 0.5821 - auc: 0.4919 - val_loss: 1.5173 - val_tp: 51.0000 - val_fp: 79.0000 - val_tn: 26.0000 - val_fn: 23.0000 - val_accuracy: 0.4302 - val_precision: 0.3923 - val_recall: 0.6892 - val_auc: 0.5654\n",
      "Epoch 35/700\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.5236 - tp: 141.0000 - fp: 260.0000 - tn: 184.0000 - fn: 127.0000 - accuracy: 0.4565 - precision: 0.3516 - recall: 0.5261 - auc: 0.4778 - val_loss: 1.5163 - val_tp: 51.0000 - val_fp: 79.0000 - val_tn: 26.0000 - val_fn: 23.0000 - val_accuracy: 0.4302 - val_precision: 0.3923 - val_recall: 0.6892 - val_auc: 0.5633\n",
      "Epoch 36/700\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.5117 - tp: 155.0000 - fp: 250.0000 - tn: 194.0000 - fn: 113.0000 - accuracy: 0.4902 - precision: 0.3827 - recall: 0.5784 - auc: 0.5165 - val_loss: 1.5153 - val_tp: 51.0000 - val_fp: 79.0000 - val_tn: 26.0000 - val_fn: 23.0000 - val_accuracy: 0.4302 - val_precision: 0.3923 - val_recall: 0.6892 - val_auc: 0.5617\n",
      "Epoch 37/700\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.5274 - tp: 155.0000 - fp: 259.0000 - tn: 185.0000 - fn: 113.0000 - accuracy: 0.4775 - precision: 0.3744 - recall: 0.5784 - auc: 0.4725 - val_loss: 1.5144 - val_tp: 51.0000 - val_fp: 79.0000 - val_tn: 26.0000 - val_fn: 23.0000 - val_accuracy: 0.4302 - val_precision: 0.3923 - val_recall: 0.6892 - val_auc: 0.5618\n",
      "Epoch 38/700\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.5181 - tp: 147.0000 - fp: 254.0000 - tn: 190.0000 - fn: 121.0000 - accuracy: 0.4733 - precision: 0.3666 - recall: 0.5485 - auc: 0.4973 - val_loss: 1.5135 - val_tp: 51.0000 - val_fp: 77.0000 - val_tn: 28.0000 - val_fn: 23.0000 - val_accuracy: 0.4413 - val_precision: 0.3984 - val_recall: 0.6892 - val_auc: 0.5741\n",
      "Epoch 39/700\n",
      "712/712 [==============================] - 0s 166us/sample - loss: 2.2473 - tp: 188.0000 - fp: 304.0000 - tn: 140.0000 - fn: 80.0000 - accuracy: 0.4607 - precision: 0.3821 - recall: 0.7015 - auc: 0.5148 - val_loss: 2.1837 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6405\n",
      "Epoch 209/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 2.2356 - tp: 178.0000 - fp: 275.0000 - tn: 169.0000 - fn: 90.0000 - accuracy: 0.4874 - precision: 0.3929 - recall: 0.6642 - auc: 0.5342 - val_loss: 2.1836 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6415\n",
      "Epoch 210/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.2344 - tp: 195.0000 - fp: 310.0000 - tn: 134.0000 - fn: 73.0000 - accuracy: 0.4621 - precision: 0.3861 - recall: 0.7276 - auc: 0.5290 - val_loss: 2.1835 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6398\n",
      "Epoch 211/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 2.2326 - tp: 192.0000 - fp: 284.0000 - tn: 160.0000 - fn: 76.0000 - accuracy: 0.4944 - precision: 0.4034 - recall: 0.7164 - auc: 0.5463 - val_loss: 2.1834 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6408\n",
      "Epoch 212/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 2.2445 - tp: 185.0000 - fp: 304.0000 - tn: 140.0000 - fn: 83.0000 - accuracy: 0.4565 - precision: 0.3783 - recall: 0.6903 - auc: 0.5048 - val_loss: 2.1834 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6502\n",
      "Epoch 213/500\n",
      "712/712 [==============================] - 0s 147us/sample - loss: 2.2410 - tp: 171.0000 - fp: 284.0000 - tn: 160.0000 - fn: 97.0000 - accuracy: 0.4649 - precision: 0.3758 - recall: 0.6381 - auc: 0.5112 - val_loss: 2.1833 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6504\n",
      "Epoch 214/500\n",
      "712/712 [==============================] - 0s 156us/sample - loss: 2.2157 - tp: 199.0000 - fp: 282.0000 - tn: 162.0000 - fn: 69.0000 - accuracy: 0.5070 - precision: 0.4137 - recall: 0.7425 - auc: 0.5753 - val_loss: 2.1832 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6504\n",
      "Epoch 215/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 2.2555 - tp: 174.0000 - fp: 293.0000 - tn: 151.0000 - fn: 94.0000 - accuracy: 0.4565 - precision: 0.3726 - recall: 0.6493 - auc: 0.4961 - val_loss: 2.1832 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6506\n",
      "Epoch 216/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.2298 - tp: 177.0000 - fp: 283.0000 - tn: 161.0000 - fn: 91.0000 - accuracy: 0.4747 - precision: 0.3848 - recall: 0.6604 - auc: 0.5298 - val_loss: 2.1831 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6527\n",
      "Epoch 217/500\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 2.2332 - tp: 188.0000 - fp: 291.0000 - tn: 153.0000 - fn: 80.0000 - accuracy: 0.4789 - precision: 0.3925 - recall: 0.7015 - auc: 0.5330 - val_loss: 2.1830 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6523\n",
      "Epoch 218/500\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 2.2375 - tp: 186.0000 - fp: 286.0000 - tn: 158.0000 - fn: 82.0000 - accuracy: 0.4831 - precision: 0.3941 - recall: 0.6940 - auc: 0.5343 - val_loss: 2.1829 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6491\n",
      "Epoch 219/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 2.2300 - tp: 193.0000 - fp: 285.0000 - tn: 159.0000 - fn: 75.0000 - accuracy: 0.4944 - precision: 0.4038 - recall: 0.7201 - auc: 0.5484 - val_loss: 2.1829 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6497\n",
      "Epoch 220/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.2155 - tp: 196.0000 - fp: 297.0000 - tn: 147.0000 - fn: 72.0000 - accuracy: 0.4817 - precision: 0.3976 - recall: 0.7313 - auc: 0.5627 - val_loss: 2.1828 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6500\n",
      "Epoch 221/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 2.2242 - tp: 188.0000 - fp: 279.0000 - tn: 165.0000 - fn: 80.0000 - accuracy: 0.4958 - precision: 0.4026 - recall: 0.7015 - auc: 0.5485 - val_loss: 2.1827 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6496\n",
      "Epoch 222/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.2170 - tp: 181.0000 - fp: 252.0000 - tn: 192.0000 - fn: 87.0000 - accuracy: 0.5239 - precision: 0.4180 - recall: 0.6754 - auc: 0.5641 - val_loss: 2.1826 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6496\n",
      "Epoch 223/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 2.2521 - tp: 178.0000 - fp: 297.0000 - tn: 147.0000 - fn: 90.0000 - accuracy: 0.4565 - precision: 0.3747 - recall: 0.6642 - auc: 0.4859 - val_loss: 2.1826 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6496\n",
      "Epoch 224/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.2285 - tp: 178.0000 - fp: 269.0000 - tn: 175.0000 - fn: 90.0000 - accuracy: 0.4958 - precision: 0.3982 - recall: 0.6642 - auc: 0.5361 - val_loss: 2.1825 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6496\n",
      "Epoch 225/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 2.2306 - tp: 190.0000 - fp: 299.0000 - tn: 145.0000 - fn: 78.0000 - accuracy: 0.4705 - precision: 0.3885 - recall: 0.7090 - auc: 0.5446 - val_loss: 2.1824 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6496\n",
      "Epoch 226/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 2.2375 - tp: 187.0000 - fp: 287.0000 - tn: 157.0000 - fn: 81.0000 - accuracy: 0.4831 - precision: 0.3945 - recall: 0.6978 - auc: 0.5321 - val_loss: 2.1824 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6506\n",
      "Epoch 227/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.2295 - tp: 186.0000 - fp: 294.0000 - tn: 150.0000 - fn: 82.0000 - accuracy: 0.4719 - precision: 0.3875 - recall: 0.6940 - auc: 0.5384 - val_loss: 2.1823 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6516\n",
      "Epoch 228/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 2.2554 - tp: 176.0000 - fp: 313.0000 - tn: 131.0000 - fn: 92.0000 - accuracy: 0.4312 - precision: 0.3599 - recall: 0.6567 - auc: 0.4830 - val_loss: 2.1822 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6516\n",
      "Epoch 229/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 2.2340 - tp: 189.0000 - fp: 285.0000 - tn: 159.0000 - fn: 79.0000 - accuracy: 0.4888 - precision: 0.3987 - recall: 0.7052 - auc: 0.5333 - val_loss: 2.1822 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6514\n",
      "Epoch 230/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 2.2216 - tp: 178.0000 - fp: 275.0000 - tn: 169.0000 - fn: 90.0000 - accuracy: 0.4874 - precision: 0.3929 - recall: 0.6642 - auc: 0.5494 - val_loss: 2.1821 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6516\n",
      "Epoch 231/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 2.2431 - tp: 178.0000 - fp: 306.0000 - tn: 138.0000 - fn: 90.0000 - accuracy: 0.4438 - precision: 0.3678 - recall: 0.6642 - auc: 0.5055 - val_loss: 2.1820 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6524\n",
      "Epoch 232/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 2.2366 - tp: 193.0000 - fp: 298.0000 - tn: 146.0000 - fn: 75.0000 - accuracy: 0.4761 - precision: 0.3931 - recall: 0.7201 - auc: 0.5290 - val_loss: 2.1819 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6524\n",
      "Epoch 233/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 2.2403 - tp: 177.0000 - fp: 298.0000 - tn: 146.0000 - fn: 91.0000 - accuracy: 0.4537 - precision: 0.3726 - recall: 0.6604 - auc: 0.5195 - val_loss: 2.1819 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6524\n",
      "Epoch 234/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 2.2484 - tp: 187.0000 - fp: 300.0000 - tn: 144.0000 - fn: 81.0000 - accuracy: 0.4649 - precision: 0.3840 - recall: 0.6978 - auc: 0.5087 - val_loss: 2.1818 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6517\n",
      "Epoch 235/500\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 2.2460 - tp: 190.0000 - fp: 302.0000 - tn: 142.0000 - fn: 78.0000 - accuracy: 0.4663 - precision: 0.3862 - recall: 0.7090 - auc: 0.5019 - val_loss: 2.1817 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6519\n",
      "Epoch 236/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 2.2531 - tp: 185.0000 - fp: 301.0000 - tn: 143.0000 - fn: 83.0000 - accuracy: 0.4607 - precision: 0.3807 - recall: 0.6903 - auc: 0.5122 - val_loss: 2.1817 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6523\n",
      "Epoch 237/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 2.2365 - tp: 196.0000 - fp: 296.0000 - tn: 148.0000 - fn: 72.0000 - accuracy: 0.4831 - precision: 0.3984 - recall: 0.7313 - auc: 0.5304 - val_loss: 2.1816 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6519\n",
      "Epoch 238/500\n",
      "712/712 [==============================] - 0s 113us/sample - loss: 2.2423 - tp: 180.0000 - fp: 294.0000 - tn: 150.0000 - fn: 88.0000 - accuracy: 0.4635 - precision: 0.3797 - recall: 0.6716 - auc: 0.5187 - val_loss: 2.1815 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6519\n",
      "Epoch 239/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 2.2454 - tp: 176.0000 - fp: 294.0000 - tn: 150.0000 - fn: 92.0000 - accuracy: 0.4579 - precision: 0.3745 - recall: 0.6567 - auc: 0.5120 - val_loss: 2.1814 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6519\n",
      "Epoch 240/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 2.2368 - tp: 198.0000 - fp: 292.0000 - tn: 152.0000 - fn: 70.0000 - accuracy: 0.4916 - precision: 0.4041 - recall: 0.7388 - auc: 0.5367 - val_loss: 2.1814 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6526\n",
      "Epoch 241/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 2.2346 - tp: 180.0000 - fp: 276.0000 - tn: 168.0000 - fn: 88.0000 - accuracy: 0.4888 - precision: 0.3947 - recall: 0.6716 - auc: 0.5296 - val_loss: 2.1813 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6532\n",
      "Epoch 242/500\n",
      "712/712 [==============================] - 0s 110us/sample - loss: 2.2271 - tp: 194.0000 - fp: 306.0000 - tn: 138.0000 - fn: 74.0000 - accuracy: 0.4663 - precision: 0.3880 - recall: 0.7239 - auc: 0.5450 - val_loss: 2.1812 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6532\n",
      "Epoch 243/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 2.2286 - tp: 194.0000 - fp: 285.0000 - tn: 159.0000 - fn: 74.0000 - accuracy: 0.4958 - precision: 0.4050 - recall: 0.7239 - auc: 0.5381 - val_loss: 2.1812 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6515\n",
      "Epoch 244/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 2.2481 - tp: 180.0000 - fp: 303.0000 - tn: 141.0000 - fn: 88.0000 - accuracy: 0.4508 - precision: 0.3727 - recall: 0.6716 - auc: 0.4980 - val_loss: 2.1811 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6515\n",
      "Epoch 245/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 2.2406 - tp: 180.0000 - fp: 285.0000 - tn: 159.0000 - fn: 88.0000 - accuracy: 0.4761 - precision: 0.3871 - recall: 0.6716 - auc: 0.5151 - val_loss: 2.1810 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6523\n",
      "Epoch 246/500\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 2.2486 - tp: 176.0000 - fp: 298.0000 - tn: 146.0000 - fn: 92.0000 - accuracy: 0.4522 - precision: 0.3713 - recall: 0.6567 - auc: 0.4993 - val_loss: 2.1810 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6521\n",
      "Epoch 247/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 2.2424 - tp: 187.0000 - fp: 302.0000 - tn: 142.0000 - fn: 81.0000 - accuracy: 0.4621 - precision: 0.3824 - recall: 0.6978 - auc: 0.5171 - val_loss: 2.1809 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6522\n",
      "Epoch 248/500\n",
      "712/712 [==============================] - 0s 112us/sample - loss: 2.2519 - tp: 189.0000 - fp: 306.0000 - tn: 138.0000 - fn: 79.0000 - accuracy: 0.4593 - precision: 0.3818 - recall: 0.7052 - auc: 0.5110 - val_loss: 2.1808 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6522\n",
      "Epoch 249/500\n",
      "712/712 [==============================] - 0s 109us/sample - loss: 2.2550 - tp: 186.0000 - fp: 315.0000 - tn: 129.0000 - fn: 82.0000 - accuracy: 0.4424 - precision: 0.3713 - recall: 0.6940 - auc: 0.4877 - val_loss: 2.1807 - val_tp: 68.0000 - val_fp: 91.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.4581 - val_precision: 0.4277 - val_recall: 0.9189 - val_auc: 0.6523\n",
      "Epoch 250/500\n",
      "712/712 [==============================] - 0s 114us/sample - loss: 2.2441 - tp: 185.0000 - fp: 293.0000 - tn: 151.0000 - fn: 83.0000 - accuracy: 0.4719 - precision: 0.3870 - recall: 0.6903 - auc: 0.5190 - val_loss: 2.1807 - val_tp: 68.0000 - val_fp: 90.0000 - val_tn: 15.0000 - val_fn: 6.0000 - val_accuracy: 0.4637 - val_precision: 0.4304 - val_recall: 0.9189 - val_auc: 0.6516\n",
      "Epoch 251/500\n",
      "712/712 [==============================] - 0s 119us/sample - loss: 2.2534 - tp: 176.0000 - fp: 305.0000 - tn: 139.0000 - fn: 92.0000 - accuracy: 0.4424 - precision: 0.3659 - recall: 0.6567 - auc: 0.4933 - val_loss: 2.1806 - val_tp: 68.0000 - val_fp: 90.0000 - val_tn: 15.0000 - val_fn: 6.0000 - val_accuracy: 0.4637 - val_precision: 0.4304 - val_recall: 0.9189 - val_auc: 0.6514\n",
      "Epoch 252/500\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 2.2422 - tp: 170.0000 - fp: 268.0000 - tn: 176.0000 - fn: 98.0000 - accuracy: 0.4860 - precision: 0.3881 - recall: 0.6343 - auc: 0.5136 - val_loss: 2.1805 - val_tp: 68.0000 - val_fp: 90.0000 - val_tn: 15.0000 - val_fn: 6.0000 - val_accuracy: 0.4637 - val_precision: 0.4304 - val_recall: 0.9189 - val_auc: 0.6515\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 6.2999 - tp: 130.0000 - fp: 228.0000 - tn: 216.0000 - fn: 138.0000 - accuracy: 0.4860 - precision: 0.3631 - recall: 0.4851 - auc: 0.5027 - val_loss: 6.3054 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4865\n",
      "Epoch 67/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 6.2867 - tp: 139.0000 - fp: 209.0000 - tn: 235.0000 - fn: 129.0000 - accuracy: 0.5253 - precision: 0.3994 - recall: 0.5187 - auc: 0.5212 - val_loss: 6.2943 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4865\n",
      "Epoch 68/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 6.2805 - tp: 124.0000 - fp: 211.0000 - tn: 233.0000 - fn: 144.0000 - accuracy: 0.5014 - precision: 0.3701 - recall: 0.4627 - auc: 0.4875 - val_loss: 6.2833 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4932\n",
      "Epoch 69/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 6.2647 - tp: 127.0000 - fp: 198.0000 - tn: 246.0000 - fn: 141.0000 - accuracy: 0.5239 - precision: 0.3908 - recall: 0.4739 - auc: 0.5233 - val_loss: 6.2722 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 70/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 6.2533 - tp: 136.0000 - fp: 211.0000 - tn: 233.0000 - fn: 132.0000 - accuracy: 0.5183 - precision: 0.3919 - recall: 0.5075 - auc: 0.5239 - val_loss: 6.2613 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4865\n",
      "Epoch 71/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 6.2493 - tp: 117.0000 - fp: 200.0000 - tn: 244.0000 - fn: 151.0000 - accuracy: 0.5070 - precision: 0.3691 - recall: 0.4366 - auc: 0.4721 - val_loss: 6.2502 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 72/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 6.2276 - tp: 145.0000 - fp: 190.0000 - tn: 254.0000 - fn: 123.0000 - accuracy: 0.5604 - precision: 0.4328 - recall: 0.5410 - auc: 0.5541 - val_loss: 6.2393 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4730\n",
      "Epoch 73/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 6.2262 - tp: 112.0000 - fp: 201.0000 - tn: 243.0000 - fn: 156.0000 - accuracy: 0.4986 - precision: 0.3578 - recall: 0.4179 - auc: 0.4775 - val_loss: 6.2283 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4777\n",
      "Epoch 74/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 6.2114 - tp: 125.0000 - fp: 189.0000 - tn: 255.0000 - fn: 143.0000 - accuracy: 0.5337 - precision: 0.3981 - recall: 0.4664 - auc: 0.5031 - val_loss: 6.2173 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4777\n",
      "Epoch 75/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 6.1988 - tp: 133.0000 - fp: 187.0000 - tn: 257.0000 - fn: 135.0000 - accuracy: 0.5478 - precision: 0.4156 - recall: 0.4963 - auc: 0.5206 - val_loss: 6.2064 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5261\n",
      "Epoch 76/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 6.1896 - tp: 123.0000 - fp: 185.0000 - tn: 259.0000 - fn: 145.0000 - accuracy: 0.5365 - precision: 0.3994 - recall: 0.4590 - auc: 0.5089 - val_loss: 6.1954 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4853\n",
      "Epoch 77/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 6.1808 - tp: 112.0000 - fp: 206.0000 - tn: 238.0000 - fn: 156.0000 - accuracy: 0.4916 - precision: 0.3522 - recall: 0.4179 - auc: 0.4904 - val_loss: 6.1845 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4833\n",
      "Epoch 78/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 6.1673 - tp: 119.0000 - fp: 187.0000 - tn: 257.0000 - fn: 149.0000 - accuracy: 0.5281 - precision: 0.3889 - recall: 0.4440 - auc: 0.5107 - val_loss: 6.1736 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4873\n",
      "Epoch 79/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 6.1568 - tp: 121.0000 - fp: 193.0000 - tn: 251.0000 - fn: 147.0000 - accuracy: 0.5225 - precision: 0.3854 - recall: 0.4515 - auc: 0.5099 - val_loss: 6.1627 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4900\n",
      "Epoch 80/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 6.1504 - tp: 111.0000 - fp: 196.0000 - tn: 248.0000 - fn: 157.0000 - accuracy: 0.5042 - precision: 0.3616 - recall: 0.4142 - auc: 0.4748 - val_loss: 6.1518 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5194\n",
      "Epoch 81/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 6.1367 - tp: 122.0000 - fp: 184.0000 - tn: 260.0000 - fn: 146.0000 - accuracy: 0.5365 - precision: 0.3987 - recall: 0.4552 - auc: 0.4961 - val_loss: 6.1409 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5372\n",
      "Epoch 82/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 6.1162 - tp: 135.0000 - fp: 173.0000 - tn: 271.0000 - fn: 133.0000 - accuracy: 0.5702 - precision: 0.4383 - recall: 0.5037 - auc: 0.5722 - val_loss: 6.1301 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5217\n",
      "Epoch 83/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 6.1086 - tp: 128.0000 - fp: 180.0000 - tn: 264.0000 - fn: 140.0000 - accuracy: 0.5506 - precision: 0.4156 - recall: 0.4776 - auc: 0.5439 - val_loss: 6.1193 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4847\n",
      "Epoch 84/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 6.1028 - tp: 125.0000 - fp: 206.0000 - tn: 238.0000 - fn: 143.0000 - accuracy: 0.5098 - precision: 0.3776 - recall: 0.4664 - auc: 0.5003 - val_loss: 6.1084 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4847\n",
      "Epoch 85/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 6.0914 - tp: 120.0000 - fp: 190.0000 - tn: 254.0000 - fn: 148.0000 - accuracy: 0.5253 - precision: 0.3871 - recall: 0.4478 - auc: 0.5068 - val_loss: 6.0976 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4624\n",
      "Epoch 86/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 6.0824 - tp: 123.0000 - fp: 209.0000 - tn: 235.0000 - fn: 145.0000 - accuracy: 0.5028 - precision: 0.3705 - recall: 0.4590 - auc: 0.4873 - val_loss: 6.0868 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4409\n",
      "Epoch 87/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 6.0704 - tp: 120.0000 - fp: 192.0000 - tn: 252.0000 - fn: 148.0000 - accuracy: 0.5225 - precision: 0.3846 - recall: 0.4478 - auc: 0.4985 - val_loss: 6.0760 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4624\n",
      "Epoch 88/600\n",
      "712/712 [==============================] - 0s 143us/sample - loss: 6.0601 - tp: 115.0000 - fp: 197.0000 - tn: 247.0000 - fn: 153.0000 - accuracy: 0.5084 - precision: 0.3686 - recall: 0.4291 - auc: 0.4967 - val_loss: 6.0652 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4692\n",
      "Epoch 89/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 6.0508 - tp: 105.0000 - fp: 192.0000 - tn: 252.0000 - fn: 163.0000 - accuracy: 0.5014 - precision: 0.3535 - recall: 0.3918 - auc: 0.4810 - val_loss: 6.0544 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5420\n",
      "Epoch 90/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 6.0387 - tp: 121.0000 - fp: 194.0000 - tn: 250.0000 - fn: 147.0000 - accuracy: 0.5211 - precision: 0.3841 - recall: 0.4515 - auc: 0.4982 - val_loss: 6.0436 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5284\n",
      "Epoch 91/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 6.0277 - tp: 115.0000 - fp: 203.0000 - tn: 241.0000 - fn: 153.0000 - accuracy: 0.5000 - precision: 0.3616 - recall: 0.4291 - auc: 0.4938 - val_loss: 6.0329 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5205\n",
      "Epoch 92/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 6.0118 - tp: 123.0000 - fp: 175.0000 - tn: 269.0000 - fn: 145.0000 - accuracy: 0.5506 - precision: 0.4128 - recall: 0.4590 - auc: 0.5398 - val_loss: 6.0222 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4692\n",
      "Epoch 93/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 6.0091 - tp: 122.0000 - fp: 209.0000 - tn: 235.0000 - fn: 146.0000 - accuracy: 0.5014 - precision: 0.3686 - recall: 0.4552 - auc: 0.4823 - val_loss: 6.0115 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4254\n",
      "Epoch 94/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 5.9932 - tp: 118.0000 - fp: 186.0000 - tn: 258.0000 - fn: 150.0000 - accuracy: 0.5281 - precision: 0.3882 - recall: 0.4403 - auc: 0.5180 - val_loss: 6.0008 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4314\n",
      "Epoch 95/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 5.9830 - tp: 109.0000 - fp: 186.0000 - tn: 258.0000 - fn: 159.0000 - accuracy: 0.5154 - precision: 0.3695 - recall: 0.4067 - auc: 0.5111 - val_loss: 5.9900 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4847\n",
      "Epoch 96/600\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 5.9755 - tp: 113.0000 - fp: 196.0000 - tn: 248.0000 - fn: 155.0000 - accuracy: 0.5070 - precision: 0.3657 - recall: 0.4216 - auc: 0.4926 - val_loss: 5.9793 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5205\n",
      "Epoch 97/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 5.9578 - tp: 137.0000 - fp: 185.0000 - tn: 259.0000 - fn: 131.0000 - accuracy: 0.5562 - precision: 0.4255 - recall: 0.5112 - auc: 0.5519 - val_loss: 5.9686 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5272\n",
      "Epoch 98/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 5.9546 - tp: 115.0000 - fp: 191.0000 - tn: 253.0000 - fn: 153.0000 - accuracy: 0.5169 - precision: 0.3758 - recall: 0.4291 - auc: 0.4817 - val_loss: 5.9580 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4982\n",
      "Epoch 99/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 5.9409 - tp: 136.0000 - fp: 201.0000 - tn: 243.0000 - fn: 132.0000 - accuracy: 0.5323 - precision: 0.4036 - recall: 0.5075 - auc: 0.5134 - val_loss: 5.9473 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5380\n",
      "Epoch 100/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 5.9278 - tp: 121.0000 - fp: 171.0000 - tn: 273.0000 - fn: 147.0000 - accuracy: 0.5534 - precision: 0.4144 - recall: 0.4515 - auc: 0.5324 - val_loss: 5.9366 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5252\n",
      "Epoch 101/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 5.9231 - tp: 116.0000 - fp: 194.0000 - tn: 250.0000 - fn: 152.0000 - accuracy: 0.5140 - precision: 0.3742 - recall: 0.4328 - auc: 0.4792 - val_loss: 5.9260 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5185\n",
      "Epoch 102/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 5.9110 - tp: 116.0000 - fp: 200.0000 - tn: 244.0000 - fn: 152.0000 - accuracy: 0.5056 - precision: 0.3671 - recall: 0.4328 - auc: 0.4900 - val_loss: 5.9153 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5185\n",
      "Epoch 103/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 5.8989 - tp: 123.0000 - fp: 193.0000 - tn: 251.0000 - fn: 145.0000 - accuracy: 0.5253 - precision: 0.3892 - recall: 0.4590 - auc: 0.5030 - val_loss: 5.9047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5252\n",
      "Epoch 104/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 370/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 371/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 372/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4898 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 373/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 374/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5014 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 375/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 376/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 377/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 378/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 379/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5011 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 380/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 381/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 382/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 383/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 384/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 385/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 386/500\n",
      "712/712 [==============================] - 0s 126us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 387/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 388/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 389/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 390/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 391/500\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 392/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 393/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5007 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 394/500\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 395/500\n",
      "712/712 [==============================] - 0s 128us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 396/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 397/500\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4792 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 398/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5018 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 399/500\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5037 - val_loss: 0.7111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 400/500\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4902 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 401/500\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4879 - val_loss: 0.7111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 402/500\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5004 - val_loss: 0.7111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 403/500\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 404/500\n",
      "712/712 [==============================] - 0s 125us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4992 - val_loss: 0.7111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 405/500\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5074 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 406/500\n",
      "712/712 [==============================] - 0s 127us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4723 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 407/500\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 0.6973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 444.0000 - fn: 268.0000 - accuracy: 0.6236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4810 - val_loss: 0.7112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 105.0000 - val_fn: 74.0000 - val_accuracy: 0.5866 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 408/500\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3642 - tp: 149.0000 - fp: 196.0000 - tn: 248.0000 - fn: 119.0000 - accuracy: 0.5576 - precision: 0.4319 - recall: 0.5560 - auc: 0.5692 - val_loss: 1.3617 - val_tp: 33.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 41.0000 - val_accuracy: 0.6927 - val_precision: 0.7021 - val_recall: 0.4459 - val_auc: 0.8247\n",
      "Epoch 212/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.3605 - tp: 148.0000 - fp: 197.0000 - tn: 247.0000 - fn: 120.0000 - accuracy: 0.5548 - precision: 0.4290 - recall: 0.5522 - auc: 0.5794 - val_loss: 1.3609 - val_tp: 33.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 41.0000 - val_accuracy: 0.6927 - val_precision: 0.7021 - val_recall: 0.4459 - val_auc: 0.8242\n",
      "Epoch 213/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3676 - tp: 150.0000 - fp: 196.0000 - tn: 248.0000 - fn: 118.0000 - accuracy: 0.5590 - precision: 0.4335 - recall: 0.5597 - auc: 0.5563 - val_loss: 1.3602 - val_tp: 33.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 41.0000 - val_accuracy: 0.6927 - val_precision: 0.7021 - val_recall: 0.4459 - val_auc: 0.8245\n",
      "Epoch 214/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3614 - tp: 133.0000 - fp: 182.0000 - tn: 262.0000 - fn: 135.0000 - accuracy: 0.5548 - precision: 0.4222 - recall: 0.4963 - auc: 0.5661 - val_loss: 1.3594 - val_tp: 33.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 41.0000 - val_accuracy: 0.6927 - val_precision: 0.7021 - val_recall: 0.4459 - val_auc: 0.8255\n",
      "Epoch 215/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3618 - tp: 143.0000 - fp: 186.0000 - tn: 258.0000 - fn: 125.0000 - accuracy: 0.5632 - precision: 0.4347 - recall: 0.5336 - auc: 0.5735 - val_loss: 1.3586 - val_tp: 33.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 41.0000 - val_accuracy: 0.6927 - val_precision: 0.7021 - val_recall: 0.4459 - val_auc: 0.8258\n",
      "Epoch 216/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.3628 - tp: 143.0000 - fp: 189.0000 - tn: 255.0000 - fn: 125.0000 - accuracy: 0.5590 - precision: 0.4307 - recall: 0.5336 - auc: 0.5596 - val_loss: 1.3578 - val_tp: 33.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 41.0000 - val_accuracy: 0.6927 - val_precision: 0.7021 - val_recall: 0.4459 - val_auc: 0.8255\n",
      "Epoch 217/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.3598 - tp: 134.0000 - fp: 175.0000 - tn: 269.0000 - fn: 134.0000 - accuracy: 0.5660 - precision: 0.4337 - recall: 0.5000 - auc: 0.5687 - val_loss: 1.3571 - val_tp: 34.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 40.0000 - val_accuracy: 0.6983 - val_precision: 0.7083 - val_recall: 0.4595 - val_auc: 0.8257\n",
      "Epoch 218/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.3606 - tp: 148.0000 - fp: 198.0000 - tn: 246.0000 - fn: 120.0000 - accuracy: 0.5534 - precision: 0.4277 - recall: 0.5522 - auc: 0.5690 - val_loss: 1.3563 - val_tp: 33.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 41.0000 - val_accuracy: 0.6927 - val_precision: 0.7021 - val_recall: 0.4459 - val_auc: 0.8252\n",
      "Epoch 219/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3623 - tp: 130.0000 - fp: 188.0000 - tn: 256.0000 - fn: 138.0000 - accuracy: 0.5421 - precision: 0.4088 - recall: 0.4851 - auc: 0.5527 - val_loss: 1.3555 - val_tp: 33.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 41.0000 - val_accuracy: 0.6927 - val_precision: 0.7021 - val_recall: 0.4459 - val_auc: 0.8265\n",
      "Epoch 220/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3602 - tp: 138.0000 - fp: 186.0000 - tn: 258.0000 - fn: 130.0000 - accuracy: 0.5562 - precision: 0.4259 - recall: 0.5149 - auc: 0.5600 - val_loss: 1.3547 - val_tp: 33.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 41.0000 - val_accuracy: 0.6927 - val_precision: 0.7021 - val_recall: 0.4459 - val_auc: 0.8259\n",
      "Epoch 221/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.3492 - tp: 153.0000 - fp: 173.0000 - tn: 271.0000 - fn: 115.0000 - accuracy: 0.5955 - precision: 0.4693 - recall: 0.5709 - auc: 0.6045 - val_loss: 1.3539 - val_tp: 34.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 40.0000 - val_accuracy: 0.6983 - val_precision: 0.7083 - val_recall: 0.4595 - val_auc: 0.8267\n",
      "Epoch 222/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.3634 - tp: 130.0000 - fp: 199.0000 - tn: 245.0000 - fn: 138.0000 - accuracy: 0.5267 - precision: 0.3951 - recall: 0.4851 - auc: 0.5346 - val_loss: 1.3531 - val_tp: 34.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 40.0000 - val_accuracy: 0.6983 - val_precision: 0.7083 - val_recall: 0.4595 - val_auc: 0.8276\n",
      "Epoch 223/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.3619 - tp: 134.0000 - fp: 200.0000 - tn: 244.0000 - fn: 134.0000 - accuracy: 0.5309 - precision: 0.4012 - recall: 0.5000 - auc: 0.5428 - val_loss: 1.3523 - val_tp: 34.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 40.0000 - val_accuracy: 0.6983 - val_precision: 0.7083 - val_recall: 0.4595 - val_auc: 0.8285\n",
      "Epoch 224/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.3433 - tp: 154.0000 - fp: 178.0000 - tn: 266.0000 - fn: 114.0000 - accuracy: 0.5899 - precision: 0.4639 - recall: 0.5746 - auc: 0.6253 - val_loss: 1.3515 - val_tp: 34.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 40.0000 - val_accuracy: 0.6983 - val_precision: 0.7083 - val_recall: 0.4595 - val_auc: 0.8260\n",
      "Epoch 225/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3527 - tp: 144.0000 - fp: 178.0000 - tn: 266.0000 - fn: 124.0000 - accuracy: 0.5758 - precision: 0.4472 - recall: 0.5373 - auc: 0.5812 - val_loss: 1.3507 - val_tp: 34.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 40.0000 - val_accuracy: 0.6983 - val_precision: 0.7083 - val_recall: 0.4595 - val_auc: 0.8258\n",
      "Epoch 226/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.3548 - tp: 131.0000 - fp: 173.0000 - tn: 271.0000 - fn: 137.0000 - accuracy: 0.5646 - precision: 0.4309 - recall: 0.4888 - auc: 0.5763 - val_loss: 1.3499 - val_tp: 34.0000 - val_fp: 14.0000 - val_tn: 91.0000 - val_fn: 40.0000 - val_accuracy: 0.6983 - val_precision: 0.7083 - val_recall: 0.4595 - val_auc: 0.8202\n",
      "Epoch 227/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.3652 - tp: 111.0000 - fp: 182.0000 - tn: 262.0000 - fn: 157.0000 - accuracy: 0.5239 - precision: 0.3788 - recall: 0.4142 - auc: 0.5133 - val_loss: 1.3490 - val_tp: 34.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 40.0000 - val_accuracy: 0.6927 - val_precision: 0.6939 - val_recall: 0.4595 - val_auc: 0.8214\n",
      "Epoch 228/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.3508 - tp: 150.0000 - fp: 180.0000 - tn: 264.0000 - fn: 118.0000 - accuracy: 0.5815 - precision: 0.4545 - recall: 0.5597 - auc: 0.5805 - val_loss: 1.3482 - val_tp: 34.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 40.0000 - val_accuracy: 0.6927 - val_precision: 0.6939 - val_recall: 0.4595 - val_auc: 0.8207\n",
      "Epoch 229/600\n",
      "712/712 [==============================] - 0s 149us/sample - loss: 1.3510 - tp: 139.0000 - fp: 183.0000 - tn: 261.0000 - fn: 129.0000 - accuracy: 0.5618 - precision: 0.4317 - recall: 0.5187 - auc: 0.5715 - val_loss: 1.3474 - val_tp: 36.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 38.0000 - val_accuracy: 0.7039 - val_precision: 0.7059 - val_recall: 0.4865 - val_auc: 0.8206\n",
      "Epoch 230/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3462 - tp: 139.0000 - fp: 179.0000 - tn: 265.0000 - fn: 129.0000 - accuracy: 0.5674 - precision: 0.4371 - recall: 0.5187 - auc: 0.5968 - val_loss: 1.3466 - val_tp: 36.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 38.0000 - val_accuracy: 0.7039 - val_precision: 0.7059 - val_recall: 0.4865 - val_auc: 0.8223\n",
      "Epoch 231/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.3479 - tp: 148.0000 - fp: 187.0000 - tn: 257.0000 - fn: 120.0000 - accuracy: 0.5688 - precision: 0.4418 - recall: 0.5522 - auc: 0.5801 - val_loss: 1.3457 - val_tp: 37.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 37.0000 - val_accuracy: 0.7039 - val_precision: 0.6981 - val_recall: 0.5000 - val_auc: 0.8209\n",
      "Epoch 232/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.3541 - tp: 135.0000 - fp: 182.0000 - tn: 262.0000 - fn: 133.0000 - accuracy: 0.5576 - precision: 0.4259 - recall: 0.5037 - auc: 0.5535 - val_loss: 1.3450 - val_tp: 36.0000 - val_fp: 15.0000 - val_tn: 90.0000 - val_fn: 38.0000 - val_accuracy: 0.7039 - val_precision: 0.7059 - val_recall: 0.4865 - val_auc: 0.8226\n",
      "Epoch 233/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3469 - tp: 139.0000 - fp: 191.0000 - tn: 253.0000 - fn: 129.0000 - accuracy: 0.5506 - precision: 0.4212 - recall: 0.5187 - auc: 0.5819 - val_loss: 1.3442 - val_tp: 37.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 37.0000 - val_accuracy: 0.7039 - val_precision: 0.6981 - val_recall: 0.5000 - val_auc: 0.8228\n",
      "Epoch 234/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.3488 - tp: 136.0000 - fp: 176.0000 - tn: 268.0000 - fn: 132.0000 - accuracy: 0.5674 - precision: 0.4359 - recall: 0.5075 - auc: 0.5734 - val_loss: 1.3434 - val_tp: 37.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 37.0000 - val_accuracy: 0.7039 - val_precision: 0.6981 - val_recall: 0.5000 - val_auc: 0.8223\n",
      "Epoch 235/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.3401 - tp: 152.0000 - fp: 179.0000 - tn: 265.0000 - fn: 116.0000 - accuracy: 0.5857 - precision: 0.4592 - recall: 0.5672 - auc: 0.6082 - val_loss: 1.3426 - val_tp: 37.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 37.0000 - val_accuracy: 0.7039 - val_precision: 0.6981 - val_recall: 0.5000 - val_auc: 0.8227\n",
      "Epoch 236/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.3528 - tp: 136.0000 - fp: 198.0000 - tn: 246.0000 - fn: 132.0000 - accuracy: 0.5365 - precision: 0.4072 - recall: 0.5075 - auc: 0.5533 - val_loss: 1.3418 - val_tp: 37.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 37.0000 - val_accuracy: 0.7039 - val_precision: 0.6981 - val_recall: 0.5000 - val_auc: 0.8221\n",
      "Epoch 237/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3497 - tp: 140.0000 - fp: 180.0000 - tn: 264.0000 - fn: 128.0000 - accuracy: 0.5674 - precision: 0.4375 - recall: 0.5224 - auc: 0.5638 - val_loss: 1.3409 - val_tp: 37.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 37.0000 - val_accuracy: 0.7039 - val_precision: 0.6981 - val_recall: 0.5000 - val_auc: 0.8227\n",
      "Epoch 238/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 1.3375 - tp: 149.0000 - fp: 178.0000 - tn: 266.0000 - fn: 119.0000 - accuracy: 0.5829 - precision: 0.4557 - recall: 0.5560 - auc: 0.6085 - val_loss: 1.3401 - val_tp: 37.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 37.0000 - val_accuracy: 0.7039 - val_precision: 0.6981 - val_recall: 0.5000 - val_auc: 0.8232\n",
      "Epoch 239/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3362 - tp: 155.0000 - fp: 164.0000 - tn: 280.0000 - fn: 113.0000 - accuracy: 0.6110 - precision: 0.4859 - recall: 0.5784 - auc: 0.6231 - val_loss: 1.3394 - val_tp: 37.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 37.0000 - val_accuracy: 0.7039 - val_precision: 0.6981 - val_recall: 0.5000 - val_auc: 0.8219\n",
      "Epoch 240/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.3427 - tp: 147.0000 - fp: 182.0000 - tn: 262.0000 - fn: 121.0000 - accuracy: 0.5744 - precision: 0.4468 - recall: 0.5485 - auc: 0.5856 - val_loss: 1.3386 - val_tp: 37.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 37.0000 - val_accuracy: 0.7039 - val_precision: 0.6981 - val_recall: 0.5000 - val_auc: 0.8251\n",
      "Epoch 241/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.3394 - tp: 142.0000 - fp: 176.0000 - tn: 268.0000 - fn: 126.0000 - accuracy: 0.5758 - precision: 0.4465 - recall: 0.5299 - auc: 0.5961 - val_loss: 1.3378 - val_tp: 37.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 37.0000 - val_accuracy: 0.7039 - val_precision: 0.6981 - val_recall: 0.5000 - val_auc: 0.8226\n",
      "Epoch 242/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.3467 - tp: 129.0000 - fp: 182.0000 - tn: 262.0000 - fn: 139.0000 - accuracy: 0.5492 - precision: 0.4148 - recall: 0.4813 - auc: 0.5670 - val_loss: 1.3370 - val_tp: 37.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 37.0000 - val_accuracy: 0.7039 - val_precision: 0.6981 - val_recall: 0.5000 - val_auc: 0.8255\n",
      "Epoch 243/600\n",
      "712/712 [==============================] - 0s 170us/sample - loss: 1.3388 - tp: 140.0000 - fp: 187.0000 - tn: 257.0000 - fn: 128.0000 - accuracy: 0.5576 - precision: 0.4281 - recall: 0.5224 - auc: 0.5828 - val_loss: 1.3362 - val_tp: 37.0000 - val_fp: 16.0000 - val_tn: 89.0000 - val_fn: 37.0000 - val_accuracy: 0.7039 - val_precision: 0.6981 - val_recall: 0.5000 - val_auc: 0.8259\n",
      "Epoch 244/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.3353 - tp: 149.0000 - fp: 171.0000 - tn: 273.0000 - fn: 119.0000 - accuracy: 0.5927 - precision: 0.4656 - recall: 0.5560 - auc: 0.6055 - val_loss: 1.3354 - val_tp: 38.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 36.0000 - val_accuracy: 0.7039 - val_precision: 0.6909 - val_recall: 0.5135 - val_auc: 0.8262\n",
      "Epoch 245/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.3361 - tp: 145.0000 - fp: 183.0000 - tn: 261.0000 - fn: 123.0000 - accuracy: 0.5702 - precision: 0.4421 - recall: 0.5410 - auc: 0.5928 - val_loss: 1.3346 - val_tp: 38.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 36.0000 - val_accuracy: 0.7039 - val_precision: 0.6909 - val_recall: 0.5135 - val_auc: 0.8263\n",
      "Epoch 246/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 1.3296 - tp: 154.0000 - fp: 176.0000 - tn: 268.0000 - fn: 114.0000 - accuracy: 0.5927 - precision: 0.4667 - recall: 0.5746 - auc: 0.6278 - val_loss: 1.3338 - val_tp: 38.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 36.0000 - val_accuracy: 0.7039 - val_precision: 0.6909 - val_recall: 0.5135 - val_auc: 0.8247\n",
      "Epoch 247/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3407 - tp: 149.0000 - fp: 192.0000 - tn: 252.0000 - fn: 119.0000 - accuracy: 0.5632 - precision: 0.4370 - recall: 0.5560 - auc: 0.5825 - val_loss: 1.3330 - val_tp: 38.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 36.0000 - val_accuracy: 0.7039 - val_precision: 0.6909 - val_recall: 0.5135 - val_auc: 0.8250\n",
      "Epoch 248/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.3322 - tp: 158.0000 - fp: 174.0000 - tn: 270.0000 - fn: 110.0000 - accuracy: 0.6011 - precision: 0.4759 - recall: 0.5896 - auc: 0.6190 - val_loss: 1.3323 - val_tp: 38.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 36.0000 - val_accuracy: 0.7039 - val_precision: 0.6909 - val_recall: 0.5135 - val_auc: 0.8262\n",
      "Epoch 249/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.3445 - tp: 139.0000 - fp: 193.0000 - tn: 251.0000 - fn: 129.0000 - accuracy: 0.5478 - precision: 0.4187 - recall: 0.5187 - auc: 0.5567 - val_loss: 1.3314 - val_tp: 38.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 36.0000 - val_accuracy: 0.7039 - val_precision: 0.6909 - val_recall: 0.5135 - val_auc: 0.8254\n",
      "Epoch 250/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3347 - tp: 142.0000 - fp: 175.0000 - tn: 269.0000 - fn: 126.0000 - accuracy: 0.5772 - precision: 0.4479 - recall: 0.5299 - auc: 0.5955 - val_loss: 1.3306 - val_tp: 39.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 35.0000 - val_accuracy: 0.7095 - val_precision: 0.6964 - val_recall: 0.5270 - val_auc: 0.8245\n",
      "Epoch 251/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.3335 - tp: 137.0000 - fp: 173.0000 - tn: 271.0000 - fn: 131.0000 - accuracy: 0.5730 - precision: 0.4419 - recall: 0.5112 - auc: 0.5958 - val_loss: 1.3298 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 35.0000 - val_accuracy: 0.7039 - val_precision: 0.6842 - val_recall: 0.5270 - val_auc: 0.8241\n",
      "Epoch 252/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3234 - tp: 152.0000 - fp: 171.0000 - tn: 273.0000 - fn: 116.0000 - accuracy: 0.5969 - precision: 0.4706 - recall: 0.5672 - auc: 0.6314 - val_loss: 1.3290 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 35.0000 - val_accuracy: 0.7039 - val_precision: 0.6842 - val_recall: 0.5270 - val_auc: 0.8255\n",
      "Epoch 253/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.3244 - tp: 155.0000 - fp: 176.0000 - tn: 268.0000 - fn: 113.0000 - accuracy: 0.5941 - precision: 0.4683 - recall: 0.5784 - auc: 0.6296 - val_loss: 1.3283 - val_tp: 38.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 36.0000 - val_accuracy: 0.7039 - val_precision: 0.6909 - val_recall: 0.5135 - val_auc: 0.8250\n",
      "Epoch 254/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.3323 - tp: 142.0000 - fp: 178.0000 - tn: 266.0000 - fn: 126.0000 - accuracy: 0.5730 - precision: 0.4437 - recall: 0.5299 - auc: 0.5959 - val_loss: 1.3276 - val_tp: 38.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 36.0000 - val_accuracy: 0.7039 - val_precision: 0.6909 - val_recall: 0.5135 - val_auc: 0.8248\n",
      "Epoch 255/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.3352 - tp: 139.0000 - fp: 182.0000 - tn: 262.0000 - fn: 129.0000 - accuracy: 0.5632 - precision: 0.4330 - recall: 0.5187 - auc: 0.5859 - val_loss: 1.3268 - val_tp: 38.0000 - val_fp: 17.0000 - val_tn: 88.0000 - val_fn: 36.0000 - val_accuracy: 0.7039 - val_precision: 0.6909 - val_recall: 0.5135 - val_auc: 0.8270\n",
      "Epoch 256/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.3330 - tp: 142.0000 - fp: 174.0000 - tn: 270.0000 - fn: 126.0000 - accuracy: 0.5787 - precision: 0.4494 - recall: 0.5299 - auc: 0.5865 - val_loss: 1.3260 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 35.0000 - val_accuracy: 0.7039 - val_precision: 0.6842 - val_recall: 0.5270 - val_auc: 0.8277\n",
      "Epoch 257/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3292 - tp: 142.0000 - fp: 172.0000 - tn: 272.0000 - fn: 126.0000 - accuracy: 0.5815 - precision: 0.4522 - recall: 0.5299 - auc: 0.6035 - val_loss: 1.3251 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 35.0000 - val_accuracy: 0.7039 - val_precision: 0.6842 - val_recall: 0.5270 - val_auc: 0.8272\n",
      "Epoch 258/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.3399 - tp: 125.0000 - fp: 174.0000 - tn: 270.0000 - fn: 143.0000 - accuracy: 0.5548 - precision: 0.4181 - recall: 0.4664 - auc: 0.5465 - val_loss: 1.3243 - val_tp: 40.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 34.0000 - val_accuracy: 0.7095 - val_precision: 0.6897 - val_recall: 0.5405 - val_auc: 0.8255\n",
      "Epoch 259/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.3352 - tp: 131.0000 - fp: 181.0000 - tn: 263.0000 - fn: 137.0000 - accuracy: 0.5534 - precision: 0.4199 - recall: 0.4888 - auc: 0.5673 - val_loss: 1.3236 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 35.0000 - val_accuracy: 0.7039 - val_precision: 0.6842 - val_recall: 0.5270 - val_auc: 0.8268\n",
      "Epoch 260/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.3274 - tp: 152.0000 - fp: 180.0000 - tn: 264.0000 - fn: 116.0000 - accuracy: 0.5843 - precision: 0.4578 - recall: 0.5672 - auc: 0.6038 - val_loss: 1.3228 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 35.0000 - val_accuracy: 0.7039 - val_precision: 0.6842 - val_recall: 0.5270 - val_auc: 0.8262\n",
      "Epoch 261/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3356 - tp: 125.0000 - fp: 182.0000 - tn: 262.0000 - fn: 143.0000 - accuracy: 0.5435 - precision: 0.4072 - recall: 0.4664 - auc: 0.5613 - val_loss: 1.3220 - val_tp: 40.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 34.0000 - val_accuracy: 0.7095 - val_precision: 0.6897 - val_recall: 0.5405 - val_auc: 0.8237\n",
      "Epoch 262/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.3332 - tp: 135.0000 - fp: 192.0000 - tn: 252.0000 - fn: 133.0000 - accuracy: 0.5435 - precision: 0.4128 - recall: 0.5037 - auc: 0.5638 - val_loss: 1.3212 - val_tp: 41.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 33.0000 - val_accuracy: 0.7151 - val_precision: 0.6949 - val_recall: 0.5541 - val_auc: 0.8241\n",
      "Epoch 263/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.3215 - tp: 147.0000 - fp: 170.0000 - tn: 274.0000 - fn: 121.0000 - accuracy: 0.5913 - precision: 0.4637 - recall: 0.5485 - auc: 0.6268 - val_loss: 1.3202 - val_tp: 41.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 33.0000 - val_accuracy: 0.7151 - val_precision: 0.6949 - val_recall: 0.5541 - val_auc: 0.8232\n",
      "Epoch 264/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.3232 - tp: 148.0000 - fp: 182.0000 - tn: 262.0000 - fn: 120.0000 - accuracy: 0.5758 - precision: 0.4485 - recall: 0.5522 - auc: 0.6107 - val_loss: 1.3195 - val_tp: 41.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 33.0000 - val_accuracy: 0.7151 - val_precision: 0.6949 - val_recall: 0.5541 - val_auc: 0.8236\n",
      "Epoch 265/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.3244 - tp: 142.0000 - fp: 169.0000 - tn: 275.0000 - fn: 126.0000 - accuracy: 0.5857 - precision: 0.4566 - recall: 0.5299 - auc: 0.6080 - val_loss: 1.3187 - val_tp: 41.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 33.0000 - val_accuracy: 0.7151 - val_precision: 0.6949 - val_recall: 0.5541 - val_auc: 0.8256\n",
      "Epoch 266/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.3300 - tp: 135.0000 - fp: 167.0000 - tn: 277.0000 - fn: 133.0000 - accuracy: 0.5787 - precision: 0.4470 - recall: 0.5037 - auc: 0.5792 - val_loss: 1.3179 - val_tp: 41.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 33.0000 - val_accuracy: 0.7151 - val_precision: 0.6949 - val_recall: 0.5541 - val_auc: 0.8232\n",
      "Epoch 267/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3265 - tp: 138.0000 - fp: 173.0000 - tn: 271.0000 - fn: 130.0000 - accuracy: 0.5744 - precision: 0.4437 - recall: 0.5149 - auc: 0.5847 - val_loss: 1.3171 - val_tp: 41.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 33.0000 - val_accuracy: 0.7151 - val_precision: 0.6949 - val_recall: 0.5541 - val_auc: 0.8227\n",
      "Epoch 268/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.3227 - tp: 148.0000 - fp: 164.0000 - tn: 280.0000 - fn: 120.0000 - accuracy: 0.6011 - precision: 0.4744 - recall: 0.5522 - auc: 0.6021 - val_loss: 1.3163 - val_tp: 41.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 33.0000 - val_accuracy: 0.7151 - val_precision: 0.6949 - val_recall: 0.5541 - val_auc: 0.8235\n",
      "Epoch 269/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.3277 - tp: 140.0000 - fp: 180.0000 - tn: 264.0000 - fn: 128.0000 - accuracy: 0.5674 - precision: 0.4375 - recall: 0.5224 - auc: 0.5846 - val_loss: 1.3155 - val_tp: 41.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 33.0000 - val_accuracy: 0.7151 - val_precision: 0.6949 - val_recall: 0.5541 - val_auc: 0.8242\n",
      "Epoch 270/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3196 - tp: 152.0000 - fp: 178.0000 - tn: 266.0000 - fn: 116.0000 - accuracy: 0.5871 - precision: 0.4606 - recall: 0.5672 - auc: 0.6088 - val_loss: 1.3147 - val_tp: 41.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 33.0000 - val_accuracy: 0.7151 - val_precision: 0.6949 - val_recall: 0.5541 - val_auc: 0.8236\n",
      "Epoch 271/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.3286 - tp: 148.0000 - fp: 174.0000 - tn: 270.0000 - fn: 120.0000 - accuracy: 0.5871 - precision: 0.4596 - recall: 0.5522 - auc: 0.5805 - val_loss: 1.3140 - val_tp: 41.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 33.0000 - val_accuracy: 0.7151 - val_precision: 0.6949 - val_recall: 0.5541 - val_auc: 0.8258\n",
      "Epoch 272/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3264 - tp: 140.0000 - fp: 188.0000 - tn: 256.0000 - fn: 128.0000 - accuracy: 0.5562 - precision: 0.4268 - recall: 0.5224 - auc: 0.5706 - val_loss: 1.3131 - val_tp: 41.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 33.0000 - val_accuracy: 0.7151 - val_precision: 0.6949 - val_recall: 0.5541 - val_auc: 0.8258\n",
      "Epoch 273/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3081 - tp: 159.0000 - fp: 168.0000 - tn: 276.0000 - fn: 109.0000 - accuracy: 0.6110 - precision: 0.4862 - recall: 0.5933 - auc: 0.6489 - val_loss: 1.3123 - val_tp: 41.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 33.0000 - val_accuracy: 0.7151 - val_precision: 0.6949 - val_recall: 0.5541 - val_auc: 0.8243\n",
      "Epoch 274/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.3245 - tp: 136.0000 - fp: 175.0000 - tn: 269.0000 - fn: 132.0000 - accuracy: 0.5688 - precision: 0.4373 - recall: 0.5075 - auc: 0.5838 - val_loss: 1.3114 - val_tp: 42.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 32.0000 - val_accuracy: 0.7207 - val_precision: 0.7000 - val_recall: 0.5676 - val_auc: 0.8234\n",
      "Epoch 275/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.3234 - tp: 143.0000 - fp: 179.0000 - tn: 265.0000 - fn: 125.0000 - accuracy: 0.5730 - precision: 0.4441 - recall: 0.5336 - auc: 0.5799 - val_loss: 1.3106 - val_tp: 42.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 32.0000 - val_accuracy: 0.7207 - val_precision: 0.7000 - val_recall: 0.5676 - val_auc: 0.8238\n",
      "Epoch 276/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.3156 - tp: 158.0000 - fp: 177.0000 - tn: 267.0000 - fn: 110.0000 - accuracy: 0.5969 - precision: 0.4716 - recall: 0.5896 - auc: 0.6198 - val_loss: 1.3098 - val_tp: 42.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 32.0000 - val_accuracy: 0.7207 - val_precision: 0.7000 - val_recall: 0.5676 - val_auc: 0.8245\n",
      "Epoch 277/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.3138 - tp: 149.0000 - fp: 177.0000 - tn: 267.0000 - fn: 119.0000 - accuracy: 0.5843 - precision: 0.4571 - recall: 0.5560 - auc: 0.6129 - val_loss: 1.3091 - val_tp: 42.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 32.0000 - val_accuracy: 0.7207 - val_precision: 0.7000 - val_recall: 0.5676 - val_auc: 0.8261\n",
      "Epoch 278/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.3203 - tp: 142.0000 - fp: 195.0000 - tn: 249.0000 - fn: 126.0000 - accuracy: 0.5492 - precision: 0.4214 - recall: 0.5299 - auc: 0.5817 - val_loss: 1.3082 - val_tp: 42.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 32.0000 - val_accuracy: 0.7207 - val_precision: 0.7000 - val_recall: 0.5676 - val_auc: 0.8240\n",
      "Epoch 279/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.3141 - tp: 153.0000 - fp: 182.0000 - tn: 262.0000 - fn: 115.0000 - accuracy: 0.5829 - precision: 0.4567 - recall: 0.5709 - auc: 0.6118 - val_loss: 1.3075 - val_tp: 42.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 32.0000 - val_accuracy: 0.7207 - val_precision: 0.7000 - val_recall: 0.5676 - val_auc: 0.8266\n",
      "Epoch 280/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.3101 - tp: 149.0000 - fp: 178.0000 - tn: 266.0000 - fn: 119.0000 - accuracy: 0.5829 - precision: 0.4557 - recall: 0.5560 - auc: 0.6246 - val_loss: 1.3065 - val_tp: 43.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 31.0000 - val_accuracy: 0.7263 - val_precision: 0.7049 - val_recall: 0.5811 - val_auc: 0.8253\n",
      "Epoch 281/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3170 - tp: 140.0000 - fp: 174.0000 - tn: 270.0000 - fn: 128.0000 - accuracy: 0.5758 - precision: 0.4459 - recall: 0.5224 - auc: 0.5918 - val_loss: 1.3058 - val_tp: 43.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 31.0000 - val_accuracy: 0.7263 - val_precision: 0.7049 - val_recall: 0.5811 - val_auc: 0.8253\n",
      "Epoch 282/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.3096 - tp: 153.0000 - fp: 178.0000 - tn: 266.0000 - fn: 115.0000 - accuracy: 0.5885 - precision: 0.4622 - recall: 0.5709 - auc: 0.6231 - val_loss: 1.3049 - val_tp: 43.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 31.0000 - val_accuracy: 0.7207 - val_precision: 0.6935 - val_recall: 0.5811 - val_auc: 0.8229\n",
      "Epoch 283/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.3128 - tp: 152.0000 - fp: 175.0000 - tn: 269.0000 - fn: 116.0000 - accuracy: 0.5913 - precision: 0.4648 - recall: 0.5672 - auc: 0.6060 - val_loss: 1.3042 - val_tp: 43.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 31.0000 - val_accuracy: 0.7263 - val_precision: 0.7049 - val_recall: 0.5811 - val_auc: 0.8236\n",
      "Epoch 284/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3176 - tp: 142.0000 - fp: 183.0000 - tn: 261.0000 - fn: 126.0000 - accuracy: 0.5660 - precision: 0.4369 - recall: 0.5299 - auc: 0.5909 - val_loss: 1.3034 - val_tp: 43.0000 - val_fp: 18.0000 - val_tn: 87.0000 - val_fn: 31.0000 - val_accuracy: 0.7263 - val_precision: 0.7049 - val_recall: 0.5811 - val_auc: 0.8242\n",
      "Epoch 285/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.3147 - tp: 126.0000 - fp: 169.0000 - tn: 275.0000 - fn: 142.0000 - accuracy: 0.5632 - precision: 0.4271 - recall: 0.4701 - auc: 0.5868 - val_loss: 1.3025 - val_tp: 43.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 31.0000 - val_accuracy: 0.7207 - val_precision: 0.6935 - val_recall: 0.5811 - val_auc: 0.8237\n",
      "Epoch 286/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.3018 - tp: 157.0000 - fp: 160.0000 - tn: 284.0000 - fn: 111.0000 - accuracy: 0.6194 - precision: 0.4953 - recall: 0.5858 - auc: 0.6516 - val_loss: 1.3017 - val_tp: 43.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 31.0000 - val_accuracy: 0.7207 - val_precision: 0.6935 - val_recall: 0.5811 - val_auc: 0.8239\n",
      "Epoch 287/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3160 - tp: 140.0000 - fp: 189.0000 - tn: 255.0000 - fn: 128.0000 - accuracy: 0.5548 - precision: 0.4255 - recall: 0.5224 - auc: 0.5709 - val_loss: 1.3009 - val_tp: 43.0000 - val_fp: 19.0000 - val_tn: 86.0000 - val_fn: 31.0000 - val_accuracy: 0.7207 - val_precision: 0.6935 - val_recall: 0.5811 - val_auc: 0.8264\n",
      "Epoch 288/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.3051 - tp: 151.0000 - fp: 167.0000 - tn: 277.0000 - fn: 117.0000 - accuracy: 0.6011 - precision: 0.4748 - recall: 0.5634 - auc: 0.6294 - val_loss: 1.3000 - val_tp: 43.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 31.0000 - val_accuracy: 0.7151 - val_precision: 0.6825 - val_recall: 0.5811 - val_auc: 0.8246\n",
      "Epoch 289/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.3020 - tp: 148.0000 - fp: 157.0000 - tn: 287.0000 - fn: 120.0000 - accuracy: 0.6110 - precision: 0.4852 - recall: 0.5522 - auc: 0.6462 - val_loss: 1.2992 - val_tp: 43.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 31.0000 - val_accuracy: 0.7151 - val_precision: 0.6825 - val_recall: 0.5811 - val_auc: 0.8254\n",
      "Epoch 290/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.3110 - tp: 140.0000 - fp: 178.0000 - tn: 266.0000 - fn: 128.0000 - accuracy: 0.5702 - precision: 0.4403 - recall: 0.5224 - auc: 0.5936 - val_loss: 1.2984 - val_tp: 43.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 31.0000 - val_accuracy: 0.7095 - val_precision: 0.6719 - val_recall: 0.5811 - val_auc: 0.8256\n",
      "Epoch 291/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.3179 - tp: 142.0000 - fp: 181.0000 - tn: 263.0000 - fn: 126.0000 - accuracy: 0.5688 - precision: 0.4396 - recall: 0.5299 - auc: 0.5674 - val_loss: 1.2976 - val_tp: 43.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 31.0000 - val_accuracy: 0.7151 - val_precision: 0.6825 - val_recall: 0.5811 - val_auc: 0.8268\n",
      "Epoch 292/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.3055 - tp: 158.0000 - fp: 177.0000 - tn: 267.0000 - fn: 110.0000 - accuracy: 0.5969 - precision: 0.4716 - recall: 0.5896 - auc: 0.6241 - val_loss: 1.2968 - val_tp: 43.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 31.0000 - val_accuracy: 0.7151 - val_precision: 0.6825 - val_recall: 0.5811 - val_auc: 0.8268\n",
      "Epoch 293/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3123 - tp: 150.0000 - fp: 191.0000 - tn: 253.0000 - fn: 118.0000 - accuracy: 0.5660 - precision: 0.4399 - recall: 0.5597 - auc: 0.5909 - val_loss: 1.2960 - val_tp: 43.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 31.0000 - val_accuracy: 0.7151 - val_precision: 0.6825 - val_recall: 0.5811 - val_auc: 0.8263\n",
      "Epoch 294/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.3007 - tp: 152.0000 - fp: 147.0000 - tn: 297.0000 - fn: 116.0000 - accuracy: 0.6306 - precision: 0.5084 - recall: 0.5672 - auc: 0.6335 - val_loss: 1.2952 - val_tp: 43.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 31.0000 - val_accuracy: 0.7151 - val_precision: 0.6825 - val_recall: 0.5811 - val_auc: 0.8263\n",
      "Epoch 295/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3024 - tp: 149.0000 - fp: 183.0000 - tn: 261.0000 - fn: 119.0000 - accuracy: 0.5758 - precision: 0.4488 - recall: 0.5560 - auc: 0.6189 - val_loss: 1.2945 - val_tp: 43.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 31.0000 - val_accuracy: 0.7151 - val_precision: 0.6825 - val_recall: 0.5811 - val_auc: 0.8256\n",
      "Epoch 296/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.2981 - tp: 153.0000 - fp: 179.0000 - tn: 265.0000 - fn: 115.0000 - accuracy: 0.5871 - precision: 0.4608 - recall: 0.5709 - auc: 0.6344 - val_loss: 1.2938 - val_tp: 43.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 31.0000 - val_accuracy: 0.7151 - val_precision: 0.6825 - val_recall: 0.5811 - val_auc: 0.8272\n",
      "Epoch 297/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.3001 - tp: 147.0000 - fp: 152.0000 - tn: 292.0000 - fn: 121.0000 - accuracy: 0.6166 - precision: 0.4916 - recall: 0.5485 - auc: 0.6274 - val_loss: 1.2929 - val_tp: 43.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 31.0000 - val_accuracy: 0.7151 - val_precision: 0.6825 - val_recall: 0.5811 - val_auc: 0.8267\n",
      "Epoch 298/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3031 - tp: 148.0000 - fp: 180.0000 - tn: 264.0000 - fn: 120.0000 - accuracy: 0.5787 - precision: 0.4512 - recall: 0.5522 - auc: 0.6104 - val_loss: 1.2921 - val_tp: 43.0000 - val_fp: 20.0000 - val_tn: 85.0000 - val_fn: 31.0000 - val_accuracy: 0.7151 - val_precision: 0.6825 - val_recall: 0.5811 - val_auc: 0.8256\n",
      "Epoch 299/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.2877 - tp: 164.0000 - fp: 176.0000 - tn: 268.0000 - fn: 104.0000 - accuracy: 0.6067 - precision: 0.4824 - recall: 0.6119 - auc: 0.6647 - val_loss: 1.2912 - val_tp: 43.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 31.0000 - val_accuracy: 0.7095 - val_precision: 0.6719 - val_recall: 0.5811 - val_auc: 0.8268\n",
      "Epoch 300/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.3000 - tp: 145.0000 - fp: 159.0000 - tn: 285.0000 - fn: 123.0000 - accuracy: 0.6039 - precision: 0.4770 - recall: 0.5410 - auc: 0.6185 - val_loss: 1.2903 - val_tp: 43.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 31.0000 - val_accuracy: 0.7095 - val_precision: 0.6719 - val_recall: 0.5811 - val_auc: 0.8263\n",
      "Epoch 301/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.2940 - tp: 143.0000 - fp: 154.0000 - tn: 290.0000 - fn: 125.0000 - accuracy: 0.6081 - precision: 0.4815 - recall: 0.5336 - auc: 0.6364 - val_loss: 1.2894 - val_tp: 43.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 31.0000 - val_accuracy: 0.7095 - val_precision: 0.6719 - val_recall: 0.5811 - val_auc: 0.8268\n",
      "Epoch 302/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.2994 - tp: 148.0000 - fp: 165.0000 - tn: 279.0000 - fn: 120.0000 - accuracy: 0.5997 - precision: 0.4728 - recall: 0.5522 - auc: 0.6238 - val_loss: 1.2886 - val_tp: 43.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 31.0000 - val_accuracy: 0.7095 - val_precision: 0.6719 - val_recall: 0.5811 - val_auc: 0.8275\n",
      "Epoch 303/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.3000 - tp: 142.0000 - fp: 164.0000 - tn: 280.0000 - fn: 126.0000 - accuracy: 0.5927 - precision: 0.4641 - recall: 0.5299 - auc: 0.6163 - val_loss: 1.2878 - val_tp: 43.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 31.0000 - val_accuracy: 0.7095 - val_precision: 0.6719 - val_recall: 0.5811 - val_auc: 0.8263\n",
      "Epoch 304/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.2941 - tp: 161.0000 - fp: 178.0000 - tn: 266.0000 - fn: 107.0000 - accuracy: 0.5997 - precision: 0.4749 - recall: 0.6007 - auc: 0.6344 - val_loss: 1.2871 - val_tp: 43.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 31.0000 - val_accuracy: 0.7095 - val_precision: 0.6719 - val_recall: 0.5811 - val_auc: 0.8259\n",
      "Epoch 305/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.2943 - tp: 156.0000 - fp: 171.0000 - tn: 273.0000 - fn: 112.0000 - accuracy: 0.6025 - precision: 0.4771 - recall: 0.5821 - auc: 0.6302 - val_loss: 1.2863 - val_tp: 43.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 31.0000 - val_accuracy: 0.7095 - val_precision: 0.6719 - val_recall: 0.5811 - val_auc: 0.8256\n",
      "Epoch 306/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.2963 - tp: 153.0000 - fp: 173.0000 - tn: 271.0000 - fn: 115.0000 - accuracy: 0.5955 - precision: 0.4693 - recall: 0.5709 - auc: 0.6261 - val_loss: 1.2855 - val_tp: 43.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 31.0000 - val_accuracy: 0.7095 - val_precision: 0.6719 - val_recall: 0.5811 - val_auc: 0.8288\n",
      "Epoch 307/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2914 - tp: 150.0000 - fp: 158.0000 - tn: 286.0000 - fn: 118.0000 - accuracy: 0.6124 - precision: 0.4870 - recall: 0.5597 - auc: 0.6408 - val_loss: 1.2846 - val_tp: 43.0000 - val_fp: 21.0000 - val_tn: 84.0000 - val_fn: 31.0000 - val_accuracy: 0.7095 - val_precision: 0.6719 - val_recall: 0.5811 - val_auc: 0.8261\n",
      "Epoch 308/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.2959 - tp: 142.0000 - fp: 155.0000 - tn: 289.0000 - fn: 126.0000 - accuracy: 0.6053 - precision: 0.4781 - recall: 0.5299 - auc: 0.6186 - val_loss: 1.2837 - val_tp: 43.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 31.0000 - val_accuracy: 0.7039 - val_precision: 0.6615 - val_recall: 0.5811 - val_auc: 0.8288\n",
      "Epoch 309/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3004 - tp: 145.0000 - fp: 170.0000 - tn: 274.0000 - fn: 123.0000 - accuracy: 0.5885 - precision: 0.4603 - recall: 0.5410 - auc: 0.6023 - val_loss: 1.2830 - val_tp: 43.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 31.0000 - val_accuracy: 0.7039 - val_precision: 0.6615 - val_recall: 0.5811 - val_auc: 0.8289\n",
      "Epoch 310/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2915 - tp: 145.0000 - fp: 170.0000 - tn: 274.0000 - fn: 123.0000 - accuracy: 0.5885 - precision: 0.4603 - recall: 0.5410 - auc: 0.6268 - val_loss: 1.2821 - val_tp: 43.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 31.0000 - val_accuracy: 0.7039 - val_precision: 0.6615 - val_recall: 0.5811 - val_auc: 0.8286\n",
      "Epoch 311/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.2875 - tp: 158.0000 - fp: 170.0000 - tn: 274.0000 - fn: 110.0000 - accuracy: 0.6067 - precision: 0.4817 - recall: 0.5896 - auc: 0.6487 - val_loss: 1.2813 - val_tp: 43.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 31.0000 - val_accuracy: 0.7039 - val_precision: 0.6615 - val_recall: 0.5811 - val_auc: 0.8287\n",
      "Epoch 312/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.3000 - tp: 140.0000 - fp: 168.0000 - tn: 276.0000 - fn: 128.0000 - accuracy: 0.5843 - precision: 0.4545 - recall: 0.5224 - auc: 0.5979 - val_loss: 1.2805 - val_tp: 43.0000 - val_fp: 22.0000 - val_tn: 83.0000 - val_fn: 31.0000 - val_accuracy: 0.7039 - val_precision: 0.6615 - val_recall: 0.5811 - val_auc: 0.8284\n",
      "Epoch 313/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.2891 - tp: 145.0000 - fp: 163.0000 - tn: 281.0000 - fn: 123.0000 - accuracy: 0.5983 - precision: 0.4708 - recall: 0.5410 - auc: 0.6409 - val_loss: 1.2796 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8285\n",
      "Epoch 314/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2848 - tp: 161.0000 - fp: 151.0000 - tn: 293.0000 - fn: 107.0000 - accuracy: 0.6376 - precision: 0.5160 - recall: 0.6007 - auc: 0.6611 - val_loss: 1.2787 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8292\n",
      "Epoch 315/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2967 - tp: 144.0000 - fp: 172.0000 - tn: 272.0000 - fn: 124.0000 - accuracy: 0.5843 - precision: 0.4557 - recall: 0.5373 - auc: 0.5949 - val_loss: 1.2779 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8292\n",
      "Epoch 316/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.3000 - tp: 152.0000 - fp: 184.0000 - tn: 260.0000 - fn: 116.0000 - accuracy: 0.5787 - precision: 0.4524 - recall: 0.5672 - auc: 0.5863 - val_loss: 1.2771 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8272\n",
      "Epoch 317/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2868 - tp: 159.0000 - fp: 168.0000 - tn: 276.0000 - fn: 109.0000 - accuracy: 0.6110 - precision: 0.4862 - recall: 0.5933 - auc: 0.6467 - val_loss: 1.2763 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8292\n",
      "Epoch 318/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2852 - tp: 157.0000 - fp: 176.0000 - tn: 268.0000 - fn: 111.0000 - accuracy: 0.5969 - precision: 0.4715 - recall: 0.5858 - auc: 0.6359 - val_loss: 1.2755 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8292\n",
      "Epoch 319/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.2907 - tp: 138.0000 - fp: 170.0000 - tn: 274.0000 - fn: 130.0000 - accuracy: 0.5787 - precision: 0.4481 - recall: 0.5149 - auc: 0.6129 - val_loss: 1.2746 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8270\n",
      "Epoch 320/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.2820 - tp: 156.0000 - fp: 162.0000 - tn: 282.0000 - fn: 112.0000 - accuracy: 0.6152 - precision: 0.4906 - recall: 0.5821 - auc: 0.6492 - val_loss: 1.2739 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8265\n",
      "Epoch 321/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2816 - tp: 157.0000 - fp: 174.0000 - tn: 270.0000 - fn: 111.0000 - accuracy: 0.5997 - precision: 0.4743 - recall: 0.5858 - auc: 0.6422 - val_loss: 1.2730 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8265\n",
      "Epoch 322/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.2878 - tp: 146.0000 - fp: 158.0000 - tn: 286.0000 - fn: 122.0000 - accuracy: 0.6067 - precision: 0.4803 - recall: 0.5448 - auc: 0.6235 - val_loss: 1.2723 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8277\n",
      "Epoch 323/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.2912 - tp: 152.0000 - fp: 165.0000 - tn: 279.0000 - fn: 116.0000 - accuracy: 0.6053 - precision: 0.4795 - recall: 0.5672 - auc: 0.6121 - val_loss: 1.2714 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8273\n",
      "Epoch 324/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2831 - tp: 144.0000 - fp: 157.0000 - tn: 287.0000 - fn: 124.0000 - accuracy: 0.6053 - precision: 0.4784 - recall: 0.5373 - auc: 0.6283 - val_loss: 1.2706 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8263\n",
      "Epoch 325/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2838 - tp: 146.0000 - fp: 165.0000 - tn: 279.0000 - fn: 122.0000 - accuracy: 0.5969 - precision: 0.4695 - recall: 0.5448 - auc: 0.6239 - val_loss: 1.2699 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8259\n",
      "Epoch 326/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.2843 - tp: 156.0000 - fp: 177.0000 - tn: 267.0000 - fn: 112.0000 - accuracy: 0.5941 - precision: 0.4685 - recall: 0.5821 - auc: 0.6303 - val_loss: 1.2691 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8279\n",
      "Epoch 327/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.2802 - tp: 155.0000 - fp: 158.0000 - tn: 286.0000 - fn: 113.0000 - accuracy: 0.6194 - precision: 0.4952 - recall: 0.5784 - auc: 0.6454 - val_loss: 1.2682 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8275\n",
      "Epoch 328/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.2862 - tp: 140.0000 - fp: 160.0000 - tn: 284.0000 - fn: 128.0000 - accuracy: 0.5955 - precision: 0.4667 - recall: 0.5224 - auc: 0.6211 - val_loss: 1.2674 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8288\n",
      "Epoch 329/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.2770 - tp: 151.0000 - fp: 152.0000 - tn: 292.0000 - fn: 117.0000 - accuracy: 0.6222 - precision: 0.4983 - recall: 0.5634 - auc: 0.6436 - val_loss: 1.2666 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8277\n",
      "Epoch 330/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.2907 - tp: 141.0000 - fp: 173.0000 - tn: 271.0000 - fn: 127.0000 - accuracy: 0.5787 - precision: 0.4490 - recall: 0.5261 - auc: 0.5921 - val_loss: 1.2658 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8275\n",
      "Epoch 331/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 1.2838 - tp: 157.0000 - fp: 170.0000 - tn: 274.0000 - fn: 111.0000 - accuracy: 0.6053 - precision: 0.4801 - recall: 0.5858 - auc: 0.6218 - val_loss: 1.2649 - val_tp: 45.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 29.0000 - val_accuracy: 0.7095 - val_precision: 0.6618 - val_recall: 0.6081 - val_auc: 0.8261\n",
      "Epoch 332/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.2735 - tp: 155.0000 - fp: 153.0000 - tn: 291.0000 - fn: 113.0000 - accuracy: 0.6264 - precision: 0.5032 - recall: 0.5784 - auc: 0.6551 - val_loss: 1.2642 - val_tp: 44.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 30.0000 - val_accuracy: 0.7039 - val_precision: 0.6567 - val_recall: 0.5946 - val_auc: 0.8277\n",
      "Epoch 333/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.2689 - tp: 161.0000 - fp: 150.0000 - tn: 294.0000 - fn: 107.0000 - accuracy: 0.6390 - precision: 0.5177 - recall: 0.6007 - auc: 0.6826 - val_loss: 1.2633 - val_tp: 46.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 28.0000 - val_accuracy: 0.7151 - val_precision: 0.6667 - val_recall: 0.6216 - val_auc: 0.8267\n",
      "Epoch 334/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.2772 - tp: 151.0000 - fp: 158.0000 - tn: 286.0000 - fn: 117.0000 - accuracy: 0.6138 - precision: 0.4887 - recall: 0.5634 - auc: 0.6451 - val_loss: 1.2624 - val_tp: 46.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 28.0000 - val_accuracy: 0.7151 - val_precision: 0.6667 - val_recall: 0.6216 - val_auc: 0.8259\n",
      "Epoch 335/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.2857 - tp: 143.0000 - fp: 175.0000 - tn: 269.0000 - fn: 125.0000 - accuracy: 0.5787 - precision: 0.4497 - recall: 0.5336 - auc: 0.5981 - val_loss: 1.2616 - val_tp: 46.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 28.0000 - val_accuracy: 0.7151 - val_precision: 0.6667 - val_recall: 0.6216 - val_auc: 0.8287\n",
      "Epoch 336/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.2746 - tp: 161.0000 - fp: 167.0000 - tn: 277.0000 - fn: 107.0000 - accuracy: 0.6152 - precision: 0.4909 - recall: 0.6007 - auc: 0.6497 - val_loss: 1.2608 - val_tp: 46.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 28.0000 - val_accuracy: 0.7151 - val_precision: 0.6667 - val_recall: 0.6216 - val_auc: 0.8311\n",
      "Epoch 337/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2662 - tp: 163.0000 - fp: 161.0000 - tn: 283.0000 - fn: 105.0000 - accuracy: 0.6264 - precision: 0.5031 - recall: 0.6082 - auc: 0.6691 - val_loss: 1.2600 - val_tp: 46.0000 - val_fp: 23.0000 - val_tn: 82.0000 - val_fn: 28.0000 - val_accuracy: 0.7151 - val_precision: 0.6667 - val_recall: 0.6216 - val_auc: 0.8311\n",
      "Epoch 338/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.2689 - tp: 163.0000 - fp: 154.0000 - tn: 290.0000 - fn: 105.0000 - accuracy: 0.6362 - precision: 0.5142 - recall: 0.6082 - auc: 0.6728 - val_loss: 1.2591 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8315\n",
      "Epoch 339/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.2769 - tp: 148.0000 - fp: 170.0000 - tn: 274.0000 - fn: 120.0000 - accuracy: 0.5927 - precision: 0.4654 - recall: 0.5522 - auc: 0.6288 - val_loss: 1.2583 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8302\n",
      "Epoch 340/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.2788 - tp: 142.0000 - fp: 166.0000 - tn: 278.0000 - fn: 126.0000 - accuracy: 0.5899 - precision: 0.4610 - recall: 0.5299 - auc: 0.6223 - val_loss: 1.2574 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8313\n",
      "Epoch 341/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2667 - tp: 152.0000 - fp: 157.0000 - tn: 287.0000 - fn: 116.0000 - accuracy: 0.6166 - precision: 0.4919 - recall: 0.5672 - auc: 0.6617 - val_loss: 1.2565 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8311\n",
      "Epoch 342/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.2699 - tp: 156.0000 - fp: 160.0000 - tn: 284.0000 - fn: 112.0000 - accuracy: 0.6180 - precision: 0.4937 - recall: 0.5821 - auc: 0.6475 - val_loss: 1.2557 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8297\n",
      "Epoch 343/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2768 - tp: 144.0000 - fp: 169.0000 - tn: 275.0000 - fn: 124.0000 - accuracy: 0.5885 - precision: 0.4601 - recall: 0.5373 - auc: 0.6292 - val_loss: 1.2548 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8283\n",
      "Epoch 344/600\n",
      "712/712 [==============================] - 0s 145us/sample - loss: 1.2634 - tp: 153.0000 - fp: 152.0000 - tn: 292.0000 - fn: 115.0000 - accuracy: 0.6250 - precision: 0.5016 - recall: 0.5709 - auc: 0.6654 - val_loss: 1.2539 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8293\n",
      "Epoch 345/600\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 1.2670 - tp: 162.0000 - fp: 165.0000 - tn: 279.0000 - fn: 106.0000 - accuracy: 0.6194 - precision: 0.4954 - recall: 0.6045 - auc: 0.6542 - val_loss: 1.2530 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8280\n",
      "Epoch 346/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.2698 - tp: 151.0000 - fp: 157.0000 - tn: 287.0000 - fn: 117.0000 - accuracy: 0.6152 - precision: 0.4903 - recall: 0.5634 - auc: 0.6431 - val_loss: 1.2521 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8279\n",
      "Epoch 347/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.2621 - tp: 164.0000 - fp: 152.0000 - tn: 292.0000 - fn: 104.0000 - accuracy: 0.6404 - precision: 0.5190 - recall: 0.6119 - auc: 0.6736 - val_loss: 1.2513 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8275\n",
      "Epoch 348/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.2586 - tp: 172.0000 - fp: 163.0000 - tn: 281.0000 - fn: 96.0000 - accuracy: 0.6362 - precision: 0.5134 - recall: 0.6418 - auc: 0.6780 - val_loss: 1.2504 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8294\n",
      "Epoch 349/600\n",
      "712/712 [==============================] - 0s 141us/sample - loss: 1.2591 - tp: 167.0000 - fp: 155.0000 - tn: 289.0000 - fn: 101.0000 - accuracy: 0.6404 - precision: 0.5186 - recall: 0.6231 - auc: 0.6758 - val_loss: 1.2495 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8299\n",
      "Epoch 350/600\n",
      "712/712 [==============================] - 0s 144us/sample - loss: 1.2712 - tp: 146.0000 - fp: 168.0000 - tn: 276.0000 - fn: 122.0000 - accuracy: 0.5927 - precision: 0.4650 - recall: 0.5448 - auc: 0.6293 - val_loss: 1.2488 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8317\n",
      "Epoch 351/600\n",
      "712/712 [==============================] - 0s 174us/sample - loss: 1.2602 - tp: 159.0000 - fp: 154.0000 - tn: 290.0000 - fn: 109.0000 - accuracy: 0.6306 - precision: 0.5080 - recall: 0.5933 - auc: 0.6652 - val_loss: 1.2479 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8299\n",
      "Epoch 352/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.2594 - tp: 152.0000 - fp: 152.0000 - tn: 292.0000 - fn: 116.0000 - accuracy: 0.6236 - precision: 0.5000 - recall: 0.5672 - auc: 0.6650 - val_loss: 1.2470 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8313\n",
      "Epoch 353/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.2557 - tp: 168.0000 - fp: 144.0000 - tn: 300.0000 - fn: 100.0000 - accuracy: 0.6573 - precision: 0.5385 - recall: 0.6269 - auc: 0.6895 - val_loss: 1.2460 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8299\n",
      "Epoch 354/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2589 - tp: 166.0000 - fp: 160.0000 - tn: 284.0000 - fn: 102.0000 - accuracy: 0.6320 - precision: 0.5092 - recall: 0.6194 - auc: 0.6588 - val_loss: 1.2452 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8302\n",
      "Epoch 355/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.2598 - tp: 157.0000 - fp: 153.0000 - tn: 291.0000 - fn: 111.0000 - accuracy: 0.6292 - precision: 0.5065 - recall: 0.5858 - auc: 0.6608 - val_loss: 1.2444 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8279\n",
      "Epoch 356/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.2677 - tp: 155.0000 - fp: 159.0000 - tn: 285.0000 - fn: 113.0000 - accuracy: 0.6180 - precision: 0.4936 - recall: 0.5784 - auc: 0.6226 - val_loss: 1.2436 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8281\n",
      "Epoch 357/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 1.2618 - tp: 151.0000 - fp: 158.0000 - tn: 286.0000 - fn: 117.0000 - accuracy: 0.6138 - precision: 0.4887 - recall: 0.5634 - auc: 0.6477 - val_loss: 1.2427 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8281\n",
      "Epoch 358/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.2537 - tp: 159.0000 - fp: 160.0000 - tn: 284.0000 - fn: 109.0000 - accuracy: 0.6222 - precision: 0.4984 - recall: 0.5933 - auc: 0.6743 - val_loss: 1.2419 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8283\n",
      "Epoch 359/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.2679 - tp: 145.0000 - fp: 169.0000 - tn: 275.0000 - fn: 123.0000 - accuracy: 0.5899 - precision: 0.4618 - recall: 0.5410 - auc: 0.6259 - val_loss: 1.2411 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8317\n",
      "Epoch 360/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.2538 - tp: 151.0000 - fp: 148.0000 - tn: 296.0000 - fn: 117.0000 - accuracy: 0.6278 - precision: 0.5050 - recall: 0.5634 - auc: 0.6664 - val_loss: 1.2403 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8314\n",
      "Epoch 361/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.2582 - tp: 149.0000 - fp: 154.0000 - tn: 290.0000 - fn: 119.0000 - accuracy: 0.6166 - precision: 0.4917 - recall: 0.5560 - auc: 0.6534 - val_loss: 1.2395 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8310\n",
      "Epoch 362/600\n",
      "712/712 [==============================] - 0s 142us/sample - loss: 1.2610 - tp: 154.0000 - fp: 148.0000 - tn: 296.0000 - fn: 114.0000 - accuracy: 0.6320 - precision: 0.5099 - recall: 0.5746 - auc: 0.6506 - val_loss: 1.2386 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8317\n",
      "Epoch 363/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2551 - tp: 156.0000 - fp: 148.0000 - tn: 296.0000 - fn: 112.0000 - accuracy: 0.6348 - precision: 0.5132 - recall: 0.5821 - auc: 0.6609 - val_loss: 1.2377 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8300\n",
      "Epoch 364/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2584 - tp: 158.0000 - fp: 156.0000 - tn: 288.0000 - fn: 110.0000 - accuracy: 0.6264 - precision: 0.5032 - recall: 0.5896 - auc: 0.6563 - val_loss: 1.2369 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8304\n",
      "Epoch 365/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2541 - tp: 155.0000 - fp: 153.0000 - tn: 291.0000 - fn: 113.0000 - accuracy: 0.6264 - precision: 0.5032 - recall: 0.5784 - auc: 0.6668 - val_loss: 1.2360 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8312\n",
      "Epoch 366/600\n",
      "712/712 [==============================] - 0s 140us/sample - loss: 1.2589 - tp: 158.0000 - fp: 156.0000 - tn: 288.0000 - fn: 110.0000 - accuracy: 0.6264 - precision: 0.5032 - recall: 0.5896 - auc: 0.6432 - val_loss: 1.2351 - val_tp: 47.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 27.0000 - val_accuracy: 0.7151 - val_precision: 0.6620 - val_recall: 0.6351 - val_auc: 0.8296\n",
      "Epoch 367/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.2576 - tp: 154.0000 - fp: 155.0000 - tn: 289.0000 - fn: 114.0000 - accuracy: 0.6222 - precision: 0.4984 - recall: 0.5746 - auc: 0.6378 - val_loss: 1.2343 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8291\n",
      "Epoch 368/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.2437 - tp: 158.0000 - fp: 143.0000 - tn: 301.0000 - fn: 110.0000 - accuracy: 0.6447 - precision: 0.5249 - recall: 0.5896 - auc: 0.6897 - val_loss: 1.2334 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 28.0000 - val_accuracy: 0.7095 - val_precision: 0.6571 - val_recall: 0.6216 - val_auc: 0.8289\n",
      "Epoch 369/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2441 - tp: 163.0000 - fp: 140.0000 - tn: 304.0000 - fn: 105.0000 - accuracy: 0.6559 - precision: 0.5380 - recall: 0.6082 - auc: 0.6949 - val_loss: 1.2325 - val_tp: 47.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 27.0000 - val_accuracy: 0.7151 - val_precision: 0.6620 - val_recall: 0.6351 - val_auc: 0.8280\n",
      "Epoch 370/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.2457 - tp: 161.0000 - fp: 145.0000 - tn: 299.0000 - fn: 107.0000 - accuracy: 0.6461 - precision: 0.5261 - recall: 0.6007 - auc: 0.6824 - val_loss: 1.2316 - val_tp: 47.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 27.0000 - val_accuracy: 0.7151 - val_precision: 0.6620 - val_recall: 0.6351 - val_auc: 0.8287\n",
      "Epoch 371/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2443 - tp: 168.0000 - fp: 165.0000 - tn: 279.0000 - fn: 100.0000 - accuracy: 0.6278 - precision: 0.5045 - recall: 0.6269 - auc: 0.6802 - val_loss: 1.2307 - val_tp: 47.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 27.0000 - val_accuracy: 0.7151 - val_precision: 0.6620 - val_recall: 0.6351 - val_auc: 0.8287\n",
      "Epoch 372/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.2486 - tp: 166.0000 - fp: 162.0000 - tn: 282.0000 - fn: 102.0000 - accuracy: 0.6292 - precision: 0.5061 - recall: 0.6194 - auc: 0.6714 - val_loss: 1.2299 - val_tp: 47.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 27.0000 - val_accuracy: 0.7151 - val_precision: 0.6620 - val_recall: 0.6351 - val_auc: 0.8304\n",
      "Epoch 373/600\n",
      "712/712 [==============================] - 0s 129us/sample - loss: 1.2449 - tp: 166.0000 - fp: 152.0000 - tn: 292.0000 - fn: 102.0000 - accuracy: 0.6433 - precision: 0.5220 - recall: 0.6194 - auc: 0.6780 - val_loss: 1.2289 - val_tp: 47.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 27.0000 - val_accuracy: 0.7151 - val_precision: 0.6620 - val_recall: 0.6351 - val_auc: 0.8312\n",
      "Epoch 374/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.2507 - tp: 153.0000 - fp: 144.0000 - tn: 300.0000 - fn: 115.0000 - accuracy: 0.6362 - precision: 0.5152 - recall: 0.5709 - auc: 0.6612 - val_loss: 1.2281 - val_tp: 47.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 27.0000 - val_accuracy: 0.7151 - val_precision: 0.6620 - val_recall: 0.6351 - val_auc: 0.8313\n",
      "Epoch 375/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2410 - tp: 158.0000 - fp: 141.0000 - tn: 303.0000 - fn: 110.0000 - accuracy: 0.6475 - precision: 0.5284 - recall: 0.5896 - auc: 0.6861 - val_loss: 1.2272 - val_tp: 48.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 26.0000 - val_accuracy: 0.7207 - val_precision: 0.6667 - val_recall: 0.6486 - val_auc: 0.8300\n",
      "Epoch 376/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.2433 - tp: 163.0000 - fp: 154.0000 - tn: 290.0000 - fn: 105.0000 - accuracy: 0.6362 - precision: 0.5142 - recall: 0.6082 - auc: 0.6759 - val_loss: 1.2265 - val_tp: 48.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 26.0000 - val_accuracy: 0.7207 - val_precision: 0.6667 - val_recall: 0.6486 - val_auc: 0.8304\n",
      "Epoch 377/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2432 - tp: 165.0000 - fp: 166.0000 - tn: 278.0000 - fn: 103.0000 - accuracy: 0.6222 - precision: 0.4985 - recall: 0.6157 - auc: 0.6774 - val_loss: 1.2256 - val_tp: 48.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 26.0000 - val_accuracy: 0.7207 - val_precision: 0.6667 - val_recall: 0.6486 - val_auc: 0.8299\n",
      "Epoch 378/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.2488 - tp: 153.0000 - fp: 152.0000 - tn: 292.0000 - fn: 115.0000 - accuracy: 0.6250 - precision: 0.5016 - recall: 0.5709 - auc: 0.6555 - val_loss: 1.2248 - val_tp: 48.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 26.0000 - val_accuracy: 0.7207 - val_precision: 0.6667 - val_recall: 0.6486 - val_auc: 0.8305\n",
      "Epoch 379/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2498 - tp: 152.0000 - fp: 151.0000 - tn: 293.0000 - fn: 116.0000 - accuracy: 0.6250 - precision: 0.5017 - recall: 0.5672 - auc: 0.6531 - val_loss: 1.2239 - val_tp: 48.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 26.0000 - val_accuracy: 0.7207 - val_precision: 0.6667 - val_recall: 0.6486 - val_auc: 0.8288\n",
      "Epoch 380/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.2396 - tp: 157.0000 - fp: 134.0000 - tn: 310.0000 - fn: 111.0000 - accuracy: 0.6559 - precision: 0.5395 - recall: 0.5858 - auc: 0.6844 - val_loss: 1.2230 - val_tp: 48.0000 - val_fp: 24.0000 - val_tn: 81.0000 - val_fn: 26.0000 - val_accuracy: 0.7207 - val_precision: 0.6667 - val_recall: 0.6486 - val_auc: 0.8292\n",
      "Epoch 381/600\n",
      "712/712 [==============================] - 0s 132us/sample - loss: 1.2400 - tp: 161.0000 - fp: 143.0000 - tn: 301.0000 - fn: 107.0000 - accuracy: 0.6489 - precision: 0.5296 - recall: 0.6007 - auc: 0.6850 - val_loss: 1.2221 - val_tp: 48.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 26.0000 - val_accuracy: 0.7151 - val_precision: 0.6575 - val_recall: 0.6486 - val_auc: 0.8282\n",
      "Epoch 382/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.2411 - tp: 169.0000 - fp: 150.0000 - tn: 294.0000 - fn: 99.0000 - accuracy: 0.6503 - precision: 0.5298 - recall: 0.6306 - auc: 0.6806 - val_loss: 1.2212 - val_tp: 48.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 26.0000 - val_accuracy: 0.7151 - val_precision: 0.6575 - val_recall: 0.6486 - val_auc: 0.8284\n",
      "Epoch 383/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.2475 - tp: 159.0000 - fp: 151.0000 - tn: 293.0000 - fn: 109.0000 - accuracy: 0.6348 - precision: 0.5129 - recall: 0.5933 - auc: 0.6589 - val_loss: 1.2203 - val_tp: 49.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 25.0000 - val_accuracy: 0.7207 - val_precision: 0.6622 - val_recall: 0.6622 - val_auc: 0.8286\n",
      "Epoch 384/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.2328 - tp: 169.0000 - fp: 142.0000 - tn: 302.0000 - fn: 99.0000 - accuracy: 0.6615 - precision: 0.5434 - recall: 0.6306 - auc: 0.7012 - val_loss: 1.2194 - val_tp: 49.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 25.0000 - val_accuracy: 0.7207 - val_precision: 0.6622 - val_recall: 0.6622 - val_auc: 0.8293\n",
      "Epoch 385/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.2453 - tp: 154.0000 - fp: 156.0000 - tn: 288.0000 - fn: 114.0000 - accuracy: 0.6208 - precision: 0.4968 - recall: 0.5746 - auc: 0.6558 - val_loss: 1.2186 - val_tp: 49.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 25.0000 - val_accuracy: 0.7207 - val_precision: 0.6622 - val_recall: 0.6622 - val_auc: 0.8285\n",
      "Epoch 386/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.2470 - tp: 152.0000 - fp: 155.0000 - tn: 289.0000 - fn: 116.0000 - accuracy: 0.6194 - precision: 0.4951 - recall: 0.5672 - auc: 0.6515 - val_loss: 1.2177 - val_tp: 49.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 25.0000 - val_accuracy: 0.7207 - val_precision: 0.6622 - val_recall: 0.6622 - val_auc: 0.8289\n",
      "Epoch 387/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.2398 - tp: 159.0000 - fp: 146.0000 - tn: 298.0000 - fn: 109.0000 - accuracy: 0.6419 - precision: 0.5213 - recall: 0.5933 - auc: 0.6648 - val_loss: 1.2169 - val_tp: 49.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 25.0000 - val_accuracy: 0.7207 - val_precision: 0.6622 - val_recall: 0.6622 - val_auc: 0.8301\n",
      "Epoch 388/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.2381 - tp: 169.0000 - fp: 152.0000 - tn: 292.0000 - fn: 99.0000 - accuracy: 0.6475 - precision: 0.5265 - recall: 0.6306 - auc: 0.6770 - val_loss: 1.2160 - val_tp: 49.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 25.0000 - val_accuracy: 0.7207 - val_precision: 0.6622 - val_recall: 0.6622 - val_auc: 0.8318\n",
      "Epoch 389/600\n",
      "712/712 [==============================] - 0s 137us/sample - loss: 1.2298 - tp: 166.0000 - fp: 149.0000 - tn: 295.0000 - fn: 102.0000 - accuracy: 0.6475 - precision: 0.5270 - recall: 0.6194 - auc: 0.6976 - val_loss: 1.2150 - val_tp: 49.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 25.0000 - val_accuracy: 0.7207 - val_precision: 0.6622 - val_recall: 0.6622 - val_auc: 0.8311\n",
      "Epoch 390/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.2433 - tp: 157.0000 - fp: 168.0000 - tn: 276.0000 - fn: 111.0000 - accuracy: 0.6081 - precision: 0.4831 - recall: 0.5858 - auc: 0.6441 - val_loss: 1.2142 - val_tp: 49.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 25.0000 - val_accuracy: 0.7207 - val_precision: 0.6622 - val_recall: 0.6622 - val_auc: 0.8301\n",
      "Epoch 391/600\n",
      "712/712 [==============================] - 0s 138us/sample - loss: 1.2322 - tp: 154.0000 - fp: 147.0000 - tn: 297.0000 - fn: 114.0000 - accuracy: 0.6334 - precision: 0.5116 - recall: 0.5746 - auc: 0.6872 - val_loss: 1.2133 - val_tp: 49.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 25.0000 - val_accuracy: 0.7207 - val_precision: 0.6622 - val_recall: 0.6622 - val_auc: 0.8309\n",
      "Epoch 392/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.2313 - tp: 170.0000 - fp: 151.0000 - tn: 293.0000 - fn: 98.0000 - accuracy: 0.6503 - precision: 0.5296 - recall: 0.6343 - auc: 0.6896 - val_loss: 1.2124 - val_tp: 49.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 25.0000 - val_accuracy: 0.7207 - val_precision: 0.6622 - val_recall: 0.6622 - val_auc: 0.8301\n",
      "Epoch 393/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.2341 - tp: 170.0000 - fp: 139.0000 - tn: 305.0000 - fn: 98.0000 - accuracy: 0.6671 - precision: 0.5502 - recall: 0.6343 - auc: 0.6831 - val_loss: 1.2115 - val_tp: 49.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 25.0000 - val_accuracy: 0.7207 - val_precision: 0.6622 - val_recall: 0.6622 - val_auc: 0.8299\n",
      "Epoch 394/600\n",
      "712/712 [==============================] - 0s 130us/sample - loss: 1.2388 - tp: 152.0000 - fp: 124.0000 - tn: 320.0000 - fn: 116.0000 - accuracy: 0.6629 - precision: 0.5507 - recall: 0.5672 - auc: 0.6767 - val_loss: 1.2105 - val_tp: 50.0000 - val_fp: 25.0000 - val_tn: 80.0000 - val_fn: 24.0000 - val_accuracy: 0.7263 - val_precision: 0.6667 - val_recall: 0.6757 - val_auc: 0.8294\n",
      "Epoch 395/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2307 - tp: 158.0000 - fp: 141.0000 - tn: 303.0000 - fn: 110.0000 - accuracy: 0.6475 - precision: 0.5284 - recall: 0.5896 - auc: 0.6815 - val_loss: 1.2095 - val_tp: 50.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 24.0000 - val_accuracy: 0.7207 - val_precision: 0.6579 - val_recall: 0.6757 - val_auc: 0.8290\n",
      "Epoch 396/600\n",
      "712/712 [==============================] - 0s 136us/sample - loss: 1.2304 - tp: 172.0000 - fp: 158.0000 - tn: 286.0000 - fn: 96.0000 - accuracy: 0.6433 - precision: 0.5212 - recall: 0.6418 - auc: 0.6884 - val_loss: 1.2087 - val_tp: 50.0000 - val_fp: 26.0000 - val_tn: 79.0000 - val_fn: 24.0000 - val_accuracy: 0.7207 - val_precision: 0.6579 - val_recall: 0.6757 - val_auc: 0.8297\n",
      "Epoch 397/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.2362 - tp: 160.0000 - fp: 152.0000 - tn: 292.0000 - fn: 108.0000 - accuracy: 0.6348 - precision: 0.5128 - recall: 0.5970 - auc: 0.6691 - val_loss: 1.2078 - val_tp: 50.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 24.0000 - val_accuracy: 0.7151 - val_precision: 0.6494 - val_recall: 0.6757 - val_auc: 0.8286\n",
      "Epoch 398/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2326 - tp: 163.0000 - fp: 155.0000 - tn: 289.0000 - fn: 105.0000 - accuracy: 0.6348 - precision: 0.5126 - recall: 0.6082 - auc: 0.6726 - val_loss: 1.2070 - val_tp: 50.0000 - val_fp: 27.0000 - val_tn: 78.0000 - val_fn: 24.0000 - val_accuracy: 0.7151 - val_precision: 0.6494 - val_recall: 0.6757 - val_auc: 0.8305\n",
      "Epoch 399/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 1.2285 - tp: 168.0000 - fp: 134.0000 - tn: 310.0000 - fn: 100.0000 - accuracy: 0.6713 - precision: 0.5563 - recall: 0.6269 - auc: 0.6891 - val_loss: 1.2061 - val_tp: 55.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 19.0000 - val_accuracy: 0.7374 - val_precision: 0.6627 - val_recall: 0.7432 - val_auc: 0.8299\n",
      "Epoch 400/600\n",
      "712/712 [==============================] - 0s 134us/sample - loss: 1.2275 - tp: 159.0000 - fp: 141.0000 - tn: 303.0000 - fn: 109.0000 - accuracy: 0.6489 - precision: 0.5300 - recall: 0.5933 - auc: 0.6867 - val_loss: 1.2053 - val_tp: 55.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 19.0000 - val_accuracy: 0.7374 - val_precision: 0.6627 - val_recall: 0.7432 - val_auc: 0.8297\n",
      "Epoch 401/600\n",
      "712/712 [==============================] - 0s 139us/sample - loss: 1.2252 - tp: 172.0000 - fp: 145.0000 - tn: 299.0000 - fn: 96.0000 - accuracy: 0.6615 - precision: 0.5426 - recall: 0.6418 - auc: 0.6951 - val_loss: 1.2043 - val_tp: 55.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 19.0000 - val_accuracy: 0.7374 - val_precision: 0.6627 - val_recall: 0.7432 - val_auc: 0.8302\n",
      "Epoch 402/600\n",
      "712/712 [==============================] - 0s 133us/sample - loss: 1.2314 - tp: 161.0000 - fp: 147.0000 - tn: 297.0000 - fn: 107.0000 - accuracy: 0.6433 - precision: 0.5227 - recall: 0.6007 - auc: 0.6708 - val_loss: 1.2035 - val_tp: 55.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 19.0000 - val_accuracy: 0.7374 - val_precision: 0.6627 - val_recall: 0.7432 - val_auc: 0.8308\n",
      "Epoch 403/600\n",
      "712/712 [==============================] - 0s 131us/sample - loss: 1.2200 - tp: 175.0000 - fp: 153.0000 - tn: 291.0000 - fn: 93.0000 - accuracy: 0.6545 - precision: 0.5335 - recall: 0.6530 - auc: 0.7147 - val_loss: 1.2026 - val_tp: 55.0000 - val_fp: 28.0000 - val_tn: 77.0000 - val_fn: 19.0000 - val_accuracy: 0.7374 - val_precision: 0.6627 - val_recall: 0.7432 - val_auc: 0.8324\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, Y_train, validation_data=(X_dev, Y_dev))\n",
    "\n",
    "# tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Results of the tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tuned model 0\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.3739 - tp: 214.0000 - fp: 44.0000 - tn: 400.0000 - fn: 54.0000 - accuracy: 0.8624 - precision: 0.8295 - recall: 0.7985 - auc: 0.9060\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 99us/sample - loss: 0.4321 - tp: 62.0000 - fp: 14.0000 - tn: 91.0000 - fn: 12.0000 - accuracy: 0.8547 - precision: 0.8158 - recall: 0.8378 - auc: 0.9131\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,689\n",
      "Trainable params: 2,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 2, 'dense_units_0': 32, 'dense_activation_0': 'relu', 'l1_0': 1e-05, 'l2_0': 0.001, 'dropout_0': 0.35000000000000003, 'dense_units_1': 64, 'dense_activation_1': 'tanh', 'l1_1': 1e-05, 'l2_1': 1e-05, 'dropout_1': 0.25, 'dense_units_2': 40, 'dense_activation_2': 'relu', 'l1_2': 0.0001, 'l2_2': 0.0001, 'dropout_2': 0.05, 'learning_rate': 0.001, 'optimizer': 'RMSprop', 'epoch_number': 600, 'dense_units_3': 8, 'dense_activation_3': 'relu', 'l1_3': 0.0, 'l2_3': 0.01, 'dropout_3': 0.15000000000000002, 'dense_units_4': 8, 'dense_activation_4': 'sigmoid', 'l1_4': 1e-05, 'l2_4': 0.01, 'dropout_4': 0.35000000000000003, 'dense_units_5': 48, 'dense_activation_5': 'relu', 'l1_5': 0.01, 'l2_5': 1e-05, 'dropout_5': 0.0, 'dense_units_6': 16, 'dense_activation_6': 'sigmoid', 'l1_6': 0.0001, 'l2_6': 1e-05, 'dropout_6': 0.25}\n",
      "\n",
      "\n",
      "Tuned model 1\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.4062 - tp: 214.0000 - fp: 43.0000 - tn: 401.0000 - fn: 54.0000 - accuracy: 0.8638 - precision: 0.8327 - recall: 0.7985 - auc: 0.8860\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 107us/sample - loss: 0.4473 - tp: 62.0000 - fp: 14.0000 - tn: 91.0000 - fn: 12.0000 - accuracy: 0.8547 - precision: 0.8158 - recall: 0.8378 - auc: 0.9078\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 48)                1584      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 56)                2744      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 24)                1368      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 8,345\n",
      "Trainable params: 8,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 6, 'dense_units_0': 32, 'dense_activation_0': 'relu', 'l1_0': 1e-05, 'l2_0': 0.01, 'dropout_0': 0.05, 'dense_units_1': 32, 'dense_activation_1': 'relu', 'l1_1': 1e-05, 'l2_1': 1e-05, 'dropout_1': 0.2, 'dense_units_2': 32, 'dense_activation_2': 'sigmoid', 'l1_2': 0.0001, 'l2_2': 1e-05, 'dropout_2': 0.30000000000000004, 'learning_rate': 0.001, 'optimizer': 'adam', 'epoch_number': 600, 'dense_units_3': 48, 'dense_activation_3': 'relu', 'l1_3': 0.0001, 'l2_3': 0.001, 'dropout_3': 0.05, 'dense_units_4': 56, 'dense_activation_4': 'tanh', 'l1_4': 0.0001, 'l2_4': 0.001, 'dropout_4': 0.35000000000000003, 'dense_units_5': 24, 'dense_activation_5': 'sigmoid', 'l1_5': 1e-05, 'l2_5': 0.0, 'dropout_5': 0.30000000000000004, 'dense_units_6': 40, 'dense_activation_6': 'tanh', 'l1_6': 0.001, 'l2_6': 0.0001, 'dropout_6': 0.4}\n",
      "\n",
      "\n",
      "Tuned model 2\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.4302 - tp: 198.0000 - fp: 33.0000 - tn: 411.0000 - fn: 70.0000 - accuracy: 0.8553 - precision: 0.8571 - recall: 0.7388 - auc: 0.8893\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 112us/sample - loss: 0.4770 - tp: 56.0000 - fp: 11.0000 - tn: 94.0000 - fn: 18.0000 - accuracy: 0.8380 - precision: 0.8358 - recall: 0.7568 - auc: 0.9018\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                640       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                656       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 56)                1400      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 57        \n",
      "=================================================================\n",
      "Total params: 3,969\n",
      "Trainable params: 3,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 6, 'dense_units_0': 40, 'dense_activation_0': 'relu', 'l1_0': 0.001, 'l2_0': 0.0, 'dropout_0': 0.45, 'dense_units_1': 16, 'dense_activation_1': 'tanh', 'l1_1': 0.0001, 'l2_1': 0.0001, 'dropout_1': 0.1, 'dense_units_2': 24, 'dense_activation_2': 'relu', 'l1_2': 0.0001, 'l2_2': 0.0, 'dropout_2': 0.4, 'learning_rate': 0.001, 'optimizer': 'adam', 'epoch_number': 700, 'dense_units_3': 16, 'dense_activation_3': 'tanh', 'l1_3': 0.001, 'l2_3': 0.001, 'dropout_3': 0.15000000000000002, 'dense_units_4': 24, 'dense_activation_4': 'tanh', 'l1_4': 0.01, 'l2_4': 0.0, 'dropout_4': 0.05, 'dense_units_5': 56, 'dense_activation_5': 'relu', 'l1_5': 0.0, 'l2_5': 0.01, 'dropout_5': 0.4, 'dense_units_6': 56, 'dense_activation_6': 'tanh', 'l1_6': 1e-05, 'l2_6': 0.01, 'dropout_6': 0.4}\n",
      "\n",
      "\n",
      "Tuned model 3\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.4659 - tp: 188.0000 - fp: 27.0000 - tn: 417.0000 - fn: 80.0000 - accuracy: 0.8497 - precision: 0.8744 - recall: 0.7015 - auc: 0.8773\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 102us/sample - loss: 0.5225 - tp: 55.0000 - fp: 11.0000 - tn: 94.0000 - fn: 19.0000 - accuracy: 0.8324 - precision: 0.8333 - recall: 0.7432 - auc: 0.8978\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 56)                896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                912       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 48)                816       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 24)                792       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 8,201\n",
      "Trainable params: 8,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 6, 'dense_units_0': 56, 'dense_activation_0': 'relu', 'l1_0': 0.01, 'l2_0': 0.0, 'dropout_0': 0.15000000000000002, 'dense_units_1': 56, 'dense_activation_1': 'tanh', 'l1_1': 0.0, 'l2_1': 1e-05, 'dropout_1': 0.35000000000000003, 'dense_units_2': 16, 'dense_activation_2': 'tanh', 'l1_2': 0.01, 'l2_2': 1e-05, 'dropout_2': 0.0, 'learning_rate': 0.001, 'optimizer': 'adam', 'epoch_number': 500, 'dense_units_3': 48, 'dense_activation_3': 'tanh', 'l1_3': 0.0, 'l2_3': 0.001, 'dropout_3': 0.15000000000000002, 'dense_units_4': 32, 'dense_activation_4': 'tanh', 'l1_4': 0.0001, 'l2_4': 0.0, 'dropout_4': 0.15000000000000002, 'dense_units_5': 24, 'dense_activation_5': 'sigmoid', 'l1_5': 0.001, 'l2_5': 1e-05, 'dropout_5': 0.2, 'dense_units_6': 16, 'dense_activation_6': 'tanh', 'l1_6': 0.001, 'l2_6': 0.001, 'dropout_6': 0.45}\n",
      "\n",
      "\n",
      "Tuned model 4\n",
      "\n",
      "\n",
      "Tuned train:\n",
      "712/712 [==============================] - 1s 1ms/sample - loss: 0.4054 - tp: 201.0000 - fp: 36.0000 - tn: 408.0000 - fn: 67.0000 - accuracy: 0.8553 - precision: 0.8481 - recall: 0.7500 - auc: 0.8837\n",
      "Tuned dev:\n",
      "179/179 [==============================] - 0s 107us/sample - loss: 0.4526 - tp: 58.0000 - fp: 14.0000 - tn: 91.0000 - fn: 16.0000 - accuracy: 0.8324 - precision: 0.8056 - recall: 0.7838 - auc: 0.9064\n",
      "Model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 56)                896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                1368      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                1000      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2624      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 9,057\n",
      "Trainable params: 9,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Hyperparameters\n",
      "{'batch_size': 32, 'num_layers': 5, 'dense_units_0': 56, 'dense_activation_0': 'relu', 'l1_0': 1e-05, 'l2_0': 0.01, 'dropout_0': 0.30000000000000004, 'dense_units_1': 24, 'dense_activation_1': 'tanh', 'l1_1': 0.0, 'l2_1': 1e-05, 'dropout_1': 0.30000000000000004, 'dense_units_2': 40, 'dense_activation_2': 'sigmoid', 'l1_2': 0.0, 'l2_2': 1e-05, 'dropout_2': 0.2, 'learning_rate': 0.0003, 'optimizer': 'RMSprop', 'epoch_number': 400, 'dense_units_3': 64, 'dense_activation_3': 'relu', 'l1_3': 1e-05, 'l2_3': 0.01, 'dropout_3': 0.2, 'dense_units_4': 48, 'dense_activation_4': 'sigmoid', 'l1_4': 1e-05, 'l2_4': 0.001, 'dropout_4': 0.05, 'dense_units_5': 32, 'dense_activation_5': 'relu', 'l1_5': 0.01, 'l2_5': 1e-05, 'dropout_5': 0.4, 'dense_units_6': 24, 'dense_activation_6': 'relu', 'l1_6': 0.001, 'l2_6': 0.0001, 'dropout_6': 0.35000000000000003}\n"
     ]
    }
   ],
   "source": [
    "NUM_TOP_MODELS = min(5, MAX_TRIALS)\n",
    "\n",
    "top_models = tuner.get_best_models(num_models=NUM_TOP_MODELS)\n",
    "top_hyperparameters = tuner.get_best_hyperparameters(num_trials=NUM_TOP_MODELS)\n",
    "\n",
    "for exp_id in range(NUM_TOP_MODELS):\n",
    "    print(f\"\\n\\nTuned model {exp_id}\\n\\n\")\n",
    "    cur_model = top_models[exp_id]\n",
    "    \n",
    "    print(\"Tuned train:\")\n",
    "    evaluation_tuned_train = cur_model.evaluate(X_train, Y_train)\n",
    "    # draw_confusion_matrix(evaluation_tuned_train, f\"tuned train {exp_id}\")\n",
    "\n",
    "    print(\"Tuned dev:\")\n",
    "    evaluation_tuned_dev = cur_model.evaluate(X_dev, Y_dev)\n",
    "    # draw_confusion_matrix(evaluation_tuned_dev, f\"tuned dev {exp_id}\")\n",
    "\n",
    "    print(\"Model summary\")\n",
    "    cur_model.summary()\n",
    "    \n",
    "    print(\"Hyperparameters\")\n",
    "    print(top_hyperparameters[exp_id].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Predict with the Tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl_tuned_0_submission:\n",
      "[0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 1\n",
      " 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 1 1 0 1 1 1 0 1 0 0 1]\n",
      "dl_tuned_1_submission:\n",
      "[0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0\n",
      " 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0\n",
      " 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 1 1 0 1 0 0 1]\n",
      "dl_tuned_2_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1]\n",
      "dl_tuned_3_submission:\n",
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0\n",
      " 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 0 0 1 0 0 1]\n",
      "dl_tuned_4_submission:\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 1\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "for exp_id in range(NUM_TOP_MODELS):\n",
    "    store_predictions(top_models[exp_id], f\"dl_tuned_{exp_id}_submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
