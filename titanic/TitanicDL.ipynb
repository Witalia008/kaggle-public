{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Deep Learning approach to the Titanic problem"
            ]
        },
        {
            "metadata": {
                "trusted": true,
                "tags": []
            },
            "cell_type": "code",
            "source": [
                "%env PYTHONHASHSEED=0\n",
                "\n",
                "import os\n",
                "DEVMODE = os.getenv(\"KAGGLE_MODE\") == \"DEV\"\n",
                "print(f\"DEV MODE: {DEVMODE}\")\n",
                "\n",
                "# Define seed to reprodicibility of random generation\n",
                "SEED = 42\n",
                "DEV_SPLIT = 0.2"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import importlib\n",
                "if importlib.util.find_spec(\"comet_ml\"):\n",
                "    from comet_ml import Experiment\n",
                "    experiment = Experiment(project_name=\"titanic\")\n",
                "else:\n",
                "    experiment = None"
            ]
        },
        {
            "metadata": {
                "trusted": true,
                "tags": []
            },
            "cell_type": "code",
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "# To display all the columns from left to right without breaking into next line.\n",
                "pd.set_option(\"display.width\", 1500)\n",
                "pd.plotting.register_matplotlib_converters()\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "%matplotlib inline\n",
                "\n",
                "import seaborn as sns\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "\n",
                "print(tf.__version__)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": [
                "import random as python_random\n",
                "\n",
                "# Make sure Keras produces reproducible results.\n",
                "\n",
                "np.random.seed(SEED)\n",
                "python_random.seed(SEED)\n",
                "tf.random.set_seed(SEED)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "tags": []
            },
            "cell_type": "code",
            "source": [
                "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
                "print(physical_devices)\n",
                "for device in (physical_devices or []):\n",
                "    tf.config.experimental.set_memory_growth(device, True)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "## Load data and split into train/dev sets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from titanic.titanic_data import load_titanic_data, split_data, get_data_preprocessor\n",
                "\n",
                "X_train_full, y_train_full, X_pred = load_titanic_data()\n",
                "X_train, X_valid, y_train, y_valid = split_data(X_train_full, y_train_full, test_size=DEV_SPLIT, random_state=SEED)"
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "## Define pre-processing of the data"
            ]
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": [
                "preprocessor, preprocessed_column_names = get_data_preprocessor()"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train = pd.DataFrame(preprocessor.fit_transform(X_train), index=X_train.index, columns=preprocessed_column_names)\n",
                "X_valid = pd.DataFrame(preprocessor.transform(X_valid), index=X_valid.index, columns=preprocessed_column_names)\n",
                "X_pred = pd.DataFrame(preprocessor.transform(X_pred), index=X_pred.index, columns=preprocessed_column_names)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train.head()"
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "## DL model using Keras"
            ]
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": [
                "METRICS = [\n",
                "      keras.metrics.TruePositives(name=\"tp\"),\n",
                "      keras.metrics.FalsePositives(name=\"fp\"),\n",
                "      keras.metrics.TrueNegatives(name=\"tn\"),\n",
                "      keras.metrics.FalseNegatives(name=\"fn\"),\n",
                "      keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
                "      keras.metrics.Precision(name=\"precision\"),\n",
                "      keras.metrics.Recall(name=\"recall\"),\n",
                "      keras.metrics.AUC(name=\"auc\"),\n",
                "]\n",
                "\n",
                "def get_model(input_size):\n",
                "    from tensorflow.keras.models import Sequential\n",
                "    from tensorflow.keras.layers import Dense, Dropout, Input\n",
                "    from tensorflow.keras.regularizers import l2\n",
                "\n",
                "    model = Sequential([\n",
                "        Input(shape=(input_size,)),\n",
                "        Dense(40, activation=\"relu\", kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001), kernel_initializer=\"he_uniform\"),\n",
                "        Dropout(0.2),\n",
                "        Dense(56, activation=\"tanh\", kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1), kernel_initializer=\"glorot_uniform\"),\n",
                "        Dropout(0.3),\n",
                "        Dense(56, activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), kernel_initializer=\"he_uniform\"),\n",
                "        Dropout(0.3),\n",
                "        Dense(16, activation=\"relu\", kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001), kernel_initializer=\"he_uniform\"),\n",
                "        Dropout(0.45),\n",
                "        Dense(16, activation=\"tanh\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), kernel_initializer=\"glorot_uniform\"),\n",
                "        Dropout(0.35),\n",
                "        Dense(8, activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), kernel_initializer=\"he_uniform\"),\n",
                "        Dropout(0.4),\n",
                "        Dense(1, activation=\"sigmoid\")\n",
                "    ])\n",
                "    \n",
                "    model.compile(optimizer=keras.optimizers.Adam(1e-3), metrics=METRICS, loss=\"binary_crossentropy\")\n",
                "    \n",
                "    return model"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from titanic.titanic_data import get_class_weights\n",
                "\n",
                "# Create a new model each time before running training (otherwise new trainings would just be on already trained model)\n",
                "model = get_model(X_train.shape[1])\n",
                "\n",
                "history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_valid, y_valid), class_weight=get_class_weights(y_train), verbose=1)"
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "## Results of the DL model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from utils.visualising import plot_model_history\n",
                "\n",
                "plot_model_history(history)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from utils.visualising import draw_confusion_matrix\n",
                "\n",
                "print(\"Train evaluation:\")\n",
                "evaluation_train = model.evaluate(X_train, y_train, verbose=2)\n",
                "draw_confusion_matrix(evaluation_train, \"train\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "print(\"Valid evaluation:\")\n",
                "evaluation_valid = model.evaluate(X_valid, y_valid, verbose=2)\n",
                "draw_confusion_matrix(evaluation_valid, \"valid\")"
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "## Predict with DL model"
            ]
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": [
                "from utils.predicting import store_predictions"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "tags": []
            },
            "cell_type": "code",
            "source": [
                "store_predictions(model, X_pred=X_pred, index=X_pred.index, submission_name=\"dl\")"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "if experiment:\n",
                "    experiment.end()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "language": "python",
            "display_name": "Python 3.7.6 64-bit",
            "name": "python37664bit26036f9dd6fd4360b35d7bd99f8e1f11"
        },
        "language_info": {
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "version": "3.7.6-final",
            "file_extension": ".py",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "name": "python",
            "mimetype": "text/x-python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}